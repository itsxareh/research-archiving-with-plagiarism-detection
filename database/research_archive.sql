-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Nov 08, 2024 at 04:03 AM
-- Server version: 10.4.32-MariaDB
-- PHP Version: 8.2.12

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `online_thesis`
--

-- --------------------------------------------------------

--
-- Table structure for table `admin_account`
--

CREATE TABLE `admin_account` (
  `id` int(11) NOT NULL,
  `uniqueID` varchar(200) NOT NULL,
  `first_name` varchar(100) NOT NULL,
  `middle_name` varchar(100) NOT NULL,
  `last_name` varchar(100) NOT NULL,
  `complete_address` varchar(300) NOT NULL,
  `phone_number` varchar(13) NOT NULL,
  `admin_email` varchar(200) NOT NULL,
  `admin_password` varchar(200) NOT NULL,
  `admin_profile_picture` varchar(500) NOT NULL,
  `verification_code` int(8) NOT NULL,
  `verify_status` varchar(80) NOT NULL DEFAULT 'Not Verified',
  `online_offlineStatus` varchar(50) NOT NULL DEFAULT 'Offline'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `admin_account`
--

INSERT INTO `admin_account` (`id`, `uniqueID`, `first_name`, `middle_name`, `last_name`, `complete_address`, `phone_number`, `admin_email`, `admin_password`, `admin_profile_picture`, `verification_code`, `verify_status`, `online_offlineStatus`) VALUES
(1, '66ee85d4b73f85078', 'Rolly', '', 'Raytos', '1321321231212', '321312312312', 'raytos.r.bsinfotech@gmail.com', '21232f297a57a5a743894a0e4a801fc3', '../imageFiles/67285fc302cd2-aiahhhhh.jpg', 814557, 'Verified', 'Online');

-- --------------------------------------------------------

--
-- Table structure for table `admin_systemnotification`
--

CREATE TABLE `admin_systemnotification` (
  `id` int(11) NOT NULL,
  `admin_id` int(12) NOT NULL,
  `logs` varchar(200) NOT NULL,
  `logs_date` varchar(50) NOT NULL,
  `logs_time` varchar(50) NOT NULL,
  `status` varchar(100) NOT NULL DEFAULT 'Unread'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `admin_systemnotification`
--

INSERT INTO `admin_systemnotification` (`id`, `admin_id`, `logs`, `logs_date`, `logs_time`, `status`) VALUES
(1, 1, 'You successfully logged in to your account.', 'January / 03 Wednesday / 2024', '8:25 PM', 'Read'),
(2, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:46 PM', 'Read'),
(3, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:46 PM', 'Read'),
(4, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:47 PM', 'Read'),
(5, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:47 PM', 'Read'),
(6, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:48 PM', 'Read'),
(7, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:48 PM', 'Read'),
(8, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:50 PM', 'Read'),
(9, 1, 'You successfully inserted a Department.', 'January / 03 Wednesday / 2024', '8:51 PM', 'Read'),
(10, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:51 PM', 'Read'),
(11, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:51 PM', 'Read'),
(12, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:52 PM', 'Read'),
(13, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:52 PM', 'Read'),
(14, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:53 PM', 'Read'),
(15, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:53 PM', 'Read'),
(16, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:53 PM', 'Read'),
(17, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '8:54 PM', 'Read'),
(18, 1, 'You successfully updated your information.', 'January / 03 Wednesday / 2024', '8:56 PM', 'Read'),
(19, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '9:23 PM', 'Read'),
(20, 1, 'You successfully inserted a Course.', 'January / 03 Wednesday / 2024', '9:24 PM', 'Read'),
(21, 1, 'You successfully submitted a Research Project.', 'January / 03 Wednesday / 2024', '9:35 PM', 'Read'),
(22, 1, 'You successfully submitted a Research Project.', 'January / 03 Wednesday / 2024', '9:40 PM', 'Read'),
(23, 1, 'You successfully submitted a Research Project.', 'January / 03 Wednesday / 2024', '9:43 PM', 'Read'),
(24, 1, 'You successfully submitted a Research Project.', 'January / 03 Wednesday / 2024', '9:49 PM', 'Read'),
(25, 1, 'You successfully submitted a Research Project.', 'January / 03 Wednesday / 2024', '9:57 PM', 'Read'),
(26, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:23 AM', 'Read'),
(27, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:33 AM', 'Read'),
(28, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:40 AM', 'Read'),
(29, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:42 AM', 'Read'),
(30, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:44 AM', 'Read'),
(31, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '8:00 AM', 'Read'),
(32, 1, 'You successfully logged out to your account.', 'January / 04 Thursday / 2024', '8:08 AM', 'Read'),
(33, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '8:12 AM', 'Read'),
(34, 1, 'You successfully logged out to your account.', 'January / 04 Thursday / 2024', '8:13 AM', 'Read'),
(35, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '12:06 PM', 'Read'),
(36, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '12:27 PM', 'Read'),
(37, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '12:29 PM', 'Read'),
(38, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '12:30 PM', 'Read'),
(39, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '12:32 PM', 'Read'),
(40, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '12:41 PM', 'Read'),
(41, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '12:43 PM', 'Read'),
(42, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '12:46 PM', 'Read'),
(43, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '1:33 PM', 'Read'),
(44, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '1:41 PM', 'Read'),
(45, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '1:45 PM', 'Read'),
(46, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '1:47 PM', 'Read'),
(47, 1, 'You successfully submitted a Research Project.', 'January / 04 Thursday / 2024', '1:52 PM', 'Read'),
(48, 1, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '2:42 PM', 'Read'),
(49, 1, 'You successfully Updated a Department.', 'January / 04 Thursday / 2024', '2:48 PM', 'Read'),
(50, 1, 'You successfully Updated a Department.', 'January / 04 Thursday / 2024', '3:07 PM', 'Read'),
(51, 1, 'You successfully inserted a Department.', 'January / 04 Thursday / 2024', '3:09 PM', 'Read'),
(52, 1, 'You successfully logged out to your account.', 'January / 04 Thursday / 2024', '3:27 PM', 'Read'),
(53, 1, 'You successfully inserted a Course.', 'January / 06 Saturday / 2024', '12:51 PM', 'Read'),
(54, 1, 'You successfully submitted a Research Project.', 'January / 06 Saturday / 2024', '12:59 PM', 'Read'),
(55, 1, 'You successfully submitted a Research Project.', 'January / 06 Saturday / 2024', '2:39 PM', 'Read'),
(56, 1, 'You successfully inserted a Course.', 'January / 06 Saturday / 2024', '2:44 PM', 'Read'),
(57, 1, 'You successfully submitted a Research Project.', 'January / 06 Saturday / 2024', '3:37 PM', 'Read'),
(58, 1, 'You successfully logged in to your account.', 'January / 06 Saturday / 2024', '9:59 PM', 'Read'),
(59, 1, 'You successfully submitted a Research Project.', 'January / 06 Saturday / 2024', '10:04 PM', 'Read'),
(60, 1, 'You successfully inserted a Course.', 'January / 06 Saturday / 2024', '10:54 PM', 'Read'),
(61, 1, 'You successfully submitted a Research Project.', 'January / 06 Saturday / 2024', '10:56 PM', 'Read'),
(62, 1, 'You successfully inserted a Course.', 'January / 06 Saturday / 2024', '11:30 PM', 'Read'),
(63, 1, 'You successfully submitted a Research Project.', 'January / 06 Saturday / 2024', '11:33 PM', 'Read'),
(64, 1, 'You successfully submitted a Research Project.', 'January / 06 Saturday / 2024', '11:46 PM', 'Read'),
(65, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '12:03 AM', 'Read'),
(66, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '12:11 AM', 'Read'),
(67, 1, 'You successfully inserted a Course.', 'January / 07 Sunday / 2024', '12:21 AM', 'Read'),
(68, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '12:30 AM', 'Read'),
(69, 1, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '2:46 PM', 'Read'),
(70, 1, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:39 PM', 'Read'),
(71, 1, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:39 PM', 'Read'),
(72, 1, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:54 PM', 'Read'),
(73, 1, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '10:22 PM', 'Read'),
(74, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '10:26 PM', 'Read'),
(75, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '10:30 PM', 'Read'),
(76, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '10:32 PM', 'Read'),
(77, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '10:37 PM', 'Read'),
(78, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '10:41 PM', 'Read'),
(79, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '10:44 PM', 'Read'),
(80, 1, 'You successfully Updated a Department.', 'January / 07 Sunday / 2024', '10:45 PM', 'Read'),
(81, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '10:47 PM', 'Read'),
(82, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '11:11 PM', 'Read'),
(83, 1, 'You successfully inserted a Course.', 'January / 07 Sunday / 2024', '11:20 PM', 'Read'),
(84, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '11:21 PM', 'Read'),
(85, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '11:27 PM', 'Read'),
(86, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '11:32 PM', 'Read'),
(87, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '11:45 PM', 'Read'),
(88, 1, 'You successfully submitted a Research Project.', 'January / 07 Sunday / 2024', '11:59 PM', 'Read'),
(89, 1, 'You successfully inserted a Course.', 'January / 08 Monday / 2024', '12:06 AM', 'Read'),
(90, 1, 'You successfully submitted a Research Project.', 'January / 08 Monday / 2024', '12:11 AM', 'Read'),
(91, 1, 'You successfully submitted a Research Project.', 'January / 08 Monday / 2024', '12:23 AM', 'Read'),
(92, 1, 'You successfully logged in to your account.', 'January / 09 Tuesday / 2024', '10:11 PM', 'Read'),
(93, 1, 'You successfully inserted a Course.', 'January / 09 Tuesday / 2024', '10:15 PM', 'Read'),
(94, 1, 'You successfully inserted a Course.', 'January / 09 Tuesday / 2024', '10:15 PM', 'Read'),
(95, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:18 PM', 'Read'),
(96, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:23 PM', 'Read'),
(97, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:41 PM', 'Read'),
(98, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:45 PM', 'Read'),
(99, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:46 PM', 'Read'),
(100, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:48 PM', 'Read'),
(101, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:52 PM', 'Read'),
(102, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:55 PM', 'Read'),
(103, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:57 PM', 'Read'),
(104, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '10:57 PM', 'Read'),
(105, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:04 PM', 'Read'),
(106, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:07 PM', 'Read'),
(107, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:10 PM', 'Read'),
(108, 1, 'You successfully inserted a Course.', 'January / 09 Tuesday / 2024', '11:16 PM', 'Read'),
(109, 1, 'You successfully inserted a Course.', 'January / 09 Tuesday / 2024', '11:16 PM', 'Read'),
(110, 1, 'You successfully inserted a Course.', 'January / 09 Tuesday / 2024', '11:17 PM', 'Read'),
(111, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:23 PM', 'Read'),
(112, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:25 PM', 'Read'),
(113, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:28 PM', 'Read'),
(114, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:30 PM', 'Read'),
(115, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:33 PM', 'Read'),
(116, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:52 PM', 'Read'),
(117, 1, 'You successfully submitted a Research Project.', 'January / 09 Tuesday / 2024', '11:57 PM', 'Read'),
(118, 1, 'You successfully submitted a Research Project.', 'January / 10 Wednesday / 2024', '12:09 AM', 'Read'),
(119, 1, 'You successfully Updated a Department.', 'January / 10 Wednesday / 2024', '12:12 AM', 'Read'),
(120, 1, 'You successfully submitted a Research Project.', 'January / 10 Wednesday / 2024', '12:13 AM', 'Read'),
(121, 1, 'You successfully Updated a Department.', 'January / 10 Wednesday / 2024', '12:14 AM', 'Read'),
(122, 1, 'You successfully submitted a Research Project.', 'January / 10 Wednesday / 2024', '12:22 AM', 'Read'),
(123, 1, 'You successfully logged in to your account.', 'January / 10 Wednesday / 2024', '9:12 PM', 'Read'),
(124, 1, 'You successfully Updated a Department.', 'January / 10 Wednesday / 2024', '9:19 PM', 'Read'),
(125, 1, 'You successfully Updated a Department.', 'January / 10 Wednesday / 2024', '9:20 PM', 'Read'),
(126, 1, 'You successfully Updated a Department.', 'January / 10 Wednesday / 2024', '9:24 PM', 'Read'),
(127, 1, 'You successfully Updated a Department.', 'January / 10 Wednesday / 2024', '9:25 PM', 'Read'),
(128, 1, 'You successfully logged out to your account.', 'January / 10 Wednesday / 2024', '10:55 PM', 'Read'),
(129, 1, 'You successfully logged in to your account.', 'January / 10 Wednesday / 2024', '11:00 PM', 'Read'),
(130, 1, 'You successfully submitted a Research Project.', 'January / 10 Wednesday / 2024', '11:25 PM', 'Read'),
(131, 1, 'You successfully submitted a Research Project.', 'January / 10 Wednesday / 2024', '11:40 PM', 'Read'),
(132, 1, 'You successfully logged in to your account.', 'January / 11 Thursday / 2024', '2:24 PM', 'Read'),
(133, 1, 'You successfully logged out to your account.', 'January / 11 Thursday / 2024', '2:38 PM', 'Read'),
(134, 1, 'You successfully logged in to your account.', 'January / 18 Thursday / 2024', '12:38 PM', 'Read'),
(135, 1, 'You successfully logged out to your account.', 'January / 18 Thursday / 2024', '9:39 PM', 'Read'),
(136, 1, 'You successfully logged in to your account.', 'January / 19 Friday / 2024', '10:55 AM', 'Read'),
(137, 1, 'You successfully logged out to your account.', 'January / 19 Friday / 2024', '10:57 AM', 'Read'),
(138, 1, 'You successfully logged in to your account.', 'January / 19 Friday / 2024', '1:29 PM', 'Read'),
(139, 1, 'You successfully inserted a Course.', 'January / 19 Friday / 2024', '1:31 PM', 'Read'),
(140, 1, 'You successfully submitted a Research Project.', 'January / 19 Friday / 2024', '1:34 PM', 'Read'),
(141, 1, 'You successfully submitted a Research Project.', 'January / 19 Friday / 2024', '1:37 PM', 'Read'),
(142, 1, 'You successfully inserted a Course.', 'January / 19 Friday / 2024', '1:50 PM', 'Read'),
(143, 1, 'You successfully submitted a Research Project.', 'January / 19 Friday / 2024', '1:51 PM', 'Read'),
(144, 1, 'You successfully logged in to your account.', 'January / 21 Sunday / 2024', '1:02 PM', 'Read'),
(145, 1, 'You successfully submitted a Research Project.', 'January / 21 Sunday / 2024', '1:04 PM', 'Read'),
(146, 1, 'You successfully submitted a Research Project.', 'January / 21 Sunday / 2024', '1:19 PM', 'Read'),
(147, 1, 'You successfully submitted a Research Project.', 'January / 21 Sunday / 2024', '1:49 PM', 'Read'),
(148, 1, 'You successfully submitted a Research Project.', 'January / 21 Sunday / 2024', '2:15 PM', 'Read'),
(149, 1, 'You successfully submitted a Research Project.', 'January / 21 Sunday / 2024', '2:32 PM', 'Read'),
(150, 1, 'You successfully logged in to your account.', 'January / 21 Sunday / 2024', '9:32 PM', 'Read'),
(151, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '1:46 PM', 'Read'),
(152, 1, 'You successfully logged out to your account.', 'January / 24 Wednesday / 2024', '1:48 PM', 'Read'),
(153, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '1:48 PM', 'Read'),
(154, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '1:49 PM', 'Read'),
(155, 1, 'You successfully logged out to your account.', 'January / 24 Wednesday / 2024', '2:00 PM', 'Read'),
(156, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '2:00 PM', 'Read'),
(157, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '2:16 PM', 'Read'),
(158, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '2:48 PM', 'Read'),
(159, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '4:24 PM', 'Read'),
(160, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '4:26 PM', 'Read'),
(161, 1, 'You successfully logged out to your account.', 'January / 24 Wednesday / 2024', '4:47 PM', 'Read'),
(162, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '9:58 PM', 'Read'),
(163, 1, 'You successfully logged out to your account.', 'January / 24 Wednesday / 2024', '10:02 PM', 'Read'),
(164, 1, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '10:04 PM', 'Read'),
(165, 1, 'You successfully Updated a Department.', 'January / 24 Wednesday / 2024', '10:06 PM', 'Read'),
(166, 1, 'You successfully Updated a Department.', 'January / 24 Wednesday / 2024', '10:06 PM', 'Read'),
(167, 1, 'You successfully inserted a Department.', 'January / 24 Wednesday / 2024', '10:06 PM', 'Read'),
(168, 1, 'You successfully inserted a Course.', 'January / 24 Wednesday / 2024', '10:07 PM', 'Read'),
(169, 1, 'You successfully logged in to your account.', 'January / 25 Thursday / 2024', '2:31 PM', 'Read'),
(170, 1, 'You successfully logged in to your account.', 'January / 25 Thursday / 2024', '3:23 PM', 'Read'),
(171, 1, 'You successfully logged in to your account.', 'January / 25 Thursday / 2024', '11:19 PM', 'Read'),
(172, 1, 'You successfully logged in to your account.', 'January / 26 Friday / 2024', '4:49 PM', 'Read'),
(173, 1, 'You successfully Updated a Department.', 'January / 26 Friday / 2024', '4:55 PM', 'Read'),
(174, 1, 'You successfully Updated a Department.', 'January / 26 Friday / 2024', '4:55 PM', 'Read'),
(175, 1, 'You successfully inserted a Course.', 'January / 26 Friday / 2024', '4:56 PM', 'Read'),
(176, 1, 'You successfully logged out to your account.', 'January / 26 Friday / 2024', '5:02 PM', 'Read'),
(177, 1, 'You successfully logged in to your account.', 'January / 26 Friday / 2024', '9:39 PM', 'Read'),
(178, 1, 'You successfully Updated a Department.', 'January / 26 Friday / 2024', '9:54 PM', 'Read'),
(179, 6, 'You successfully logged in to your account.', 'September / 21 Saturday / 2024', '4:38 PM', 'Read'),
(180, 6, 'You successfully logged in to your account.', 'September / 24 Tuesday / 2024', '10:25 AM', 'Read'),
(181, 6, 'You successfully logged out to your account.', 'September / 24 Tuesday / 2024', '10:25 AM', 'Read'),
(182, 6, 'You successfully logged in to your account.', 'September / 24 Tuesday / 2024', '10:29 AM', 'Read'),
(183, 6, 'You successfully logged out to your account.', 'September / 24 Tuesday / 2024', '10:29 AM', 'Read'),
(184, 6, 'You successfully logged in to your account.', 'September / 24 Tuesday / 2024', '10:30 AM', 'Read'),
(185, 6, 'You successfully logged out to your account.', 'September / 24 Tuesday / 2024', '10:33 AM', 'Read'),
(186, 6, 'You successfully logged in to your account.', 'September / 24 Tuesday / 2024', '10:33 AM', 'Read'),
(187, 6, 'You successfully logged out to your account.', 'September / 24 Tuesday / 2024', '10:35 AM', 'Read'),
(188, 6, 'You successfully logged in to your account.', 'October / 07 Monday / 2024', '10:38 PM', 'Read'),
(189, 6, 'You successfully logged in to your account.', 'October / 10 Thursday / 2024', '10:37 PM', 'Read'),
(190, 6, 'You successfully logged out to your account.', 'October / 10 Thursday / 2024', '10:38 PM', 'Read'),
(191, 6, 'You successfully logged in to your account.', 'October / 13 Sunday / 2024', '6:56 PM', 'Read'),
(192, 6, 'You successfully logged out to your account.', 'October / 13 Sunday / 2024', '7:08 PM', 'Read'),
(193, 6, 'You successfully logged in to your account.', 'October / 13 Sunday / 2024', '8:20 PM', 'Read'),
(194, 6, 'You successfully logged out to your account.', 'October / 13 Sunday / 2024', '8:45 PM', 'Read'),
(195, 6, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '1:25 PM', 'Read'),
(196, 6, 'You successfully logged out to your account.', 'October / 14 Monday / 2024', '1:29 PM', 'Read'),
(197, 6, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '1:37 PM', 'Read'),
(198, 6, 'You successfully logged out to your account.', 'October / 14 Monday / 2024', '1:46 PM', 'Read'),
(199, 6, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '11:05 PM', 'Read'),
(200, 6, 'You successfully logged in to your account.', 'October / 15 Tuesday / 2024', '9:40 PM', 'Read'),
(201, 6, 'You successfully logged in to your account.', 'October / 16 Wednesday / 2024', '8:42 PM', 'Read'),
(202, 6, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '3:25 PM', 'Read'),
(203, 6, 'You successfully logged out to your account.', 'October / 17 Thursday / 2024', '4:25 PM', 'Read'),
(204, 6, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '10:43 PM', 'Read'),
(205, 6, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '10:36 AM', 'Read'),
(206, 6, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '3:18 PM', 'Read'),
(207, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '3:49 PM', 'Read'),
(208, 1, 'You successfully logged out to your account.', 'October / 18 Friday / 2024', '4:40 PM', 'Read'),
(209, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '5:28 PM', 'Read'),
(210, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '9:14 PM', 'Read'),
(211, 1, 'You successfully logged out to your account.', 'October / 18 Friday / 2024', '9:33 PM', 'Read'),
(212, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '9:45 PM', 'Read'),
(213, 1, 'You successfully logged out to your account.', 'October / 18 Friday / 2024', '10:48 PM', 'Read'),
(214, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '11:31 PM', 'Read'),
(215, 1, 'You successfully logged in to your account.', 'October / 19 Saturday / 2024', '3:31 PM', 'Read'),
(216, 1, 'You successfully logged out to your account.', 'October / 19 Saturday / 2024', '3:32 PM', 'Read'),
(217, 1, 'You successfully logged in to your account.', 'October / 19 Saturday / 2024', '3:34 PM', 'Read'),
(218, 1, 'You successfully logged in to your account.', 'October / 19 Saturday / 2024', '5:31 PM', 'Read'),
(219, 1, 'You successfully logged in to your account.', 'October / 19 Saturday / 2024', '11:10 PM', 'Read'),
(220, 1, 'You successfully logged in to your account.', 'October / 20 Sunday / 2024', '3:13 PM', 'Read'),
(221, 1, 'You successfully logged in to your account.', 'October / 20 Sunday / 2024', '4:51 PM', 'Read'),
(222, 1, 'You successfully logged out to your account.', 'October / 20 Sunday / 2024', '4:53 PM', 'Read'),
(223, 1, 'You successfully logged in to your account.', 'October / 22 Tuesday / 2024', '10:23 PM', 'Read'),
(224, 1, 'You successfully logged in to your account.', 'October / 22 Tuesday / 2024', '10:34 PM', 'Read'),
(225, 1, 'You successfully logged in to your account.', 'October / 23 Wednesday / 2024', '1:24 PM', 'Read'),
(226, 1, 'You successfully logged in to your account.', 'October / 23 Wednesday / 2024', '9:12 PM', 'Read'),
(227, 1, 'You successfully logged out to your account.', 'October / 23 Wednesday / 2024', '10:35 PM', 'Read'),
(228, 1, 'You successfully logged in to your account.', 'October / 23 Wednesday / 2024', '10:35 PM', 'Read'),
(229, 1, 'You successfully logged in to your account.', 'October / 23 Wednesday / 2024', '11:42 PM', 'Read'),
(230, 1, 'You successfully logged out to your account.', 'October / 23 Wednesday / 2024', '11:42 PM', 'Read'),
(231, 1, 'You successfully logged in to your account.', 'October / 23 Wednesday / 2024', '11:42 PM', 'Read'),
(232, 1, 'You successfully logged in to your account.', 'October / 24 Thursday / 2024', '2:52 PM', 'Read'),
(233, 1, 'You successfully logged in to your account.', 'October / 24 Thursday / 2024', '4:23 PM', 'Read'),
(234, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '10:11 AM', 'Read'),
(235, 1, 'You successfully logged out to your account.', 'October / 26 Saturday / 2024', '10:14 AM', 'Read'),
(236, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '10:53 AM', 'Read'),
(237, 1, 'You successfully logged out to your account.', 'October / 26 Saturday / 2024', '10:53 AM', 'Read'),
(238, 1, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '8:02 PM', 'Read'),
(239, 1, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '8:03 PM', 'Read'),
(240, 1, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '8:03 PM', 'Read'),
(241, 1, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '8:05 PM', 'Read'),
(242, 1, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '8:07 PM', 'Read'),
(243, 1, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '8:17 PM', 'Read'),
(244, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '11:51 AM', 'Read'),
(245, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '12:11 PM', 'Read'),
(246, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:19 PM', 'Read'),
(247, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:25 PM', 'Read'),
(248, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:39 PM', 'Read'),
(249, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '12:40 PM', 'Read'),
(250, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:41 PM', 'Read'),
(251, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:58 PM', 'Read'),
(252, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:00 PM', 'Read'),
(253, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:04 PM', 'Read'),
(254, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:08 PM', 'Read'),
(255, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:17 PM', 'Read'),
(256, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:48 PM', 'Read'),
(257, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:36 PM', 'Read'),
(258, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:58 PM', 'Read'),
(259, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '10:06 PM', 'Read'),
(260, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '10:11 PM', 'Read'),
(261, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '10:15 PM', 'Read'),
(262, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '10:15 PM', 'Read'),
(263, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '11:05 PM', 'Read'),
(264, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '1:21 PM', 'Read'),
(265, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '1:23 PM', 'Read'),
(266, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '1:56 PM', 'Read'),
(267, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:47 PM', 'Read'),
(268, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:52 PM', 'Read'),
(269, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:58 PM', 'Read'),
(270, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:59 PM', 'Read'),
(271, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '11:52 PM', 'Read'),
(272, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '11:54 PM', 'Read'),
(273, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '7:58 AM', 'Read'),
(274, 1, 'You successfully Updated a Department.', 'November / 05 Tuesday / 2024', '9:18 AM', 'Read'),
(275, 1, 'You successfully Updated a Department.', 'November / 05 Tuesday / 2024', '9:19 AM', 'Read'),
(276, 1, 'You successfully Updated a Department.', 'November / 05 Tuesday / 2024', '9:20 AM', 'Read'),
(277, 1, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '10:24 AM', 'Read'),
(278, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '4:59 PM', 'Read'),
(279, 1, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '5:02 PM', 'Read'),
(280, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '5:13 PM', 'Read'),
(281, 1, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '5:14 PM', 'Read'),
(282, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '8:53 PM', 'Read'),
(283, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:20 PM', 'Unread'),
(284, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:31 PM', 'Unread'),
(285, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:35 PM', 'Unread'),
(286, 1, 'You successfully logged in to your account.', 'November / 06 Wednesday / 2024', '11:08 AM', 'Unread'),
(287, 1, 'You successfully logged out to your account.', 'November / 06 Wednesday / 2024', '11:33 AM', 'Unread'),
(288, 1, 'You successfully logged in to your account.', 'November / 06 Wednesday / 2024', '11:46 AM', 'Unread'),
(289, 1, 'You successfully logged out to your account.', 'November / 06 Wednesday / 2024', '11:58 AM', 'Unread'),
(290, 1, 'You successfully logged in to your account.', 'November / 08 Friday / 2024', '10:34 AM', 'Unread');

-- --------------------------------------------------------

--
-- Table structure for table `archive_research`
--

CREATE TABLE `archive_research` (
  `id` int(11) NOT NULL,
  `archive_id` varchar(13) NOT NULL,
  `student_id` varchar(20) NOT NULL,
  `department_id` int(11) NOT NULL,
  `course_id` int(11) NOT NULL,
  `project_title` varchar(200) NOT NULL,
  `dateOFSubmit` varchar(50) NOT NULL,
  `project_year` varchar(80) NOT NULL,
  `project_abstract` varchar(5000) NOT NULL,
  `keywords` varchar(255) NOT NULL,
  `content` text NOT NULL,
  `research_owner_email` varchar(200) NOT NULL,
  `project_members` varchar(700) NOT NULL,
  `project_picture` varchar(800) NOT NULL,
  `documents` varchar(700) NOT NULL,
  `date_published` varchar(80) NOT NULL,
  `document_status` varchar(200) NOT NULL DEFAULT 'Not Accepted'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `archive_research`
--

INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(1, '5118052229', '1', 3, 3, 'Acceptability of Turmeric and Taro Pasta', '2024-09-27', '2021', 'Filipino occasions is not complete without pasta on the table. It is one of the comfort food of everyone special the young ones. Filipino pasta always comes with a slice of hotdog or bits of mushroom and carrots and a little bit sweet compare to the traditional pasta that is a bit slightly sour because of tomato. The researchers conducted this study to create new variety of pasta using turmeric and taro which often neglected and underutilized despite of its nutritional value. Hence, this study aimed to developed a healthy and nutritious type of pasta, and assess the level of acceptability of Turmeric and Taro Pasta', '', 'Filipino occasions is not complete without pasta on the table. It is one of the comfort food of everyone special the young ones. Filipino pasta always comes with a slice of hotdog or bits of mushroom and carrots and a little bit sweet compare to the traditional pasta that is a bit slightly sour because of tomato. The researchers conducted this study to create new variety of pasta using turmeric and taro which often neglected and underutilized despite of its nutritional value. Hence, this study aimed to developed a healthy and nutritious type of pasta, and assess the level of acceptability of Turmeric and Taro Pasta', 'raytos.r.bsinfotech@gmail.com', 'Karl Lewis Marquez, Christian Jade Ozaeta and Rocarleo Villamil', '', '../pdf_files/65956299efbac-ACCEPTABILITY OF TURMERIC AND TARO PASTA.pdf', '2024-08-26', 'Accepted'),
(2, '9915882483', '1', 3, 3, 'Anchovy Pineapple Jam', '2024-09-27', '2022', ' Fruit jams have been one of the most common methods used to preserve fruit for decades. Fruit that has fiber content or is high in pectin in their jam formulation. Appropriate acidity, total soluble solid substance, and calcium content are all imperative for pectin gelation. The terms jam, marmalade, and preserve are used interchangeably. In the English language, preserves describe a product containing cooked or gelled whole fruit. The researchers conducted the study to developed Anchovy Pineapple Jam to make children eat fish without tasting musty flavor and enjoy all the healthful benefits of it.', '', ' Fruit jams have been one of the most common methods used to preserve fruit for decades. Fruit that has fiber content or is high in pectin in their jam formulation. Appropriate acidity, total soluble solid substance, and calcium content are all imperative for pectin gelation. The terms jam, marmalade, and preserve are used interchangeably. In the English language, preserves describe a product containing cooked or gelled whole fruit. The researchers conducted the study to developed Anchovy Pineapple Jam to make children eat fish without tasting musty flavor and enjoy all the healthful benefits of it.', 'raytos.r.bsinfotech@gmail.com', 'Melissa Calzada, Rochelle Dimaano, Brian Harvey Jota', '', '../pdf_files/659563dcdce2c-ANCHOVY PINEAPPLE JAM.pdf', '2024-09-28', 'Accepted'),
(3, '1791740225', '1', 6, 10, 'Ginataang Halo-halo Ice Cream', '2024-09-27', '2019', 'Ginataang Halo-Halo also known as Binignit in some regions in the Philippines, according to panlasangpinoy.com, dished that are cooked in coconut milk are locally called “Ginataan”. The word was derived from the root word “gata”, which means cococnut milk. At the same time, the word “Halo-Halo” refers to the combination of different components or ingredients that were used to complete the dish and is also referred to as another famous Filipino summer dessert. 	The researcher came up with the idea of combining the two of the famous pride of Filipinos that accepted its variation. The two deserts are complemented and will create a new taste.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Christian Cruz, Julius San Lorenzo, Abby Grace Flores, Christine Joy Labad, Jessica  Lloren, Paulynne Parado, Anna Chel Valdez', '', '../pdf_files/6595648e9e4e3-GINATAANG HALO-HALO ICE CREAM.pdf', '2024-09-28', 'Accepted'),
(4, '8046523565', '1', 6, 10, 'Squash Buchi', '2024-09-27', '2020', 'The Innovation of the production of dessert or smack and sweetened food products for kids and young once is becoming popular because of its nutritional value. The production and research on\r\nhealthy food is continuously advances due to public demand. The practical utilization of vegetable into healthy snack was already applied in making this product. The study aimed to present the easiest method on how to to utilized indigenous material. The five-point Likert scale evaluation and t-test was used to determine the significant differences between the evaluation of expert and consumer respondents. The respondents of the product are consumers and experts.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Kimberly Carl Banzuelo,  Mary Joy Calma, Gabriel Gabriel, Hannah Mae Guererro, Kristine Joy Viaje, Lian Visto', '', '../pdf_files/659565fc461e3-SQUASH BUCHI.pdf', '2024-09-28', 'Accepted'),
(5, '1353057342', '1', 1, 1, 'VIVA Homes Estate Subdivision Expense Management System', '2024-09-27', '2023', 'Viva Homes State Subdivision is a plot of land divided into two or more parcels. On a single piece of land, there are numerous homes and industrial buildings. The Homeowners Association (HOA) officers use spreadsheets, paper- based invoicing and receipt tracking, and manual data entry for spending management as their primary methods of expense tracking and reporting.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Mikaela Tarle, Noriel Millares, Bryan Kyle Espina', '', '../pdf_files/659567b6d6b01-Viva Homes Expense Management System.pdf', '', 'Not Accepted'),
(8, '8870456450', '1', 3, 3, 'Honey Dew and Corn Milk Ice Cream', '2024-09-27', '2018', 'Ice cream is one of the most known desert in town like in the Philippines ice cream is well known because in summer season it is not just for the kids by eating ice cream its also good in alduts to eat ice cream. Base on our research Ice cream is a frozen delight desert that have eggs, cream, sugar, and flavors for example chocolate, vanilla, mango, and other fruits. But we used Honeydew for the flavor and corn milk for the based of the ice cream and to change the alternative flavor of the ice cream. The researchers are inspired to develop an ice cream by using honeydew and corn milk because of health benefits that one can get from it and to have another variety of ice cream in the market. Likewise, to determine the quality characteristics and level of acceptability of the finished product as evaluated by selected group of respondents.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Josephine C. De Mesa, John Mark Cruz, Armila Jean T. Banate,  Frances Mitchelle B. Antonio', '', '../pdf_files/659633c5c60dd-HONEYDEW AND CORN MILK ICE CREAM.pdf', '2024-09-28', 'Accepted'),
(9, '4933784591', '1', 3, 3, 'Jute Lasagna Noodles', '2024-09-27', '2020', 'Many children refused to eat vegetables nowadays because they don\'t know the importance that it may give to their body. They are not also familiar with some vegetables especially those who lived in the urban areas. They are more likely to eat foods with preservatives like junk foods, chocolates, candies, etc. that suit their taste but they lack the necessary nutrients needed by the body. \r\nThe researchers as pasta lovers will conduct this study in order to innovate another variety of lasagna noodles using jute leaves which is known for its anti- cancer agent and helps control blood pressure and cholesterol level; determine the quality and acceptability of the finished product in terms of appearance, translucency, and flavor.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Mary Kris M. Olarte, Shena Karen V. Guiang, Melody Mauffine L. Emar ', '', '../pdf_files/65963423cb88f-JUTE LASAGNA NOODLES.pdf', '2024-09-28', 'Accepted'),
(10, '9749167622', '1', 3, 3, 'Papait Herb Pasta', '2024-09-27', '2018', 'Pasta is a satisfying and convenient meal, but some types of pasta are rich in empty carbs and provide little nutritive benefit in addition to calories. As far as people\'s knowledge of carbohydrates, gluten, and the glycemic index is involved. Nowadays, most Filipinos preferred ready-to-eat food because of their 65 busy schedules without realizing its health risk and nutrient content, with this the proponents came up with the idea of innovating pasta noodles using indigenous matenal which is Papait Herb that contains important nutrients like fiber The product was evaluated its acceptability base on the parameter such as appearance, flavor, firmness, cohesiveness.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Denzel Marie Flores, Maila E. Basangan, and Abbiegail M. Buan', '', '../pdf_files/6596347f745ca-PAPAIT HERB PASTA.pdf', '2024-09-28', 'Accepted'),
(11, '9215124222', '1', 3, 3, 'Peanut Milk Guyabano and Moringa Ice Cream', '2024-09-27', '2021', 'This study covers the production of peanut milk as an alternative to milk by the means of extraction of fresh native peanuts to introduce new source of milk that can be commercialize internationally. Guyabano helps to enhance the aroma, flavor, and color of the product and texture, also to contribute nutrients in the product. To give additional nutrients, the presence of moringa levels up the nutrients present in the ice cream. The reason of conducting this experiment is to introduce peanut milk as a source of milk by means of ice cream as alternative for whole milk. Also, to create new variety of dessert contains nutrients that average that people needs to nurture health in the presence of moringa that is known for its versatility and guyabano as flavoring ingredient.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Helen Q. Estrella, Geraldine D. Grutas, Zyril Anne L. Aguila', '', '../pdf_files/659634e93ac45-PEANUT MILK GUYABANO AND MORINGA ICE CREAM.pdf', '2024-09-28', 'Accepted'),
(12, '1428063800', '1', 3, 3, 'Rambutan And Lemon As Concentrated Juice', '2024-09-27', '2021', 'Juice concentrate is convenient to us, especially for kids and some adults Juice concentrate is 90% highly fresh and healthy plus the nutrition of the specific fruit that is used. Juice concentrate does not consist of sugar, and it does not add any artificial in it. The present study was conducted to develop and innovate a product made from seasonal fruit like rambutan with the addition of lemon into a concentrated juice. The product will assess its level of acceptability in terms of appearance, aroma, and flavor. The Output box is the Acceptable Rambutan and Lemon Concentrated Juice. ', '', '', 'raytos.r.bsinfotech@gmail.com', 'Romelie S. Maddela, Mark Joaquin G. Ramos, Julienne Rosche V. Tripolca', '', '../pdf_files/659636f027b84-RAMBUTAN AND LEMON AS CONCENTRATED JUICE.pdf', '2024-09-28', 'Accepted'),
(13, '8537430711', '1', 3, 3, 'Sensory Evaluation And Proximate Analysis of Nutri-Bread', '2024-09-27', '2021', 'Nutri bread is yeast leavened and mainly composed of healthy vegetable such as Chinese kangkung, sweet potato tops, pechay. That can help regulate your blood sugar, cholesterol levels and blood pressure. Nutri Bread has fiber which is good for digestion, which will also benefit and is good for your heart. Now a day\'s children of all ages wants a junk foods like chips, pizza, French fries, burger, hotdogs that not good to our body, that can cause sickness. Children this day\'s these days get easily sick, that\'s why we come up with the idea preparing a nutritional snacks. \r\nBread is a staple food prepared from a dough of flour and water, usually by baking. Throughout recorded history it has been popular around the world and is one of the oldest artificial foods, having been of importance since the dawn of agriculture. Proportions of types of flour and other ingredients vary widely, as do modes of preparation. As a result, types, shapes, sizes, and textures of breads differ around the world. The reason why the researchers conducted this study is because they want to provide a healthier bread and give new flavor and to offer new variety of bread. Furthermore, the proponents wants to determine the most preferred formation.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Jessica Mae P. Meek, Annalyn Grace D. Escober, Leonard Villar', '', '../pdf_files/6596377b0b19e-SENSORY EVALUATION AND PROXIMATE ANALYSIS OF NUTRI-BREAD.pdf', '2024-09-28', 'Accepted'),
(14, '5345625905', '1', 3, 3, 'SMB Chips (Squash Malunggay, Banana)', '2024-09-27', '2021', 'Chips are one of the common snacks for children. The most popular chips in the market are made from sliced potato or potato dough-based from a variety of starches. Deep-frying is a common technique for processing snack foods. These chips are considered unhealthy because of their high level of fat and salt content. A healthy snack must contain nutrients and should provide energy. With these, the proponents come up with the idea of infusing squash, malunggay, and banana in chips preparation to utilize its nutritional benefits. This is a type of chip suitable for all ages. In doing this, the product will be evaluated as to the level of acceptability based on the criteria set for chips and determine the significant difference in the evaluation made by the respondents.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Joseph Jerry Viohla Jr., Rodelyn Latagan, Cherwin Jacobe, Mary Ann Vibar, Daniela Ereno, Danica Ereno, and May Biscoro', '', '../pdf_files/659638282c58a-SMB CHIPS.pdf', '2024-09-28', 'Accepted'),
(16, '5477905649', '1', 6, 10, 'Sweet Potato Hopia With Jackfruit', '2024-09-27', '2023', 'Sweets, desserts, biscuits, bread, a delicacy of foods, people tend to find, testing new tastes and flavors that will satisfy their selves, many pastries that are good in taste, kids, old agen are like sweets, and people that have sweet tooth will definitely like a kind of delicacy that is sweet, slightly crunch or flakey filled with some bean paste filling inside that will blow flavor in your mouth, this delicacy a mooncake-like pastry is called Bopia or Hopia is famous. The researchers seek for taste, texture, aroma, and color of its significant difference in the level of acceptability of Hopia sweet potato filled with jackfruit paste filling, and what will be the result of nutrient analysis of Hopia sweet potato filled with Jackfruit.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Shayrrah Mae T. Rafales, Rhea Joy A. Casimiro, Jasmin A. Zamora, Jolyet E, Canillo, Janine R. Deonila, Quena R. Rey ', '', '../pdf_files/659645e031b1b-SWEET POTATO HOPIA WITH JACKFRUIT.pdf', '2024-09-28', 'Accepted'),
(17, '6012093582', '1', 6, 10, 'Squash Buchi', '2024-09-27', '2020', 'Utilizing fruits and vegetables into a healthy snack food will help answer the problem of undernutrition in the country. Squash is a common fruit in the country that is underdeveloped or underutilized, it is very nutritious and can be a healthy addition to our diet. It is rich in vitamins, minerals, and antioxidants found in squash provide several health benefits. The antioxidants in squash can play an important role in reducing oxidative stress. In turn, this may help with cancer prevention. With these, the proponents want to produce a healthy version of finger food or snack food made from Squash. The researcher made this product to help answer the problem of undernutrition among children in the country by using underutilized vegetables but a nutritious one. It is comparable to local karyoka made from glutinous rice but less expensive.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Kimberly Carl C. Banzuelo,  Mary Joy Calma, Gabriel Gabriel, Hannah Mae Guererro, Kristine Joy Viaje, Lian Visto ', '', '../pdf_files/6596465778915-SQUASH BUCHI.pdf', '2024-09-28', 'Accepted'),
(18, '3749256247', '1', 6, 9, 'Rolled-Up Bread With Chocomon Fillings', '2024-09-27', '2017', 'The bread is integral part of every meal and it is served during the three main meals. The breads are distinguished by their regional variations Bread is a staple food preferred from dough of flour and water, usually by baking. There are many combinations and proportions of types of flour and other ingredients, and also of traditional recipes and modes of preparation of bread. Breads available in the market are of different sizes, shapes and flavors. If the consumer/s are to eat more bread, an all-out effort must made to raise bread, in school, at home, in the community and also increase bakery production and make the country self-sufficient in bread.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Rachel Grace C. Macatisbes, Judy Ann C. Pidul, Maria Merceded C. Omadio, Shiela Marie D. Nueva, Carlos Mico D. Hustre', '', '../pdf_files/65964795657c0-ROLLED-UP BREAD.pdf', '2024-09-28', 'Accepted'),
(19, '3015686003', '1', 4, 11, 'Smart Face Shield with Emergency Features Using IoT System', '2024-09-27', '2021', 'Face Shield are personal protective equipment devices that are used by many workers (for medical, veterinary, dental)for protection of the facial area and associated mucous eyes, nose, mouth from splashes, sprays, and spatter of body of Fluids. Although there are millions of potential uses of face shields, guidelines for their use vary between governmental research is little and professional societies agencies available regarding their efficacy. Nowadays it is more often or even required to use due to Covid case, we came up to an idea to innovate face pandemic. In this not only to protect ourselves but also to us not shield that helps reduce the risk of the pandemic Covid-19. SMART FACESHIELD with is a wearable device IOT SYSTEM\" is Feature\'s using EMERGENCY Feature\'s\r\ntechnology that is design for security staff, medical front liner and health Worker. It\'s electrically operated by a power bank supply that keeps awake for 8 to 12 hours. It has an organic light energy use for with low consumption (OLED) emitting diode Interface. It has a temperature scanner and ultrasonic sensor that Scan a temperature of an object over 20-to-100-centimeter distant range. It has a global system mobile for communication (GSM) that can access emergency calls and sends information thru SMS if the face shield detects a temperature above 37.5 degrees centigrade . Also has a global positioning system (GPS) that helps us to monitor the area of the device. In line with its functionality, it helps easily in monitoring people with possible covid cases without an intervention and keep us safe from the use of human-to-human disease.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Garduque Daniel L., Guillermo Courtney O., Ibanez Czar Ryenbert C., Napila Jaspher, Ocampo Rodolofo Jr. S., Ortiz Christine Grace M., Samson Kyllie Anne A.', '', '../pdf_files/6598de4b7760a-SMART FACE SHIELD WITH EMERGENCY FEATURES USING IOT SYSTEM.pdf', '2024-09-28', 'Accepted'),
(20, '3440130111', '1', 4, 7, 'Hybrid Source Charging Station Using SuperCapacitor', '2024-09-27', '2018', 'The HYSCAP Charging Station or the (HYBRID SOURCE CHARGING STATION USING SUPERCAPACITOR) is an alternative for electricity. This eco-friendly Charging Station uses renewable sources of electricity coming from solar and wind energy. Theseare converted into electricity for charging purposes and it has fast charging capability by means of Supercapacitor. HYSCAP Charging Station used the Supercapacitor which is the hottest and most advanced technology invention and also called the fuel tank of tomorrow for a brighter future. It can acceptand deliver charge much faster than batteries. It is also used in applications requiring rapid charge/discharge cycles and can quickly store and release energy over long times with a high cycle rate. In this project, the researchers came up with the design of a modular system which can be stacked or rearranged in different formations, easy to move, and reassembled for flexibility. Allow the module to be transported, move around to a place where it is needed to attain an access of this eco-friendly Charging Station using renewable source of electricity. ', '', '', 'raytos.r.bsinfotech@gmail.com', 'Ilustirismo Kiven James B., Pitapit Alberto C., Marasigan Jameal Angelo M., Lozada June Venzar F., Canotal Limuille P., Danan Allen John C., Resos Gilbert C., Baclaan Jhaira Marie S., Gomez Trixie Mae ', '', '../pdf_files/6598f5bda9d1f-Hybrid Source Charging Station Using SuperCapacitor.pdf', '2024-09-28', 'Accepted'),
(21, '1380562741', '1', 4, 12, 'PowerTtr3ss Water Purifier', '2024-09-27', '2019', 'ssities. He uses it for bathing, household chores, and of course for drinking. Man needs to drink at least 8 glasses of water a day to stay healthy. Sad to say, not everyone is able to access safe and clean drinking water. There are different means of water treatment nowadays but not all of them are practical to be implemented in poor rural/urban areas. Some of these are boiling, solar disinfection, chemical treatment (uses chlorine and iodine), reverse osmosis, wells, slow sand and UV.\r\n\r\nReverse osmosis purifies bacteria, salts, sugars, proteins, particles, dyes, heavy metals, chlorine, and other contaminants with a molecular weight greater than 150 250 daltons. Deep wells seem like a great solution for the water problems of the rural poor. But these have major shortcomings in application. Often dug and tube wells need purification because these may become contaminated during the rainy season. If the wells are poorly constructed or maintained, then these may be contaminated on a regular basis. UV light is a form of electromagnetic radiation and should not be confused with nuclear radiation. Ultraviolet light kills bacteria by penetrating cells commonly called DNA.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Dangalan Rudolf H., Falcutila Juan Miguel D., Frio Jennifer C., Llorera Jeremiah, Abella Carlyn B., Avila Santhy, Parreno Jeremeh', '', '../pdf_files/6599034889e5c-PowerTtr3ss Water Purifier.pdf', '2024-09-28', 'Accepted'),
(22, '8920732117', '1', 4, 7, 'Surface Disinfecting Robot (Using UVC Light)', '2024-09-27', '2021', 'Surface Disinfecting Robot (Using UVC Light) is a device that can disinfect a flat surface using ultraviolet germicidal irradiation Radiation warps their genetic material preventing them from spreading, UV light is capable of killing harmful viruses but note that direct contact with the contaminated spaces can be dangerous that is why building a robot that can function separately is a big help to decrease the rising cares of coronavirus. The aim of this project is to avoid a physical manpower act in disinfecting the infected areas, and the Robot has LEDs that radiate uitraviolet light that can effectively kill germs, viruses, and other DNA and RNA of harmful contaminants. This Robot is equipped with AK9753 4 channel PIR a human presence sensor uned for human movement and presence sensing. The Robot will automatically turn off the UV light once there is a human nearby.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Baltar Ivy Mimsy B., Caras Carolyn M., Dipon Kate V., Manalo Timothy D., Parcarey Jolsean A., Paulo Ruby Jean', '', '../pdf_files/65995dfae638d-Surface Disinfecting Robot (Using UVC Light).pdf', '2024-09-28', 'Accepted'),
(23, '2175957611', '1', 4, 13, 'Hybrid Orthopedically Handicapped Wheels Maneuver', '2024-09-27', '2018', 'The Hybrid Orthopedically Handicap Wheels Maneuver is eated to inspire people who are orthopedically handicapped or ysically incapacitated. The basic part is the steering whose sic aim is to ensure that the wheels are pointing in the sired directions; ramp, a flat supporting surface tilted at an gle, used as an aid for raising or lowering a load; windshield ich controls a vital operation for the driver during driving all weather even in dusty, rainy, or summer days.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Badeo Debi Ann M., Benitez Baby Diana P., Castillo Carlo M., Cortez Marc Vincent C., Funtilar Richmon D., Lumugdang Rafael P., Salamania RJ Rey S., San Juan John Edzel H., Ogsimer Sonny T.', '', '../pdf_files/65996a06e2e13-Hybrid Orthopedically Handicapped Wheels Maneuver.pdf', '2024-09-28', 'Accepted'),
(24, '7214065929', '1', 7, 14, 'Assesment Of The Products of Gourmet Farm In Tagaytay City', '2024-09-27', '2015', 'Gourmet Farms has survived competition from neighbouring towns and has its own way of sustaining their operation that makes them competitive. The study attempted to focus on how Gourmet Farms was able to sustain their competitiveness in spite of competition of even bigger farm and resorts in their neighborhood. Gourmet Farms has survived competition from neighbouring towns and has its own way of sustaining their operation that makes them competitive. The study attempted to focus on how Gourmet Farms was able to sustain their competitiveness in spite of competition of even bigger farm and resorts in their neighborhood.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Alano, Jay Aflred D., Antolin, Donita B., Retuya, John Clyde C.', '', '../pdf_files/659972d52ad16-Assesment Of The Products of Gourmet Farm In Tagaytay City.docx.pdf', '2024-09-28', 'Accepted'),
(25, '6190378423', '1', 7, 14, 'Quezon City As A Potential Culinary Tourism Destination', '2024-09-27', '2016', 'Culinary Tourism is a type of tourism that tells exploration for foods. It tends to be largely a domestic tourism activity, with consumers travelling places to eat and drink. Culinary Tourism gives travellers a chance to visit a new destination and sample local or regional cuisine. Aside from enjoying the food the tourist will be also educated about local food trends, cooking techniques and food history. It could also drive the local business and restaurateurs to meet the growing demand. Culinary Tourism is about what is unique, authentic and memorable about the delicious stories that regions have to tell. It was also a growth segment and a typically gastronomic tours are increasingly as combined with other activities such a s cultural tours, cycling and walking.  This study aims to share to people and the significance of food in Quezon City to be a Potential Culinary Tourism Destination in addition it aims determine the benefits of Quezon City when it comes to Culinary Tourism.        ', '', '', 'raytos.r.bsinfotech@gmail.com', '  April F. Suaverdez, Janine O. Ortega, Julien Anne R. Bondoc ', '', '../pdf_files/659975cd841db-Quezon As A Potential Culinary Tourism Destination.docx.pdf', '2024-09-28', 'Accepted'),
(26, '9459526989', '1', 1, 2, 'Water Contaminant Detector Application', '2024-09-27', '2019', 'Water is one of the most valuable sources that can sustain life on our planet. However, since it has become scarce little by little due to population, it is uncertain whether the water we are drinking or using is safe in terms of quality.  The researchers of this study titled Water ContamInant Detector Application used the descriptive method of gathering information. The researchers also used different tools such as survey questionnaire to gather necessary data and information for the better development of the system. Additionally, in order to create the application, the researchers gathered information from numerous sources in order to supply the database needed for the application.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Ariel J. Garcia Jr., John Joshua V. Layaog, Abigail J. Purificacion, Marycel G. Zapanta', '', '../pdf_files/659979dd20fed-Water Contaminant Detector Application.docx.pdf', '2024-09-28', 'Accepted'),
(27, '6630943655', '1', 1, 2, 'Smart Xylophone Tutorial App', '2024-09-27', '2018', 'The study aimed to help musicians who want to study how a xylophone works. This application is running through a mobile phone and it needs an actual xylophone or a virtual xylophone on other mobile phones to play. The application filters the background sounds and it would only determine the xylophone\'s sounds. The audio is used as an input that would trasmit through the microphone of the\r\n mobile phone. The software processes the audio that would analyze whether what the bar or note name has been hit by the mallet. With the help of the microphone, it would be received audio which would analyzed and would identify if what note had been hit. The user had to choose a song that they wanted to learn that is being played on the xylophone. At the same time, the application would determine the wrong and right hit of the bars. It also get the time limits of the songs that can be reduced to the total score to determine the progression of the player. This application has a few features and simple screen layout. In the home scree, note names would be displayed based on the song chosen to be played. On the bottom of it would be the visual display of the xylophone serving as a guide on what bar must be hit. The user can choose the level of difficulties to challenge their skills. The user view the result of every play. ', '', '', 'raytos.r.bsinfotech@gmail.com', 'Guevarra, Gian Rey N., Maragana, Reynaldo S., Bernard M. Quizon Jr., Salinas, Tyrone L.', '', '../pdf_files/65997bacd6121-Smart Xylophone Tutorial App.docx.pdf', '2024-09-28', 'Accepted'),
(28, '8135930823', '1', 1, 15, 'The Quality of Life and Resiliency of 4th Year Female BSP Students In Earist Manila During Pandemic', '2024-09-27', '2020', '	The researchers aimed to determine the quality of life and resiliency  of 4th year Female college students in EARIST, Manila in this time of pandemic. Upon knowing the quality of life of the respondents, the are four specific domain which are physical health, psychological health, social relationship, and environment, There is also an environment to indicate how safe it is to be in outdoors when going to school and going back home especially during the Covid pandemic, Obviously the female genders have experience and anxieties on how to deal with the situations.On the other hand, female college students have different ways of resiliency which is the ability to recover and bounce back due to struggle and stress.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Josefina, Irene S. Allorde, Janelle J. Buenaventura, Gretchen T. Villaluz, Daisy ann C. Lutay', '', '../pdf_files/6599801a871e4-The Quality of Life and Resiliency of 4th Year Female BSP Students In Earist Manila During Pandemic.docx.pdf', '2024-09-28', 'Accepted'),
(29, '1704679742', '1', 4, 11, 'Internet Of Things Data Integration System For COVID 19 - Tracing', '2024-09-27', '2021', 'This COVID-19 pandemic is one of the global health crises of our time that we have faced since World War Two. However, this pandemic is more than just a health crisis; it is also a unique social-economic crisis. The global pandemic has completely altered the way things are done, not just in the Philippines but worldwide. Many countries implement their preventive protocol like total lockdown and social distancing. The Philippines Implemented various actions, including community\r\nquarantine in Metro Manila which expanded to Luzon and other parts of the country. Aside from that Philippines also implement preventive measures such as facemask, face shield, and proper hand sanitizing.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Endaya Shiena Mai N., Gatus Mitchie Ren M., Leodin Sario A., Almusura Ariel B., Barbosa Joyce G.,  Santocildes Lawrence Maynard A.', '', '../pdf_files/659ab49b5d72f-INTERNET OF THINGS DATA INTERGRATION SYSTEM FOR COVID 19 - TRACING.pdf', '2024-09-28', 'Accepted'),
(30, '2929713674', '1', 4, 11, 'Automatic UV Light Disinfection Machine', '2024-09-27', '2021', 'Personal protective equipment(PPE), including surgical masks and face shield, is crucially important to the safety of both patients and medical personnel, particularly in the event of infectious pandemics. As the incidence of Coronavirus Disease (COVID-19) is increasing exponentially in the Philippines and worldwide, healthcare providers demand for these necessities is currently outpacing supply. As such, strategies to safely expand the lifespan of the supply of medical equipment are critically important. Some hospitals have already begun using UV-C light to sterilize N95 respirators, but many lack the space or equipment to implement existing protocols. In this study our main mission\r\nis to provide support to healthcare organizations that are looking for alternative methods to extend their reserves of PPE. To alleviate the PPE shortage is to providing a way to sterilize PPE to allow safe daily re-use. This method would be preferred compared to re-use without sterilization.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Baranda Carl John, Dantes Kier P., Embang Smart M., Manzano Mc Ronel Y., Pillas John Allen G., Sumaoang, Paolo A.,  Panganiban Denver O.', '', '../pdf_files/659ab57f0a390-AUTOMATIC UV LIGHT DISINFECTION MACHINE.pdf', '2024-09-28', 'Accepted'),
(31, '6240167932', '1', 4, 13, 'Building Management Power System (BMPS)', '2024-09-27', '2020', 'This research study can effectively manage and monitor many building services in terms of building management. This building management system (BMS) is a complicated device that serves as data center or the brain of whole Building. BMS are using Magnetic contactor as a momentary switch to control the load in the circuit like lights, and motors such as an air conditioning unit, exhaust fan, HVAC, FDAS, and others. By using microcontroller, we use MCU to install the Program or the protocols needed for the BMS, we also use RS485 that can address up to 128 device using two wire half duplex or four wire system full duplex that transmit up to 300 meters at the rate of 10 MB/s and can be extended using repeater up to 3000 meters. The main goal of this study is to provide an overview of the building management system, power efficiency and to identify the new challenges from emerging building infrastructures.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Cubol Gerald M., Castillo Cassandro Lex B., Duray Irvin Bryan U., Mambong Julie Anne S., Morata Sharmaine S., Murillo Arjay P., Navalta Jomar R.', '', '../pdf_files/659ab60f571a5-BUILDING MANAGEMENT POWER SYSTEM (BMPS).pdf', '2024-09-28', 'Accepted'),
(32, '5059095186', '1', 4, 7, 'Wireless Multi-Access With Projection System', '2024-09-27', '2021', 'A projection system that can be used in daily basis such as presenting topic, watching your favorite movie and also expressing your passion through singing. A presentation system having both video and projecting images for viewing by a user and audio for broadcasting sound. The presentation system comprises of projector having a power cable that gets power supply directly from the AC voltage; audio speaker which can be connected via Bluetooth connection; a wireless microphone that has range of 5 meter Bluetooth connection to the speaker; the speaker case which has an adjustable table for projection height adjustment. Making presentation easy by using this projection system, with wide and long range of projection and a loud speaker for better and enhance sound and is equip with roller and a handle for which you can easily carry the equipment. The rise Our system not only supports mobility but also wide screen display. Usability of our system is verified through experimental results and user evaluation.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Dimpas Lesther, Jamin Gabriel, Perez Reza Lyn, Jazon Jean Roann,  Mendez Julius, Bautista Rica Mae, Larona Raven', '', '../pdf_files/659ab72ce7fc7-WIRELESS MULTI-ACCESS WITH PROJECTION SYSTEM .pdf', '2024-09-28', 'Accepted'),
(33, '4325400266', '1', 4, 7, 'Room Disenfecting Management System', '2024-09-27', '2021', 'Room Disinfectant management system agree that careful cleaning and disinfection of environmental surfaces are essential elements of effective infection prevention programs. However, traditional manual cleaning and disinfection practices in area that often suboptimal. This is often due in part to a variety of personnel issues that many Environmental Services departments encounter. Failure to follow manufacturer\'s recommendations for disinfectant use and lack of antimicrobial activity of some disinfectants against healthcare-associated pathogens may also affect the efficacy of disinfection practices.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Probador Lester B., Candole Ryan A., Anthony Anabelle N. ,Cancino Ma. Danica A., Tala Jinky L., Pinga Vincent Martin B.,  Penamora Dustin U.', '', '../pdf_files/659ab80cd30e6-Room Disenfecting Management System - ECE.pdf', '2024-09-28', 'Accepted'),
(34, '8595794519', '1', 4, 7, 'Innovation And Development Of Hybrid Powered Streetlight WIith Surveillance Security', '2024-09-27', '2021', 'An Innovative renewable hybrid microgeneration unit has been designed to be fully embedded into a dedicated LED street lighting system. The key feature of this new concept is the arrangement of a multiple Savonius vertical axis wind turbine into the structure itself of the post. A photovoltaic panel is integrated to contribute to power generation. The energy is collected by a power conversion equipment along with a storage device which ensures the lighting also during windless nights. The main application of this project is the standalone street lighting', '', '', 'raytos.r.bsinfotech@gmail.com', 'Basconcillo, Benji Felis B., Fabillar, Christopher C., De Guzman, Aldren P., Dulay, Allan, Balboa, Marlon R., Lagrada, Jerry II F.,  Coronacion, Karl Kevin, Pempena, Roque Mark Leo', '', '../pdf_files/659ab8c0be70e-INNOVATION AND DEVELOPMENT OF HYBRID POWERED STREETLIGHT WITH SURVELANCE SECURITY - ECE.pdf', '2024-09-28', 'Accepted'),
(35, '8344232910', '1', 4, 7, 'Face Shield With Body Temperature Scanner And Recording System', '2024-09-27', '2020', 'The number increase of COVID-19 cases day by day is alarming. COVID-19 is a life-threatening disease caused by a newly discovered coronavirus. This COVID-19 can lead to pneumonia, respiratory failure, heart problems, liver problems and even death. Symptoms of COVID-19 can range from mild to severe. Fever is one of the highest- frequency or most common symptoms of COVID -19. Because of that, body temperature screening became the major test performed at points of entry in any establishment especially in a hospital setting. Checking temperature upon entering the premises alone is not enough to prevent the virus but the use of non-contact thermal screening technology is reasonably better way to check body temperature and monitoring core body temperatures is a more accurate indicator than the skin thermometers that are subject to variations that sometimes give inaccurate results.\r\n\r\nIn this project, the proponents came up with contact-less body temperature scanning and monitoring to prevent the spread of the virus.\r\n\r\nThe study used the survey method through Google forms for from students, data gathering. Data were collected professionals and community. The researcher gathered data by administering an online survey questionnaire to the said respondents to collect information and data about their opinion and experience after using our prototype design project.\r\n\r\nIn the findings, resulting that the respondents rate the design project as very satisfactory in terms of functionality, usability, maintainability, efficiency and reliability.\r\n', '', '', 'raytos.r.bsinfotech@gmail.com', 'Abella, Odracir Jan S., Pardo, Jeric G., Paula, Jasmin S., Lucero, John Ariel B., Lopez, Jhon Robert F., Canaria, Angelica R., Maning,  Jessa Mae N.', '', '../pdf_files/659ab99065988-FACE SHIELD WITH BODY TEMPERATURE SCANNER AND RECORDING SYSTEM-ECE.pdf', '2024-09-28', 'Accepted'),
(36, '2875489705', '1', 7, 14, 'Acceptability Of German Cuisine To The Filipino Diners', '2024-09-27', '2016', 'Today, Germans still fall back on rich heritage, serving wild game, lamb, pork and beef with old and new ways of preparing them and their side dishes. Popular spices mustard, horseradish and juniper berries, which are found, for instance, in the Lune burger Health. Still, modern German chefs have started to create newer, lighter fare, incorporating traditional foods into their menus. The acceptance of German cuisine to Filipino diners. Considered Taste, Presentation, Aroma and Appearance as a factor, because Filipinos seek food in a sensory quality. One of the biggest Challenges is predicting how it will be accepted by Filipinos. The acceptance of food depends on how the Filipinos will be satisfied on it.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Luis T. Florentino, Jillian B. Javier, Kevin O. Mendoza', '', '../pdf_files/659abf066ce90-Acceptability Of German Cuisine To The Filipino Diners.docx.pdf', '2024-09-28', 'Accepted'),
(37, '4249421567', '1', 1, 16, 'On Complete Derangement; Properties, Relationshhip An Application', '2024-09-27', '2016', 'The value of Mathematics plays an important role in the fast growing world. It used as effective and essential tool in many field including natural sciences. It is divided in different branches and one of its braches is Combinatorial Mathematics. Combinatorial Mathematics is branch of mathematics which is about where everyone could discover many exciting example of things they can count. First combinatorial problems have been studied by ancient Indian, Arabian, and Greek mathematics. Combinatorial Mathematics has many applications in other area of mathematics, including graph theory, coding and cryptography, and probability. The derangement problem was formulated by Pierre Raymond de Montmort in 1708 and solved by him in 1713. Nicholas Bernoulli also solved the problem using inclusion-exclusion principle.', '', '', 'raytos.r.bsinfotech@gmail.com', ' Alaguia, Riden C., Alferez, Shaira H., Luzano, Jomar G.', '', '../pdf_files/659ac18ec0ff5-On Complete Derangement; Properties, Relationshhip An Application.docx (1).pdf', '2024-09-28', 'Accepted'),
(38, '6645679568', '1', 3, 3, 'Sunflower Seed Ice Cream', '2024-09-27', '2020', 'us desserts in climate countries like Philippines. It comes from variety of flavors and colors. Ice Cream in the Philippines was influenced by the Americans. The Philippine version of which is the famous “dirty ice cream” which is asually peddle in the afternoon and serve in a cone or sandwich ban.\r\nSunflower seed is not a common food or snacks among Filipinos. We are only familiar in the flower itself that’s why the researcher come up with the study, to develop a nutritious and new variety of ice cream using sunflower seeds; assessing the acceptability as evaluated by selected respondents and determine if the two groups of respondents differ in perception in terms of appearance, aroma, flavour and texture. We offer this new type of nutritious ice cream.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Rosemarie Anne Soriano Aguilar, Carla May Bagotsay Pagulayan, Retchmon Estaquia Vista', '', '../pdf_files/659ac2e665aff-Sunflower Seed Ice Cream.docx.pdf', '2024-09-28', 'Accepted'),
(39, '2709883351', '1', 6, 10, 'Sili-Kamias Sorbetes', '2024-09-27', '2017', 'Siling labuyo is a small chilli pepper cultivar that developed in the Philippines after the Columbian Exchange. It belongs to the spices capsicum frutescent and is characterized by triangular fruits which grow pointing upwards. The fruits and leaves are used is traditional Philippines Cuisine. The fruit is a pungent ranking from 80,000 to 100,000 heat units in the Scoville Scale. It is something known as a Filipino bird’s eye to differentiate it from the Thai bird’s eye chili. Siling labuyo is an excellent source of Vitamin A and C, it also contains iron, folate, magnesium, fiber, and riboflavin. The pepper also provides capsaicin, which is a chemical compound that triggers the brain to feel spice or heat and has been shown to have anti-inflammatory properties.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Marc Dane Alivario, Cristina V. Baduya, Maria C. Compentente, Karen D. Velarde, Louie Erald Santos, Neal John Ramos', '', '../pdf_files/659ac41a79d35-SILI-KAMIAS SORBETES.docx.pdf', '', 'Not Accepted'),
(40, '2744554562', '1', 1, 1, 'Online Trading System For Agriculture Related Products And Services', '2024-09-27', '2018', 'Agriculture and agribusiness together account for a significant  portion of output in developing economies. The size of agribusiness grows in proportion primary to the size of  agriculture as income rises. Even during the period of falling real commodity prices. Online Trading System is a method that facilitates buying and selling of financial instruments such as mutual funds, equities, bonds, Sovereign gold bonds, derivatives, stocks, ETFs and commodities through an electronic interface. Online Trading has simplified a complex process into a few clicks.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Montefalcon, Uelysar S. Sudo, Ysabella Maria Theresa P. Espedido, Mae Shanti M. Gatela, Marisol L.', '', '../pdf_files/659ac708c265f-Online Trading System For Agriculture Related Products And Services.docx.pdf', '2024-09-28', 'Accepted'),
(41, '8578571764', '1', 3, 3, 'Utilization of Lemon Grass As A Main Ingredients in Preparation in Candy', '2024-09-27', '2018', 'A new Product Development is the term used to describe the complete process of bringing a new product to market. A new product is one that is totally new or different version of something already on the market. New products  are developed because of demand enthused by changing lifestyles, convenience, health or fitness.Developing new product is a challenge to the developer, especially that there are more new existing products are constantly being design and developed. Candy (also called as sweets or lollies) is made by dissolving crystallized sugar in water or milk to form a  syrup, which is boiled until it reaches the desired concentration or starts to caramelize. Candy comes in a wide variety of textures, from soft and chewy to hard and brittle. The texture of candy depends on the ingredients and the temperatures that the candy depends primarily on the sugar concentration. As the syrup is heated, it boils, water evaporates, the sugar concentration increases and the boiling point rises. A given temperature corresponds to a particular sugar concentration.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Rommel DG. Aquino, Ma. Jovilyn T. Alegre, Vladimir A. Eguirra, Nestor B. Lansangan Jr.', '', '../pdf_files/659aca51af763-Utilization of Lemon Grass As A Main Ingredients in Preparation in Candy.docx.pdf', '2024-09-28', 'Accepted'),
(42, '4167290608', '1', 6, 17, 'Inclusion Of Special Education Pupils In The Mainstream', '2024-09-27', '2019', 'Mainstreaming schools are established distinctively for improving special education pupil`s level of learning in regular classroom set up. Particularly, Mainstreaming aims to help children with special needs` progress in their learning outcomes, including their social skills, academic achievement and personal development. Mainstreaming targets to establish more effective schools that recognize students` difficulties in learning; hence, effective schools support the need for appropriate modifications. While mainstreaming is beneficial for developing the competencies and skills of both students and teachers alike, implementing a program of mainstreaming will most likely put under considerable pressure brought about by the required environmental rearrangement. Mainstreaming wherein individual with disability is integrated or included in a least restrictive environment together with his/her regular classmates. Before a child with special needs enters special educations schools he/she will undergo an assessment process for a placement consideration, as well as in entering mainstreaming education. Researchers believe that teacher will be in the best position to know and help support the learning process of children. Teachers are necessary for effectively including students with special needs in the regular classes. It requires frequent obligation for the benefit of all students in the class.\r\nHowever, general education teachers in the mainstreaming experiencing variety of problems in handling special education pupils in the selected public and private schools Quezon City.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Concan, Amelyn B., Bajar, Sir Enrickson L., Gozun, Donna Marie C., Mendoza, Elizabeth V., Mescallado, Maylyn G., Rueda, Carmela O., Tenerife, Jayanara A.', '', '../pdf_files/659acd2808a0e-Inclusion Of Special Education Pupils In The Mainstream.docx.pdf', '2024-09-28', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(43, '2351759511', '1', 4, 11, 'INTERNET OF THINGS DATA INTEGRATION SYSTEM FOR COVID 19 TRACING', '2024-09-27', '2017', 'It has been a year since the COVID-19 virus caused technology to take on new apllications in order to prevent covid-19 virus transmissions.  We are all aware that the DOH has developed a guideline to combat the spread of Covid-19. By wearing a facemask and face shield to protect ourselves, install\r\n an alcohol dispencer, check the temperature at each entranc to the establishment, and answer the covid-19 form at every place we viwsit. However, as time passes, we notice that the protocol that has been implemented has a disadvantage, similar to Covid-19 form where establishments allowing the ball-pen to be used by anyone and all the Covid-19 froms used where just put it somehwere else or sometimes in too much quantity it is simply discarded. As a result, the task of contact tracing employees has become more complex. As an ECE student, we believe that proper aoidance and monitoring are essential in preventing this covid-19, which is why our team developed and integrated the common preventive measures that will help to minimize human interaction, which is refered to INTERNET OF THINGS.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Endaya,Shiena Mai N., Gatus, Mitchie Ren M., Leodin, Sario A. Almusura, Ariel B., Barbosa, Joyce G.', '', '../pdf_files/659ad01cd6f7c-INTERNET OF THINGS DATA INTEGRATION SYSTEM FOR COVID 19 TRACING.docx.pdf', '2024-09-28', 'Accepted'),
(45, '5816511669', '1', 8, 18, 'Leadership Skills OF The Chairman In Barangay 126 Caloocan City An Assessment', '2024-09-27', '2017', 'Effective leadership is characterized by attention to the welfare of the citizens. Lipham and his colleagues have developed a four factor theory ofleadership. Thefirst is structured leadership. It indicates taking immediate action on important issues, delegating tasks to subordinates, stressing organizational goals and monitoring implementation of decisions. This leadership behavior indicates that the leader lets the subordinates know what is expected of them, provides specific guidelines concerning what is to be done and how to do it, sets performance standards, schedules and coordinates work.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Aldrin Manalansan, Angelo Mateo, Rolando Navarro, Noannille Samson', '', '../pdf_files/659d56f1d1ed7-Leadership Skills OF The Chairman In Barangay 126 Caloocan City_ An Assessment.pdf', '2024-09-28', 'Accepted'),
(46, '1960435178', '1', 8, 18, 'FIRE PREVENTION AND CONTROL PROGRAM OF THE BUREAU OF FIRE PROTECTION IN ZONE 33, BARANGAY 327 STA. CRUZ, MANILA', '2024-09-27', '2017', 'The important things of using how to Learn effectiveness reactions in the event of fire is essential to a successful fire prevention program. Poz more information of the fire is chemical reaction needs three elements of the triangle (Fuel, Heat, and Oxygen), that causes of fire, To reduce the impact and possibility of fire, we should place the proper shelves of fire hazards make sure after use the LPG tank is always closed, Our human society could not exist without fire and we often forget it\'s positive impacts A fire may be accidentally started, but that\'s enough information to help your analysis. You\'ll need to know why the accident occurred. Examples: electrical wiring such as overloading jumpers overheat open flames like lighted candles, but the cause might have been due to individuals lack of fire safety knowledge, poor judgment or perhaps. To incorporate fire prevention devices, alarm and exit; frequently the cases of fires are listed as being accidental, careless, defective equipment, arson, natural so on. To isolate equipment and materials that could cause a fire or explode if exposed to fire.', '', '', 'raytos.r.bsinfotech@gmail.com', 'John Rikko Bautista, Jay Manuel Quizada, Duanne Martin De Guzman, Abdulrahman Mamasaranao ', '', '../pdf_files/659d5b2fae68d-FIRE PREVENTION AND CONTROL PROGRAM OF THE BUREAU OF FIRE PROTECTION IN ZONE 33, BARANGAY 327 STA.pdf', '2024-09-28', 'Accepted'),
(47, '2729140530', '1', 8, 18, 'Response Capabilities On Natural Disaster Of Police Station 3, Manila', '2024-09-27', '2018', 'The preparedness of everyonevis necessary when there are alarmsvand announcements of incidents andvcalamities. Oftentimes, the peoplevmay to seek help from the Local Government Units such as:Barangay Officials, Philippine National Police, Non-Government Units, church, the Municipality itself. The people in Metro Manila,\r\nspecifically in the City of Manila have witnessed series of typhoons, floods, earthquakes that varied in strength, duration, and impacts. According to a study conducted by the Geneva-based United Nations Office for Disaster Risk Reduction, the Philippines is the fourth most disaster prone country in the world. It also revealed\r\nthat the Philippines has alwaysbeen one of the top ten countries with the most number of people afflicted by such disasters. In the reports made by Joint Typhoon\r\nWarning Center, annually, approximately 80 typhoons develop above tropical waters, of which nineteen enter the Philippine region and six to nine make landfall. In fact, it is the country most exposed to tropical storms in the world.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Jessie De Mesa, John Cen Nanzan, Willy Boy Ramos, Mark Romylou  Villanueva', '', '../pdf_files/659d5bf293a32-Response Capabilities On Natural Disaster Of Police Station 3, Manila.pdf', '2024-09-28', 'Accepted'),
(48, '7501005430', '1', 8, 18, 'Factors Influencing Harlotry Practice In 23 Hunters Street Barangay Tatalon, Quezon City', '2024-09-27', '2018', 'Harlotry is the exchange of sexual acts for payment. Harlotry dates back at least as far as ancient Greece. Today, street hariotry and the various methods to control it, have sparked heated debates among law enforcement agencies and residential and business communities. In recent years, numerous task forces and committees have been established to study harlotry and its effect on businesses, communities and individuals. All committees agree that the effects of harlotry are harmful, but their proposed solutions range from increasing the punitive nature of harlotry related laws to legalizing or decriminalizing hariotry and implementing more social programs. Harlotry has been called the world\'s oldest \"profession.\" In reality, it is the world\'s oldest \"oppression\" and continues to be one of the most overlooked homes rights abuses of the planet today. Harlorty of women is a particularly lethal form of violence against women, and a violation of  matchaman rights.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Joemar Alias, Merry Chris Gonzales, Agnes Morong, Gina Tabones', '', '../pdf_files/659d5c5e36714-Factors Influencing Harlotry Practice In 23 Hunters Street Barangay Tatalon, Quezon City.pdf', '2024-09-28', 'Accepted'),
(49, '7086927026', '1', 5, 19, 'Implementation Of Juvenile Curfew Ordinance In Barangay Malanday, Valenzuela City', '2024-09-27', '2018', 'Curfew ordinances in many cities restrict the hours that juveniles may be on the streets or in public places at night. It is justified in many cities or municipalities as a simple method to not only reduce opportunities for Juvenile to commit crimes but also to protect them from becoming crime victims. Curfews are promoted as beneficial to law enforcement: they give police as well as barangay council an additional control over the presence and behavior of juveniles on the street during curfew hours. They are also endorsed 43 a valuable complement to parental supervision: they provide community support to parents placing limits on the hours that their children may be out at night.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Renford Agabao, Peter John Sumalinog, Rene Tolingin, Rey Zamudio', '', '../pdf_files/659d5cd632fb6-Implementation Of Juvenile Curfew Ordinance In Barangay Malanday, Valenzuela City.pdf', '2024-09-28', 'Accepted'),
(51, '9225983121', '1', 5, 19, 'PROPERTY MANAGEMENT SERVICES OF EULOGIO “AMANG” RODRIGUEZ INSTITUTE OF SCIENCE AND TECHNOLOGY', '2024-09-27', '2018', 'All government institutions are enjoined to observe strictly these standards on property utilization. However, these imposed rules and regulations on property management are sometimes or oftentimes not observed by the government institutions. They usually resort to property practices which run counter with the standards thus resulting to uneconomical and inefficient property utilization. These property practices are the effects of poor property planning or no planning at all. According to Nigro (1987) property planning in supply management is important because the needed materials, supplies and equipment must be on hand if the institution programs are to be carried out successfully.\r\n', '', '', 'raytos.r.bsinfotech@gmail.com', 'Laurio, Genevy R., Lemoneras, Marah Mae P., Matining, Rezil F., Paderan, Joseph L. ', '', '../pdf_files/659d5e68e20f5-PROPERTY MANAGEMENT SERVICES OF EULOGIO “AMANG” RODRIGUEZ INSTITUTE OF SCIENCE AND TECHNOLOGY AN ASSESSMENT-CPAC.pdf', '2024-09-28', 'Accepted'),
(53, '4898743024', '1', 5, 19, 'Management Practice and Conflict Management Styles of the Administrators in Earist Manila', '2024-09-27', '2018', 'Management plays a unique role in modern society. It regulates our productive activities achieve the objectives of an organization or institution. Arun Kumar & Rachara Unwick and Brech by saying that no ideology, no political important human activities within an organization. From ensure the coordination of individual efforts. As society Sharma (2000) emphasized the management principles of theory can win greater output with lesser efforts, but only sound management. Managing is one of the most the time human beings began firming social organizations to accomplish aims and objectives they could not accomplish as individuals, managing has been essential to continuously, relied on group effort, and as many organized groups have become large, the task of managers has been increasing in importance and complexity. Henceforth, good management practices has become crucial in the way managers manage complex organizations (Olum, 2004).\r\n\r\nIn fact, higher education is provided by facilities owned by the national and local government, private individuals or corporations, religious groups, state universities. According to the latest figures from the Commission on Higher Education, revealed that as of August 2010, there were 1,573 private and 607 public universities and colleges in the Philippines.\r\n', '', '', 'raytos.r.bsinfotech@gmail.com', 'Andales, Jerald B., Bagang, Riyadh B., Jone, Emerita E., Novida, Danielle B.', '', '../pdf_files/659d5ef7e25af-Management Practice and Conflict Management styles of the Administrators in Earist Manila - CPAC.pdf', '2024-09-28', 'Accepted'),
(54, '1811755222', '1', 5, 19, 'The Role of Non-Goverment Organization in the Governance and Development of Barangay 677, Zone 74, District V, City of Manila', '2024-09-27', '2018', 'This study aimed to assess several aspects on the role Non-Government organization the Governance and which is the smallest local of Development of barangay, government unit. This design tried to determine the actual assistance that Non-Governmental Organization has given to the barangay and if there are, factors that influencing the accomplishment of its purpose as provided by law. This method is often intent to improve the process of compliance. The result of this evaluation have provided program managers direction and enabled those ways of modification of the mechanics of implementation so that the objectives of the programs will effectively fulfill. Included in the study is, the evaluation of the assistance given by the NGO to the barangay.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Arboleda, Melody T., Lopez, Crishiella A., Napalit, Ellen C., Padronzolan, Loida O. ', '', '../pdf_files/659d60944a9b8-The Role of Non-Goverment Organization in the Governance and Development of Barangay 677, Zone 74, District V, City of Manila - CPAC.pdf', '2024-09-28', 'Accepted'),
(55, '8640798709', '1', 5, 19, 'Perception on Extrajudicial killing in Barangay 105 zone 8 in District I, Tondo Manila', '2024-09-27', '2017', 'Alleged criminals killed in police operations are another disturbing matter. The rise in incidents of drug suspects reportedly killed while trying to resist arrest are too dramatic to be given a presumption of regularity. A number have telltale signs of a rubout as acknowledged by the police themselves. What makes today\'s EJKs particularly complicated is that the victims are considered undesirable members of\r\nsociety. Unlike activists or revolutionaries, drug addicts and pushers have no redeeming quality. These are not idealists being killed for exercising their constitutional rights or addressing legitimate social grievances. Druggies, for\r\nmost people, are the scum of the earth that should be wiped out from\r\nexistence.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Buce, Sheena M., Dulfo, Riza Joy T., Pelonio, Jolina N., Servo,  Melisa S.', '', '../pdf_files/659d614f6d1cc-Perception on Extrajudicial killing in Barangay 105 zone 8 in district I, Tondo Manila - CPAC.pdf', '2024-09-28', 'Accepted'),
(56, '9708587233', '1', 5, 19, 'THE EFFCTIVENESS OF SPORTS DEVELOPMENT IN BARANGAY 628, STA.MESA, MANILA; BASIS FOR PHYSICAL INTERVENTION PROGRAM', '2024-09-27', '2017', 'Through the different period,physical activity has always been part of individual and social life of human beings. It plays a great role in family connections and social activities. Physical activities through sports bring happiness and satisfaction for all family members. The strong progress of youth in sport is a fundamental building block of our society, for some reason, sport is being used as a\r\ntool for peace building. Philippines passion for sports is enormous. Filipinos excel in so many sports locally and internationally.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Conching, Jomarie C., Dela Cruz, Mark John C., Francisco, Rengie  T., Laxamana, Michael Jr. R., Mendoza, Richard C.', '', '../pdf_files/659d61c9d4b1f-THE EFFCTIVENESS OF SPORTS DEVELOPMENT IN BARANGAY 628, STA.MESA, MANILA; BASIS FOR PHYSICAL INTERVENTION PROGRAM - CPAC.pdf', '2024-09-28', 'Accepted'),
(57, '9996062995', '1', 7, 20, 'PROMOTIONAL ACTIVITIES IMPLEMENTED IN SELECTED NATURAL FOOD RESTAURANTS IN TAGUIG CITY', '2024-09-27', '2019', 'Promotional activities is the strategy used by many companies because they include the advertising, personal selling of telemarketing, publicity, short term sales promotion and direct marketing. One can use any combination of these methods to target your customers. The right promotional mix will help you satisfy customers\' needs, increase sales, improve results and increase ability to reach multiple customers within a target market. In relation to this, the researchers aim to know the Promotional Activities implemented in selected food in Taguig City. The focus of the study was the The Wholesome Table located in 30th Bonifacio High Street, Taguig Metro Manila and Recovery Food located in 32nd St, Taguig, Metro Manila. The researchers wanted to know the promotional activities implemented in selected restaurants in Taguig City problems encountered. The to the ascertain the researchers hope to know possible solution in the problems encountered based on the selected restaurants.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Mark Gauden V. Atog, Sophia Cama Castro, Jemalyn Exclamado,  Jasmine Cipriano Idjao', '', '../pdf_files/659d64d85bf7a-PROMOTIONAL ACTIVITIES IMPLEMENTED IN SELECTED NATURAL FOOD RESTAURANTS IN TAGUIG CITY.pdf', '2024-09-28', 'Accepted'),
(58, '2869292061', '1', 7, 21, 'JACKFRUIT SQUASH FLOWER AND ROSE WINE', '2024-09-27', '2016', 'The researchers conducted this study in order develop and jackfruit. prepare squash wine flowers, out and of to the combination of rose petals as major Ingredients. It was also desire of the proponents to develop another variety of wine not yet found in the market yet nutritious because of the major ingredients used and find out the nutrition facts of the finished product.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Darwin D. Blanco, Joselle M. Aggabao, Patrick John T. Pablo', '', '../pdf_files/659d656c2fc3a-JACKFRUIT SQUASH FLOWER AND ROSE WINE.pdf', '2024-09-28', 'Accepted'),
(59, '6718087245', '1', 7, 21, 'MANGO AND WILD RASPBERRY WINE', '2024-09-27', '2018', 'The various fruit-like flavors delectable in wine contribute nuances to the sweetness taste. It\'s fun ] trying detect different fruit characteristics, such as berries, plums, apples, pears. The researchers decided to conduct this study in order to prepare another wine using Mango with Raspberry and offer another variant and made available in the market. It is also the hope and desire of the proponents to utilize other fruits in the preparation of wine.', '', '', 'raytos.r.bsinfotech@gmail.com', 'John Rafael R. Lumba, Ralph Gerald Paul E. Amparado', '', '../pdf_files/659d6601845b9-MANGO AND WILD RASPBERRY WINE.pdf', '2024-09-28', 'Accepted'),
(60, '2487129941', '1', 7, 21, 'MULBERRIES AND RAMBUTAN WINE', '2024-09-27', '2019', 'Rambutan is native to tropical Southeast Asia and commonly throughout Indonesia, Malaysia, Thailand, Vietnam, grown Cambodia and the Philippines. It has spread from there to various parts of Asia, Africa, Oceania and Central America. The widest variety of cultivars, wild and cultivated, is found in Malaysia. The researchers conducted this study in order to develop a unique wine using mulberries and rambutan offer another variant to those who are wine lovers.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Mayca P. Ribot, Princess Joy P. Mendoza, Ronald M. Burgos', '', '../pdf_files/659d668649e86-MULBERRIES AND RAMBUTAN WINE.pdf', '2024-09-28', 'Accepted'),
(61, '3403093616', '1', 7, 22, 'AN ASSESSMENT OF THE CRUISING EXPERIENCE OF THE HOSPITALITY GRADUATES IN SELECTED HIGHER  EDUCATIONAL INSTITUTION', '2024-09-27', '2016', 'Since cruises are all- inclusive when it comes to passenger\'s room/board, food, and transportation, passengers save quite a bit as it is. When cruising, it is easy to keep costs low, while having the freedom to customize the trip via excursions and activities, depending on the budget and goals.\r\nThe researchers conducted, \"Cruising Experience of CHM Hospitality Graduates in Selected Higher Educational Institution\", to assess the importance of having experience for BSHM-CO students for the acquisition of more knowledge. It is likewise the desire of the proponents to have a better understanding of Cruising experience as future cruise liners.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Septembermie Grace Cruz, Sebasthian Josh Maniego, Alyzza S. Law, Honey Grace C. Tumbokon', '', '../pdf_files/659d674ae9026-AN ASSESSMENT OF THE CRUISING EXPERIENCE OF THE HOSPITALITY GRADUATES IN SELECTED HIGHER EDUCATIONAL INSTITUTION.pdf', '2024-09-28', 'Accepted'),
(62, '6584026759', '1', 4, 7, 'INNOVATION AND DEVELOPMENT OF HYBRID POWERED STREE', '2024-09-27', '2018', 'This paper will present the Innovation and Development of a Hybrid Powered Streetlight with Surveillance Security that can be used in rural areas. This device is powered by solar and wind energy, all of which are renewable sources of energy. Added to that, it has advanced technology to convert into electricity, and has a capability of charging. This device can be used to capture footage of its surroundings using a surveillance camera that operates 24 hours a day, seven days a week. The\r\ndevice has modular framework that can be stacked or rearranged in various formations, is easy to transfer, navigate, and reassembled for flexibility. Enabling the device to be relocated and moved to a location where it is expected to secure access to this eco-friendly.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Basconcillo, Benji Felis B., Fabillar, Christopher C., De Guzman, Aldren P., Dulay, Allan, Balboa, Marlon R., Lagrada, Jerry II F.,', '', '../pdf_files/659d6bb2d31fe-INNOVATION AND DEVELOPMENT OF HYBRID POWERED STREE.pdf', '2024-09-28', 'Accepted'),
(63, '4516476255', '1', 4, 13, 'ROAD BARRIER WITH GSM MODULED POWERED BYSOLARENERGY', '2024-09-27', '2020', 'In view of this, we propose road barrier with GSM module powered by solar energy so that the system can promptly determine whether the accident occurred according to the posture information of the vehicle, and is determine to achieve a timely warning when the accident happened. The research is directed to the above problems and aims to provide a road barrier for landslide and vehicle accident exact location emergency system and also preventing severe damage. In the event of an accident, it is convenient to automatically locate the location of the accident automatically send a distress message. ', '', '', 'raytos.r.bsinfotech@gmail.com', 'Kieran S. Mañalac, Fiel Symon Berdejo, Claudio II L. Barria, Jerome A Cornilez, Deither S. Nacanan, Lemark Q. Nava,  Laurence L Lasquite,  Soharto M. Bucua', '', '../pdf_files/659d6cdb38812-ROAD BARRIER WITH GSM MODULED POWERED BY SOLAR ENE.pdf', '2024-09-28', 'Accepted'),
(64, '5680908253', '1', 4, 11, 'MICROCONTROLLER BASED INTERNET OF THINGS DATA ACQUISITION FOR MONITORING AND CONTROL SYSTEM USING CLOUD PLATFORM', '2024-09-27', '2021', 'The microcontroller serves as the overall control unit of the device component present on the prototype. It is connected to every other part of the prototype and executed a program that enables\r\ncommunication with different system features. As part of the system, the prototype comprises a microprocessor, DAC converter, power transistors, HMI, Wi-Fi module, a powerful development tool\r\nfor programming and debugging, and software for coding.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Banila Kevin, Ferranco Spencer, Herreros Erica, Papa John Vince, Roldan Haideza, Serquiña Rica Joy, Villarin Josef, Mackenzie Louis', '', '../pdf_files/659d6fc5846c7-MICROCONTROLLER BASED INTERNET OF THINGS DATA ACQUISITION FOR MONITORING AND CONTROL SYSTEM USING CLOUD PLATFORM.pdf', '2024-09-28', 'Accepted'),
(67, '1337397493', '1', 4, 7, 'Paperless Conferencing System', '2024-09-27', '2020', 'Paperless conference system, a system that can be used at meetings  and presentations. Presentations can be projected to the screen  by sending their files through the system via smartphones or  laptops wirelessly. Paperless Conference system uses peer to peer  \r\n(PTP) as its server network. Using the system makes it easier to  present reports in meetings or class presentations. Currently we  are facing pandemic we must keep distance and avoid close contact  to prevent the spread of the virus. In order to adopt in our  current situation many services transformed their way of  transactions from manual transactions to automated using  applications in our smartphones or desktop/laptop. Now, we came  up on an idea to innovate projector into a Paperless conference  system to ease of access and at the same time follow covid  protocols.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Arcena, Robert Renzo Hernadez, Marco Gabriel Soriano, Bryant Christian Silvano, Jenalyn Malunas, ramil Obenario, John Michael Permejo, Jonard', '', '../pdf_files/659eb6e796e23-Paperless Conferencing System.docx.pdf', '2024-09-28', 'Accepted'),
(68, '6159426200', '1', 5, 19, 'PUBLIC PERCEPTIONS OF THE AQUINO ADMINISTRATION IN ADDRESSING CRIMINALITY IN METRO MANILA', '2024-09-27', '2015', 'Administration is an organizational process concerned with the implementation of objective and plans and internal operating efficiency. It is aggregate of those persons whose hands reigns of the government are placed for the time being.\r\n\r\nGovernment is described as the repository of confidence and power of the people delegated by then for a fixed period of time for the express purpose of identifying, mobilizing, organizing, guiding and directing all available resources, human and other, to facilitate planned and participatory transformation of their society towards enhanced well-being of its people, via just enjoyment of all its needs, rights, seperations and sustainable peace.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Camu Monica, Fulgencio Bryan, Labrador Tiffany, Lagas Rhea Ivy', '', '../pdf_files/659eba6338e68-PUBLIC PERCEPTIONS OF THE AQUINO ADMINISTRATION IN ADDRESSING CRIMINALITY IN METRO MANILA.pdf', '2024-09-28', 'Accepted'),
(71, '7437603904', '1', 6, 24, 'Designing an Aquaponics’ System Integrated with a Solar- Powered Arduino Aquatic Feeder in Eulogio \"Amang\" Rodriguez Institute of Science and Technology', '2024-09-27', '2023', 'Aquaponics is a closed-loop, fresh water recirculating system where fish and plants coexist in perfect harmony. the outside.\r\nFish food, a small amount of replacement water, and electricity for lighting and heating the water are the inputs to an aquaponics system. Aquaponics utilizes far less water than soil-based systems to grow plants, making it especially suitable for arid locations. In actuality, the only way water is lost from an aquaponics system is through plant transpiration and evaporation. Although there are many different types of aquaponic systems, this one is powered by an Arduino Uno, which controls sensors including temperature, pH, and water label sensors. These sensors keep an eye on the aquaponics system to regulate the water\'s acidity level and manage the water cycle that circulates around the plant. Because the solar panel collects energy to charge the battery, aquaponics makes sense. Thus, we made use of survey data that indicated that 90% of students felt that developing aquaponic systems is beneficial for students at the College of Earist. This provided the researchers with sufficient proof to support their claims. As a result, in this context, existing activities are examined in light of their technical qualities, financial sustainability, and long-term advantages.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Concan, Amelyn B., Bajar, Sir Enrickson L., Gozun, Donna Marie C., Mendoza, Elizabeth V., Mescallado, Maylyn G., Rueda, Carmela O.,  Tenerife, Jayanara A.', '', '../pdf_files/65aa0dd9d92d9-JACKFRUIT SQUASH FLOWER AND ROSE WINE.pdf', '2024-09-28', 'Accepted'),
(72, '9922883107', '1', 2, 23, 'RMC 3N1 BAG: THE FUSION THE BACKPACK, SLING BAG, AND BELT BAG', '2024-09-27', '2022', 'This study examines the RMC 3n1 Bag, a versatile and innovative backpack that combines the functionality of a backpack, sling bag, and fanny pack. The research aims to examine the acceptability and usability of the RMC 3n1 Bag among different user groups, including students, commuters, and travelers. The study utilized surveys to gather data on user perceptions and experiences with the bag. The findings reveal that the RMC 3n1 Bag is highly acceptable in terms of aesthetics, functionality, efficiency, usability, and pricing. Respondents appreciate its adaptability to various occasions and the convenience of detaching and attaching different components. However, some minor design improvements are recommended to enhance certain aspects of the bag. Overall, this study emphasizes the significance of product enhancement and user-centered design in creating a versatile bag that meets the diverse needs of modem users. The study recommends further product enhancements based on user feedback to optimize the bag\'s design and ensure customer satisfaction. The findings contribute to the understanding of consumer preferences and the development of innovative bag designs for the modern market.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Ralph Andrei Marinas, Mark Laudinez, Christopher Bandiez', '', '../pdf_files/65aca5c2ad8ca-RMC 3N1 BAG_ THE FUSION THE BACKPACK, SLING BAG, AND BELT BAG.docx.pdf', '2024-09-28', 'Accepted'),
(73, '8877342866', '1', 2, 23, 'FOLDEX: AN EXPANDABLE ARTIST TOTE BAG FOR MORE EXTENSIVE AND ECONOMICAL USE', '2024-09-27', '2023', 'This study examines the RMC 3n1 Bag, a versatile and innovative backpack that combines the functionality of a backpack, sling bag, and fanny pack. The research aims to examine the acceptability and usability of the RMC 3n1 Bag among different user groups, including students, commuters, and travelers. The study utilized surveys to gather data on user perceptions and experiences with the bag. The findings reveal that the RMC 3n1 Bag is highly acceptable in terms of aesthetics, functionality, efficiency, usability, and pricing. Respondents appreciate its adaptability to various occasions and the convenience of detaching and attaching different components. However, some minor design improvements are recommended to enhance certain aspects of the bag. Overall, this study emphasizes the significance of product enhancement and user-centered design in creating a versatile bag that meets the diverse needs of modem users. The study recommends further product enhancements based on user feedback to optimize the bag\'s design and ensure customer satisfaction. The findings contribute to the understanding of consumer preferences and the development of innovative bag designs for the modern market.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Argean Khey Aguinaga, Jejomar Calub, Ezekiel Requilman', '', '../pdf_files/65aca9689dc91-FOLDEX_ AN EXPANDABLE ARTIST TOTE BAG FOR MORE EXTENSIVE AND ECONOMICAL USE.docx.pdf', '2024-09-28', 'Accepted'),
(74, '5564942746', '1', 2, 23, 'EPIKO: A LOGIC AND DEDUCTION BOARD GAME BASED ON PHILIPPINES MYTHOLOGICAL CREATURES', '2024-09-27', '2023', 'EPIKO is an innovative logic and deduction board game that draws inspiration from the rich varieties of the Philippines\' mythological creatures. This thesis explores the conceptualization, design, and development of EPIKO, aiming to provide an engaging and immersive gaming experience while promoting cultural awareness and appreciation of the country\'s folklore. The game combines elements of strategy, and deduction, offering players an opportunity to interact with and learn about the diverse mythological creatures of the Philippines.\r\n\r\nThe design and development process involved iterative prototyping and playtesting, refining the game mechanics to provide a balanced and enjoyable experience for players. Furthermore, the thesis discusses the cultural impact and significance of EPIKO. By showcasing the mythological creatures in an interactive and engaging format, the game contributes to the preservation and dissemination of the\r\nPhilippines\' folklore, particularly among younger generations. It also serves as a platform for cultural exchange and appreciation, introducing players from different backgrounds to the diverse narratives and mythical beings that shape the cultural identity of the Philippines.\r\n\r\nOverall, EPIKO represents a fusion of entertainment, education, and cultural preservation, offering an immersive gameplay experience that intertwines strategy, deduction, and folklores. The thesis explores the development of this logic and deduction board game, highlighting its cultural relevance and potential to promote awareness and appreciation of the Philippines\' mythological creatures among players of all ages and backgrounds.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Adrian Corpuz, John Ernie Domino, Sherwin Magdaong', '', '../pdf_files/65acb04ea0598-EPIKO_ A LOGIC AND DEDUCTION BOARD GAME BASED ON PHILIPPINES MYTHOLOGICAL CREATURES.docx.pdf', '2024-09-28', 'Accepted'),
(75, '5843666600', '1', 2, 23, 'AEROPILLOW: TRAVEL NECK PILLOW', '2024-09-27', '2022', 'The primary objective of this thesis is to design a portable gadget with four various functions that can be extremely helpful for both adults and children in their day-to-day struggles. This device would be usable during any trip experience like in vehicle, airplane, train, ship or you are in a public place. The main enemies of the average commuter who might make them feel tired during daily travel can be relieved by AeroPillow, which can provide comfort during a power sleep. With those uncomfortable power nap position that can cause neck pain , hot seat that makes you tired and look unhygienic, smoke of those multiple car that you may inhale and the virus that’s keep floating in the free air that can cause of sickness and the hot sun that you may encounter while waiting for a transportation. \r\nThe Genzzy Company developed an innovative product called AeroPillow which is a neck pillow with the incredible usefulness, comfy, and portability necessary for a unique travel experience that will help alleviate discomfort, bad postures, and tiredness when traveling. AeroPillow gives you a unique experience that improves your rest through to its softness and neck support. And we are assuredly needed by many peoples like travelers, students, professionals, and commuters who like to cover themselves while napping and feel more comfortable sleeping even in hot weather. \r\nAeroPillow is 100% made of memory foam perfectly easing neck strain when you\'re moving. And more feel comfortable as you travel with soft fabric and perfect partner for a Built-in Hoodie, detachable mask, when you are in \"do not disturb\" mode and with the rechargeable mini fan if you’re not using the fan you can hide the mini fan inside the pillow. The Aeropillow provide benefits with the daily life of users. ', '', '', 'raytos.r.bsinfotech@gmail.com', 'Glenn Abion, Mencho Oliver, Cherish Rasing', '', '../pdf_files/65acb66fa231b-AEROPILLOW_ TRAVEL NECK PILLOW.docx.pdf', '2024-09-28', 'Accepted'),
(76, '2910580442', '1', 2, 23, 'INCORPORATING ETHNIC PATTERNS WITH CONTEMPORARY GRAPHIC DESIGN TO APPAREL: AN INNOVAYION', '2024-09-27', '2023', 'In the rapidly shifting perspectives of future generations. The Kiangan Weavers, a group of Ifugao\'s, tried and never gave up making ethnic textiles as a proactive way toward preserving their culture in the textile industry. Researchers studied the purchasing process of consumers and the level of acceptance that consumers across all levels provided to the product\'s effectiveness. The researchers and respondents are aware of all the product appropriations in the apparel.\r\n\r\nThe current study focuses on the incorporation of ethnic patterns into apparel from the perspectives of Kiangan weavers and customers in mind. Numerous suggestions and recommendations, accompanied by the research\'s findings, were considered and included.\r\n\r\nIncorporating ethnic pattems and contemporary graphic design is a great concept to preserve the nation\'s rich culture and help the generation support local products. Ethnic textiles can be used for more than just fashion and can be made into functional, innovative, and modernized products that benefit weavers to increase sales and production.\r\n\r\nApparel has gained immense value in the market, thanks to society\'s changing perception over the years. Hats, clothes, and bags worn on the body are now highly acceptable and in demand. Today\'s timeliness and relevance have given rise to a new platform for apparel that showcases identity and innovation. Students, professionals, and travelers want practical and creative products to make their daily activities easier and more comfortable.', '', '', 'raytos.r.bsinfotech@gmail.com', 'Allones, Hyna Nazen L., Enciso, John Dexter A., Madaya, Juaymah M.', '', '../pdf_files/65acba68408fe-INCORPORATING ETHNIC PATTERNS WITH CONTEMPORARY GRAPHIC DESIGN TO APPAREL_ AN INNOVAYION--CAFA.pdf', '2024-09-28', 'Accepted'),
(77, '7799990259', '1', 4, 11, 'Effectiveness of Interior Designing in Architectural Design', '2024-09-27', '2021', 'aaaa', '', '', 'raytos.r.bsinfotech@gmail.com', 'aaa', '', '../pdf_files/65b2055ac0e01-INCORPORATING ETHNIC PATTERNS WITH CONTEMPORARY GRAPHIC DESIGN TO APPAREL_ AN INNOVAYION--CAFA.pdf', '2024-09-28', 'Accepted'),
(80, '8787613466', '1', 1, 1, 'aaa', '2024-09-27', '2021', 'a', '', '', 'raytos.r.bsinfotech@gmail.com', 'aaa', '', '../pdf_files/65b20cf111fdf-QUIZ_Group#5.pdf', '2024-09-28', 'Accepted'),
(82, '7117949394', '1', 1, 1, 'Mobile Application For Emergency Calls', '2024-09-27', '2019', 'dadadsa', '', '', 'raytos.r.bsinfotech@gmail.com', 'sadasdsas', '', '../pdf_files/66eeb62af0e16-a mobile application for emergency calls.pdf', '2024-09-28', 'Accepted'),
(98, '1616172383', '1', 1, 1, 'Mobile Application For Emergency Calls', '2024-09-27', '2003', '', '', 'The Six Core Claims of \nGlobalization\nSummary and Examples1. Globalization Is About \nLiberalization and Global \nIntegration of Markets•Globalization is driven by the integration of \nmarkets, not by an ideology. It results from \nthe interactions of markets, often framed as a \nmoral imperative, like free trade.\n•Example: WTO agreements reduce trade \nbarriers and promote market integration.2. Globalization Is Inevitable and \nIrreversible\n•Globalization is seen as an unstoppable force \nshaped by historical and market principles. It \nis embraced as a natural development.\n•Example: The 2008 financial crisis spread \nglobally, showing how interconnected markets \nare.3. Nobody Is in Charge of \nGlobalization\n•Globalization is decentralized. No single \ngovernment, institution, or entity controls it. It \nevolves organically from interactions in trade, \ncommunication, and technology.\n•Example: Cryptocurrencies like Bitcoin operate \nwithout centralized control.4. Globalization Benefits Everyone\n•Globalization provides opportunities for \neconomic growth, investment, and \ntechnological innovation, especially in \ndeveloping countries.\n•Example: India\'s growth in the IT sector due to \noutsourcing from Western countries.5. Globalization Furthers the \nSpread of Democracy\n•Free markets and democracy are often linked, \nwith globalization promoting political and \neconomic reforms. However, critics argue that \nit overlooks deeper inequalities.\n•Example: Post -Cold War Eastern Europe \nadopted democracy as they integrated into \nglobal markets.6. Globalization Requires War on \nTerror\n•Globalization and free markets are seen as \ncritical to peace and security. Efforts like the \nIraq War were justified as promoting stability \nthrough democracy and trade.\n•Example: The Iraq War aimed to spread \ndemocracy and free markets in the Middle \nEast.', 'raytos.r.bsinfotech@gmail.com', 'asdasasaaa', '', '../pdf_files/670ba08b5940f-Six_Core_Claims_of_Globalization.pdf', '', 'Not Accepted'),
(99, '2117140599', '1', 1, 1, 'Mobile Application For Emergency Calls', '2024-09-27', '2003', 'dasdasdsadasdasdasdasdsadsa', '', 'The Six Core Claims of \nGlobalization\nSummary and Examples1. Globalization Is About \nLiberalization and Global \nIntegration of Markets•Globalization is driven by the integration of \nmarkets, not by an ideology. It results from \nthe interactions of markets, often framed as a \nmoral imperative, like free trade.\n•Example: WTO agreements reduce trade \nbarriers and promote market integration.2. Globalization Is Inevitable and \nIrreversible\n•Globalization is seen as an unstoppable force \nshaped by historical and market principles. It \nis embraced as a natural development.\n•Example: The 2008 financial crisis spread \nglobally, showing how interconnected markets \nare.3. Nobody Is in Charge of \nGlobalization\n•Globalization is decentralized. No single \ngovernment, institution, or entity controls it. It \nevolves organically from interactions in trade, \ncommunication, and technology.\n•Example: Cryptocurrencies like Bitcoin operate \nwithout centralized control.4. Globalization Benefits Everyone\n•Globalization provides opportunities for \neconomic growth, investment, and \ntechnological innovation, especially in \ndeveloping countries.\n•Example: India\'s growth in the IT sector due to \noutsourcing from Western countries.5. Globalization Furthers the \nSpread of Democracy\n•Free markets and democracy are often linked, \nwith globalization promoting political and \neconomic reforms. However, critics argue that \nit overlooks deeper inequalities.\n•Example: Post -Cold War Eastern Europe \nadopted democracy as they integrated into \nglobal markets.6. Globalization Requires War on \nTerror\n•Globalization and free markets are seen as \ncritical to peace and security. Efforts like the \nIraq War were justified as promoting stability \nthrough democracy and trade.\n•Example: The Iraq War aimed to spread \ndemocracy and free markets in the Middle \nEast.', 'raytos.r.bsinfotech@gmail.com', 'asdasasaaa', '', '../pdf_files/670ba1137e726-Six_Core_Claims_of_Globalization.pdf', '', 'Not Accepted'),
(101, '6520654158', '1', 1, 1, 'Mobile Application For Emergency Calls', '2024-09-27', '2003', 'dadsa', '', 'The Six Core Claims of \nGlobalization\nSummary and Examples1. Globalization Is About \nLiberalization and Global \nIntegration of Markets•Globalization is driven by the integration of \nmarkets, not by an ideology. It results from \nthe interactions of markets, often framed as a \nmoral imperative, like free trade.\n•Example: WTO agreements reduce trade \nbarriers and promote market integration.2. Globalization Is Inevitable and \nIrreversible\n•Globalization is seen as an unstoppable force \nshaped by historical and market principles. It \nis embraced as a natural development.\n•Example: The 2008 financial crisis spread \nglobally, showing how interconnected markets \nare.3. Nobody Is in Charge of \nGlobalization\n•Globalization is decentralized. No single \ngovernment, institution, or entity controls it. It \nevolves organically from interactions in trade, \ncommunication, and technology.\n•Example: Cryptocurrencies like Bitcoin operate \nwithout centralized control.4. Globalization Benefits Everyone\n•Globalization provides opportunities for \neconomic growth, investment, and \ntechnological innovation, especially in \ndeveloping countries.\n•Example: India\'s growth in the IT sector due to \noutsourcing from Western countries.5. Globalization Furthers the \nSpread of Democracy\n•Free markets and democracy are often linked, \nwith globalization promoting political and \neconomic reforms. However, critics argue that \nit overlooks deeper inequalities.\n•Example: Post -Cold War Eastern Europe \nadopted democracy as they integrated into \nglobal markets.6. Globalization Requires War on \nTerror\n•Globalization and free markets are seen as \ncritical to peace and security. Efforts like the \nIraq War were justified as promoting stability \nthrough democracy and trade.\n•Example: The Iraq War aimed to spread \ndemocracy and free markets in the Middle \nEast.', 'raytos.r.bsinfotech@gmail.com', 'asdasasaaa', '', '../pdf_files/670bcb40c718a-Six_Core_Claims_of_Globalization.pdf', '', 'Not Accepted'),
(118, '3408543432', '2', 1, 1, 'the professors found out that the students are not thoroughly prepared to embrace the E learning system', '2024-10-18', '2022', 'Because of the COVID-19 crisis, Higher Educational Institutions (HEIs) have resorted to online classes or E-Learning Classrooms to \r\ndeliver the content of their curriculum in various platforms. This action research examines the status of the implementation of the E\r\nLearning classroom in selected HEI’s in Region IV-A by conducting a qualitative approach using a survey questionnaire to a small group \r\nof professionals who have been teaching various courses in the tertiary level. This study utilized the descriptive method of research to \r\nbring out the current status of the implementation of the e-learning classroom in selected HEI’s. An online survey data were collected and \r\nanalyzed using the descriptive and documentary analysis. Findings indicate that the respondents had good experiences in introducing \r\nthe E-learning classroom as an immediate response to the country\'s enhanced quarantine situation. Although all the E-learning platforms \r\nused by the respondents are free of charge, still, students have encounter', '', 'Technology\nhas\ntransformed\nthe\nway\nwe\ncommunicate,\nmaking\nit\neasier\nand\nfaster\nthan\never\nbefore.\nFrom\nsocial\nmedia\nplatforms\nto\ninstant\nmessaging\napps,\npeople\ncan\nconnect\nwith\nothers\nacross\nthe\nglobe\nin\nreal-time.\nHowever,\nthis\nconvenience\nalso\ncomes\nwith\nchallenges,\nsuch\nas\nthe\nrisk\nof\nmisinformation\nspreading\nrapidly.\nAs\nwe\ncontinue\nto\nintegrate\ntechnology\ninto\nour\ndaily\nlives,\nit\nis\ncrucial\nto\ndevelop\nstrategies\nthat\npromote\nresponsible\nusage\nand\nensure\nthe\naccuracy\nof\ninformation\nbeing\nshared.', 'raytos.bsinfotech@gmail.com', 'Ethel Reyes-Chua Brandon G. Sibbaluca, Rebecca D. Miranda, Georgina B. Palmario, Ramil P.  Moreno, John Paul T. Solon', '', '../pdf_files/67127546533df-test file 1.1 .pdf', '2024-10-26', 'Accepted'),
(124, '9376590447', '2', 1, 1, 'STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS ', '2024-10-19', '2022', 'Because of the COVID-19 crisis, Higher Educational Institutions (HEIs) have resorted to online classes or E-Learning Classrooms to \r\ndeliver the content of their curriculum in various platforms. This action research examines the status of the implementation of the E\r\nLearning classroom in selected HEI’s in Region IV-A by conducting a qualitative approach using a survey questionnaire to a small group \r\nof professionals who have been teaching various courses in the tertiary level. This study utilized the descriptive method of research to \r\nbring out the current status of the implementation of the e-learning classroom in selected HEI’s. An online survey data were collected and \r\nanalyzed using the descriptive and documentary analysis. Findings indicate that the respondents had good experiences in introducing \r\nthe E-learning classroom as an immediate response to the country\'s enhanced quarantine situation. Although all the E-learning platforms \r\nused by the respondents are free of charge, still, students have encounter', '', 'Thanks\nto\ntechnology,\ncommunication\nis\nnow\neasier\nand\nfaster\nthan\never.\nindividuals\nmay\ncommunicate\nwith\nindividuals\nall\naround\nthe\nworld\nin\nreal\ntime\nby\nusing\nsocial\nnetworking\nsites\nand\ninstant\nmessaging\napplications.\nHowever,\nthere\nare\ndrawbacks\nto\nthis\nease\nas\nwell,\nsuch\nthe\npossibility\nof\nfalse\ninformation\nspreading\nquickly.\nAs\nwe\ncontinue\nto\nintegrate\ntechnology\ninto\nour\ndaily\nlives,\nstrategies\nthat\npromote\nresponsible\nuse\nand\nensure\nthe\naccuracy\nof\ninformation\nbeing\nshared\nare\ncrucial.', 'raytos.bsinfotech@gmail.com', 'Ethel Reyes-Chua Brandon G. Sibbaluca, Rebecca D. Miranda, Georgina B. Palmario, Ramil P.  Moreno, John Paul T. Solon', '', '../pdf_files/67137b6bdb8c8-test file 1.1.1.1  (1).pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(129, '1513286657', '1', 1, 1, 'Matching Composition and  Efficient Weight Reduction in Dynamic Matching', '2024-10-25', '2024', 'Weconsider the foundational problem of maintaining a (1−ε)-approximate maximum weight matching (MWM) in an n-node dynamic graph undergoing edge insertions and deletions. We provide a general reduction that reduces the problem on graphs with a weight range of poly(n) to poly(1/ε) at the cost of just an additive poly(1/ε) in update time. This improves upon the prior reduction of Gupta-Peng (FOCS 2013) which reduces the problem to a weight range of ε−O(1/ε) with a multiplicative cost of O(logn). When combined with a reduction of Bernstein-Dudeja-Langley (STOC 2021) this yields a reduction from dynamic (1 − ε)-approximate MWM in bipartite graphs with a weight range of poly(n) to dynamic (1 − ε)-approximate maximum cardinality matching in bipartite graphs at the cost of a multiplicative poly(1/ε) in update time, thereby resolving an open problem in [GP’13; BDL’21]. Additionally, we show that our approach is amenable to MWM problems in streaming, shared-memory work-depth, and massively parallel computation models. We also apply our techniques to obtain an efficient dynamic algorithm for rounding weighted fractional matchings in general graphs. Underlying our framework is a new structural result about MWM that we call the “matching composition lemma” and new dynamic matching subroutines that may be of independent interest.', 'Data Structures and Algorithms', 'Matching Composition and\nEfficient Weight Reduction in Dynamic Matching\nAaron Bernstein∗Jiale Chen†Aditi Dudeja‡Zachary Langley§\nAaron Sidford¶Ta-Wei Tu‖\nAbstract\nWe consider the foundational problem of maintaining a (1 −ε)-approximate maximum weight\nmatching (MWM) in an n-node dynamic graph undergoing edge insertions and deletions. We\nprovide a general reduction that reduces the problem on graphs with a weight range of poly( n)\nto poly(1 /ε) at the cost of just an additive poly(1 /ε) in update time. This improves upon the\nprior reduction of Gupta-Peng (FOCS 2013) which reduces the problem to a weight range of\nε−O(1/ε)with a multiplicative cost of O(logn).\nWhen combined with a reduction of Bernstein-Dudeja-Langley (STOC 2021) this yields a\nreduction from dynamic (1 −ε)-approximate MWM in bipartite graphs with a weight range\nof poly( n) to dynamic (1 −ε)-approximate maximum cardinality matching in bipartite graphs\nat the cost of a multiplicative poly(1 /ε) in update time, thereby resolving an open problem in\n[GP’13; BDL’21]. Additionally, we show that our approach is amenable to MWM problems in\nstreaming, shared-memory work-depth, and massively parallel computation models. We also\napply our techniques to obtain an efficient dynamic algorithm for rounding weighted fractional\nmatchings in general graphs. Underlying our framework is a new structural result about MWM\nthat we call the “matching composition lemma” and new dynamic matching subroutines that\nmay be of independent interest.\n∗New York University, bernstei@gmail.com . Supported by Sloan Fellowship, Google Research Fellowship, NSF\nGrant 1942010, and Charles S. Baylis endowment at NYU.\n†Stanford University, jialec@stanford.edu . Supported by a Lawrence Tang Graduate Fellowship, a Microsoft\nResearch Faculty Fellowship, and NSF CAREER Award CCF-1844855.\n‡University of Salzburg, aditi.dudeja@plus.ac.at . This work is supported by the Austrian Science Fund (FWF):\nP 32863-N. This project has received funding from the European Research Council (ERC) under the European Union’s\nHorizon 2020 research and innovation programme (grant agreement No 947702).\n§Rutgers University, zach.langley@rutgers.edu .\n¶Stanford University, sidford@stanford.edu . Supported by a Microsoft Research Faculty Fellowship, NSF CA-\nREER Grant CCF-1844855, NSF Grant CCF-1955039, and a PayPal research award.\n‖Stanford University, taweitu@stanford.edu . Supported by a Stanford School of Engineering Fellowship, a Mi-\ncrosoft Research Faculty Fellowship, and NSF CAREER Award CCF-1844855.\niarXiv:2410.18936v1  [cs.DS]  24 Oct 2024Contents\n1 Introduction 1\n1.1 Additional Computational Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2 Preliminaries 6\n3 Technical Overview 7\n3.1 Weight Reduction Framework of Gupta–Peng . . . . . . . . . . . . . . . . . . . . . . 7\n3.2 Disjoint Weight Classes Require Exponential Width . . . . . . . . . . . . . . . . . . 8\n3.3 Leveraging Weight Overlaps: the Matching Composition Lemma . . . . . . . . . . . 8\n3.3.1 Algorithmic Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3.4 Further Improvements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n4 Matching Composition and Substitution Lemmas 12\n5 Framework 15\n5.1 Dynamic Approximate MWM on Matchings in (1 /ε)-Spread Weight Classes . . . . . 15\n5.2 Dynamic Approximate MWM on Degree-Two Graphs . . . . . . . . . . . . . . . . . 17\n5.3 Weight Reduction Framework for General Graphs . . . . . . . . . . . . . . . . . . . . 20\n5.4 Low-Recourse Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n5.5 Putting Everything Together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n5.5.1 Fully Dynamic Algorithm on Low-Degree Graphs . . . . . . . . . . . . . . . . 29\n5.5.2 Rounding Weighted Fractional Matching . . . . . . . . . . . . . . . . . . . . . 29\n5.5.3 Improved Weight Reduction Framework for General Graphs . . . . . . . . . . 30\n5.5.4 From Weighted Matching to Unweighted Matching in Bipartite Graphs . . . 31\n6 Applications 32\n6.1 The Dynamic Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n6.2 The Streaming Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n6.3 The MPC Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n6.4 The Parallel Shared-Memory Work-Depth Model . . . . . . . . . . . . . . . . . . . . 38\n7 Open Problems 40\nA Analysis of [BDL21] 44\nB Counterexample to Question 3.1 46\nC Reduction of α-Approximation Requires Exponential Width 46\nii1 Introduction\nThe maximum matching problem is foundational in graph algorithms and has numerous applica-\ntions. A matching is a set of vertex-disjoint edges in an (undirected) graph. In unweighted graphs ,\nG= (V, E), the problem, known as maximum cardinality matching (MCM) , is to find a match-\ning with the maximum number of edges (also known as the matching’s size). More generally, in\nweighted graphs ,G= (V, E, w ), where each e∈Ehas weight w(e)>0, the problem, known as max-\nimum weighted matching (MWM) , is to find a matching Mof maximum weight , i.e.,P\ne∈Mw(e).\nFor simplicity, throughout the paper, we assume that each w(e)∈[1, W] forW= poly( n).\nIn the standard static oroffline version of the maximum matching problem, it was recently\nshown how to compute maximum matchings in unweighted and weighted bipartite graphs in almost-\nlinear time [CKL+22, vdBCP+23] (when the edge weights are integer). Though this almost resolves\nthe complexity of the problem in the standard static, full-memory, sequential model of computation,\nthe complexities of the problem in alternative models of computation such as dynamic, streaming,\nand parallel models are yet to be determined. The problem has been studied extensively in these\nmodels and there are conditional lower bounds that rule out efficient algorithms for exact maximum\nmatching in certain settings (see, for example, [HKNS15] for dynamic and [GO16] for streaming).\nConsequently, there has been work on efficiently computing approximately maximum match-\nings. There is a range of approximation quality versus efficiency trade-offs studied (see e.g.,\n[BS15, BS16, GLS+19, Waj20, BKS23a]). We focus on the gold standard of computing (multi-\nplicative) (1 −ε)-approximate matching, that is a matching of size or weight that is at least (1 −ε)\ntimes the maximum. While there are algorithms that compute (1 −ε)-approximate maximum\nmatchings in many computational models, there is often a significant gap between the bounds for\nweighted and unweighted graphs; many state-of-the-art results are limited to unweighted graphs.\nHowever, in dynamic, streaming, and parallel computational models, there is no clear indication\nof a fundamental separation between the computational complexity of the two cases. It is plausi-\nble that the existing gap could be due to a relative lack of techniques for working with weighted\nmatchings.\nClosing the gap between the state of the art for weighted and unweighted matchings is an\nimportant open problem. Several works have made progress on this problem by developing meta-\nalgorithms that convert any algorithm for unweighted matching into an algorithm for weighted\nmatching in a black-box fashion (albeit with potential loss in approximation quality and efficiency).\nThe central focus of this paper is to provide improved meta-algorithms and new tools that more\nefficiently reduce weighted matching to unweighted matching. We motivate, develop, and introduce\nour results through the prominent dynamic matching problem (which we introduce next), though\nwe also obtain results for streaming and parallel settings.\nDynamic Weighted Matching. In the dynamic matching problem, a graph undergoes a se-\nquence of adversarial updates, and the algorithm must (explicitly) maintain an (approximate)\nmaximum matching in the graph after each update.1The goal is to minimize the update time\nof the algorithm, which is the time needed to process a single update. In the most general fully\ndynamic model, each update either inserts an edge into or deletes an edge from the graph. We\n1Some papers instead maintain a data structure that can answer queries about a maximum matching, e.g., [CS18].\nThe low-recourse transformation we propose in Section 5.4 can convert certain algorithms that maintain the matchings\nimplicitly to ones that maintain them explicitly. For the simplicity of the statement, unless stated otherwise, the\ndynamic matching algorithms in the paper should maintain a matching explicitly.\n1also consider two natural, previously studied, partially dynamic models, including the incremental\nmodel, where each update can only insert an edge, and the decremental model, where each update\ncan only delete an edge.\nOver the past decades, meta-algorithms for reducing dynamic matching on weighted to un-\nweighted graphs have been developed (with different approximation and update time trade-offs).\nThe first general reduction is by Stubbs and Williams [SW17], who show that any dynamic α-\napproximate MCM algorithm can be converted to a dynamic (1 /2−ε)α-approximate MWM algo-\nrithm with (multiplicative) poly(log n, ε−1) overhead in the update time.\nMore recently, the state of the art was achieved by a result of Bernstein, Dudeja, and Lan-\ngley [BDL21]. This paper reduces the approximation error for weighted matching to (1 −ε)αin\nbipartite graphs and (2 /3−ε)αin non-bipartite graphs with ε−Θ(1/ε)lognmultiplicative overhead in\nthe update time. [BDL21] crucially relies on different general reduction of Gupta and Peng [GP13],\nwhich reduces weighted matching in a general (not necessarily bipartite) graph with large weights\nto one with small weights—concretely, from real values in [1 , W] to integers in {1, . . . , ε−O(1/ε)}—at\nthe cost of an extra (1 −ε)-approximation factor and O(logn) multiplicative overhead.\nAll of these reductions mentioned incur a multiplicative overhead of only Oε(poly(log n)) to the\nupdate time, where we use Oε(·) to hide factors depending on ε. However, the dependence of 1 /ε\nin update time overhead in previous reductions for (1 −ε)-approximate MWM [GP13, BDL21] are\nall exponential. Consequently, even for ε= 1/O(logn), an accuracy decaying slowly with increases\nin the graph’s size, the algorithms may no longer achieve non-trivial update times.\nOur Contribution Our first contribution is the following weighted-to-unweighted reduction in\nbipartite graphs, which settles the open problem of [GP13, BDL21] for bipartite graphs. Interest-\ningly, this reduction, along with the prior reductions in [GP13, SW17, BDL21], are partially dynamic\npreserving , i.e., if the input unweighted matching algorithm is incremental or decremental, then the\nresulting weighted matching algorithm is also incremental or decremental respectively.\nTheorem 1.1 (Informal version of Theorem 5.31) .Given any dynamic (1−ε)-approximate MCM\nalgorithm in n-node m-edge bipartite graphs with update time U(n, m, ε ), there is a transformation\nwhich produces a dynamic (1−O(ε))-approximate MWM algorithm for n-node bipartite graphs with\namortized update time U(poly(1 /ε)·n,poly(1 /ε)·m, ε)·poly(1 /ε). This transformation is partially\ndynamic preserving. In non-bipartite graphs, the approximation ratio for weighted matching becomes\n2/3−O(ε). Moreover, if the unweighted algorithm is deterministic, then so is the weighted algorithm.\nBeyond improving the exponential dependence on 1 /εto polynomial, Theorem 1.1 also elim-\ninates the O(logn) factors in the update-time of [BDL21]. Therefore, Theorem 1.1 implies that\nin dynamic bipartite graphs, (1 −ε)-approximate MWM shares the same complexity as (1 −ε)-\napproximate MCM, up to poly(1 /ε) factors.\nIn the case of general graphs, we make substantial progress towards reducing weighted matching\nto unweighted matching. Indeed, a crucial ingredient of our algorithm is a reduction from large\nweights to small ones, which applies to non-bipartite graphs as well.\nTheorem 1.2 (Informal version of Theorem 3.5) .Given any dynamic (1−ε)-approximate MWM\nalgorithm in n-node m-edge general (possibly non-bipartite) graphs with weights in [1, W]with up-\ndate time U(n, m, W, ε ), there is a transformation which produces a dynamic (1−O(ε))-approximate\nMWM algorithm for n-node general graphs with amortized update time U(poly(1 /ε)·n,poly(1 /ε)·\nm,poly(1 /ε), ε)·poly(log(1 /ε)) + poly(1 /ε). This transformation is partially dynamic preserving.\n2Theorem 1.2 removes the exponential dependence on 1 /εin [GP13] and again incurs no log n\nfactors in the update-time overhead (whereas [GP13] incurs log n).\nAdditionally, our framework leads to a dynamic weighted rounding algorithm with a polyloga-\nrithmic dependence on W, improving over that of [CST23] (which depends linearly on W). Here,\na weighted rounding algorithm maintains an integral matching supported on a dynamically chang-\ningfractional one while approximately preserving its weight (see Definition 5.26). This shows\nthat dynamic integral matching, weighted or not, is equivalent to dynamic fractional matching\n(up to poly(log n,1/ε) terms). For example, as discussed in [CST23], this leads to a decremental\n(1−ε)-approximate MWM algorithm in weighted general graphs with update time poly(log n,1/ε).\nTheorem 1.3 (Informal version of Theorem 5.29) .There is a dynamic weighted rounding algorithm\nwitheO(poly(1 /ε))update time.\nTechniques Our key technical contribution is Theorem 1.2, which removes the ε−O(1/ε)factor\nin an analogous result of [GP13]. To reduce edge weights in weighted graph G= (V, E, w ) with\nvertices V, edges E, and edge weights w, both our reduction and the one in [GP13] define edge\nsetsEi⊆E, where each edge set is defined solely as a function of weights. The algorithm then\ncomputes an arbitrary (1−ε)-approximate MWM Miin each Eiand shows that the Mican be\ncombined to compute an approximate MWM Mfor the entire graph. Consequently, the edge sets,\nEi, are chosen to satisfy the following two properties:\n1. Within each Ei, the ratio ρof the maximum to minimum edge weight is small (we call this\nthewidth of the interval). This is the crux of our weight-reduction because a simple scaling\nand rounding approach yields the requested Miusing only an algorithm for integer weights\nin{1, . . . ,⌈ρ/ε⌉}.\n2.µw(M1∪...∪Mk)≥(1−ε)µw(G), where µw(·) is the weight of the MWM in the input\ngraph or edge set. This property is to ensure that the Mican be combined to obtain a\n(1−ε)-approximate matching.\nIn the algorithm of [GP13], the intervals were disjoint; in fact, they were well-separated. This\nmade it easy to prove property 2 above via a simple greedy combination. We show, however,\nthat any set of disjoint intervals Eithat satisfies property 2 must have, in the worst case, width\nρ≥exp(1 /ε). (See Appendix B for more details.)\nTo bypass this barrier, we allow for overlapping intervals. This forces us to use a different and\nmore involved analysis, as the analysis of [GP13] crucially relied on disjointedness. At the outset,\nit is not clear that this is even enough. In fact, as we discuss below, it is only narrowly suffices\nin that our analysis crucially relies on the matchings Mibeing (1 −ε)-approximate, rather than\nα-approximate for some constant α <1.\nOur key technical contribution consists of two new structural properties of weighted matching,\nwhich we call matching composition andsubstitution lemmas (see Lemmas 3.2 and 3.3). On a\nhigh level, these two lemmas show that as long as the weight classes Eioverlap slightly, a width of\npoly(1 /ε) is sufficient to ensure the second property above.\nUsing the above idea inside the framework of [BDL21] with a simple greedy aggregation al-\ngorithm in [GP13] immediately yields a weaker version of Theorem 1.1 (with poly(1 /ε)·O(logn)\nmultiplicative overhead and a slightly worse dependence on 1 /ε). We further optimize the greedy\naggregation in [GP13] to remove the log nfactor, improve the analysis of [BDL21], and propose a\nlow-recourse transformation to remove several poly(1 /ε) factors.\n3A Limitation of Our Reductions Although our results successfully remove the exponential\ndependence on 1 /εin prior work, they also have a limitation. The work of [GP13] reduces α(1−ε)-\napproximate matching with general weights to α-approximate matching with small edges weights;\ncrucially, it works for any α≤1. By contrast, our Theorem 1.2 requires α= (1−ε). As a result,\nour Theorem 1.1 also requires α= (1−ε), while the analogous result of [BDL21] works for any\nα. Consequently, there are several applications related to smaller α, for example, α= 1/(2−√\n2)\n(see [Beh23, BKSW23, ABR24]) or α= 2/3 (see [BS15, BS16]) that benefit from [BDL21] but not\nfrom our reduction. Notably, there are also conditional lower bounds ruling out efficient (1 −ε)-\napproximate matching algorithms in various models, specifically the fully dynamic [Liu24] and the\nsingle-pass streaming model [Kap21]. Nonetheless, (1 −ε)-approximate matching is a well-studied\nregime, and, as we show in Section 6, our reduction improves the state of the art in multiple\ncomputational models.\nPerhaps surprisingly, this limitation is inherent to the general framework discussed above. More\nprecisely, consider a scheme which picks edge sets Ei={e|ℓi≤w(e)≤ri}, computes an arbitrary\nα-approximate matching in each Mi, and then shows that µw(M1∪. . .∪Mk)≥(α−ε)·µw(G).\nOur key contribution is to show that for α= (1−O(ε)), there exist suitable edge sets with width\npoly(1 /ε). However, our sets do not necessarily work for a fixed constant α <1; in fact, we show\nthat for α <1, there are graphs for which anysuitable edge sets necessarily have width exp(1 /ε)\n(as what was done in [GP13]). Generalizing our result to all work for all αwould thus require a\ndifferent approach. See Appendix C for more details.\nOverview of the Paper In the remainder of the introduction, in Section 1.1 we give an informal\noverview of our results in other computational models and in Section 1.2 we discuss concrete\napplications. Thereafter, we state preliminaries in Section 2. In Section 3, we give a technical\noverview including our main structural lemma that implies our reduction framework. We then\nshow our main technical lemma in Section 4 which helps to prove the main structural lemma, and\nstate our framework in Section 5 in detail. We state applications of our framework in Section 6.\nWe conclude with open problems in Section 7.\n1.1 Additional Computational Models\nOur Results. Although the above theorems were written for dynamic models, our techniques\nare general and apply to a variety of different models. In Section 6 we state formal reductions in a\nvariety of models; here, we simply state the main takeaways. We show that analogs of the results\nin Theorems 1.1 and 1.2 also apply to the semi-streaming, massively parallel computing (MPC)\nwith O(nlogn) space per machine, and the parallel work-depth models. We suspect they apply to\nother models as well, but in this paper, we focus on these four.\nIn the case of semi-streaming and MPC, the reduction when applied to existing algorithms,\nleaves the number of passes/rounds the same (up to a constant factor), but increases the space\nrequirement by log n·poly(1 /ε). On the other hand, in the parallel work-depth model, the work\nincreases by a factor of log n·poly(1 /ε), and the depth increases by an additive log2nfactor.\nDespite these overheads, we can improve many of the state of the arts in these models. Later in\nthis section, we discuss these improvements and our contributions in more detail.\nContrast to Previous Work As in the case of dynamic algorithms, when we turn to other\nmodels our Theorems 1.1 and 1.2 achieve the same reductions as [BDL21] and [GP13] respectively,\n4except that we reduce their multiplicative overhead of ε−O(1/ε)to poly(1 /ε). There is also a different\nreduction of Gamlath, Kale, Mitrovic, and Svensson [GKMS19], which works in both the streaming\nand MPC models, but not in the dynamic model. [GKMS19] has the advantage of reducing the\nmost general case of weighted non-bipartite matching to the simplest case of unweighted bipartite\nmatching, but it has exponential dependence on 1 /εand it increases the number of passes/rounds\nby a ε−O(1/ε)factor (which is generally considered a bigger drawback than the space increase).\nSimilar to the dynamic models, our reductions have a somewhat narrower range of application\nthan those of [BDL21] and [GP13] even in MPC, parallel, and streaming models because ours\ndo not work for general approximation factors: they only reduce a (1 −ε)-approximation to a\n(1−Θ(ε))-approximation. There is also a second, more minor drawback, which is that our reduction\nin Theorem 1.2 works in a slightly narrower range of models than the corresponding reduction\nof [GP13]. For example, the reduction of [GP13] applies to algorithms that only maintain the\napproximate sizeof the maximum matching (see [BKSW23, Beh23]), whereas our reduction only\napplies to algorithms that maintain the actual matching. But for the most part, our reduction and\nthat of [GP13] apply to the same set of models.\n1.2 Applications\nIn this subsection, we give an informal overview of some of the implications of our reductions. For\na more formal statement of the results, we refer the reader to Section 6.\nApplications to Bipartite Graphs Since our reduction from weighted to unweighted matching\nis black-box, it immediately improves upon the state of the art for weighted matching in a wide\nvariety of computational models. Many of these results which achieve the state of the art were\nobtained by plugging existing unweighted algorithms into the reduction of [BDL21], and hence incur\na multiplicative overhead of ε−O(1/ε). Plugging in our Theorem 5.31 reduces the multiplicative\noverhead to poly(1 /ε). In particular, our reduction obtains weighted analogs of the following\nunweighted bipartite results.\n1. A fully dynamic algorithm for maintaining a (1 −ε)-approximate MCM in O(√mpoly(1 /ε))\ntime per update [GP13].\n2. A decremental (1 −ε)-approximate MCM algorithm with update time poly(log n, ε−1) [BGS20,\nJJST22].\n3. A fully dynamic algorithm for maintaining a (1 −ε)-approximate MCM with update time\nO(poly( ε−1)·n\n2Ω(√logn)) [Liu24].\n4. A fully dynamic offline algorithm for maintaining a (1 −ε)-approximate MCM with update\ntime O(n0.58poly( ε−1)); in the offline model, the entire sequence is known to the algorithm\nin advance [Liu24].\n5. An incremental (1 −ε)-approximate MCM algorithm with update time poly( ε−1) [BK23].\n6. An O(ε−2)-pass, O(n) space streaming algorithm for (1 −ε)-approximate MCM [ALT21]\n7. An O(ε−2·log log n)-round, O(n) space per machine, MPC algorithm for (1 −ε)-approximate\nMCM [ALT21].\n5Our reduction extends all of the above results to work in weighted graphs: the multiplicative\noverhead is only poly(1 /ε) in the dynamic model, as well as a O(logn) factor in some of the other\nmodels. Before our work, the weighted versions of 1, 3, and 4 had a multiplicative overhead of\nε−O(1/ε)·logW. For others mentioned on the list, separate weighted versions were known (see\n[BKS23b, LKK23]), but had worse dependence on either log nfactors or ε−1factors. Our main\ncontribution here is to remove these overheads and, equally importantly, to streamline existing\nresearch by removing the need for a separate weighted algorithm.\nNote that there are additional results on streaming approximate matching algorithm which\nobtain improved pass dependencies on εat the cost of poly(log n) factors [AG11, AG18, AJJ+22,\nAss24]. Our reduction does not improve the state of the art here for such methods. Therefore, we\nfocus on algorithms that have pass complexities that only depend on ε.\nApplications to Non-Bipartite Graphs Similar to Theorem 5.31, our aspect-ratio reduction\nin Theorem 3.5 also works as a black-box. Each of the results below was initially obtained by\napplying the reduction of [GP13] to a weighted matching algorithm with a large dependence on W.\nBy plugging in our reduction, we reduce the ε-dependence in all of them from ε−O(1/ε)to poly(1 /ε).\n1. A fully dynamic algorithm for maintaining a (1 −ε)-approximate MWM in general graphs in√m·ε−O(1/ε)·logWtime [GP13].\n2. A decremental algorithm for maintaining a (1 −ε)-approximate MWM in general graphs in\npoly(log n)·ε−O(1/ε)update time [CST23].\n3. A poly(log n)·ε−O(1/ε)update time algorithm for rounding (1 −ε)-approximate weighted\nfractional matchings in general graphs to (1 −Θ(ε))-approximate integral matchings [CST23].\n2 Preliminaries\nGeneral Notation For positive integer k, we let [ k]def={1, . . . , k }. For sets SandT, we let\nS⊕Tdef= (S\\T)∪(T\\S) denote their symmetric difference.\nGraphs and Matchings Throughout this work, G= (V, E) denotes an undirected graph, and\nw:E→R>0is an edge weight function. The weight ratio ofGis max ew(e)/minfw(f). A\nmatching M⊆Eis a set of vertex-disjoint edges. The weight of a matching M, denoted w(M), is\nthe sum of the weights of the edges in the matching: w(M)def=P\ne∈Mw(e). We denote the maximum\nvalue of w(M) achieved by any matching MonGbyµw(G). For α∈[0,1], an α-approximate\nMWM of Gis a matching Msuch that w(M)≥α·µw(G). The following result states that we can\ncompute an (1 −ε)-approximate MWM very efficiently.\nTheorem 2.1 ([DP14, Theorem 3.12]) .On an m-edge general weighted graph, a (1−ε)-approximate\nMWM can be computed in time O(mlog(ε−1)ε−1).\nWeight Intervals ForI⊆R, we denote by GIthe subgraph of Grestricted to edges esuch that\nw(e)∈I. A set of (disjoint) weight intervals [ ℓ1, r1), . . . , [ℓk, rk)⊆Rhasweight gap δifℓi+1≥δ·ri\nfor all i∈[k−1] and we call such a set of weight classes δ-spread . We also say that the set of\nintervals is δ-wide ifri≥δ·ℓifor all i∈[k]. Ifℓi+1=riand the intervals cover [1 , W], then we\nsay the intervals are a weight partition .\n6Computational Model We work in the standard Word-RAM model in which arithmetic oper-\nations over Θ(log n)-bit words can be performed in constant time.\n3 Technical Overview\nHere we give an overview of our framework. For comparison and motivation, in Section 3.1 we first\nintroduce a result of [GP13], which provides a deterministic framework that is partially dynamic\npreserving for dynamic approximate MWM algorithms to reduce the weight range to ε−O(1/ε)with\nan overhead of O(logW). In Section 3.2, we explain the difficulty of reducing to poly(1 /ε) weight\nrange using [GP13]. Motivated by this, in Section 3.3, we introduce our key technical innovation,\nthe matching composition lemma (Lemma 3.2), that allows us to bypass the barrier. We then show\nthat this lemma naturally induces our algorithmic framework that reduces the weight range down\nto poly(1 /ε). Finally, in Section 3.4, we overview several further improvements that we made to\nshave off log nand 1 /εfactors from the running time.\n3.1 Weight Reduction Framework of Gupta–Peng\nThe reduction framework of [GP13] works as follows. First, it groups edges geometrically by their\nweights so that the weight ratio of each group is Θ(1 /ε). It then deletes one group for every Θ(1 /ε)\nconsecutive groups and merges the remaining consecutive groups. We refer to the merged groups as\nweight classes ; note that they are Θ(1 /ε)-spread and have weight ratio ε−Θ(1/ε). For each of these\nweight classes, a (1 −ε)-approximate MWM is maintained. Because the weight classes are Θ(1 /ε)-\nspread, a simple greedy aggregation [ABGS12, GP13, SW17] of the (1 −ε)-approximate MWMs on\neach weight class leads to a (1 −O(ε))-approximation of µw(G). As a result, this reduction reduces\ngeneral approximate MWM to the problem of maintaining an approximate MWM inside a weight\nclass with weight ratio ε−Θ(1/ε).\nMore formally, the algorithm of [GP13] assigns all edges ewith weight we∈[ε−i, ε−(i+1)) to the\nith group. Let G(j)denote the graph obtained by deleting all groups isuch that i≡jmod⌈ε−1⌉.\nAn averaging argument shows that max jµw(G(j))≥(1−O(ε))µw(G). So it suffices to maintain a\n(1−O(ε))-approximate MWM on each G(j)and return the one with maximum weight.\nTo do so, [GP13] merges all groups between neighboring deletions to form weight classes in\nG(j). Those weight classes have weight ratio ε−Θ(1/ε)and are Θ(1 /ε)-spread. [GP13] proceed by\nmaintaining a (1 −ε)-approximate MWM M(j)\nkon each weight class [ ℓ(j)\nk, r(j)\nk); by scaling down\nappropriately, maintaining each M(j)\nkrequires maintaining a (1 −ε)-approximate MWM in a graph\nwith edges in range [1 , ε−Θ(1/ε)], as desired. The authors of [GP13] then greedily aggregate the Mi\ninto a single matching Mby checking the Miin descending order of weight range and including\ninMany edge that is not adjacent to existing edges in M. The Θ(1 /ε) weight gap between\nweight classes ensures that for each edge ein the final matching M, the total weight of edges inSMithat were not included in Mbecause of eis at most O(ε)·we. Since (1 −O(ε))µw(G)≤\n(1−O(ε))µw(G(j))≤P\niw(Mi), the greedy aggregation keeps a 1 −O(ε) fraction of the weight inP\niw(Mi) thus is a (1 −O(ε))-approximate MWM.\n73.2 Disjoint Weight Classes Require Exponential Width\nThe Θ(1 /ε) weight gap plays an important role in [GP13] because it ensures that µw(SMi)≥\n(1−O(ε))µw(G), while also allowing for efficient greedy aggregation. But as long as we try to\nmaintain weight classes that are 1 /ε-spread, it seems hard to reduce the weight ratio all the way\ndown to poly(1 /ε). This is because it would require deleting a constant fraction of the initial\nweight groups (the ones of weight ratio Θ(1 /ε)), so the MWM on the remaining graph G(j)would\nhave a much smaller weight than µw(G). Indeed, we rule out the possibility of a broader family of\nmethods that works with non-overlapping weight classes (which includes all methods that create\nweight gaps) by answering the following question in the negative.\nQuestion 3.1. For any graph G, is there a weight partition [ ℓ1, r1), . . . , [ℓk, rk) such that ri/ℓi≤\npoly(1 /ε) holds for all iand given any set of (1 −ε)-approximate MWM Mion each G[ℓi,ri)we have\nµw(M1∪M2∪ ··· ∪ Mk)≥(1−O(ε))·µw(G)?\nTo see why methods creating Θ(1 /ε) weight gaps are a special case of the weight partition\nallowed in Question 3.1, note that given any partition with gaps, we can naturally define a weight\npartition by letting each weight gap be its own weight class; if a large matching exists after deleting\nthe edges in the gaps, it still exists when we keep those edges.\nWe give a counterexample (see Claim B.1) that answers Question 3.1 in the negative, even\nwhen the weight partition can be chosen depending on the input graph (recall that [GP13] chose\nthe weight partition up front, oblivious to the structure of the input graph). To see why this is the\ncase, consider the gadget shown in Figure 1 below. Fix a partition Pof [1, W] into weight classes.\nObserve that if this partition “separates” the gadget, i.e., some weight class iinPcontains only\nthe weight 1 but not 1 .5 (and the other weight class jcontains 1 .5), then it leads to an overall loss\nlarger than (1 −ε). More concretely, if the matching Miin class irestricted to the gadget contains\nthe edge bc(and not ab), then MWM( Mi∪Mj) = 1 .5 while the entire gadget contains a matching\n{ab, cd}of weight 2 .5. The final counterexample we construct then contains multiple copies of the\ngadget with different weights and argues that any weight partition Pwith ri/ℓi≤poly(1 /ε) for all i\nmust “separate” sufficiently many gadgets. Consequently, it cannot preserve (1 −ε)-approximation.\na b c d1 1 1.5\nFigure 1: Gadget for answering Question 3.1 in the negative\n3.3 Leveraging Weight Overlaps: the Matching Composition Lemma\nHow can we bypass this barrier? Let us take a closer look at Figure 1. In the gadget above, there\nare two possible Mifor the weight class ithat contains the weight 1: either it contains the edge ab\norbc. As we have discussed above, the “bad” case is when Micontains bcinstead of ab, in which\ncase the edge bcwill be “kicked out” by the edge cdinMjand results in a weight loss. Notice\nalso that the weight loss affects the final approximation ratio when the weights of bcandcdare\nrelatively close (as depicted in Figure 1)—if instead of 1 .5, the weight of cdis changed to at least\n81/ε, then the weights of abandbcare negligible compared to cd(up to an εfraction), and it is\nokay if somehow Micontains bcand it is “kicked out” by cd. Therefore, to fix the issue, for any\ntwo weight values w1andw2that are close enough (in particular, ε≲w1/w2≲1/ε), we should\nhave a weight class that contains both of them. On the other hand, it is fine for w1andw2to not\nbe in any weight class together if they are far apart.\nBased on the observation, we see that if the weight classes are disjoint, then there will always be\ntwo close-enough weight values that are separated by the partition. As a result, instead of creating\nweight gaps, we should leverage overlaps between adjacent weight classes. More concretely, we\ncompute the approximate MWM for each weight class based on the information within the class\nandalsoedges of neighboring weight classes. In other words, we enlarge the intervals in which we\ncompute the matchings slightly. Perhaps surprisingly, we show that having an overlap of poly(1 /ε)\nallows us to bypass the above barrier completely, which we prove the following key technical lemma.\nLemma 3.2 (Matching Composition Lemma) .Letε≤1/6andGbe a graph, and consider a\nδ-wide weight partition [ℓ1, r1),[ℓ2, r2), . . . , [ℓk, rk). IfMiis an arbitrary (1−ε)-approximate MWM\nonG[εℓi,riε−1)for all i∈[k], then\nµw(M1∪M2∪ ··· ∪ Mk)≥(1−O(ε·logδ(1/ε)))·µw(G).\nOn a high level, the matching composition lemma states that if we “pad” the weight classes\n[ℓi, ri) slightly by a factor of 1 /εin both directions, causing overlap, then we can effectively “spar-\nsify” the graph by only considering MWM’s on each G[εℓi,riε−1). This readily leads to an algorithmic\nframework for weight reduction: fix a δ-wide weight partition of the graph, maintain a (1 −ε)-\napproximate MWM Mion each “padded” weight class using the given dynamic algorithm, and\nthen somehow aggregate them together to form the final output matching (i.e., maintain a (1 −ε)-\napproximate MWM on the union of Mi’s). As long as the aggregation can be done efficiently, the\noutput matching can be as well. We give a more detailed overview in Section 3.3.1.\nThe Matching Substitution Lemma. The moment we introduce weight overlaps, we need a\ncompletely different analysis from that of [GP13] to prove that µw(SMi)≥(1−O(ε))µw(G). By\nforcing disjoint (and in fact spread) weighted classes, [GP13] ensured that any conflict between\nmatchings MiandMjcould always be resolved in favor of the higher weight class (hence greedy\naggregation). But once there is weight overlap, it is not clear how conflicts should be resolved. Our\nnew analysis thus requires a new structural understanding of weighted matching.\nIn particular, the matching composition lemma is proved via a structural matching substitution\nlemma formally stated below. It asserts that one can effectively “substitute” parts of a matching\nSwith matchings T1, . . . , T kthat come from certain weight classes.\nLemma 3.3 (Matching Substitution Lemma) .LetGbe a graph and [ℓ1, r1), . . . , [ℓk, rk)⊆Rbe\n(1/ε)-spread. For ε≤1/2, given any matching S⊆G, and a batch of target matchings {Ti⊆\nG[εℓi,riε−1)|i∈[k]}, there exists a matching M⊆S∪T1∪ ··· ∪ Tkof weight\nw(M)≥(1−4ε)w(S)−X\ni∈[k]\0\nµw(G[εℓi,riε−1))−w(Ti)\nsuch that M∩G[ℓi,ri)⊆Tifor all i∈[k].\n9The matching substitution lemma starts with an arbitrary source matching S, and a set of\ntarget matchings T1, . . . , T kon the “padded” weight classes [ εℓ1, r1/ε), . . . , [εℓk, rk/ε). It allows us\nto build a matching starting from Sand substitute all edges of Sin each weight class [ ℓi, ri) with\nedges contained Ti; this incurs some additive approximation error, but it is easy to check that the\nerror is small as long as each Tiis a near-maximum matching for the corresponding padded weight\nclass. For example, if we take Sto be a maximum weight matching on Gand set Tito be the\n(1−ε)-approximate MWM MionG[εℓi,riε−1)from Lemma 3.2, then we can substitute each weight\nrange of Swith edges from Miat minimal loss. We defer the full proof to Section 4.\nArbitrary Approximation Ratio As discussed in the introduction, our reductions only work\nfor (1−ε)-approximations, and not for arbitrary α-approximations. In particular, in the matching\ncomposition lemma, if each Miis instead an arbitrary α-approximate MWM (for some fixed α <1),\nthen it is notthe case that µw(M1∪. . .∪Mk)≥(α−O(ε))µw(G). Somewhat surprisingly, this\nlimitation is not an artifact of our particular choice of weight classes, and turns out to be inherent\nto the general framework of composing approximate matchings between weight classes: for such a\nframework to work with any α-approxmation (as does [GP13]), exp(1 /ε)-wide weight classes are\nrequired. See Appendix C for more details.\n3.3.1 Algorithmic Framework\nThe matching composition lemma suggests the following algorithmic framework:\n1. Fix a δ-wide weight partition of the input graph and maintain a (1 −ε)-approximate MWM\nMion each padded weight class.\n2. Maintain a (1 −O(ε))-approximate MWM on the union of Mi’s as the output matching. By\nthe matching composition lemma this is (1 −O(εlogδ(1/ε)))-approximate in the input graph.\nScaling εdown by a factor of O(logδ(1/ε)) thus ensures that the matching we output is (1 −ε)-\napproximate in the input graph. We now describe how we implement Step 2 efficiently. For this\nwe set δ= Θ( ε−3). With this choice of δ, even though the neighboring “padded” weight classes\noverlap, the sets of “odd” and “even” intervals are still each Θ(1 /ε)-spread.\n(2.1) As such, similar to [GP13], these matchings can be separately aggregated using a greedy\nalgorithm in O(logn) update time. More specifically, let Mibe the matching in the i-th\nweight class. Then, we compute a (1 −ε)-approximate MWM Modd(respectively, Meven) on\nthe union M1∪M3∪ ··· (respectively, M2∪M4∪ ··· ) greedily.\n(2.2) At this point, we are left with two matchings ModdandMeventhat we need to combine\ntogether. This can be relatively easily handled in O(1/ε) time per change to ModdandMeven\nsince the union of these two matchings consists of only paths and cycles, and MWM can be\ncomputed and maintained very efficiently on them by splitting each connected component\ninto paths of length O(1/ε) and solving each path individually via a dynamic program.\nAs a result, with this choice of δwe arrive at a deterministic framework that reduces the aspect\nratio from poly( n) to Θ( ε−5) for any dynamic algorithm (note that the Θ( ε−5) term comes from\npadding the Θ( ε−3)-wide intervals in each direction).\n10Theorem 3.4. Given a dynamic (1−ε)-approximate MWM algorithm in general (possibly non-\nbipartite) graphs with maximum weight in [1,poly(1 /ε)], there is a transformation that produces\na dynamic (1−O(ε))-approximate MWM algorithm in graphs with maximum weight [1, W]. The\nreduction is partially dynamic preserving and has a multiplicative update time overhead of logn·\npoly(1 /ε). The new weighted algorithm is deterministic if the initial algorithm is deterministic.\nThe weight reduction framework described above works for both bipartite and non-bipartite\ngraphs. Moreover, combined with the unfolding framework of [BDL21], it reduces weighted match-\ning algorithms directly to unweighted matching algorithms in bipartite graphs with log n·poly(1 /ε)\nmultiplicative overhead.\n3.4 Further Improvements\nOn top of the framework Theorem 3.4, we made the following additional improvements to decrease\nlognand 1 /εfactors in the final running time which may be of independent interest.\nMore Efficient Aggregation of Spread Matchings In Step (2.1) of our framework described\nabove, we need to maintain a (1 −ε)-approximate MWM over matchings M1, . . . , M kwhose weights\nare sufficiently spread apart (by a gap of Θ(1 /ε)).\nProblem 5.1 (Fully Dynamic (1 −ε)-Approximate MWM Problem over Matchings in (1 /ε)-Spread\nWeight Classes) .Given a set of (1 /ε)-spread weight classes [ ℓ1, r1), . . . , [ℓk, rk)⊆R, and a set of k\nmatchings M1, . . . , M k⊆Gundergoing adversarial edge deletions/insertions satisfying Mi⊆G[ℓi,ri)\nfor all i∈[k]. The task is to dynamically maintain a matching Msatisfying\nw(M)≥(1−O(ε))X\ni∈[k]w(Mi).\nThe work of [GP13] solved Problem 5.1 with update time O(k) using a greedy census matching\nalgorithm that was also used in [ABGS12, SW17]. To improve upon this, we propose a different\nnotion of locally greedy census matching. We show that the new notion suffices for maintaining a\n(1−ε)-approximation and since, on a high level, the local version allows us to consider fewer edges\nin each update, we get a faster update time of O(k/logn). Note that for Step (2.1), the value of k\nis2O(logn) and thus this shaves off the O(logn) factor in the update time that would have been\nthere if we used the subroutine of [GP13]. See Section 5.1 for more details.\nLow-Recourse Transformation Note that the overall update time of our framework also de-\npends on the recourse σof the given dynamic algorithm A, i.e., the number of changes to the\nmatching Mithat it generates per update to the input graph. This is because each such changes\npropagate to the internal dynamic subroutines, and for our case it will first correspond to an update\nto our algorithm for Problem 5.1, and then be propagated to Step (2.2) which has an update time\nofO(1/ε). Our overall update time is thus U+σ/ε, where Uis the update time of the dynamic\nalgorithm A. Similar scenarios also occur in previous reductions of [GP13, BDL21], and they both\nimplicitly used the fact that σ≤ U(this is for algorithms that explicitly maintain a matching) and\ntherefore their reductions incur a multiplicative overhead in the update time of A.\n2Note that this is because we assume the input graph has weights in [1 , . . . , poly(n)].\n11However, the output recourse can be much smaller than the update time. For instance, for\nunweighted dynamic matching algorithms, the recourse can always be made O(1/ε) by a simple\nlazy update trick (the work of [SS21] further achieved a worst-case recourse bound by “smoothing”\nthe lazy update), while all known dynamic matching algorithms have update time much larger than\nthis. To address this disparity and make the overhead of our reduction additive , we design a generic\nlow-recourse transformation that converts, in a black-box way, any(1−ε)-approximate dynamic\nMWM algorithm to one with amortized recourse O(poly(log W)/ε). This improves the na¨ ıve lazy\nupdate approach that would have a recourse bound of O(W/ε). As our framework reduces the\nweight range to W= Θ( ε−5), we use this new low-recourse transformation on the input algorithm\nAto decrease the additive overhead from O(ε−6) (with the na¨ ıve lazy update) to O(log(ε−1)/ε).\nTo improve the aspect ratio further than Θ( ε−5), we continue to apply the framework on each\nΘ(ε−5) intervals. Combined with the low-recourse transformation, we provide a trade-off between\nthe aspect ratio and the efficiency of aggregation (see Corollary 5.23). We use it to improve the\nfully dynamic low-degree algorithm in [GP13] which then serves as another aggregation method\nthat finally allows us to reduce the aspect ratio to Θ( ε−2), the best we can get using Lemma 3.2.\nSee Section 5 for more details.\nThe Final Transformation In the end, applying the improvements we discussed in this section,\nwe obtain our final main theorem.\nTheorem 3.5. Given a dynamic (1−ε)-approximate MWM algorithm Athat, on input n-vertex m-\nedge graph with aspect ratio W, has initialization time I(n, m, W, ε ), and update time U(n, m, W, ε ),\nthere is a transformation which produces a dynamic (1−εlog(ε−1))-approximate MWM dynamic\nalgorithm that has initialization time\nlog(ε−1)·O(I(n, m, Θ(ε−2),Θ(ε)) +mε−1),\namortized update time\npoly(log( ε−1))·O(U(n, m, Θ(ε−2),Θ(ε)) +ε−5),\nand amortized recourse\npoly(log( ε−1))·O(ε−5).\nThe transformation is partially dynamic preserving.\n4 Matching Composition and Substitution Lemmas\nWe now turn to the proof of our key technical lemmas, the matching composition and substitution\nlemmas. We first prove the matching substitution lemma, and then use it to deduce the matching\ncomposition lemma that ultimately leads to our algorithmic framework.\nIn the matching substitution lemma, we are given a source matching Sand target matchings\nT1, . . . , T kon padded versions of (1 /ε)-spread intervals [ ℓ1, r1), . . . , [ℓk, rk); more precisely, each\nTiis a matching on [ εℓi, riε−1). The lemma states that we can find a new matching Mwith\nw(M)≈w(S)—assuming the matchings Tiare large—such that Monly uses edges of Tion the\nweight interval [ ℓi, ri) for each i∈[k]. The key idea in the proof is to identify a set of edges\nDwith small total weight (relative to S) to delete such that the edges of every component in\n(S∪T1∪ ··· ∪ Tk)\\Dare confined to a single weight class.\n12Lemma 3.3 (Matching Substitution Lemma) .LetGbe a graph and [ℓ1, r1), . . . , [ℓk, rk)⊆Rbe\n(1/ε)-spread. For ε≤1/2, given any matching S⊆G, and a batch of target matchings {Ti⊆\nG[εℓi,riε−1)|i∈[k]}, there exists a matching M⊆S∪T1∪ ··· ∪ Tkof weight\nw(M)≥(1−4ε)w(S)−X\ni∈[k]\0\nµw(G[εℓi,riε−1))−w(Ti)\nsuch that M∩G[ℓi,ri)⊆Tifor all i∈[k].\nProof. We construct a sequence of matchings M0, M1, . . . , M k, such that M0=Sis the source\nmatching, Miis constructed from Mi−1∪Ti, and Mk=Mis the desired matching in the lemma.\nWe first describe how to construct Mifori≥1. The components of Mi−1⊕Tiare only paths\nand cycles. Construct a set Di⊆Mi−1as follows: For each path or cycle P⊆Mi−1⊕Tiand\ne∈P∩Mi−1such that w(e)≥riε−1, in both directions of P, add the closest edges in P∩Mi−1of\nweight at most riintoDi. For each e∈P∩Mi−1such that ℓi≤w(e)< riε−1, in both directions\nofP, add the closest edges in P∩Mi−1of weight less than εℓiintoDi.\nNow let fMi−1def=Mi−1\\Diand again consider fMi−1⊕Tiand any path or cycle P⊆fMi−1⊕Ti.\nNotice that if there is an e∈P∩fMi−1such that w(e)∈[ℓi, ri), then it must be the case that P⊆\nG[εℓi,riε−1). Let Libe the collection of such paths and cycles. We then construct Midef=fMi−1⊕Li,\nand thus Mi⊆fMi−1∪TiandMi∩G[ℓi,ri)⊆Ti. It follows by induction that Mk⊆Mk−1∪Tk⊆\n··· ⊆ S∪T1∪ ··· ∪ TkandMk∩G[ℓi,ri)⊆Tifor all i.\nWe now analyze w(Mk). Starting with M0, two kinds of changes happened to the matching.\nThe first one is the edge deletion D1∪···∪ Dk, and the second one is the edge substitution through\nL1∪ ··· ∪ Lk. We analyze the total weight loss in each part respectively.\n1. Since ℓi≥ri−1ε−1, only edges in Scause deletion. For any edge e∈S, it could cause\nat most 2 edges deletions with respect to every weight class [ εℓi, riε−1). The weight of\nthe deleted edges in the ith weight class would be at least εsmaller than weand at most\nri. Since ri≥ℓi≥ri−1ε−1, the total weight of those deleted edges would be at most\nw(e)·\0\n2ε+ 2ε2+···\n≤4ε·w(e). Thus\nw(D1∪ ··· ∪ Dk)≤4ε·w(M).\n2. For each of the substitution induced by Li, notice that Li⊆G[εℓi,riε−1), thus\nX\nP∈Liw(P∩fMi−1)−w(P∩Ti)≤µw(G[εℓi,riε−1))−w(Ti).\nTherefore, the second part leads to a total weight loss of at most\nX\ni∈[k]\0\nµw(G[εℓi,riε−1))−w(Ti)\n.\nWe also need the following helper lemma.\nLemma 4.1. Forε≤1/6, any graph Gand any set of (1/ε)-spread weight classes\n[ℓ1, r1), . . . , [ℓk, rk)⊆R, we have\nX\ni∈[k]µw(G[ℓi,ri))≤(1 + 4 ε)·µw(G).\n13Proof. Suppose that ℓ1< ℓ2<···< ℓk. Let Mibe a MWM on G[ℓi,ri), and let Hdef=M1∪···∪ Mk.\nLetMbe the matching obtained by the following greedy process: While His non-empty, we pick\nan edge einHwith the maximum weight and include it into M. Then, to ensure that the next\nedge we pick from Hstill forms a matching with M, we remove all edges in Hthat are adjacent\ntoe(including eitself). Observe that if an edge fis removed from Hbye, then we must have\nw(f)≤w(e). Let iebe such that e∈Mie. We also have that for each j < i e, at most two edges\nfrom Mjwill be removed by e(the two matched edges in Mjfor the endpoints of e). As the weight\nclasses are (1 /ε)-spread, we have\nX\nfremoved by ew(f)≤w(e)·(1 + 2 ·(ε+ε2+···))≤(1 + 4 ε)·w(e).\nAt the end of the process, Hwill become empty. In other words, each edge in His removed by\nsome edge in M. This shows that\nX\ni∈[k]µw(G[ℓi,ri)) =X\nf∈Hw(f)≤(1 + 4 ε)·w(M)≤(1 + 4 ε)·µw(G).\nWe can now prove the matching composition lemma.\nLemma 3.2 (Matching Composition Lemma) .Letε≤1/6andGbe a graph, and consider a\nδ-wide weight partition [ℓ1, r1),[ℓ2, r2), . . . , [ℓk, rk). IfMiis an arbitrary (1−ε)-approximate MWM\nonG[εℓi,riε−1)for all i∈[k], then\nµw(M1∪M2∪ ··· ∪ Mk)≥(1−O(ε·logδ(1/ε)))·µw(G).\nProof. Letg=⌈logδ(1/ε3)⌉+ 1, and for all j∈ {0, . . . , g −1}, let Ij={i∈[k] :i≡jmod g}.\nFor the weight classes in each Ij, the weight gap between neighboring weight classes is at least\nδg−1≥1/ε3. The set of weight classes {[ℓi, ri) :i∈Ij}is (1/ε3)-spread, and thus the set of\npadded weight classes {[εℓi, riε−1) :i∈Ij}is (1/ε)-spread. Consider any exact MWM M∗onG.\nWe will start with the initial source matching S0=M∗, and for j= 0,1, . . . , g −1, sequentially\napply Lemma 3.3 on the source matching Sjand target matchings {Mi|i∈Ij}and get Sj+1. For\na fixed j, since Miis a (1 −ε)-approximate MWM on G[εℓi,riε−1)fori∈Ij, Lemmas 3.3 and 4.1\ngive us a matching Sj+1⊆Sj∪(S\ni∈IjMi) that satisfies\nw(Sj+1)≥(1−4ε)w(Sj)−ε·X\ni∈Ijµw(G[εℓi,riε−1))\n≥(1−4ε)w(Sj)−ε(1 + 4 ε)·µw(G)≥(1−4ε)w(Sj)−3ε·µw(G),\nand that Sj+1∩G[ℓi,ri)⊆Mifor all i∈Ij. By induction, we have\nw(Sj+1)≥(1−4(j+ 1)ε)·w(S0)−3(j+ 1)ε·µw(G)≥(1−7(j+ 1)ε)µw(G),\nand that\nSj+1∩G[ℓi,ri)⊆\0\nSj∩G[ℓi,ri)\n∪\n[\nt∈IjMt\n⊆ ··· ⊆j[\nl=j′[\nt∈IlMt\n14hold for all j′≤jandi∈Ij′. Thus, we have\nw(Sg)≥(1−O(g·ε))µw(G)≥(1−O(logδ(1/ε)·ε))µw(G),\nand\nSg∩G[ℓj,rj)⊆[\ni∈[k]Mi\nfor all j∈[k]. Therefore, the matching Sgis contained in the union of all Mi’s and consequently\nµw(M1∪M2∪ ··· ∪ Mk)≥w(Sg)≥(1−O(logδ(1/ε)·ε))µw(G).\n5 Framework\nIn this section, we will describe our framework in detail. As suggested by Lemma 3.2, we first fix a\nΘ(ε−3)-wide weight partition, and compute a (1 −ε)-approximate MWM on each “padded” weight\nclasses with aspect ratio Θ( ε−5). The choice of width ensures that the set of odd “padded” weight\nclasses has Θ(1 /ε) weight gaps and so does the set of even ones. We use a subroutine Algorithm 1\nin Section 5.1 to aggregate odd matchings and even matchings, and maintain a (1 −ε)-approximate\nMWM on the union of them using the second subroutine Algorithm 2 in Section 5.2. In Section 5.3\nwe give the complete framework to reduce the aspect ratio with multiplicative poly(1 /ε) overhead.\nIn Section 5.4, we introduce a low-recourse transformation for (1 −ε)-approximate dynamic MWM\nto change the multiplicative poly(1 /ε) overhead to an additive poly(1 /ε) overhead. Finally, in Sec-\ntion 5.5, we use the low-recourse transformation to obtain an efficient fully dynamic algorithm on\nlow-degree graphs, which leads to an efficient weighted rounding algorithm and could also serve as\nan efficient aggregation that allows us to reduce the aspect ratio to O(ε−2), which is the best we can\nhope for based on Lemma 3.2. Also, combined with [BDL21] we achieve a poly(1 /ε) multiplicative\noverhead reduction from weighted matching algorithms to unweighted ones in bipartite graphs.\n5.1 Dynamic Approximate MWM on Matchings in (1/ε)-Spread Weight Classes\nOur first subroutine is an improved algorithm that combines matchings in weight classes that are\nsufficiently spread. In particular, the goal is to solve the following problem.\nProblem 5.1 (Fully Dynamic (1 −ε)-Approximate MWM Problem over Matchings in (1 /ε)-Spread\nWeight Classes) .Given a set of (1 /ε)-spread weight classes [ ℓ1, r1), . . . , [ℓk, rk)⊆R, and a set of k\nmatchings M1, . . . , M k⊆Gundergoing adversarial edge deletions/insertions satisfying Mi⊆G[ℓi,ri)\nfor all i∈[k]. The task is to dynamically maintain a matching Msatisfying\nw(M)≥(1−O(ε))X\ni∈[k]w(Mi).\nAs mentioned in Section 3.4, our improvement comes from maintaining the following locally\ngreedy census matchings.\nDefinition 5.2 (Locally Greedy Census) .Consider kmatchings M1, M2, . . . , M k. A matching M\nis alocally greedy census matching ofM1, M2, . . . , M k⊆Gif for every edge e∈Mi\\M, there exists\nanf∈Mjsuch that e∩f̸=∅for some j > i.\n15The above local notion should be compared with the standard greedy census matching con-\nsidered in [ABGS12, GP13, SW17]. In the standard notion, an edge can only be removed if it is\nincident to some higher-weight edge that is included into the output matching . In contrast to that,\nin our locally greedy census matching, if an edge is incident to anyhigher-weight edge, regardless of\nwhether that edge is in the output matching we are allowed to remove it. This allows us to consider\npotentially much fewer edges when maintaining the local greedy census matching. Nevertheless,\nwe show that a similar charging argument can be used to prove the following guarantee.\nLemma 5.3. Forε≤1/2, any set of (1/ε)-spread weight classes [ℓ1, r1), . . . , [ℓk, rk)⊆R, and\nmatchings M1, . . . , M k⊆Gsatisfying Mi⊆G[ℓi,ri)for all i∈[k], every locally greedy census\nmatching Mover the union of M1, . . . , M ksatisfies\nw(M)≥(1−4ε)X\ni∈[k]w(Mi).\nProof. The proof idea is similar to Lemma 4.1. For any edge e∈Mj, at most two edges in each\nlower weight class i < j are not included in Mbecause of e, and the total weight of these edges is\nat mostX\ni∈[j−1]2·w(e)·ε−(i−j)≤2ε\n1−ε·w(e).\nThus,\nw(M)≥\n1−2ε\n1−εX\ni∈[k]w(Mi)≥(1−4ε)X\ni∈[k]w(Mi).\nWe show that our modified notion allows us to maintain a locally greedy census matching more\nefficiently than what is achieved in [SW17] for the non-local version. Remarkably, our algorithm\nachieves a constant update time when there are only O(logn) matchings.\nTheorem 5.4. Algorithm 1 initializes in O(m)time and solves Problem 5.1 by dynamically main-\ntaining a locally greedy census matching with min{O(logk), O(k/logn)}worst-case update time and\nO(1)worst-case recourse.\nProof. For any edge uv, it is contained in the locally greedy census matching if and only if it is\nin the highest weight class among NuandNv. By definition, after the initialization, Algorithm 1\nmaintains a locally greedy census matching. And the initialization takes O(m) time.\nFor an edge update uv, the only possible changes in the locally greedy census matching are\ninNuandNv. For insertion of uv, Algorithm 1 checks whether the edges related to uandvin\nthe current matching still satisfies the condition, and whether uvcan be added. For deletion of\nuv, only the edges in the highest weight class among NuorNvcan be added into the matching.\nAlgorithm 1 finds those edges and checks whether the condition is met. Therefore, it maintains a\nlocally greedy census matching and the worst-case recourse is O(1).\nFor each node u, there is at most one edge from each weight class in Nu, i.e., |Nu| ≤k. To\nmaintain the maximum element in Nu, we can use a binary search tree which runs in O(logk)\ntime. Both Insert andDelete have O(1) number of updates and queries to the binary search tree.\nTherefore, the update time would be O(logk).\nAlternatively, we can use a packed bit-representation of the weight-class information in Nu. We\nset the i-th bit to be 1 if and only if there is an edge in Nuin the ( k−i)-th weight class. Thus\nto find the edge in the highest weight class among Nu, it suffices to look at the lowest bit in the\nrepresentation, which can be done in O(k/logn) time in the word RAM model.\n16Algorithm 1: Dynamic Locally Greedy Census Matching\n1function Initialize()\n2 foreach node u∈Gdo\n3 Initialize its neighborhood Nu← ∅.\n4 forj=k, . . . , 1do\n5 foruv∈Mjdo\n6 ifNu=∅andNv=∅then\n7 Add uvto the matching.\n8 Add uvtoNuandNv.\n9function Insert( j, uv)\n10 Add uvtoNuandNv.\n11 ifuis matched to some vertex u′, and uu′∈Misuch that i < j then\n12 Delete uu′from the matching.\n13 ifvis matched to some vertex v′, and vv′∈Misuch that i < j then\n14 Delete vv′from the matching.\n15 ifuvis in the highest weight class among NuandNvthen\n16 Add uvto the matching.\n17function Delete( j, uv)\n18 Delete uvfrom NuandNv.\n19 ifNuis not empty then\n20 uu′←the edge in the highest weight class among Nu.\n21 ifuu′is in the highest weight class among Nu′.then\n22 Add uu′to the matching.\n23 ifNvis not empty then\n24 vv′←the edge in the highest weight class among Nv.\n25 ifvv′is in the highest weight class among Nv′.then\n26 Add vv′to the matching.\n5.2 Dynamic Approximate MWM on Degree-Two Graphs\nAfter combining the odd and even matchings with our locally greedy census matching algorithm,\nwe are left with a union of two matchings which is a graph with maximum degree at most two.\nThat is, we need to solve the following problem.\nProblem 5.5 (Fully-Dynamic (1 −ε)-Approximate MWM on Degree-Two Graphs) .Given a graph\nGundergoing edge updates satisfying that its maximum degree is at most two. The task is to\ndynamically maintain a matching Msatisfying the following condition:\nw(M)≥(1−O(ε))·µw(G).\nObserve that a degree-two graph consists of paths and cycles. Since an exact MWM on a path\nor cycle Pcan be computed in O(|P|) time with dynamic programming, it suffices to maintain\n17a collection of short paths and cycles on which a large-weight matching is supported. For this,\none can delete the minimum weight edge in each Θ(1 /ε)-length neighborhood while keeping a\n1−O(ε) fraction of the total weight. We propose Algorithm 2 to solve Problem 5.5 by dynamically\nmaintaining this O(1/ε)-length decomposition of the paths and cycles and computing an exact\nMWM on each piece.\nLemma 5.6 (Dynamic Path/Cycle Maintainer) .There is a deterministic data structure Dthat\nmaintains a set of dynamic paths or cycles {Pi}under the insertion/deletion of edges and supports\nthe following operations, where all update times and recourse mentioned are worst-case:\n1. Find the path/cycle Puthatubelongs to in O(|Pu|)time.\n2.FindHeads (P): For a path P, find its both ends in O(|Pu|)time.\n3.Insert /Delete (uv): Insert/delete an edge uvinO(|Pu|+|Pv|+ 1) time.\n4.FindMin (P, h, ℓ, r ): For a path P, find the edge with the minimum weight between the ℓ-th\nand the r-th edges counting from h, one of the end of P, inO(|P|)time.\n5. For a path/cycle P, explicitly maintain its MWM in O(|P|)time and recourse.\nProof. We can check all elements in a path in linear time in its size. Thus the first 4 operations\nare straightforward to achieve. Now we prove that it can output the MWM. Consider the following\ndynamic programming for computing MWM on paths. For a path P, number its edges from P1to\nP|P|. Denote fi,0/1as the MWM on the path P1. . . P iwhen Piis in the matching or not. For any\ni≤ |P|,fi,0/1can be computed by\nfi,x=wi·x+ max\n0≤y≤1−xfi−1,y.\nTherefore, the value can be computed in O(|P|) time and the edge list corresponding to the MWM\ncan be inferred by taking notes of how each state is updated.\nLemma 5.7. During the execution of Algorithm 2, Dmaintains a set of paths/cycles with length\nat most 3⌈ε−1⌉.\nProof. The length of a path only increases after an edge insertion in D, and Algorithm 2 calls\nMaintain every time which splits the path into two whenever its length is at least 3 ⌈ε−1⌉. Thus\nthe paths have lengths at most 3 ⌈ε−1⌉ −1. The only case Dkeeps a cycle is that before the\nformation of that cycle, the path has a length at most 3 ⌈ε−1⌉ −1. Therefore, the cycle has length\nat most 3 ⌈ε−1⌉.\nLemma 5.8. Algorithm 2 initializes in O(mε−1)time and solves Problem 5.5 by explicitly main-\ntaining an matching with O(ε−1)worst-case update time and O(ε−1)worst-case recourse.\nProof. Lemma 5.7 show that Dmaintains a set of paths/cycles with length at most 3 ⌈ε−1⌉. By\nLemma 5.6, we know that each operation of Dtakes time O(1/ε). Now consider the recurrence in\nMaintain . Any path that appears in Maintain has length at most O(1/ε) and will be at least ⌈ε−1⌉\nshorter in line 24. Thus there are only O(1) recurrences in Maintain . Therefore, the worst-case\nupdate time of the algorithm is O(1/ε) and the worst-case recourse is O(1/ε).\n18Algorithm 2: Fully-Dynamic (1 −ε)-Approximate MWM on Degree-Two Graphs\n1function Initialize()\n2D ← an instance of the dynamic path/cycle maintainer described in Lemma 5.6.\n3 R← ∅.\n4 foruv∈EdoInsert( uv).\n5function Insert( u, v)\n6D.Insert (uv).\n7 ifPuis a path then Maintain( Pu).\n8function Delete( uv)\n9 ifuv∈Rthen R←R\\uv.\n10 D.Delete (uv).\n11 hu, u← D.FindHeads (Pu).\n12 ifthere is an edge huh′\nu∈Rthen\n13 R←R\\huh′\nu.\n14 D.Insert (huh′\nu).\n15 Maintain( Pu).\n16 hv, v← D.FindHeads (Pv).\n17 ifthere is an edge hvh′\nv∈Rthen\n18 R←R\\hvh′\nv.\n19 D.Insert (hvh′\nv).\n20 Maintain( Pv).\n21function Maintain( P)\n22 h, t← D.FindHeads (P).\n23 if|P| ≥3⌈ε−1⌉then\n24 uv← D.FindMin (P, h,⌊(|P| − ⌈ε−1⌉)/2⌋,⌊(|P| − ⌈ε−1⌉)/2⌋+⌈ε−1⌉ −1).\n25 D.Delete (uv).\n26 R←R∪ {uv}.\n27 Maintain( Pu).\n28 Maintain( Pv).\nNow we show it maintains a (1 −O(ε))-approximated MWM. In a degree-two graph, every con-\nnected component is either a path or a cycle, and Dmaintains an exact MWM on each component\nofG\\Raccording to the last operation in Lemma 5.6. We know that µw(G)≥1\n2P\ne∈Gwe, since\nfor each component in G, the “odd” edges and “even” edges both form a matching. On the other\nhand, an edge is added into Ronly if it is the minimum among a set of ⌈ε−1⌉edges, and those sets\nare disjoint for different edges in Rsince we only add edges to Rwhen the path is at least 3 ⌈ε−1⌉\nlong. ThusP\ne∈Rwe≤ε·P\ne∈Gwe≤2ε·µw(G). Denote Mas the matching output by D, we have\nw(M) =µw(G\\R)≥µw(G)−X\ne∈Rwe≥(1−2ε)µw(G).\n195.3 Weight Reduction Framework for General Graphs\nWe are now ready to show our main result, a deterministic framework with poly(1 /ε) multiplica-\ntive overhead and recourse, which reduces the aspect ratio from Wto poly(1 /ε) for any (1 −ε)-\napproximate dynamic MWM algorithm.\nTheorem 5.9. Given a dynamic (1−ε)-approximate MWM algorithm Athat, on input n-vertex m-\nedge graph with aspect ratio W, has initialization time I(n, m, W, ε ), amortized/worst-case update\ntimeU(n, m, W, ε ), amortized/worst-case recourse σ(n, m, W, ε ), there is a transformation which\nproduces a dynamic (1−O(ε))-approximate MWM algorithm with initialization time\nO(I(n, m, Θ(ε−5),Θ(ε)) +mε−1)\ntime, amortized/worst-case update time\nO(U(n, m, Θ(ε−5),Θ(ε)) +σ(n, m, Θ(ε−5),Θ(ε))ε−1),\nand amortized/worst-case recourse\nO(σ(n, m, Θ(ε−5),Θ(ε))ε−1).\nThe transformation is partially dynamic preserving.\nThere are three steps in Algorithm 3. In the first step, for all 1 ≤i≤ ⌈(L+ 1)/3⌉,Miis\nmaintained by Aiand is a (1 −ε)-approximation of µw(eEi). In the second step, we use the locally\ngreedy census matching Algorithm 1 to aggregate Mifor odd iand even irespectively, into Modd\nandMeven, with the guarantee from Lemma 5.3 that ModdandMevenboth keep at least a (1 −4ε)\nfraction of the total weight of the corresponding matchings. Then we use Algorithm 2 for degree-\ntwo graphs to aggregate ModdandMeven, and Lemma 5.8 shows that the final matching output by\nAlgorithm 3 is a (1 −2ε)-approximated MWM on Modd∪Meven. We will prove that since at each\nstep we lose a O(ε) fraction, the final matching we output keeps a (1 −O(ε))-approximate MWM.\nLemma 5.10. Forε≤1/2, Algorithm 3 maintains a matching Mwithµw(M)≥(1−O(ε))µw(G).\nProof. Lemma 3.2 shows that\nµw(M1∪M2∪ ··· ∪ M⌈(L+1)/3⌉)≥(1−O(ε))µw(G).\nConsider the locall', 'raytos.r.bsinfotech@gmail.com', 'Aaron Bernstein, Jiale Chen, Aditi Dudeja, Zachary Langley, Aaron Sidford, Ta-Wei Tu', '', '../pdf_files/671b4a15eccf3-Matching Composition and Efficient Weight Reduction in Dynamic Matching.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(130, '9848906603', '1', 1, 1, 'Testing Support Size More Efficiently Than Learning Histograms', '2024-10-25', '2024', 'Consider two problems about an unknown probability distribution p: \r\n1. How many samples from p are required to test if p is supported on n elements or not? Specifically, given samples from p, determine whether it is supported on at most n elements, or it is “ε-far” (in total variation distance) from being supported on n elements. \r\n2. Given m samples from p, what is the largest lower bound on its support size that we can produce? \r\nThe best known upper bound for problem (1) uses a general algorithm for learning the histogram of the distribution p, which requires Θ( n ε2 logn) samples. We show that testing can be done more efficiently than learning the histogram, using only O( n εlogn log(1/ε)) samples, nearly matching the best known lower bound of Ω( n εlogn). This algorithm also provides a better solution to problem (2), producing larger lower bounds on support size than what follows from previous work. The proof relies on an analysis of Chebyshev polynomial approximations outside the range where they are designed to be good approximations, and the paper is intended as an accessible self-contained exposition of the Chebyshev polynomial method.', 'Data Structures and Algorithms, Machine Learning', 'Testing Support Size More Efficiently Than Learning Histograms\nRenato Ferreira Pinto Jr.\nUniversity of WaterlooNathaniel Harms\nEPFL\nAbstract\nConsider two problems about an unknown probability distribution p:\n1. How many samples from pare required to test if pis supported on nelements or not?\nSpecifically, given samples from p, determine whether it is supported on at most nelements,\nor it is “ ε-far” (in total variation distance) from being supported on nelements.\n2. Given msamples from p, what is the largest lower bound on its support size that we can\nproduce?\nThe best known upper bound for problem (1) uses a general algorithm for learning the histogram\nof the distribution p, which requires Θ(n\nε2logn) samples. We show that testing can be done more\nefficiently than learning the histogram, using only O(n\nεlognlog(1/ε)) samples, nearly matching\nthe best known lower bound of Ω(n\nεlogn). This algorithm also provides a better solution to\nproblem (2), producing larger lower bounds on support size than what follows from previous\nwork. The proof relies on an analysis of Chebyshev polynomial approximations outside the\nrange where they are designed to be good approximations, and the paper is intended as an\naccessible self-contained exposition of the Chebyshev polynomial method.arXiv:2410.18915v1  [cs.DS]  24 Oct 2024Contents\n1 Introduction 1\n2 Defining a Test Statistic 6\n2.1 Small ε. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.2 The test statistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.3 Choosing a function f. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.4 Chebyshev polynomials and the definition of Pd. . . . . . . . . . . . . . . . . . . . . 9\n3 Choosing Parameters 10\n3.1 Constraint I: Choose dsuch that δ≤ε. . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.2 Constraint II: Choose msuch that Q(pi)≈1 when pi> r . . . . . . . . . . . . . . . 12\n3.3 Constraint III: Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.4 Constraint IV: E[bS]≥(1 +ε)nwhen pisε-far . . . . . . . . . . . . . . . . . . . . . . 14\n3.5 Correctness of the tester and optimizing the parameters . . . . . . . . . . . . . . . . 17\n3.6 Constraint IVb: Improvements from loosening constraint IV . . . . . . . . . . . . . . 20\n4 An Effective Lower Bound on Support Size 26\n5 Testing Support Size of Functions 28\nA Coefficients of Pdand Values of f 30\nB Derivative of Td 33\nC Remark on the Bounded Support Size Assumption 34\nC.1 Using histogram learner with TV distance guarantee. . . . . . . . . . . . . . . . . . . 34\nC.2 Using the histogram learner with relative Earth-mover distance guarantee. . . . . . . 341 Introduction\nSadly, it is often necessary to make decisions based on probability distributions. For example, you\nmay need to make a decision based on the support size of an unknown distribution:\nExample 1.1. There is a population of fish in the lake, which may be described as a\nprobability distribution pover the set of possible fish species. You want to preserve a\nspecimen of each species. You have no idea how many fish or fish species there are, and you\nonly have 10000 sample jars. Is that enough, or should you buy more? You would like to\ndecide between:\n1. There are at most 10000 species of fish in the lake. (You have enough jars.)\n2. Any collection of 10000 species will miss at least 0.1% of the population, i.e. 0.1% of\nthe fish will belong to species notin the collection. (You need more jars.)\nThe na¨ ıve strategy is to sample random fish until you have filled all the jars, and if you\ncontinue to see new species, buy more jars. Of course, you prefer to predict in advance if\nyou need more jars. How many fish do you need to sample before you can make this decision\n(and be correct with probability at least 99%)?\nThe best known algorithms for making this type of decision work by learning the histogram\nof the distribution (the unordered multiset of nonzero probabilities densities {pi|pi̸= 0}). In this\npaper we show there is a more sample-efficient way to do it. Formally, the problem is to distinguish\nbetween distributions with support size at most n, and those which are ε-farfrom having support\nsize at most n. We say pisε-farfrom having support size at most nwhen, for every probability\ndistribution qwith support size |supp( q)| ≤n, the total variation (TV) distance between pandq\nisdistTV(p, q)> ε. Then:\nDefinition 1.2 (Testing Support Size) .Asupport-size tester with sample complexity\nm(n, ε, σ ) is an algorithm Awhich takes as input the parameters n∈N,ε∈(0,1), and\nσ∈(0,1). It draws a multiset Sofm=m(n, ε, σ ) independent samples from an unknown\nprobability distribution poverN, and its output must satisfy:\n1. If|supp( p)| ≤nthenP\nS[A(S) outputs Accept ]≥σ; and\n2. If pisε-farfrom having support size at most n, then P\nS[A(S) outputs Reject ]≥σ.\nUnless otherwise noted, we set σ= 3/4.\nTesting support size is a basic statistical decision problem (see e.g. the textbook [Gol17, §11.4]\nand recent work [GR23, AF24, AFL24]) that underlies many other commonly studied tasks. For\nexample, it is a decision version of the problem of estimating support size – a problem whose history\ndates back to Fisher [FCW43], Goodman [Goo49], and Good & Turing [Goo53]; see [BF93] for a\nsurvey, and more recent work including [RRSS09, VV11a, VV17, WY19, HO19b]. Testing support\nsize is also important for understanding the testing vs. learning question in property testing.\nTesting vs. learning distributions. Testing support size is a distribution testing problem,\nwhich is a type of property testing . A basic technique in property testing is the testing-by-learning\napproach of [GGR98], where the tester learns an approximation of the input and makes its decision\nbased on this approximation. One of the guiding questions in property testing is: When can this\ntechnique be beaten?\n1It requires Θ( n/ε2) samples to learn a distribution pover domain [ n], up to TV distance ε(see\ne.g. the survey [Can20]). Remarkable and surprising recent work [VV11a, VV17, HJW18, HO19a]\nproves that the histogram of distributions pover [ n] can be learned with only Θ(n\nε2logn) samples —\na vanishing fraction of the domain. This means one can test the support size – or perform several\nother tasks – using O(n\nε2logn) samples to learn the histogram. As noted in the textbook [Gol17]\nand recent work [GR23, AFL24], this testing-by-learning algorithm gives the best known upper\nbound for testing support size when the true support size is promised to satisfy |supp( p)|=O(n).\nWithout this promise there does not appear to be a simple way to obtain a similar bound from\nknown results (see [GR23, pp.21] and the discussion in Appendix C, where we sketch arguments to\nobtain bounds of O(n\nε3logn) from [VV16]). We show that the testing-by-learning algorithm can be\nbeaten, while also removing any restriction on the true support size:\nTheorem 1.3. For all n∈Nandε∈(0,1), the sample complexity of testing support size of\nan unknown distribution p(over any countable domain) is at most\nm(n, ε) =On\nεlogn·min{log(1/ε),logn}\n.\nIn terms of Example 1.1, if you have njars, you can decide whether to buy more jars after taking\nO(n\nεlognlog(1/ε)) samples, filling less than a sublinear O(log(1/ε)\nεlogn)-fraction of the jars. Theorem 1.3\nnearly matches the best known lower bound of Ω(n\nεlogn) (which can be deduced from lower bounds\nof [VV11a, WY19]). An important note about this problem is that, in the setting of Theorem 1.3,\nthe related problem of estimating the support size is impossible: the unknown support size of pis\nunbounded and the probability densities pican be arbitrarily small. If one makes assumptions to\navoid these issues, then there are tight bounds of Θ(k\nlogklog2(1/ε)) for estimating the support size\nup to ±εkwhen each nonzero density piis promised to satisfy pi>1/k[WY19, HO19b] (see also\n[RRSS09, VV11a, ADOS17, VV17]). Recalling Example 1.1, kwould be the total number of fish\nin the lake, whereas in our results nis the number of species .\nGood lower bounds on support size. Quoting I. J. Good in [BF93], “I don’t believe it is usu-\nally possible to estimate the number of unseen species [i.e. support size]. . . but only an approximate\nlower bound to that number.” So, in lieu of an estimate, what is the best lower bound we can get?\nQuestion 1.4. Given msamples from a distribution pand parameter ε∈(0,1), what is the\nbiggest number bSthat we can output, while still satisfying bS≤(1 +ε)|supp( p)|?\nOur algorithm can produce lower bounds as large as Ω(ε\nlog(1/ε)mlogm) out of only msamples.\nLet us formalize the quality of these lower bounds. A reasonable target for such a “Good” lower\nbound bSis that it should exceed the ε-effective support size , the smallest number of elements\ncovering 1 −εprobability mass:\nDefinition 1.5 (Effective support size) .For any probability distribution poverNand any\nε∈(0,1), we define the ε-effective support size effε(p) as the smallest number k∈Nsuch\nthat there exists distribution qwith|supp( q)|=kanddistTV(p, q)≤ε.\nWith no assumptions on the distribution, the effective support size is a more natural target for\nestimation, because it accounts for the fact that an arbitrarily large number of elements in the\n2support may comprise an arbitrarily small probability mass. Effective support size was used in\n[CDS18, BCG19], and algorithms for estimating it were analyzed in [Gol19a, Gol19b, NT23], but\nthese algorithms assume the algorithm can learn the probability densities piby quering element i.\nOur algorithm provides a Good lower bound using only samples:\nCorollary 1.6. For all n∈Nandε∈(0,1), there is an algorithm which draws at most\nOn\nεlogn·min{log(1/ε),logn}\nsamples from an arbitrary distribution p, and outputs a number bSwhich satisfies (with prob-\nability at least 3/4)\nmin{effε(p), n} ≤bS≤(1 +ε)|supp( p)|.\nWe are not aware of any prior work focusing on this type of guarantee, although it seems quite\nnatural: the value bSoutput by the algorithm can be used for problems like Example 1.1 to predict\nthe resources required for a task depending on support size. The algorithm will tell us either:\n1. IfbS < n (which would be the case if we were promised, say, |supp( p)|< n/ 2), then bSunits\n(jars) suffice to cover the distribution up to the removal of εmass, and fewer than ≈bSunits\nwill fail to cover the whole distribution. Furthermore, we obtain this estimate using fewer\nsamples than required to learn the histogram.\n2. IfbS≥n, then we have learned that we need more than ≈bSunits to cover the distribution.\nLet us translate this result into an answer for Question 1.4. For a fixed sample size m, the na¨ ıve\napproach, taking bSto be the number of unique elements appearing in the sample, produces a\nlower bound bS≤ |supp( p)|that exceeds min {effε(p),Θ(εm)}(see Proposition 2.2). The histogram\nlearners (if they were proved to succeed on this task without an assumption on true support size)\nproduce a lower bound bS≤(1+ε)|supp( p)|that exceeds min {effε(p),Θ(ε2mlogm)}. Our algorithm\nimproves this lower bound up to min {effε(p),Θ(ε\nlog(1/ε)mlogm)}.\nTesting vs. learning Boolean functions. Testing support size of distributions is also important\nfor understanding testing vs. learning of Boolean functions. Arguably the most well understood\nmodel of learning is the distribution-free sample-based PAC model: The algorithm receives samples\nof the form ( x, f(x)) where x∼pis drawn from an unknown distribution, and labeled by an\nunknown function f:X → { 0,1}, which is promised to belong to a hypothesis class H. The\nalgorithm should output a function g∈ H such that Px∼p[f(x)̸=g(x)]≤ε. (Requiring g∈ H is\ncalled proper PAC learning.)\nWhereas the PAC learner assumes the input fbelongs to the hypothesis class H, atester for\nHis an algorithm which tests this assumption:\nDefinition 1.7 (Distribution-free sample-based testing; see formal Definition 5.1) .Given\nlabeled samples ( x, f(x)) with x∼pdrawn from unknown distribution pand labeled by\nunknown function f, decide whether (1) f∈ H or (2) fisε-far from all functions g∈ H,\nmeaning P\nx∼p[f(x)̸=g(x)]≥ε.\nTesting Hcan be done by running a proper PAC learner and checking if it worked [GGR98]. One\nmotivation for testing algorithms is to aid in model selection, i.e. choosing an appropriate hypothesis\n3classHfor learning. To be useful for this, the tester should be more efficient than the learner. The\nsample complexity of proper PAC learning is between Ω( VC/ε) and O(VC\nεlog(1/ε)), where VCis the\nVC dimension of H(and there are examples where either bound is tight) [BEHW89, Han16, Han19].\nBut there is no similar characterization of the sample complexity for testing , and it is not known\nwhen it is possible to do better than the testing-by-PAC-learning method.\nIn fact, very little is known about property testing in the distribution-free sample-based setting,\nand there are not many positive results (see e.g. [GR16, Gol17, RR20, BFH21, RR22]). For example,\nthe basic class Hnof functions f:N→ {0,1}with|f−1(1)| ≤nhas a tight bound of Θ( VC/ε) for\nproper learning with samples, but for testing with samples, tight bounds in terms of both VCandε\nare not known1. Using the lower bounds of [VV17, WY19] for support size estimation, [BFH21] show\nlower bounds of the form Ω(VC\nεlogVC) for this class and several others (e.g. halfspaces, k-alternating\nfunctions &c.). This still leaves room for interesting upper bounds: any bound of o(VC/ε) means\nthat the tester is doing something significantly different than testing-by-PAC-learning.\nIndeed, [GR16] show an upper bound of O(VC\nε2logVC) samples for testing Hn(with the extra\npromise that f−1(1)⊂[2n]), by learning the distribution instead of the function : their algorithm\nlearns the histogram of the underlying distribution pon the subdomain f−1(1), with some adjust-\nments to handle the fact that the probability mass of pinside f−1(1) may be small. This shows\nthat the lower bound of [BFH21] from support-size estimation is sometimes tight in terms of the\nVC dimension, and hints at a closer connection to distribution testing. We give a simple proof\nof a tighter and cleaner relationship – that testing support size of distributions and functions are\nessentially the same problem.\nTheorem 1.8 (Equivalence of testing support size for distributions and functions) .Let\nmDIST(n, ε, σ )be the sample complexity for testing support size with success probability σ.\nLetmFUN(n, ε, σ )be the sample complexity for distribution-free sample-based testing Hnwith\nsuccess probability σ. Then ∀n∈N,ε, σ∈(0,1), and ξ∈(0,1−σ),\nmDIST(n, ε, σ )≤mFUN(n, ε, σ )≤mDIST(n, ε, σ +ξ) +O\nlog(1/ξ)\nε\n.\nWith Theorem 1.3, this improves the best upper bound for testing Hnfrom O(VC\nε2logVC) [GR16]\ntoO(VC\nεlogVClog(1/ε)). So, not only can Hnbe tested more efficiently than learned, but even more\nefficiently than the histogram of the underlying distribution can be learned.\nWe note also that there are reductions from testing the class Hnto testing several other classes\nlikek-alternating functions, halfspaces, and decision trees [BFH21, FH23], which emphasizes the\nrole of testing support size of distributions to the testing vs. learning question for Boolean functions.\nTechniques. The first part of our proof closely follows the optimal upper bound of [WY19] for\nthe support size estimation problem, using Chebyshev polynomial approximations. We will diverge\nfrom [WY19] and require a more technical analysis in the second part, because we need to handle ar-\nbitrary probability distributions, which requires that we analyze the performance of the Chebyshev\npolynomial approximations outside where they are “designed” to be good approximations.\nThe idea is to construct a test statistic bSthat is small if |supp( p)| ≤nand large if pisε-far\nfrom|supp( p)| ≤n. The estimator will be of the form\nbS=X\ni∈N(1 +f(Ni)),\n1If the domain Nis replaced with [ Cn] for constant C, and queries are allowed, then O(1/ε2) queries suffice.\n4where Niis the number of times i∈Nappears in the sample, and fis a carefully chosen function\nsatisfying f(0) =−1 (so that elements outside the support contribute nothing). If the sample size\nwas large enough to guarantee that every i∈supp( p) appears in the sample, we could take f(j) = 0\nfor all j≥1 (which gives the “plug-in estimator” that counts the number of observed elements),\nbut this is not the case, so we must choose f(j) to extrapolate over the unseen elements.\nA standard technique is to analyze the Poissonized version of the tester, where each element i\nappears in the sample with multiplicity Ni∼Poi(mpi), with Poi(·) denoting the Poisson distribution\nandmbeing (roughly) the desired sample size. When we do this, the expected value of the test\nstatistic becomes\nEh\nbSi\n=X\ni∈N\0\n1 +e−mpiP(pi)\n,\nwhere Pis a polynomial whose coefficients are determined by the choice of f. Our goal is now\nto choose a polynomial P(x) which has both P(0) = −1 and P(x)≈0 for x > 0. Chebyshev\npolynomials are uniquely well-suited to this task, allowing us to achieve P(0) =−1 and P(x)≈0 on\na chosen “safe interval” [ ℓ, r]. Indeed, in the setting where there is a lower bound of pi≥1/non all\nnonzero probability densities, [WY19] use a safe interval with ℓ= 1/n, so that that e−mpiP(pi) =±ε\nfor all elements in the support, allowing to accurately estimate |supp( p)|.\nUnlike [WY19], we do not have any lower bounds on the values of pi, and it is not possible\nto get an accurate estimate of |supp( p)|. Instead, we use Chebyshev polynomials that are good\napproximations on a wider “safe interval” [ ℓ, r], and we must also analyze what happens to densities\npioutside the safe interval, where the Chebyshev polynomials are notgood approximations. bSis\nessentially an underestimate of |supp( p)|, so we must show that it is not too small when pisε-far.\nWe observe that, if pisε-far, then it either has enough densities piin the safe interval [ ℓ, r] to\nmakebSlarge, or it has many small densities pi< ℓ. If it has many small densities, we use a careful\nanalysis of the Chebyshev polynomial P, based on the fact that it is concave on the range (0 , ℓ),\nto show that bSwill be large enough for the tester to reject, even if it is a severe underestimate.\nWe give two proofs of this last claim: the first proof sets the boundary of the safe interval at\nℓ=O(ε/n). This proof (completed in Section 3.5) is simpler and clearer but only gives an upper\nbound of O(n\nεlognlog2(1/ε)) (already an improvement on the best known bound), and we include it\nfor the purpose of exposition. The second proof is more technical and gives the improved bound in\nTheorem 1.3, by raising ℓtoℓ=O(ε\nnlog(1/ε)). This is done by combining the concavity argument\nwith a characterization of the worst-case behaviour of the estimator in terms of a differential\ninequality, completed in Section 3.6. Our proof strategy does not seem to allow improving the\nparameters any further than this (Remark 3.31).\nOrganization. One may treat the first part of our paper (up to Remark 3.8) as an alternative\nself-contained exposition of [WY19], and we intend the paper to be as clear and accessible an\nexplanation of the Chebyshev polynomial method as possible (we also refer the reader to the\ntextbook [WY20] on polynomial methods in statistics).\nSection 2 sets up the testing algorithm using generic parameters.\nSection 3 places Constraints I to IV on the parameters in order to guarantee the success of the\ntester, and then in Section 3.5 we optimize the parameters to complete a weaker (but simpler)\nversion of Theorem 1.3. The stronger version follows by replacing Constraint IV with the\nlooser Constraint IVb in Section 3.6.\nSection 4 proves that the algorithm outputs a lower bound on support size, Corollary 1.6.\nSection 5 proves equivalence of testing support size of distributions and functions, Theorem 1.8.\n52 Defining a Test Statistic\nWe begin by defining a “test statistic” bSwhich the tester will use to make its decision – the tester\nwill output Accept ifbSis small and output Reject if it large. But our test statistic will require\nlog(1/ε)<log(n), so we first handle the case where the parameter εis very small.\n2.1 Small ε\nIfεis small enough that log(1 /ε) = Ω(log n), we will use the following simple tester. This re-\nsult is folklore (appearing e.g. in [GR23, AF24, AFL24]) but we include a proof for the sake of\ncompleteness. We start with the following simple observation:\nObservation 2.1. For any n∈N,ε∈(0,1), and probability distribution p,pisε-far from\nhaving support size at most nif and only if effε(p)> n.\nUsing this observation, we give\nProposition 2.2. There is an algorithm which, given inputs n∈N,ε∈(0,1), and sample\naccess to an arbitrary distribution p, draws at most O(n/ε)samples from pand outputs a\nnumber bSwhich (with probability at least 3/4) satisfies\nmin{effε(p), n} ≤bS≤ |supp( p)|.\nIn particular, there is a support size tester using using O(n/ε)samples, obtained by running\nby this algorithm with parameters n+ 1, εand outputting Accept if and only if bS≤n.\nProof. Write k..= min {n,effε(p)}. Let m..= 10n/ε. The algorithm draws mindependent random\nsamples points from pand outputs bS, defined as the number of distinct domain elements in the\nsample.\nIt is clear that bS≤ |supp( p)|with probability 1. To show that bS≥min{effε(p), n}, suppose we\ndraw an infinite sequence of independent random samples S={s1,s2, . . .}from p. For each i∈N,\ndefine the random variable tias the smallest index ti∈[m] such that the multiset {s1, . . . ,sti}is\nsupported on iunique elements. Note that t1= 1.\nClaim 2.3. For all i∈ {2, . . . , k },E[ti−ti−1]≤1/ε.\nProof of claim. Write St..={s1, . . . ,st}as the prefix of Sup to element t. Fix any ti−1. Con-\nditional on the event ti−1=ti−1, the multiset Sti−1={s1, . . . ,sti−1}is supported on i−1< k\nelements. Then p(supp( Sti−1))<1−εsince pisε-far from having support size at most k−1\nby Observation 2.1. Therefore for every t > t i−1we have P\nst̸∈Sti−1|ti−1=ti−1\n> ε, so\nE[ti−ti−1]≤1/ε. ■\nFrom this claim we may deduce E[tk]≤t1+ (k−1)/ε≤n/ε, so by Markov’s inequality\nP[tk>10n/ε]≤1/10.\nTherefore if m≥10n/εthe tester will see at least kunique elements in a sample of size m, with\nprobability at least 9 /10. ■\n62.2 The test statistic\nWe now turn to the case where εis large. Specifically, we fix a small universal constant a∈(0,1)\n(e.g. a= 1/128 suffices; we prioritize clarity of exposition over optimizing constants) and assume:\nAssumption 2.4. For every n∈N, we assume n−a< ε < 1/3, so that log(1/ε)< alogn.\nWe will write S⊂Nfor the (random) multiset of samples received by the algorithm.\nDefinition 2.5 (Sample Histogram) .For a fixed multiset S⊂N, the sample histogram is the\nsequence Niwhere Niis the number of times i∈Nappears in S. IfSis a random multiset then\nwe write Ni.\nThe goal will be to find the best function fto plug in to the following definition of our test\nstatistic; we will show how to choose fin Section 2.3 and the remainder of the paper, but for now\nwe leave it undetermined.\nDefinition 2.6 (Test statistic) .For a given function f:{0} ∪N→R(which is required to\nsatisfy f(0) =−1), we define a test statistic as follows. On random sample S,\nbS..=X\ni∈N(1 +f(Ni)).\nGiven an appropriate function fand resulting test statistic, we define our support-size tester:\nDefinition 2.7 (Support-Size Tester) .Given parameters n∈Nandε∈(0,1) our tester\nchooses mindependent samples Sfrom the distribution p, and outputs Accept if and only if\nbS<(1 +ε/2)n .\nRemark 2.8. Our test statistic is a linear estimator (see e.g. [VV11a, VV11b, VV17, WY19])\nbecause it can be written as\nbS=mX\nj=1Fj·(1 +f(j)),\nwhere Fjis the number of elements i∈Nwhich occur jtimes in the sample S, i.e.Ni=j. The\nsequence F1,F2, . . .is known as the fingerprint .\nA standard trick to ease the analysis is to consider instead the Poissonized version of the\nalgorithm.\nDefinition 2.9 (Poissonized Support-Size Tester) .Given parameters n∈Nandε∈(0,1)\nour tester chooses m∼Poi(m) and then takes mindependent samples Sfrom the distribu-\ntionp, and outputs Accept if and only if\nbS<(1 +ε/2)n .\nThe advantages of Poissonization are these (see e.g. the survey [Can20]):\n7Fact 2.10. LetSbe the sample of size m∼Poi(m)drawn by the Poissonized tester. Then the\nrandom variables Niare mutually independent and are distributed as\nNi∼Poi(mpi).\nFact 2.11. If there is a Poissonized support-size tester with sample complexity m(n, ε)and success\nprobability σ, then there is a standard support-size tester with sample complexity at most O(m(n, ε))\nand success probability 0.99σ.\n2.3 Choosing a function f\nNow we see how to choose the function fto complete Definition 2.6. To motivate the choice,\ncompute the expected value of the statistic:\nProposition 2.12. For any given finitely supported f:{0}∪N→Rwithf(0) =−1and parameter\nm, the (Poissonized) test statistic bSsatisfies\nEh\nbSi\n=X\ni∈N(1 +e−mpiP(pi)) (1)\nwhere P(x)is the polynomial\nP(x) =∞X\nj=0f(j)mj\nj!xj.\nProof. Using Fact 2.10,\nEh\nbSi\n=X\ni∈NE[1 +f(Ni)] =X\ni∈N\n1 +X\nj≥0P[Ni=j]f(j)\n=X\ni\n1 +X\nj≥0e−mpi(mpi)j\nj!f(j)\n\n=X\ni\n1 +e−mpiX\nj≥0mjf(j)\nj!pj\ni\n=X\ni\0\n1 +e−mpiP(pi)\n. ■\nFor convenience, we define\nDefinition 2.13. For given polynomial P(x), define\nQ(x)..= 1 + e−mxP(x),\nso that Q(pi) quantifies the contribution of element i∈Nto the expected value of bS:\nEh\nbSi\n=X\ni∈NQ(pi). (2)\nIf we could set Q(x) =1[x >0] then Eh\nbSi\n=|supp( p)|. But this means P(0) =−1 while P(x) = 0\nfor all x >0, which is not a polynomial. Our goal is therefore to choose a polynomial Pwhich\napproximates this function as closely as possible.\n8Specifically, if we choose any coefficients a1, . . . , a d, we may then define\nf(j)..=\n\najj!\nmjifj∈[d]\n−1 if j= 0\n0 if j > d\nto obtain the degree- dpolynomial\nPd(x)..=∞X\nj=0f(j)mj\nj!xj=\ndX\nj=1ajxj\n−1,\nwhich satisfies the necessary condition Pd(0) = −1. The other condition that we want Pd(x) to\nsatisfy is that Pd(x)≈0 for x > 0. This cannot be achieved by a low-degree polynomial, but\nwe can instead ask for Pd(x)≈0 inside a chosen “safe interval” [ ℓ, r]. In other words, we want a\npolynomial which satisfies Pd(0) =−1 and\nmax\nx∈[ℓ,r]|Pd(x)| ≤δ ,\nfor some some small δ. The lowest-degree polynomials which satisfy these conditions are known as\nthe (shifted and scaled) Chebyshev polynomials , which we define in Section 2.4.\nRemark 2.14. In the support-size estimation problem, there is a lower bound pi≥1/non\nthe nonzero densities, so [WY19] choose a “safe interval” [ ℓ, r] with ℓ= 1/n, so that there\nis no density pito the left of the interval, pi∈(0, ℓ). In our problem, we do not have this\nguarantee, and therefore we must handle values pithat do not fall in the “safe” interval [ ℓ, r].\n2.4 Chebyshev polynomials and the definition of Pd\nFor a given degree d, the Chebyshev polynomial Td(x) is the polynomial which grows fastest on\nx >1 while satisfying |Td(x)| ≤1 in the interval x∈[−1,1].\nDefinition 2.15 (Chebyshev polynomials) .We write Td(x) for the degree- dChebyshev\npolynomial. These can be defined recursively as\nT0(x)..= 1\nT1(x)..=x\nTd(x)..= 2x·Td−1(x)−Td−2(x).\nTd(x) may also be computed via the following closed-form formula: For all d∈Nandx∈R,\nTd(x) =1\n2\nx+p\nx2−1d\n+\nx−p\nx2−1d\n.\nWe want the polynomials Pd(x) to be bounded in [ ℓ, r] and to grow fast on x∈[0, ℓ) so that\nPd(0) =−1. So we define a map ψwhich translates [ ℓ, r] to [−1,1],\nψ(x)..=−2x−r−ℓ\nr−ℓ\n91.01\n 0.00 1.011\n01(a)T11(x), x∈[−1.01,1.01].\n0\n r 2r0.00.51.0 (b)Q(pi) = 1 + e−mp iP11(pi)\nFigure 1: The polynomial T11(x)and the resulting Q(pi) = 1 + e−mp iPd(pi)ford= 11\nand certain choices of ℓ, r, n, m . The ‘safe’ interval [ℓ, r]is between the two vertical\nlines in Figure 1b. See that Q(pi)is an approximation of the ‘idealized’ function\nQ(pi) =1[pi>0].\nsoψ(0) =r+ℓ\nr−ℓ. For convenience we write\nα..=ℓ\nr\nso that ψ(0) = 1 +2α\n1−α. We now define\nDefinition 2.16 (Shifted & Scaled Chebyshev Polynomials) .For any d, define\nPd(x)..=−δTd(ψ(x)),\nwhere δ..=1\nTd(1+2α\n1−α).\nThis way, as required,\nPd(0) =−δTd(ψ(0)) = −1,and|Pd(x)| ≤δforx∈[ℓ, r].\nWe illustrate the Chebyshev polynomial Td(x) and the shifted and scaled result Q(pi) in Figure 1.\nThe resulting function values f(Ni) which define our test statistic are given in Proposition A.4.\n3 Choosing Parameters\nOur goal is now:\nGoal 3.1. Choose degree dand “safe interval” [ ℓ, r] such that the (Poissonized) support-size\ntester in Definition 2.9, instantiated with the (shifted and scaled) Chebyshev polynomial Pd,\nworks with the smallest sample size parameter m, even though densities pimay not belong\nto [ℓ, r].\nTo do this, we will set up a series of constraints that these parameters must satisfy in order for\nthe tester to succeed, and then minimize mwith respect to these parameters.\n103.1 Constraint I: Choose dsuch that δ≤ε\nWe will want that δ≤εso that for every density piin the “safe interval” [ ℓ, r] we have Q(pi)≈1,\nspecifically |Q(pi)−1| ≤ε. We will write this constraint in terms of ℓandr:\nConstraint I. For constant Cd..= 4 ln(2) , we will require for any choice of ℓ, r, ε thatr≥3ℓ\nand that the degree dsatisfies\nd≥Cdr\nr−ℓ\n2ℓlog20\nε\n.\nProposition 3.2. Assume Constraint I. Then δ≤ε/20and for all x∈[ℓ, r],\n|Q(x)−1| ≤δ≤ε\n20.\nTo prove this, we require a lower bound on the growth rate of the Chebyshev polynomials. This\nis well known but we provide a proof for the sake of completeness:\nProposition 3.3. There is a universal constant c..=1\n2 ln(2)such that, for all d∈Nandγ∈[0,1],\nTd(1 +γ)≥2c·d√γ−1.\nProof. Using Definition 2.15, we have\nTd(1 +γ) =1\n2\n(1 +γ) +p\n(1 +γ)2−1d\n+\n(1 +γ)−p\n(1 +γ)2−1d\n≥1\n2\n1 +p\n2γd\n=1\n2edln(1+√2γ).\nUsing the inequality ln(1 + x)≥x\n1+x, which is valid for x >−1, together with the assumption that\nγ≤1, we obtain\nTd(1 +γ)≥1\n2ed·√2γ\n1+√2γ≥1\n2ed·√2γ\n2√\n2=1\n2e1\n2d√γ. ■\nProof of Proposition 3.2. Recall α..=ℓ/randψ(0) = 1 +2α\n1−α. It suffices to show\nTd\n1 +2α\n1−α\n≥20\nε\nso that, for x∈[ℓ, r] (which satisfies ψ(x)∈[−1,1] and therefore Td(ψ(x))∈[−1,1])),\nPd(x) =−δTd(ψ(x)) =−Td(ψ(x))\nTd(ψ(0))\nis within the interval [ −ε/20, ε/20]. By Constraint I,2α\n1−α≤1 since α≤1/3, so we may apply\nProposition 3.3 to get\nTd\n1 +2α\n1−α\n≥2c·dq\n2α\n1−α−1,\nwhere c=1\n2 ln(2)is the constant from Proposition 3.3. Therefore when d≥2\ncq\nr−ℓ\n2ℓlog(20 /ε) =\n2\ncq\n1−α\n2αlog(20 /ε)≥1\ncq\n1−α\n2α(1 + log(20 /ε)) we have the result with Cd=2\nc= 4 ln(2). ■\n113.2 Constraint II: Choose msuch that Q(pi)≈1when pi> r\nNext we need to choose large enough msuch that the term e−mpicancels out the growth of Pd(pi)\nto the right of the “safe interval” , leading to the desired Q(pi) = 1 + e−mpiPd(pi)≈1 in this case.\n(Figure 2 shows 1 + Pd(pi) without the e−mpiterm.)\n0\n r 2r0359.0718.0\nFigure 2: Untamed right tail.We place the following constraint:\nConstraint II. We require m≥5.5·d/(r−ℓ).\nProposition 3.4. Assume Constraint II. Then\n∀x∈(r,1] :|1−Q(x)| ≤δ .\nProof. Write γ= 2x−r\nr−ℓso that\n−ψ(x) =2x−r−ℓ\nr−ℓ=r−ℓ−2r+ 2x\nr−ℓ= 1+2x−2r\nr−ℓ= 1+ γ .\nNote that |Td(z)|=|Td(−z)|for all z. We need to bound |1−Q(x)|=e−mx|Pd(x)|=\nδe−mx|Td(ψ(x))|forx > r , and|Td(ψ(x))|=Td(−ψ(x)) =Td(1+γ). So we require emx≥Td(1+γ).\nBound Td(1 +γ) by\nTd(1 +γ) =1\n2\n(1 +γ+p\n2γ+γ2)d+ (1 + γ−p\n2γ+γ2)d\n≤(1 +γ+p\n2γ+γ2)d≤ed(γ+√\n2γ+γ2).\nIfγ <1 then γ+p\n2γ+γ2<1 +√\n3, and therefore sincex\nr−ℓ>x\nr>1 we have\nd(γ+p\n2γ+γ2)≤d(1 +√\n3)≤d(1 +√\n3)x\nr−ℓ≤mx .\nIfγ≥1 then γ+p\n2γ+γ2≤(1 +√\n3)γ, so\nd(γ+p\n2γ+γ2)≤d(1 +√\n3)·2x−r\nr−ℓ≤d(1 +√\n3)·2x\nr−ℓ≤mx .\nWe then conclude\nTd(1 +γ)≤ed(γ+√\n2γ+γ2)≤emx. ■\n3.3 Constraint III: Variance\nWe will need the test statistic bSto satisfy two conditions. First, when |supp( p)| ≤nwe need\nPh\nbS>(1 +ε/2)ni\n≤1/4.\nSecond, when pisε-far from having support size n, we need\nPh\nbS<(1 +ε/2)ni\n≤1/4.\nWe will bound Eh\nbSi\nin each of these cases in Section 3.4. But first we will bound the variance.\nWe impose the following constraint:\n12Constraint III. We require m≤1\n44ε2n2, and d69d\nr+ℓ\nr−ℓ2d−2\n≤1\n4m(r−ℓ)2n2.\nProposition 3.5. Assume Constraints I to III. Then Varh\nbSi\n≤ε2n2\n43, and therefore (by\nChebyshev’s inequality),\nPh\n|bS−Eh\nbSi\n|>ε\n4ni\n≤1\n4.\nTo prove Proposition 3.5, we will require bounds on the values of f(Ni) in the definition of\nbS=X\ni∈N(1 +f(Ni)).\nFor this we do some tedious calculations using the coefficients of the polynomial Pd(x). We put\nthese in Appendix A. The result is:\nProposition 3.6. For any dand any k∈[d],\n|f(k)| ≤δ·d2·3d·2d\nm(r−ℓ)kr+ℓ\nr−ℓd−k\n.\nWe may now estimate the variance.\nProof of Proposition 3.5. Recall that each Niis an independent Poisson random variable Ni∼\nPoi(mpi). Then\nVarh\nbSi\n=X\ni∈NVar [1 + f(Ni)] =X\ni∈NVar [(1 + f(Ni))1[Ni>0]]\n≤X\ni∈NE\n(1 +f(Ni))21[Ni>0]\n≤max\nj∈[0,d](1 +f(j))2·X\ni∈NE[1[Ni>0]]\n= max\nj∈[0,d](1 +f(j))2·X\ni∈N(1−e−mpi)≤max\nj∈[0,d](1 +f(j))2·mX\ni∈Npi=m·max\nj∈[0,d](1 +f(j))2.\nFrom Constraint II, which implies m(r−ℓ)>2d, the upper bound in Proposition 3.6 is maximized\natk= 1, so we have |f(0)|= 1 and\n∀j∈[d] :|f(j)| ≤δ·d2·3d·2d\nm(r−ℓ)·r+ℓ\nr−ℓd−1\n.\nIf this is at most 1, then the first part of Constraint III gives the desired bound.\nVarh\nbSi\n≤4m≤ε2n2\n43\nOtherwise, (1 + |f(j)|)2≤4f(j)2, so (using Constraint I and Proposition 3.2 to ensure δ≤ε/20≤\nε/42), we get from Constraint III that\nVarh\nbSi\n≤42mδ2·d6·9d·1\nm2(r−ℓ)2r+ℓ\nr−ℓ2d−2\n≤1\n42ε2·d6·9d·1\nm(r−ℓ)2r+ℓ\nr−ℓ2d−2\n≤ε2n2\n43. ■\n133.4 Constraint IV: E[bS]≥(1 +ε)nwhen pisε-far\nThe above Constraints I and II ensure that Q(x)∈1±δwhen x∈[ℓ,1]. The properties of the\nChebyshev polynomial also ensure that Q(x)≤1 +δforx < ℓ (see the behaviour of Q(x) for x≤ℓ\nin Figure 3). This means Eh\nbSi\n=P\ni:pi>0Q(pi) is essentially an underestimate of |supp( p)|, which\nis enough to guarantee that that the tester will accept pwhen|supp( p)| ≤nwith high probability:\nLemma 3.7. Assume Constraints I and II. Then\nEh\nbSi\n≤(1 +δ)|supp( p)|<(1 +ε/4)|supp( p)|.\nProof. First note that ψ(x)>1 for all x∈(0, ℓ), so that Pd(x) =−δTd(ψ(x))<0. Hence\nQ(x) = 1 + e−mxPd(x)<1. Combining with Propositions 3.2 and 3.4 we conclude that, for all\nx∈(0,1],Q(x)≤1 +δ. We also have Q(0) = 0. Recalling (2), we obtain\nEh\nbSi\n=X\ni∈NQ(pi)≤X\ni∈N:pi>0(1 +δ) = (1 + δ)|supp( p)|<(1 +ε/4)|supp( p)|,\nthe last inequality since δ < ε/ 4 by Proposition 3.2. ■\nRemark 3.8. If we were guaranteed that all nonzero densities satisfied pi≥ℓ, then\nLemma 3.7 would also show Eh\nbSi\n≥(1−δ)|supp( p)|. In particular, for the support-size esti-\nmation task, where the nonzero densities satisfy pi>1/n, we could simply set ℓ= 1/n, skip\nthe remainder of this section, and recover the optimal O\nn\nlognlog2(1/ε)\nbound of [WY19].\nNow we need to ensure that Eh\nbSi\nwill be large when pisε-far from having support size n.\nThe difficulty is that the densities pimay be arbitrarily small and lie outside the “safe interval”\n[ℓ, r] where the polynomial approximation guarantees Q(pi)≈1. So we will require properties of\nthe Chebyshev polynomial approximation outside of the interval [ ℓ, r]. We impose the following\nconstraint:\nConstraint IV. We require ℓ≤Cℓε\nn, where Cℓis any constant Cℓ≤1/20.\nThe constraint will give us the desired guarantee:\nLemma 3.9. Assume Constraints I, II and IV. Then for every k≤n, ifpisε-far from\nbeing supported on kelements,\nEh\nbSi\n>(1 + 3 ε/4)k .\n14Remark 3.10. Constraint IV and Lemma 3.9 lead to an upper bound of O\nn\nεlognlog2(1/ε)\ninstead of O\nn\nεlognlog(1/ε)\n. We put them here to ease the exposition, since the argument\nis simpler. The argument for the better bound (using a weaker constraint ℓ≤Cℓε\nnlog(1/ε))\nis in Section 3.6.\n0\n01\nFigure 3: Q(pi)forpi< ℓ , and the\nlinear lower bound Q(pi)≥(1−δ)pi\nℓin\nProposition 3.14To prove Lemma 3.9, we will use the concavity\nofPd(x) on [0 , ℓ] to lower bound Q(pi) by the line\nbetween the points (0 ,0) and ( ℓ, Q(ℓ)). This is illus-\ntrated in Figure 3, which shows Qcompared to the\nlinear lower bound. First, we need a standard fact\nabout the roots of Chebyshev polynomials.\nFact 3.11. For each d∈N,Td(x)hasddistinct\nroots, all within [−1,1].\nCorollary 3.12. For each d∈N,Td(x)is convex\nincreasing in [1,+∞).\nProof. Since Td(x) has a positive leading coefficient,\nall of its first dderivatives are eventually positive\nnondecreasing as x→+∞. Moreover, all of its derivatives have their roots within [ −1,1] by\nFact 3.11 and the Gauss-Lucas theorem. Hence all of its first dderivatives are positive on (1 ,+∞).\n■\nCorollary 3.13. Pdis concave increasing on [0, ℓ].\nProof. This follows from the Corollary 3.12 and the fact that Pd=−δTd(ψ(x)), with ψan affine\nfunction mapping [0 , ℓ] ontoh\n1 +2α\n1−α,1i\n. ■\nProposition 3.14. For each x∈[0, ℓ], we have (1−δ)x\nℓ≤Q(x)≤1.\nProof. Recall that Pd(0) = −1 by construction. It is also immediate to check that Td(1) = 1 and\nhence Pd(ℓ) =−δTd(ψ(ℓ)) =−δTd(1) = −δ. By Corollary 3.13, Pd(x) is concave increasing (and\nhence negative) on [0 , ℓ]. Thus for any x∈[0, ℓ] we have\nQ(x) = 1 + e−mxPd(x)≤1 +e−mx·0 = 1\nand, on the other hand,\nQ(x) = 1+ e−mxPd(x)≥1+Pdx\nℓ·ℓ+\n1−x\nℓ\n·0\n≥1+x\nℓ·(−δ) +\n1−x\nℓ\n·(−1)\n= (1−δ)x\nℓ.\n■\nWe now calculate the lower bound on the test statistic by partitioning the densities piinto\nweight classes.\nDefinition 3.15 (Heavy and light elements) .An element i∈supp( p) is called heavy ifpi≥ℓ;\notherwise, if pi∈(0, ℓ), it is called light.\n15Lemma 3.16 (Refinement of Lemma 3.9) .Assume Constraints I, II and IV. For any dis-\ntribution p, let nHbe the number of heavy elements in supp( p), and let µLbe the total\nprobability mass of the light elements in supp( p). Then\nEh\nbSi\n≥(1−δ)\nnH+µL\nℓ\n. (3)\nIn particular, for any k≤n, ifpisε-far from being supported on kelements, then\nEh\nbSi\n>(1 + 3 ε/4)k .\nProof. LetH⊂supp( p) denote the set of heavy elements, so that nH=|H|. Recall that, by (2),\nEh\nbSi\n=X\ni∈NQ(pi) =X\ni∈HQ(pi) +X\ni∈supp( p)\\HQ(pi).\nBy Propositions 3.2 and 3.4, the first summation is\nX\ni∈HQ(pi)≥X\ni∈H(1−δ) = (1 −δ)nH.\nBy Proposition 3.14, the second summation is\nX\ni∈supp( p)\\HQ(pi)≥X\ni∈supp( p)\\H(1−δ)pi\nℓ= (1−δ)µL\nℓ.\nThis establishes (3). Now, suppose pisε-far from being supported on k≤nelements. We consider\ntwo cases.\nCase 1. Suppose µL> ε/10. Then, using δ≤ε/20 (from Proposition 3.2) and ℓ≤ε\n20n≤ε\n20k\n(from Constraint IV),\nEh\nbSi\n≥(1−δ)µL\nℓ>(1−ε/20)·ε/10·20k\nε= (1−ε/20)·2k >(1 + 3 ε/4)k .\nCase 2. Suppose µL≤ε/10. Then there must exist a partition H=R∪Tof the heavy elements\nsuch that |R|=kandp(T)>9ε/10, since otherwise pwould be ε-close to some distribution\nsupported on at most kelements. In fact, we can choose this partition such that p(i)> p(j) for\nevery i∈Randj∈T. It follows that pj≤1/kfor every j∈T, since otherwise we would have\np(R)>1\nk· |R|= 1. Hence\n|T| ≥p(T)\n1/k>9ε/10\n1/k=9kε\n10.\nThus we have\nEh\nbSi\n≥(1−δ)nH≥(1−ε/20) (|R|+|T|)>(1−ε/20)\nk+9kε\n10\n= (1−ε/20)·(1 + 9 ε/10)k >(1 + 9 ε/10−ε/20·2)k >(1 + 3 ε/4)k . ■\n163.5 Correctness of the tester and optimizing the parameters\nLet us repeat our list of constraints:\n•Constraint I: r≥3ℓandd≥Cdq\nr−ℓ\n2ℓlog\020\nε\n, where Cd= 4 ln(2).\n•Constraint II: m≥5.5d/(r−ℓ).\n•Constraint III: m≤1\n44ε2n2andd69d\nr+ℓ\nr−ℓ2d−2\n≤1\n4m(r−ℓ)2n2.\n•Constraint IV: ℓ≤Cℓε\nnfor any Cℓ≤1/20.\nWe show in Section 3.5.1 that if these constraints are satisfied, then the tester defined in Defini-\ntion 2.7 will be correct. Then we optimize maccording to these constraints in Section 3.5.2.\n3.5.1 Correctness\nLemma 3.17 (Correctness (Poissonized)) .Suppose n, εsatisfy Assumption 2.4, and that\nConstraints I to IV are satisfied with some sample size m=m(n, ε). Then the Poissonized\ntest statistic bSin Definition 2.6 satisfies\n(1 + 3 ε/4) min {effε(p)−1, n}<Eh\nbSi\n<(1 +ε/4)|supp( p)|\nand\nPh\n|bS−Eh\nbSi\n|> εn/ 4i\n≤1/4.\nIn particular, if pisε-far from having support size at most n, then effε(p)> n (Obser-\nvation 2.1), so bS>(1 + ε/2)nwith probability at least 3/4; and if |supp( p)| ≤nthen\nbS<(1 +ε/2)nwith probability at least 3/4. So the algorithm in Definition 2.9 is a correct\n(Poissonized) support-size tester with sample complexity m.\nProof. Lemma 3.7 gives that Eh\nbSi\n<(1 + ε/4)|supp( p)|, while Lemma 3.9 gives that Eh\nbSi\n>\n(1 + 3 ε/4) min {effε(p)−1, n}. Combining these with Chebyshev’s inequality via Proposition 3.5\ngives the result. ■\nTranslating to the standard (non-Poissonized) testing model using Fact 2.11:\nCorollary 3.18 (Correctness (Standard)) .Suppose that, for n, εsatisfying Assumption 2.4,\nConstraints I to IV are satisfied with some sample size m=m(n, ε). Then (also for n, ε\nsatisfying Assumption 2.4), there is a support-size tester with sample complexity O(m(n, ε)).\n3.5.2 Optimizing the parameters\nNow we complete Goal 3.1 and find the setting of parameters which minimizes mwhile satisfying\nall of our constraints. The (weaker version of the) main Theorem 1.3 follows from Proposition 3.19,\nusing Corollary 3.18, and Proposition 2.2 to handle small εthat do not satisfy Assumption 2.4.\n17Proposition 3.19. Under Assumption 2.4, we may satisfy all of the constraints in such a\nway that\nm(n, ε) =On\nεlognlog2\01\nε\n.\nWe first sketch some rough calculations to motivate the asymptotic dependence that each of ℓ,\nr,dandmshould have on nandε. Combining Constraints I and II, we obtain\nm≳d\nr≳r\n1\nℓrlog1\nε\n. (4)\nThus, to allow mto be as small as possible, we should make ℓandras large as possible. We\nalready have the bound ℓ≲ε\nnfrom Constraint IV. As we make rlarger, dneeds to grow due\nto Constraint I, which can only happen as long as the bound d69d\nr+ℓ\nr−ℓ2d−2\n≤1\n4m(r−ℓ)2n2is\npreserved. The left hand side of this inequality is exponential in dwhile the right hand side is\npolynomial in n, suggesting that we need d=O(logn). Since d≳pr\nℓlog\01\nε\n, this suggests setting\nr≈ℓ·log2n\nlog2(1/ε).\nPlugging back into (4), we obtain\nm≳1\nℓ·log2(1/ε)\nlogn≈n\nεlognlog21\nε\n. (5)\nRemark 3.20. In Section 3.6 we replace Constraint IV with the looser Constraint IVb that\nℓ≤Cℓε\nnlog(1/ε), which we can see from Equation (5) should improve mby a log(1 /ε) factor.\nLet us now make this plan rigorous. (We have not tried too hard to optimize the constants.)\nProof. We require Assumption 2.4 with a..= 1/128. We set\n•ℓ..=Cℓε\nnforCℓ..= 1/20.\n•r..=Crε\nnlog2n\nlog2(1/ε), for constant Cr..= 4a2Cℓ.\n•d..=⌈Cdq\nr−ℓ\n2ℓlog\020\nε\n⌉, recalling that Cd= 4 ln(2).\n•m..= 5.5d\nr−ℓ.\nWe claim that Constraints I to IV are satisfied. Constraints II and IV are immediately satisfied by\nthe choices of mandℓ, while Constraint I is satisfied by the choice of d, and because r≥4ℓsince\nr\nℓ=Crlog2n\nCℓlog2(1/ε)>4a2·log2n\n(alogn)2= 4.\n18Let us now verify Constraint III. Start with a calculation ofd\nr−ℓ, which also gives the claimed bound\nofm=O(n\nεlognlog2(1/ε)):\nd\nr−ℓ≤2Cdq\nr−ℓ\n2ℓlog\020\nε\nr−ℓ=2Cdlog\020\nε\np\n2ℓ(r−ℓ)≤2Cdlog\020\nε\np\n2ℓ·r/2=2Cdlog\020\nε\nr\nε\nn·Cℓ·Crε\nnlog2n\nlog2(1/ε)\n=2Cd√CℓCr·n\nε·log(1/ε) log(20 /ε)\nlogn≤12Cd√CℓCr·n\nε·log2(1/ε)\nlogn=6Cd\nCℓa·n\nε·log2(1/ε)\nlogn,\nthe last inequality because ε <1/2 by Assumption 2.4, so log(1 /ε)>1 and hence log(20 /ε) =\nlog(20) + log(1 /ε)<5 + log(1 /ε)<6 log(1 /ε).\nTo verify Constraint III, we start with checking the inequality d69d\nr+ℓ\nr−ℓ2d−2\n≤1\n4m(r−ℓ)2n2.\nUsing m= 5.5d\nr−ℓ, the right-hand side is at least\n1\n4m(r−ℓ)2n2≥1\n4·5.5·d(r−ℓ)n2,\nso it suffices to prove\nd\nr−ℓd49dr+ℓ\nr−ℓ2d−2\n≤5.5\n4n2.\nUsing the upper bound ond\nr−ℓand the upper boundr+ℓ\nr−ℓ≤(5/4)r\n(3/4)r= 5/3, it suffices to prove\nd452(d−1)6Cd\nCℓ1\na·n\nεlog2(1/ε)\nlogn≤5.5\n4·9n2⇐⇒ 52(d−1)≤5.5Cℓ\n4·9·6Cd·a·εn\nd4·logn\nlog2(1/ε).\nUpper bound dby\nd−1≤Cdr\nr−ℓ\n2ℓlog20\nε\n≤Cd√\n2rr\nℓ·log20\nε\n≤Cd√\n2r\nCr\nCℓlog(n)\nlog(1/ε)·log20\nε\n=2Cd√\n2·a·log(n)\nlog(1/ε)·log20\nε\n≤12Cd√\n2·a·logn .\nThen (using also d≤2(d−1) for convenience on the right-hand side, and ε≥n−a) it suffices to\nestablish\nn24 log(5)√\n2Cd·a≤K·1\na5·n1−a·1\nlog5(n)\nfor constant K=5.5·4Cℓ\n4·9·6·24·124C5\nd. We have24 log(5)√\n2Cda≤0.8536 whileK\na5≥3.2, and indeed the\ninequality\nn0.8536≤3.2·n127/128\nlog5(n)\nholds for sufficiently large n(say, n≥5.4·1084).\nIt remains to verify the inequality m≤1\n44ε2n2. We have\nm= 5.5d\nr−ℓ≤5.5·6Cd\nCℓ·1\na·n\nε·log2(1/ε)\nlogn,\nso (since ε≥n−a) it suffices to have\nε3≥44·5.5·6·Cd\nCℓ·alogn\nn⇐=n1−3a\nlogn≥a·44·5.5·6·Cd\nCℓ⇐=n125/128\nlogn≥3660,\nwhich holds for sufficiently large n(say, n≥8·104). ■\n193.6 Constraint IVb: Improvements from loosening constraint IV\nIn this section we loosen Constraint IV and obtain the improved bound of O\nn\nεlognlog(1/ε)\n. We\nreplace the earlier constraint of ℓ≤Cℓε\nnwith:\nConstraint IVb. We require ℓ≤Cℓε\nnlog(1/ε)for any constant Cℓsatisfying Cℓ≤\nminn\nCd\n4√\n3,1\n3o\n.\nTo get the improved upper bound from this constraint, it is sufficient to replace the earlier\nLemma 3.9 with:\nLemma 3.21. Assume Constraints I, II and IVb. Then for all ε≥1/3, and all k≤n, ifp\nisε-far from being supported on kelements,\nEh\nbSi\n>(1 + 3 ε/4)k .\nFollowing the same arguments as in Section 3.5 then leads to our main result:\nTheorem 3.22. For all n∈Nandε∈(0,1), the sample complexity of testing support size\nis at most\nm(n, ε) =On\nεlogn·min\nlog1\nε,logn	\n.\nProof. The proof of correctness under Constraints I to III and IVb is the same as Lemma 3.17,\nreplacing Lemma 3.9 with Lemma 3.21.\nThe proof of the improved sample complexity follows from the same calculations as in Propo-\nsition 3.19: starting with the choice of parameters from Proposition 3.19, we\n1. Scale ℓandrup by a factor of log(1 /ε).\n2. Scale mdown by a factor of log(1 /ε).\n3. Leave dunchanged.\nIt is then straightforward to see that each of Constraints I to III is still satisfied under the new\nchoices of parameters, and that Constraint IVb is indeed also satisfied. ■\nTo show that Constraint IVb is sufficient, we first define a function Φ( λ) to quantify the worst-\ncase behaviour of the sumP\niQ(pi) (Section 3.6.1), and then prove a lower bound on Φ( λ) (Sec-\ntion 3.6.2).\nSome notation. Forx∈(0, ℓ), we will frequently write x=λℓforℓ∈(0,1) and\nγ=γ(λ) =2α\n1−α(1−λ)\nwhich satisfies\nψ(x) =r+ℓ−2x\nr−ℓ= 1 +2ℓ−2λℓ\nr−ℓ= 1 +2ℓ(1−λ)\nr−ℓ= 1 +2α\n1−α(1−λ) = 1 + γ . (6)\n20To simplify the analysis, we will define and analyze an auxiliary function Q∗that lower bounds\nQ. Recall Q(x) = 1 + e−mxPd(x). We define the function\nQ∗(x)..=(\n1 +Pd(x) if x < ℓ\n1−δ ifx≥ℓ ,\nwhich satisfies:\nProposition 3.23 (Properties of Q∗).Q∗is concave and non-decreasing on [0,1], and for all\nx∈(0, ℓ],Q(x)≥Q∗(x). Furthermore, if Constraints I and II hold, then Q(x)≥Q∗(x)for all\nx∈(0,1].\nProof. We first show concavity. For x≤ℓ,Pd(x) is concave and increasing (Corollary 3.13), so\nQ∗(x) = 1 + Pd(x) is also concave increasing. Now observe that\nPd(ℓ) =−δTd(ψ(ℓ)) =−δTd(1) =−δ ,\nsoQ∗(ℓ) = 1−δ= 1 + Pd(ℓ), which makes Q∗continuous. Then since Q∗(x) is concave increasing\nonx≤ℓ, and constant Q∗(x) =Q∗(ℓ) onx≥ℓ, it is concave and non-decreasing on x∈(0,1).\nNow we show Q(x)≥Q∗(x). Ifx∈(0, ℓ), write x=λℓso that ψ(x) = 1 + γ. Then\nPd(x) =−δTd(ψ(x)) =−δTd(1 +γ),\nsoPd(x)≤0 since Td(1 +γ)≥0 for γ≥0. Since mx≥0,\nQ(x) = 1 + e−mxPd(x)≥1 +Pd(x) =Q∗(x).\nIf Constraints I and II hold, then for x≥ℓ, by Propositions 3.2 and 3.4,\nQ(x)≥1−δ=Q∗(x). ■\nSince the quantityP\niQ∗(pi) is invariant under permutations of p, we may assume:\nAssumption 3.24. Without loss of generality, we assume pis sorted, so that p1≥p2≥ ··· .\n3.6.1 Worst-case behaviour and the function Φ(λ)\nWe first show that the worst-case behaviour of Q∗is captured by two variables: the nth-largest\ndensity pn, and the total mass of elements lighter than pn. Informally, the worst-case distributions\nfor our test statistic are those concentrating essentially all of their mass at pn.\nProposition 3.25. Letn∈Nand let pbe a (sorted) distribution with pn>0. Let µ..=P\ni>npi.\nThenX\niQ∗(pi)≥\nn+µ\npn\nQ∗(pn).\nProof. Recall that Q∗is concave and non-decreasing by Proposition 3.23. Since Q∗is non-decreasing\nandpi≥pnfor any i≤n, we have Q∗(pi)≥Q∗(pn) for any i≤n. On the other hand, for any\ni > n , we have pi≤pnand then, using the concavity of Q∗,\nQ∗(pi) =Q∗pi\npn·pn+\n1−pi\npn\n·0\n≥pi\npn·Q∗(pn) +\n1−pi\npn\n·Q∗(0) =pi\npn·Q∗(pn),\n21the last equality since Q∗(0) = 1 + Pd(0) = 0. We conclude that\nX\niQ∗(pi)≥X\ni≤nQ∗(pn) +X\ni>npi\npn·Q∗(pn) =\nn+µ\npn\nQ∗(pn). ■\nWe can now transform the problem of lower boundingP\niQ∗(pi) into the problem of lower\nbounding another function Φ( λ) defined as:\nDefinition 3.26. Forλ∈(0,1], define\nΦ(λ)..=\n1 +ε\nλℓn\nQ∗(λℓ).\nWe will show a lower bound of Φ( λ)≥1 + 3 ε/4 below, in Section 3.6.2. Here we show why it\nworks:\nLemma 3.27. Assume Constraint I. Suppose Φ(λ)≥1 + 3 ε/4for all λ∈(0,1). Then for\nanyk≤nand any pthat is ε-far from having |supp( p)| ≤k,\nX\niQ∗(pi)>(1 + 3 ε/4)k .\nProof. Since pis sorted and ε-far from having |supp( p)| ≤k, we have pk>0 andP\ni>kpi> ε. We\nalso have pk≤1/ksince pis a probability distribution. We consider two cases: pk≥ℓandpk< ℓ.\nFirst, suppose pk≥ℓ. Then Q∗(pk) = 1−δby definition, so by Proposition 3.25,\nX\niQ∗(pi)>\nk+ε\n1/k\n(1−δ) = (1 + ε)(1−δ)k≥(1 + 3 ε/4)k ,\nthe last inequality since δ≤ε/20< ε/ 8 by Proposition 3.2. Otherwise, if pk=λℓfor some\nλ∈(0,1), then Proposition 3.25 gives\nX\niQ∗(pi)>\nk+ε\nλℓ\nQ∗(λℓ) =k\n1 +ε\nλkℓ\nQ∗(λℓ)≥Φ(λ)·k≥(1 + 3 ε/4)k . ■\n3.6.2 Lower bound on Φ(λ)\nOur goal is to prove Φ( λ)≥1 + 3 ε/4. Figure 4 shows a plot of Φ( λ) compared to 1 + εfor certain\nexample settings of parameters.\nNote that Φ( λ) =\0\n1 +ε\nλℓn\nQ∗(λℓ) is undefined on λ= 0. We will proceed in two steps:\n1. Show that Φ( λ)≥1 + 3 ε/4 atλ= 1 and in the limit λ→0+;\n2. Show that Φ( λ)≥1 + 3 ε/4 within λ∈(0,1) by studying the derivative Φ′(λ).\nThe case λ= 1 is the easiest to handle:\nProposition 3.28. Assume Constraints I and IVb. Then for all n∈Nandε∈(0,1),\nΦ(1)≥1 + 3 ε/4.\n220.0 0.5 1.001+\n(a)Φ(λ)when dis too small\n0.0 0.5 1.001+\n (b)Φ(λ)under Constraints I and IVb.\nFigure 4: The function Φ(λ)with bad and good parameters.\nProof. Note that, by Proposition 3.2, we have δ≤ε/20< ε/8. When λ= 1, we have Q∗(λℓ) = 1−δ\nby definition and hence, using the inequality ℓ≤ε\nnlog(1/ε) obtained from Constraint IVb,\nΦ(1) =\n1 +ε\nℓn\nQ∗(ℓ)≥\n1 +1\nlog(1/ε)\n(1−δ)>(1 +ε)(1−δ)≥1 + 3 ε/4. ■\nTo reason about lim λ→0+Φ(λ), we will use L’Hˆ opital’s rule, for which we will need bounds on\nthe derivative T′\nd(x) of the Chebyshev polynomials. We state the following bound, whose proof\nproceeds by a direct calculation and is deferred to Appendix B.\nProposition 3.29. For any d∈Nandγ∈(0,1), we have\nT′\nd(1 +γ)≥d√3γ(Td(1 +γ)−1).\nWe may now complete Step 1.\nProposition 3.30. Assume Constraints I and IVb. Then the limit limλ→0+Φ(λ)exists, is\nfinite, and satisfies\nlim\nλ→0+Φ(λ)≥2. (7)\nProof. Recall from Equation (6) that Q∗(λℓ) = 1 + Pd(λℓ) = 1−δTd(1 +γ). Then\nlim\nλ→0+Φ(λ) = lim\nλ→0+\n1 +ε\nλℓn\n(1−δTd(1 +γ))\n= lim\nλ→0+[1−δTd(1 +γ)] +ε\nℓn·lim\nλ→0+1−δTd(1 +γ)\nλ\n.\nSince γ=2α\n1−α(1−λ), and by the definition of δ, the first limit evaluates to\n1−δTd\n1 +2α\n1−α\n= 1−δ·1\nδ= 0.\n23As for the second limit, note that both the numerator (for the same reason) and denominator go\nto 0 as λ→0+. Applying L’Hˆ opital’s rule,\nlim\nλ→0+Φ(λ) =ε\nℓn·lim\nλ→0+d\ndλ(1−δTd(1 +γ))\nd\ndλλ=−δε\nℓn·lim\nλ→0+d\ndλTd\n1 +2α\n1−α(1−λ)\n=δε\nℓn·2α\n1−α·lim\nλ→0+T′\nd\n1 +2α\n1−α(1−λ)\n=δε\nℓn·2α\n1−α·T′\nd\n1 +2α\n1−α\n,\nwhere the last equality holds since T′\nd(x) is a polynomial and hence continuous, and this also\nestablishes the existence and finiteness of the limit. Using Proposition 3.29 and the definition of δ,\nlim\nλ→0+Φ(λ)≥δε\nℓn·2α\n1−α·dq\n3·2α\n1−α·1\nδ−1\n=r\n2α\n1−α·δεd\nℓn√\n3·1\nδ−1\n.\nSince δ≤1/2 by Proposition 3.2, we have1\nδ−1≥1\n2δ. Using Constraints I and IVb and the\ndefinition α=ℓ/r, we obtain\nlim\nλ→0+Φ(λ)≥r\n2α\n1−α·δε\nn√\n3·n\nCℓεlog(1/ε)·Cdr\n1−α\n2αlog(1/ε)·1\n2δ≥2. ■\nRemark 3.31. The last step in the above proof shows that Constraint IVb is the best\npossible relaxation of our constraint on ℓfor the present proof strategy: if we had ℓ≫\nε\nnlog(1/ε), then we would only have obtained a o(1) lower bound on lim λ→0+Φ(λ), but we\nrequire a 1 + ε/2 lower bound.\nThanks to Proposition 3.30, we hereafter consider the continuous extension Φ : [0 ,1]→R, i.e.\nwe define Φ(0)..= lim λ→0+Φ(λ).\nThe next step is to show that Φ satisfies a certain differential inequality, which will help us\nconclude that Φ( λ)≥1 + 3 ε/4 at any critical points where Φ′(λ) = 0. It is convenient to define\nL..=ℓn\nε, so that\nΦ(λ) =\n1 +1\nLλ\n(1−δTd(1 +γ)).\nLemma 3.32. Assume Constraint I. Define A..=q\n1\n3·Cdlog\01\nε\n. Then for all λ∈(0,1),\nΦ′(λ)≥ −Φ(λ)\nA+1\nλ(Lλ+ 1)\n+ (1−δ)A\n1 +1\nLλ\n.\nProof. Recall that γ=2α\n1−α(1−λ) sod\ndλγ=−2α\n1−α. Then\nΦ′(λ) =d\ndλ\n1 +1\nLλ\n(1−δTd(1 +γ))\n=−1\nLλ2(1−δTd(1 +γ)) +\n1 +1\nLλ\n·(−δ)·T′\nd(1 +γ)·\n−2α\n1−α\n=−1\nLλ2\n1 +1\nLλΦ(λ) +δ·2α\n1−α·\n1 +1\nLλ\n·T′\nd(1 +γ)\n=−1\nλ(Lλ+ 1)Φ(λ) +δ·2α\n1−α·\n1 +1\nLλ\n·T′\nd(1 +γ).\n24Using Proposition 3.29 and Constraint I and recalling that Td(1 +γ)≥1,\nΦ′(λ)≥ −1\nλ(Lλ+ 1)Φ(λ) +δ·2α\n1−α·\n1 +1\nLλ\n·dq\n3·2α\n1−α(1−λ)(Td(1 +γ)−1)\n≥ −1\nλ(Lλ+ 1)Φ(λ) +δ·r\n2α\n1−α·\n1 +1\nLλ\n·Cdq\n1−α\n2αlog\01\nε\n√\n3(Td(1 +γ)−1)\n=−1\nλ(Lλ+ 1)Φ(λ) +δ·\n1 +1\nLλ\n·Cdlog\01\nε\n√\n3(Td(1 +γ)−1)\n=−1\nλ(Lλ+ 1)Φ(λ) +A\n1 +1\nLλ\n·δTd(1 +γ)−δA\n1 +1\nLλ\n.\nNow, we may use the definition of Φ to rewrite the middle term:\nΦ(λ) =\n1 +1\nLλ\n(1−δTd(1 +γ)) =⇒δTd(1 +γ) = 1−Φ(λ)\n1 +1\nLλ.\nTherefore\nΦ′(λ)≥ −1\nλ(Lλ+ 1)Φ(λ) +A\n1 +1\nLλ \n1−Φ(λ)\n1 +1\nLλ!\n−δA\n1 +1\nLλ\n=−1\nλ(Lλ+ 1)Φ(λ) +A\n1 +1\nLλ−Φ(λ)\n−δA\n1 +1\nLλ\n=−Φ(λ)\nA+1\nλ(Lλ+ 1)\n+ (1−δ)A\n1 +1\nLλ\n. ■\nWe may now conclude the argument.\nLemma 3.33. Assume Constraints I and IVb. Then for all n∈Nandε≤1/3,\n∀λ∈[0,1] : Φ( λ)≥1 + 3 ε/4.\nProof. Note that Propositions 3.28 and 3.30 already give the result for λ= 0 and λ= 1. Since Φ\nis continuous on [0 ,1] and differentiable in (0 ,1), it remains to check points λ∈(0,1) for which\nΦ′(λ) = 0, if any exist. Suppose λ∈(0,1) satisfies Φ′(λ) = 0. Then Lemma 3.32 implies that\n0 = Φ′(λ)≥ −Φ(λ)\nA+1\nλ(Lλ+ 1)\n+ (1−δ)A\n1 +1\nLλ\n,\nwhere again A..=q\n1\n3·Cdlog\01\nε\n. Rearranging, we obtain\nΦ(λ)≥(1−δ)A\0\n1 +1\nLλ\n\nA+1\nλ(Lλ+1)=(1−δ)A\0Lλ+1\nLλ\n\nAλ(Lλ+1)+1\nλ(Lλ+1)=(1−δ)(AL2λ2+ 2ALλ +A)\nAL2λ2+ALλ +L.\nTake K..=A/L≥Cd√\n3Cℓwhich satisfies K≥4 under Constraint IVb. Then the right hand side is\n(1−δ)\n1 +KL2λ+ (K−1)L\nKL3λ2+KL2λ+L\n= (1−δ)\n1 +KLλ + (K−1)\nKL2λ2+KLλ + 1\n.\n25IfLλ < 1/Kthen this is at least\n(1−δ)\n1 +K−1\n3\n≥(1−δ)·2≥1 + 3 ε/4,\nthe last inequality since δ≤ε/20 by Proposition 3.2. Otherwise it is at least\n(1−δ)\n1 +KLλ·min\Z1\n3KL2λ2,1\n3KLλ\n≥(1−δ)\n1 + min\Z1\n3L,1\n3\n≥(1−δ)(1 + ε)≥1 + 3 ε/4,\nwhere the penultimate inequality holds since L≤Cℓlog(1/ε)≤1\n3εby Constraint IVb. ■\nWe now have all the ingredients to conclude the soundness of the improved tester, and hence\nfinish the proof of the main theorem.\nProof of Lemma 3.21. Combine Equation (2), Proposition 3.23, and Lemmas 3.27 and 3.33 to\nobtain\nEh\nbSi\n=X\ni∈NQ(pi)≥X\ni∈NQ∗(pi)>(1 + 3 ε/4)k . ■\n4 An Effective Lower Bound on Support Size\nTo prove Corollary 1.6 from the introduction, which we restate here for convenience, we need to\nessentially do a binary search for the correct parameters, in order to control the variance (since the\nvariance depends on the parameter n).\nCorollary 4.1. There exists an algorithm Awhich, given inputs n∈N,ε∈(0,1/3)and\nsample access to unknown distribution poverN, draws O\nn\nεlogn·min{log(1/ε),logn}\nin-\ndependent samples from pand outputs a number bSwhich satisfies (with probability at least\n3/4over the samples)\nmin{effε(p), n} ≤bS≤(1 +ε)|supp( p)|.\nProof. The algorithm proceeds as follows:\n1. For i= 0 to log n, perform the following.\n(a) Set ni..=n/2iandδi=1\n4·2i+1.\n(b) If ni, εdo not satisfy Assumption 2.4, use O(m(ni, ε)·log(1/δi)) samples to obtain an\nestimate cSisatisfying the conditions of Proposition 2.2 with probability at least 1 −δi\n(using the median trick to boost the error). Output cSiand terminate.\n(c) Otherwise, if ni, εsatisfy Assumption 2.4, use O(m(ni, ε)·log(1/δi)) samples obtain\nan estimate of the test statistic cSifrom Definition 2.6, which (again using the median\ntrick) satisfies the conditions of Lemma 3.17 with probability at least 1 −δi. IfcSi≥ni+1\noutput cSiand terminate. Otherwise continue.\n2. If the algorithm did not terminate in log nsteps, then output 1.\n26The number of samples used by the algorithm is at most (for some constant C >0):\nC·lognX\ni=0ni\nlog(ni)log1\nδi1\nε·min{log(1/ε),log(ni)}\n=C·1\nε1\n2lognX\ni=0n/2i\nlog(n)−i(i+ 3)·min{log(1/ε),log(n)−i}\n+C·1\nεlognX\ni=1+1\n2lognn/2i\nlog(n)−i(i+ 3)·min{log(1/ε),log(n)−i}\n≤C·2n\nεlognmin{log(1/ε),log(n)}1\n2lognX\ni=01\n2i(i+ 3) + 2 C·1\nε√nlogn\n=On\nεlognmin{log(1/ε),logn}\n.\nThe probability that any of the estimates cSifails to satisfy the conditions in Lemma 3.17 or\nProposition 2.2 (whichever corresponds to the estimator used in the ithstep) is at mostPlogn\ni=0δi≤\n1\n4. Assuming that every cSisatisfies its corresponding condition, we separately prove the upper and\nlower bounds on the output of the algorithm.\nClaim 4.2. The output satisfies bS≤(1 +ε)|supp( p)|.\nProof. If the algorithm reaches its last step and outputs 1, there is nothing to show. Similarly, if\nit outputs an estimate cSicoming from Proposition 2.2, then cSi≤ |supp( p)|and we are done.\nThe remaining case is that the algorithm terminates at some step i∗by outputting an estimate\ncSi∗satisfying the conditions of Lemma 3.17. We claim that ni∗≤3|supp( p)|. Indeed, assuming\nthatni∗>3|supp( p)|for a contradiction, Lemma 3.17 implies that\ncSi<(1 +ε/4)|supp( p)|+εni∗\n4<(1 +ε/4)·ni∗\n3+εni∗\n4\n=ni∗1\n3+ε\n12+ε\n4\n=ni∗1\n3+ε\n3\n<ni∗\n2=ni∗+1,\ncontradicting the assumption that the algorithm terminates at step i∗. Hence ni∗≤3|supp( p)|.\nThus Lemma 3.17 gives\ncSi<(1 +ε/4)|supp( p)|+εni∗\n4≤(1 +ε/4)|supp( p)|+3ε\n4|supp( p)|= (1 + ε)|supp( p)|.■\nClaim 4.3. The output satisfies bS≥min{effε(p), n}.\nProof. We first consider the edge case where effε(p) = 1. In this case, the output satisfies bS≥effε(p)\nsince the algorithm always outputs at least 12. Going forward, suppose effε(p)≥2.\nNow let i∗be the smallest non-negative integer such that effε(p)−1≥ni∗+1, which exists\nbecause nlog(n)+1=1\n2≤effε(p)−1, so i∗= log nsatisfies the condition. We consider two cases.\n2If its output cSicomes from Proposition 2.2, then it is at least 1, and it comes from Lemma 3.17, then Assump-\ntion 2.4 is satisfied and hence cSi≥ni+1>1/ε.\n27First, suppose that effε(p)−1≥ni∗, which implies that i∗= 0 by the minimality of i∗. Then\nn=n0≤effε(p)−1, so pisε-far from having support size nby Observation 2.1, and we conclude\nthat the algorithm terminates with output satisfying cS0≥(1 +ε/2)n(by Lemma 3.17) or cS0≥n\n(by Proposition 2.2).\nOtherwise, we have that ni∗>effε(p)−1≥ni∗+1. For all j < i∗, if the algorithm terminates\non loop jthen it outputs cSj≥nj+1≥ni∗>effε(p)−1, so that cSj≥effε(p).\nFinally, suppose the algorithm reaches loop i∗. Ifni∗, εdo not satisfy Assumption 2.4, then the\noutput cSi∗satisfies cSi∗≥min{effε(p), ni∗}=effε(p) by Proposition 2.2.\nOtherwise, ni∗, εsatisfy Assumption 2.4, which implies that effε(p)−1≥ni∗+1>4/ε; then,\nsince min {effε(p)−1, ni∗}=effε(p)−1, we conclude from Lemma 3.17 that\ncSi∗>(1 + 3 ε/4)(effε(p)−1)−εni∗/4 = (1 + 3 ε/4)(effε(p)−1)−εni∗+1/2\n≥(1 +ε/4)(effε(p)−1)>effε(p)−1 +ε\n4·4\nε=effε(p),\nwhich is larger than ni∗+1, so the algorithm terminates with output satisfying cSi∗>effε(p).■\nThis completes the proof of the corollary. ■\n5 Testing Support Size of Functions\nFor any n∈N, we write Hnfor the set of functions f:N→ {0,1}which satisfy |f−1(1)| ≤n. We\nwill refer to pairs ( f, p), consisting of a function f:N→ {0,1}and a probability distribution pover\nN, asfunction-distribution pairs. A function-distribution pair ( f, p) isε-farfromHnif\n∀h∈ H n:P\nx∼p[f(x)̸=h(x)]≥ε .\nFor any multiset S⊂Nand function f:N→ {0,1}, we will write Sffor the labeled multiset\nSf..={(x, f(x)) :x∈S}.\nDefinition 5.1 (Testing Support Size of Functions) .Asupport-size tester for functions ,\nwith sample complexity m(n, ε, σ ), is an algorithm Bwhich receives as input the parameters\nn∈N,ε∈(0,1), and σ∈(0,1), and is required to satisfy the following. For any function-\ndistribution pair ( f, p) consisting of a function f:N→ {0,1}and a probability distribution\npoverN, ifSfis a labeled sample of size m=m(n, ε, σ ) drawn from p, then\n1. If f∈ H nthenP[B(Sf) outputs Accept ]≥σ; and\n2. If ( f, p) isε-far from HnthenP[B(Sf) outputs Reject ]≥σ.\nWe write mFUN(n, ε, σ ) for the optimal sample complexity of a support-size tester for func-\ntions.\nWe will also write mDIST(n, ε, ξ ) for the optimal sample complexity of support-size testing of\ndistributions, with parameters nandε, and success probability σ(replacing 3 /4 in Definition 1.2).\nThe next two propositions establish Theorem 1.8 from the introduction.\n28Proposition 5.2. For any n∈Nandε∈(0,1), and any σ∈(0,1),\nmDIST(n, ε, σ )≤mFUN(n, ε, σ ).\nProof. We reduce testing support size of distributions, to testing support size of functions. Let\nBbe a distribution-free sample-based support-size tester for functions on domain N, with sample\ncomplexity m=mFUN(n, ε). The given nandε, the support-size tester for input distribution pis\nas follows.\n1. Let Sbemindependent random samples from p.\n2. Output B(Sf), where the sample Sis labeled by the constant function f(x) = 1.\nSuppose that pisε-far from having |supp( p)| ≤n. Then for any function g:N→ {0,1}with\n|g−1(1)| ≤n, it must be the case thatP\ni/∈g−1(1)pi≥ε. So\nP\nS[B(Sf) outputs Reject ]≥3/4.\nNow suppose phas|supp( p)| ≤n. Let g:N→ {0,1}be the function g(i) =1[i∈supp( p)], so\n|g−1(1)| ≤n. Then\nP\nS[B(Sg) outputs Accept ]≥3/4.\nSinceP\ni/∈g−1(1)pi= 0, the labeled sample Sfhas the same distribution as the labeled sample Sg.\nSo\nP\nS[B(Sf) outputs Accept ]≥3/4. ■\nProposition 5.3. For any n∈Nandε∈(0,1), and any σ, ξ∈(0,1)which satisfy σ+ξ <1,\nmFUN(n, ε, σ )≤mDIST(n, ε, σ +ξ) +ln(2/ξ)\nε.\nProof. LetAbe the distribution support-size tester with sample complexity mDIST. On input\nparameters nandε, given sample access to the function-distribuiton pair ( f, p), we define the\ntester Bwhich performs the following.\n1. Take m1=ln(2/ξ)\nεrandom labeled samples S(1)\nf. IfS(1)\nf∩f−1(1) =∅, output Accept .\n2. Let z∼S(1)∩f−1(1) be chosen uniformly at random from the elements of the multiset\nS(1)∩f−1(1).\n3. Take m2=mDIST(n, ε, σ +ξ) ', 'raytos.r.bsinfotech@gmail.com', 'Renato Ferreira Pinto Jr., Nathaniel Harms', '', '../pdf_files/671b4ace22c55-Testing Support Size More Efficiently Than Learning Histograms.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(131, '2724633467', '1', 1, 1, 'Connectivity Labeling Schemes for Edge and Vertex Faults via Expander Hierarchies', '2024-10-25', '2024', 'We consider the problem of assigning short labels to the vertices and edges of a graph G so that given any query ⟨s,t,F⟩ with |F| ≤ f, we can determine whether s and t are still connected in G−F, given only the labels of F ∪{s,t}. \r\nThis problem has been considered when F ⊂ E (edge faults), where correctness is guaranteed with high probability (w.h.p.) [DP21] or deterministically [IEWM23], and when F ⊂ V (vertex faults), both w.h.p. and deterministically [PP22, PPP24]. Our main results are as follows. \r\nDeterministic Edge Faults. We give a new deterministic labeling scheme for edge faults that uses ˜ O(√f)-bit labels, which can be constructed in polynomial time. This improves on Dory and Parter’s [DP21] existential bound of O(f logn) (requiring exponential time to compute) and the efficient ˜ O(f2)-bit scheme of Izumi, Emek, Wadayama, and Ma suzawa [IEWM23]. Our construction uses an improved edge-expander hierarchy and a distributed coding technique based on Reed-Solomon codes. \r\nDeterministic Vertex Faults. We improve Parter, Petruschka, and Pettie’s [PPP24] deter ministic O(f7 log13 n)-bit labeling scheme for vertex faults to O(f4 log7.5 n) bits, using an improved vertex-expander hierarchy and better sparsification of shortcut graphs. We com pletely bypass deterministic graph sketching [IEWM23] and hit-and-miss families [KP21]. \r\nRandomized Edge/Verex Faults. We improve the size of Dory and Parter’s [DP21] ran domized edge fault labeling scheme from O(min{f + logn,log3n}) bits to O(min{f + log n,log2 nlogf}) bits, shaving a logn/logf factor. We also improve the size of Parter, Petruschka, and Pettie’s [PPP24] randomized vertex fault labeling scheme from O(f3 log5 n) bits to O(f2 log6 n) bits, which comes closer to their Ω(f)-bit lower bound [PPP24]', 'Data Structures and Algorithms', 'Connectivity Labeling Schemes for Edge and Vertex Faults\nvia Expander Hierarchies\nYaowei Long\nUniversity of MichiganSeth Pettie∗\nUniversity of MichiganThatchaphol Saranurak†\nUniversity of Michigan\nAbstract\nWe consider the problem of assigning short labels to the vertices and edges of a graph Gso\nthat given any query ⟨s, t, F⟩with|F| ≤f, we can determine whether sandtare still connected\ninG−F, given only the labels of F∪ {s, t}.\nThis problem has been considered when F⊂E(edge faults), where correctness is guaranteed\nwith high probability (w.h.p.) [DP21] or deterministically [IEWM23], and when F⊂V(vertex\nfaults), both w.h.p. and deterministically [PP22, PPP24]. Our main results are as follows.\nDeterministic Edge Faults. We give a new deterministic labeling scheme for edge faults\nthat uses ˜O(√f)-bit labels, which can be constructed in polynomial time. This improves\non Dory and Parter’s [DP21] existential bound of O(flogn) (requiring exponential time\nto compute) and the efficient ˜O(f2)-bit scheme of Izumi, Emek, Wadayama, and Ma-\nsuzawa [IEWM23]. Our construction uses an improved edge-expander hierarchy and a\ndistributed coding technique based on Reed-Solomon codes.\nDeterministic Vertex Faults. We improve Parter, Petruschka, and Pettie’s [PPP24] deter-\nministic O(f7log13n)-bit labeling scheme for vertex faults to O(f4log7.5n) bits, using an\nimproved vertex-expander hierarchy and better sparsification of shortcut graphs. We com-\npletely bypass deterministic graph sketching [IEWM23] and hit-and-miss families [KP21].\nRandomized Edge/Verex Faults. We improve the size of Dory and Parter’s [DP21] ran-\ndomized edge fault labeling scheme from O(min{f+ log n,log3n}) bits to O(min{f+\nlogn,log2nlogf}) bits, shaving a log n/logffactor. We also improve the size of Parter,\nPetruschka, and Pettie’s [PPP24] randomized vertex fault labeling scheme from O(f3log5n)\nbits to O(f2log6n) bits, which comes closer to their Ω( f)-bit lower bound [PPP24].\n∗Supported by NSF Grant CCF-2221980.\n†Supported by NSF Grant CCF-2238138.arXiv:2410.18885v1  [cs.DS]  24 Oct 2024Contents\n1 Introduction 1\n2 Deterministic Edge Fault Connectivity Labels 4\n2.1 First Tool: Edge Expander Hierarchies . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 A Simple ˜O(f)-Bit Labeling Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.3 Second Tool: Code Shares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.4 An ˜O(√f)-Bit Labeling Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n3 Deterministic Vertex Fault Connectivity Labels 13\n3.1 Overview and Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n3.2 The Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.2.1 The Basis: A Vertex Expander Hierarchy . . . . . . . . . . . . . . . . . . . . 15\n3.2.2 The Initial Structure: Low-Degree Steiner Trees and Shortcut Graphs . . . . 16\n3.2.3 Structures Affected by Queries . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.2.4 A Divide-and-Conquer Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.2.5 An Improved Divide-and-Conquer Lemma via Sparsified Shortcut Graphs . . 24\n3.3 The Strategy for Handling Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n3.4 The Labeling Scheme: Implementing the Strategy . . . . . . . . . . . . . . . . . . . 30\n3.4.1 The Euler Tours of (Extended) Steiner Trees . . . . . . . . . . . . . . . . . . 31\n3.4.2 Profiles of Vertices, Components and Subtrees . . . . . . . . . . . . . . . . . 31\n3.4.3 Labels on Euler Tours . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.4.4 Labels for Implementing EnumFromGiant (τy,Γ) . . . . . . . . . . . . . . . . . 37\n3.4.5 Space Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n3.4.6 The Final Labeling Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4 Randomized Edge Fault Connectivity Labels 44\n4.1 A Simple Labeling Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.2 A Smaller Labeling Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n5 Randomized Vertex Fault Connectivity Labels 49\n6 Lower Bound for Global Connectivity under Vertex Faults 50\n7 Conclusion and Open Problems 51\nAcknowledgments 52\nA Low-Degree Steiner Trees Spanning Tough Sets 52\nB Improved Singleton-Detection Scheme: Proof of Lemma 4.5 541 Introduction\nAlabeling scheme for a graph problem can be viewed as a distributed data structure in which all\nqueries must be answered without inspecting the underlying graph, but only the labels of the query\narguments. Early work focused on labeling schemes for adjacency [Bre66, BF67, KNR92], which is\nconnected to finding small induced universal graphs [ADK17, AKTZ19].\nThere are now many labeling schemes for basic navigation queries in rooted trees [ADK17,\nAAK+06, AHL14], such as adjacency, ancestry, and least common ancestors. There are labeling\nschemes for computing distances in general graphs [AGHP16a], planar graphs [GPPR04, BGP22,\nGU23], and trees [GPPR04, ABR05, AGHP16b], as well as labelings for approximate distances [TZ05,\nAG11]. There are several labeling schemes for answering queries about the pairwise edge- and\nvertex-connectivity in undirected graphs [KKKP04, HL09, IN12, PSY22].\nLabel Schemes under Faults. Courcelle and Twigg [CT07, CGKT08] initiated the study of\nforbidden set orfault tolerant labeling schemes. The idea is to support a standard connectiv-\nity/distance query, subject to faults (deletions) of some subset Fof vertices or edges. Several\nfault tolerant labeling schemes focus on special graph classes such as bounded treewidth graphs\n[CT07] and planar graphs [CGKT08, ACGP16, BCG+22, CMW23]. On general graphs, labeling\nschemes that handle at most one or two faults were shown for single-source reachability [Cho16]\nand single-source approximate distance [BCHR20].\nThe first labeling scheme on general graphs under multiple faults was given by Dory and\nParter [DP21], for connectivity under edge faults. More precisely, they assigned labels to edges and\nvertices of an undirected n-vertex graph Gso that, given the labels of ⟨s, t, F⟩where F⊂E(G),\none can determine if sandtare still connected in G−F. When |F| ≤f, they gave a Monte Carlo\nrandomized construction of labels of size O(min{f+ log n,log3n}) bits that answer each query\ncorrectly with high probability. By increasing the size to O(flogn) bits, their scheme answers\nallqueries correctly, with high probability, though confirming this property seems to require an\nexponential time brute force search. Recently, Izumi, Emek, Wadayama, and Masuzawa [IEWM23]\ngave a deterministic polynomial-time construction of labels of size ˜O(f2).\nParter and Petruschka [PP22] considered the same problem, but with vertex faults rather than\nedge faults, i.e., F⊂V(G). They gave deterministic labeling schemes with length O(logn) for\nf= 1, O(log3n) for f= 2, and a randomized scheme of length ˜O(n1−1/2f−2) for general f. This\nyear, Parter, Petruschka, and Pettie [PPP24] developed randomized and deterministic labeling\nschemes with label length ˜O(f3) and ˜O(f7), respectively. They also observed an Ω( f+ log n)-\nbit lower bound for vertex faults (randomized or deterministic), which established a complexity\nseparation between edge and vertex faults. See Table 1.\nOur Results. We show new connectivity labels under both edge and vertex faults that improve\nthe state-of-the-art as follows:\n1. Deterministic labels under edge faults of size ˜O(√f) bits (Theorem 2.1). This simultaneously\nimproves Dory and Parter’s [DP21] labels of size O(flogn), which require exponential time\nto construct, and Izumi et al.’s [IEWM23] efficiently constructed labels of size ˜O(f2). In fact,\nIzumi et al. [IEWM23] stated that “it seems plausible that the Ω( f)-bit lower bound holds.”\nWe refute this possibility.\n1Edge Fault Tolerant Connectivity Labels\nReference Label Size (Bits) Guarantee Notes\nDory & Parter [DP21]O(min{f+ log n,log3n}) Monte Carlo Query correct w.h.p.\nO(flogn) Deterministic Existential bound\nIzumi, Emek, Wadayama O(f2log2nlog log n)DeterministicPolynomial construction\n& Masuzawa [IEWM23] O(f2log3n) ˜O(mf2) construction\nTrivial Ω(log n) any trivial lower bound\nO(min{f+ log n,Monte Carlo Query correct w.h.p.\nnewlog2nlog(f/log2n)})\nO(√flog2nlogf) Existential bound\nO(√flog2.25nlog(flogn))Deterministic\nPolynomial construction\nVertex Fault Tolerant Connectivity Labels\nParter O(log3n) Deterministic f≤2\n& Petruschka [PP22] ˜O(n1−2−f+2) Monte Carlo f∈[3, o(log log n)]\nParter, PetruschkaO(f3log5n) Monte Carlo Query correct w.h.p.\n& Pettie [PPP24]O(f7log13n) Deterministic Polynomial construction\nΩ(f+ log n) any lower bound\nO(f2log6n) Monte Carlo Query correct w.h.p.\nnew O(f4log7n) Existential bound\nO(f4log7.5n)Deterministic\nPolynomial construction\nTable 1: All Monte Carlo results have a one-sided error probability of 1 /poly( n), i.e., they may\nreport two vertices disconnected when they are, in fact, connected. The existential result of Dory\nand Parter [DP21] constructs labels in O(mflogn) time that, with high probability, answer all\nqueries correctly. However, to verify this fact requires a brute force search. The new existential\nresults require solving an NP-hard problem, namely sparsest cut .\n22. Deterministic labels under vertex faults of size O(f4log7.5n) bits (Theorem 3.1). This im-\nproves the O(f7log13n)-bit labels of [PPP24].\n3. Randomized labels under edge faults of size O(min{f+log n,log2nlogf}) bits (Theorems 4.1\nand 4.4). This improves the O(min{f+ log n,log3n})-bit labels of Dory and Parter [DP21].\n4. Randomized labels under vertex faults of size O(f2log6n) bits (Theorem 5.1). This improves\ntheO(f3log5n)-bit labels of Parter et al. [PPP24].\nRelated Work: Connectivity Oracles. Our connectivity labels can be viewed as a distributed\nversion of connectivity oracles under faults . In this problem, we must build a centralized data\nstructure for an input graph Gso that, given a query ⟨s, t, F⟩, we can check if sandtare still\nconnected in G−Fas fast as possible using the centralized data structure. Connectivity oracles\nhave been well-studied under both edge faults [PT07, DP20, GKKT15] and vertex faults [DP20,\nvdBS19, LS22, PSS+22, Kos23, LW24] and the optimal preprocessing/query bounds have been\nproven [PT07, LS22, DP20, KPP16, HKNS15], either unconditionally, or conditioned on standard\nfine-grained complexity assumptions.\nOur Techniques. The basis of Results 1 and 2 is an expander hierarchy . This is the first\napplication of expanders in the context of fault-tolerant labeling schemes, although they have\nbeen widely applied in the centralized dynamic setting, e.g. [NSWN17, GRST21, LS22].\nWe give a clean definition of expander hierarchies for both edge expansion (Definition 2.2) and\nvertex expansion (Definition 3.2) as well as simple algorithms for computing them. In the edge\nexpansion version, our formulation turns out to be equivalent to Pˇ atra¸ scu and Thorup’s [PT07],\nbut our algorithm improves the quality by a Θ(log n) factor. Our vertex expander hierarchy is new.\nCombined with the observation that any ϕ-vertex-expanding set has an O(1/ϕ)-degree Steiner\ntree (Lemma 3.6),1this implies a new low-degree hierarchy that is strictly stronger and arguably\ncleaner than all previous low-degree hierarchies [DP20, LS22, LW24, PPP24], which are the critical\nstructures behind vertex fault tolerant connectivity oracles.\nTo obtain our deterministic labels under edge faults, we first show that the edge expander\nhierarchy immediately leads to a simple ˜O(f)-bit label (Theorem 2.5), which already improves the\nstate-of-the-art [IEWM23, DP21]. Then, we introduce a new distributed coding technique based\non Reed-Solomon codes to improve the label size to ˜O(√f) bits, obtaining Result 1.\nOur deterministic labeling scheme under vertex faults (Result 2) employs a high-level strategy\nfrom Parter et al. [PPP24], but our label is shorter by an ˜Θ(f3) factor. Roughly, this improvement\ncomes from two sources. First, Parter et al. [PPP24] employed the deterministic graph cut sketch of\nIzumi et al. [IEWM23], which contributes an ˜Θ(f2) factor to the size. We can bypass deterministic\nsketching and pay only an ˜O(f) factor because our low-degree hierarchy has an additional vertex\nexpansion property. Second, Parter et al. [PPP24] constructed a sparsified shortcut graph with\narboricity ˜O(f4) using the hit-and-miss families by Karthik and Parter [KP21]. We are able to\nuse the simpler Nagamochi-Ibaraki sparsification [NI92] to obtain a sparse shortcut graph with\narboricity ˜O(f2). These two improvements cannot be applied in a modular way, so our final\nscheme ends up being rather different from [PPP24].\n1Previously, [LS22] showed an O(log(n)/ϕ)-degree Steiner tree spanning any ϕ-vertex-expanding set.\n3All previous centralized connectivity oracles under vertex faults (including the one using vertex\nexpanders [LS22]) crucially used 2D-range counting data structures, which seem inherently incom-\npatible with the distributed labeling setting. Thus, our scheme is inherently different than the\ncentralized oracles [LS22, DP20].\n2 Deterministic Edge Fault Connectivity Labels\nThe goal of this section is to prove the following theorem.\nTheorem 2.1. Fix any undirected graph G= (V, E)and integer f≥1. There are deterministic\nlabeling functions LV:V→ {0,1}lognandLE:E→ {0,1}O(√\nf/ϕlog(f/ϕ) log2n)such that given\nany query ⟨s, t, F⟩,F⊂E,|F| ≤f, one can determine whether sandtare connected in G−F\nby inspecting only LV(s), LV(t),{LE(e)|e∈F}. The construction time is exponential for ϕ= 1/2\nand polynomial for ϕ= Ω(1 /√logn).\nWe remark that the above labeling scheme is actually more flexible. By reading only the\nlabels of the failed edges F, it can compute a representation of connected components of G−Fin\npoly( flogn) time. From this representation, we can, for example, count the number of connected\ncomponents in G−F. This is impossible in the vertex-failure setting for any vertex-labels of size\no(n1−1/f/f). See Section 6. Given the additional labels of sandt, we can then check whether sand\ntare connected in G−F, inO(1 + min {log log n\nlog log log n,logf\nlog log n}) time. We can also straightforwardly\nhandle edge insertions.\nTo prove Theorem 2.1, we introduce two new tools into the context of labeling schemes. The\nfirst tool is the edge expander hierarchy , for which we give an improved construction in Section 2.1.\nThis tool alone already leads to a simple and efficient deterministic labeling scheme of size ˜O(f)\nbits, improving prior work [IEWM23, DP21]. In Section 2.3 we introduce a second tool, distributed\ncode shares , and in Section 2.4 we combine the two tools and prove Theorem 2.1.\n2.1 First Tool: Edge Expander Hierarchies\nIn this section we recall Pˇ atra¸ scu and Thorup’s [PT07] definition of an expander hierarchy, then\ngive a new construction that improves the quality by a factor of Θ(log n).\nGiven a graph G= (V, E), a set X⊆Eand a vertex u, let DegX(u) denote the number of\nedges from Xincident to uand let DegX(S) =P\nu∈SDegX(u) denote the volume ofSwith respect\ntoX. We say that Xisϕ-expanding inGif, for every cut ( S, V\\S),\n|EG(S, V\\S)| ≥ϕmin{DegX(S),DegX(V\\S)}.\nConsider a partition {E1, . . . , E h}ofE. We denote E≤ℓ:=S\ni≤ℓEi,E>ℓ:=S\ni>ℓEi, and G≤ℓ:=\nG∩E≤ℓ. We also write Degℓ:=DegEℓ,Deg≤ℓ:=DegE≤ℓ, and so on.\nDefinition 2.2 (Expander Hierarchy) .Given a graph G= (V, E), an edge-partition P={E1, . . . , E h}\nofEinduces an (h, ϕ)-expander hierarchy ofGif, for every level ℓ≤hand every connected com-\nponent Γ of G≤ℓ,Eℓ∩Γ isϕ-expanding in Γ. That is, for every cut ( S,Γ\\S) of Γ, we have\n|E≤ℓ(S, V(Γ)\\S)| ≥ϕmin{Degℓ(S),Degℓ(V(Γ)\\S)}.\nOver all levels ℓ, the set of all connected components Γ of G\\E>ℓform a laminar family C. LetH\nbe the tree representation of C. We also call ( C,H) an ( h, ϕ)-expander hierarchy of G.\n4𝐸𝐸ℎ is 𝜙𝜙-expanding in 𝐺𝐺\nΓ1Γ2\nΓ3𝐸𝐸ℎ−1∩Γ1 is 𝜙𝜙-expanding in Γ1𝐸𝐸ℎ−1∩Γ2 is 𝜙𝜙-expanding in Γ2\n𝐸𝐸ℎ−1∩Γ3 is 𝜙𝜙-expanding in Γ3\n𝐺𝐺Figure 1: Illustration of the top two levels of an ( h, ϕ)-expander hierarchy. EhandEh−1are drawn\nin red and blue, respectively.\nSee Figure 1 for an example. Below, we give an improved construction of the expander hierarchy.\nTheorem 2.3. There exists an algorithm that, given a graph G, computes an (h, ϕ)-expander\nhierarchy with h≤lognandϕ= 1/2in exponential time, or ϕ≥Ω(1/√logn)in polynomial time.\nPˇ atra¸ scu and Thorup [PT07] gave an exponential-time algorithm for h≤logmandϕ=\n1/(2 log n) and a polynomial-time algorithm with ϕ≥Ω(1/log1.5n). Theorem 2.3 shaves one\nlognfactor in ϕfor both settings.2\nTheorem 2.3 is perhaps surprising. Recall a related and seemingly weaker concept of ϕ-expander\ndecomposition. A ϕ-expander decomposition of a graph Gis an edge set X⊆Esuch that, for\neach connected component Γ of G\\X,E∩Γ isϕ-expanding in G[Γ]. It is known that there is\nno expander decomposition with X≤0.99|E|where ϕ=ω(1/logn) [AALOG18, MS18]. Here, we\ngive an expander hierarchy with ϕ= 1/2.\nTheorem 2.3 follows immediately from the lemma below, inspired by [RST14, Lemma 3.1].\nLemma 2.4. There exists an exponential-time algorithm that, given a graph G= (V, E), computes\nan edge set Xsuch that every connected component of G\\Xcontains at most n/2vertices and X\nis1\n2-expanding. In polynomial time, we can instead guarantee that XisΩ(1/√logn)-expanding.\nProof. Initialize X←E. IfXis1\n2-expanding, we are done. Otherwise, we repeatedly update X\nas follows. Since Xis not1\n2-expanding, there exists a vertex set Swhere |S| ≤n/2 such that\n|E(S, V\\S)|<1\n2min{DegX(S),DegX(V\\S)}. Update X←X∪E(S, V\\S)\\(X∩E(S, S)).\nLetX′denote Xafter the update. Observe that every connected component of G\\X′still\ncontains at most n/2 vertices because |S| ≤n/2. Moreover, since\n1\n2(2|X∩E(S, S)|+|X∩E(S, V\\S)|) =1\n2DegX(S)>|E(S, V\\S)|,\nwe have\n|X∩E(S, S)|>|E(S, V\\S)| −1\n2|X∩E(S, V\\S)| ≥ |E(S, V\\S)\\X|.\n2The factor 1 /2 in Theorem 2.3 is quite artificial. It can be improved to 1 if we slightly change the definition such\nthatXisϕ-expanding in Gif, for every cut ( S, V\\S),|EG(S, V\\S)| ≥ϕmin{|EG(S, V)∩X|,|EG(V\\S, V)∩X|}.\n5Thus, |X′|<|X|and there can be at most |E|iterations of the procedure.\nTo get a polynomial time construction, we instead apply the sparsest cut algorithm of Arora et\nal. [ARV09] that, given X, either guarantees that Xis Ω(1 /√logn)-expanding or returns a set S\nwhere |S| ≤n/2 and |E(S, V\\S)|<1\n2min{DegX(S),DegX(V\\S)}.\nProof of Theorem 2.3. Given G, compute the edge set Xfrom Lemma 2.4 and set Eh←X. To\ncompute Eh−1, Eh−2, . . . , E 1, we recurse on each connected component CofG\\X. We have\nh≤lognbecause each component Chas size |C| ≤n/2.\n2.2 A Simple ˜O(f)-Bit Labeling Scheme\nIn this section, we prove Theorem 2.5, which uses ˜O(f)-bit labels. It is the basis for our final\n˜O(√f)-bit labeling scheme presented in Theorem 2.1.\nTheorem 2.5. Fix any undirected graph G= (V, E)and integer f≥1. There are deterministic\nlabeling functions LV:V→ {0,1}lognandLE:E→ {0,1}O(fϕ−1log2n)such that given any\nquery ⟨s, t, F⟩,F⊂E,|F| ≤f, one can determine whether sandtare connected in G−Fby\ninspecting only LV(s), LV(t),{LE(e)|e∈F}. The construction time is exponential for ϕ= 1/2\nand polynomial for ϕ= Ω(1 /√logn).\nAt a very high level, Theorem 2.5 is proved by adapting Pˇ atra¸ scu and Thorup’s [PT07] cen-\ntralized edge-failure connectivity oracle to the distributed setting. Note that Theorem 2.5 already\nimproves the state-of-the-art polynomial-time computable ˜O(f2)-bit labeling of [IEWM23].\nGiven a function level :E→[h], let{E1, . . . , E h}be the corresponding edge partition, where\nEℓ=level−1(ℓ). Suppose {E1, . . . , E h}induces an ( h, ϕ)-expander hierarchy H. Define T∗to be a\nminimum spanning tree with respect to level, and let Euler (T∗) be its Euler tour, which is a list of\nlength n+ 2(n−1) that includes each vertex once (its first appearance) and each T∗-edge{u, v}\ntwice, as ( u, v) and ( v, u), according to a DFS traversal of T∗, starting from an arbitrary root\nvertex. Each vertex uis identified by its position in Euler (T∗), denoted DFS(u). We call each edge\ninEuler (T∗) an oriented edge. See Fig. 2 for a small example.\nFor each ℓ≤h, letT≤ℓbe the set of level- ℓtrees in the forest T∗∩E≤ℓ. Observe that for each\nT∈ T≤ℓ,Euler (T) is a subsequence of Euler (T∗), not necessarily contiguous. Furthermore, because\nT∗is a minimum spanning tree with respect to level, each connected component Γ of G≤ℓhas a\nunique level- ℓtreeT∈ T≤ℓsuch that Tspans Γ.\nEuler (T∗) =\na,(a, b), b,(b, c), c,(c, b),(b, d), d,(d, e), e,(e, d),\n(d, f), f,(f, d),(d, g), g,(g, d),(d, b),(b, a),\n(a, h), h,(h, i), i,(i, h),(h, j), j,(j, h),(h, a)\n.\nFigure 2: Left: T∗on vertex set {a, b, c, . . . , j }, rooted at a. Right: Euler (T∗).\nDefinition 2.6 (Simple Deterministic Edge Labels) .Forv∈V, the vertex label LV(v) is just\nDFS(v). Each non-tree edge e={u, v} ̸∈E(T∗) has a 2 log n-bit label LE(e) = ( DFS(u),DFS(v)).\nEach tree edge e={u, v} ∈E(T∗) is assigned an O((f/ϕ) log2n)-bit label, generated as follows.\n61. Store ( LV(u), LV(v),level(e)).\n2. For each ℓ∈[level(e), h], let Tℓ∈ T≤ℓbe the tree containing e. Write Euler (Tℓ) as\nEuler (Tℓ) =X·(u, v)·Y·(v, u)·Z.\nFor each W∈ {X, Y, Z },\n(a) Store the labels of the first and last elements of W, and store the labels of the first and\nlast vertices in W(i.e. min u∈WDFS(u) and max v∈WDFS(v)).\n(b) Store the first f/ϕ+ 1 level- ℓnon-tree edges incident to vertices in W. (Each such edge\n{u, v}is encoded by LE({u, v}) = ( DFS(u),DFS(v)).)\nThe Query Algorithm. For each level 1 ≤ℓ≤h, letT≤ℓ,F⊆ T≤ℓcollect all level- ℓtrees Tsuch\nthat Tintersects F. Recall that each connected component Γ of Gℓhas a unique T∈ T≤ℓas its\nspanning tree. We define G≤ℓ,Fto be a subgraph of Gℓthat only collects the connected components\nofG≤ℓwhose spanning tree is in T≤ℓ,F.\nOur goal is to sequentially build vertex partitions P1, . . . ,Ph, where Pℓis a partition of V(G≤ℓ,F)\nthat reflects the connected components of G≤ℓ,F−F. In fact, we will compute, for each T∈ T≤ℓ,F,\na partition Pℓ[T] ofV(Γ) that reflects the connected component of Γ −F(where Γ is the connected\ncomponent of G≤ℓthat has Tas its spanning tree), and then Pℓis simply the union of Pℓ[T] over\nallT∈ T≤ℓ,F. After Phis computed, we can count the number of connected components in G−F,\nor answer s-tconnectivity queries, given LV(s), LV(t).\nEachPℓ[T] has a compact representation as follows. We start with defining intervals . Consider\naT∈ T≤ℓ. We can detect whether Tintersects Fand if so, enumerate T∩F={e1, . . . , e f0}\nusing Item 2a of the Flabels. If we remove the oriented copies of T∩F,Euler (T) breaks into\na set of 2 f0+ 1 intervals J(T, F). Note that from Item 2a, for each interval in J(T, F), we can\nobtain the labels of its first and last elements and its first and last vertices. Towards the compact\nrepresentation of Pℓ[T], we can think of each J∈ J(T, F) as the vertex set J∩V(T). Each part\nP∈ Pℓ[T] is represented by a set of intervals JP⊆ J(T, F) such that P=S\nJ∈JPJ∩V(T).\nFor the purposes of point location , we will write J∈ J(T, F) as [min u∈J∩TDFS(u),max v∈J∩TDFS(v)].\nNote that in general, an interval [ DFS(u),DFS(v)] inJ(T, F) contains (the DFS numbers of) ver-\ntices outside of T. Nonetheless, for vertices in V(T), these intervals allow us to do correct point\nlocation.\nObservation 2.7 (Point Location) .Suppose x∈V(T),T∈ T≤ℓ,F. If [DFS(u),DFS(v)]is the\n(unique) interval in J(T, F)containing DFS(x)then there is a component in T−Fcontaining\nu, x, andv.\nThe query algorithm only does point location on vertices xknown to be in V(T), so Observa-\ntion 2.7 suffices for correctness.\nSuppose Pℓ−1has been computed. For each T∈ T≤ℓintersecting F, we enumerate T∩F=\n{e1, . . . , e f0}and initialize Pℓ[T]← J (T, F) (i.e. each part P∈ P ℓ[T] is only one interval), then\nproceed to unify parts of Pℓ[T] by applying rules R1–R4and the operation Unite T(x, y). The x, y\ninUnite T(x, y) can be vertices in V(T), intervals in J(T, F) or even parts in Pℓ[T], and Unite T(x, y)\nwill unite the parts containing xandyinPℓ[T].\n7R1. IfJ, J′are two intervals of Euler (T) that share a common endpoint, say Jends with ‘ u’ and\nJ′begins with ‘( u, v)’, call Unite T(J, J′).\nR2. For each call to Unite T′(x, y) made in the construction of Pℓ−1[T′],T′⊂T, call Unite T(x, y).\nR3. For each non-tree edge {u, v} ∈Eℓencoded in the labels {LE(ei)|i∈[f0]}, if{u, v} ̸∈F, call\nUnite T(u, v).\nRuleR1is implemented with Item 2a of the F-labels. The enumeration of edges in R3uses\nItem 2b of the F-labels, but to implement Unite T(u, v) we need to locate the intervals in J(T, F)\ncontaining u, v. Since level({u, v}) =ℓ, both u, vare in V(T), and by Observation 2.7 we can locate\nthe intervals containing u, v, given DFS(u),DFS(v).\nAccording to R2, every Unite T′(x, y) performed at level ℓ−1 on some T′⊂Tis re-executed\nverbatim as Unite T(x, y) ifx, yare vertices. Since x, y∈V(T′)⊆V(T), Observation 2.7 lets us\nidentify the intervals in J(T, F) containing x, y. Ifx, ywere intervals from J(T′, F) we can pick\nthe first vertices from xandy, say x′, y′, and call Unite T(x′, y′). Once again, x′, y′∈V(T′)⊆V(T),\nso Observation 2.7 applies.\nAfter executing R1,Pℓ[T] reflects the connected components of T−F. After executing R2,\nPℓ[T] reflects the connected components of ( G≤ℓ−1[V(T)]∪T)−F. If it were the case that R3had\naccess to alllevel- ℓnon-tree edges, then it would be sufficient to find all connected components\nofG≤ℓ[V(T)]−F. However, Item 2b of the F-labels are only guaranteed to reveal up to f/ϕ+ 1\nlevel- ℓnon-tree edges per interval in J(T, F).\nLemma 2.8. IfP1, . . . , P k∈ Pℓ[T]are those parts with Degℓ(Pi)> f/ϕ , thenSk\ni=1Piare contained\nin a single connected component of G≤ℓ−F.\nProof. Suppose the claim is false, that there is some partition of {P1, . . . , P k}intoAandBwhich\nare disconnected. Then\n|E≤ℓ(A, B)|\nmin{Degℓ(A),Degℓ(B)}<f\nf/ϕ=ϕ,\ncontradicting the fact that His an ( h, ϕ)-expander hierarchy.\nIn light of Lemma 2.8, we continue to unify parts according to a fourth rule.\nR4. IfP, P′∈ Pℓ[T] have Degℓ(P),Degℓ(P′)> f/ϕ , call Unite T(P, P′).\nThefullpartition Pℓis obtained by taking the union of all Pℓ[T], for T∈ T≤ℓintersecting F,\nplus the trivial partitions Pℓ[T] ={V(T)}for every T∈ T≤ℓdisjoint from F.\nLemma 2.9 (Correctness) .IfP∈ Pℓ, then Pis a connected component in G≤ℓ−F.\nProof. Rules R1–R3are clearly sound and Lemma 2.8 implies R4is sound. We consider com-\npleteness. If there is a path between u, v∈V(T) inG≤ℓ−1−Fthen by induction on ℓ,uandv\nwill be in the same part of Pℓafter executing R1andR2. Suppose u, vare joined by a path in\nG≤ℓ−F, but u, vare in different parts Pu, Pvconnected by a level- ℓedge e′={u′, v′}. Because\nR3could not be applied, e′is not contained in Item 2b of the F-edges bounding the intervals in\nJ(T, F) containing u′, v′, implying Degℓ(Pu),Degℓ(Pv)> f/ϕ , but then by R4,Pu, Pvwould have\nbeen united.\n8Once we have constructed Ph, a connectivity query ⟨s, t, F⟩works as follows. First, identify the\ntwo intervals in Euler (T∗) of the forest T∗−Fthat contains sandt. This can be done using the pre-\ndecessor search over the endpoints of the intervals in O(min{log log n\nlog log log n,logf\nlog log n}) time [PT06, PT14],\nsince there are O(f) intervals, each represented by O(logn)-bit numbers. Then we check whether\nthe two intervals are in the same part of Ph, corresponding to the same connected component of\nG−F.\n2.3 Second Tool: Code Shares\nTheorem 2.10 gives the distributed coding scheme. We will only invoke it with d= 2.\nTheorem 2.10 (Reed-Solomon Code Shares) .Letm∈Fk\nqbe a message, with q > k . For any\ninteger parameter d≥2, there are O(dlogq)-bitcode shares C1, . . . , C kso that for any index set\nJ⊂[k]with|J| ≥k/d, we can reconstruct mfrom the code shares {Cj|j∈J}in polynomial time.\nProof. One can regard mas the coefficients of a degree-( k−1) polynomial g1overFq, or even as\na degree-( ⌈k/d⌉ −1) polynomial gdoverFqd. The code shares ( Ci)1≤i≤kare defined to be distinct\nevaluations of gd.\nCi= (i, gd(i)).\nGiven the code shares {Ci|i∈J}for|J| ≥k/d, we can reconstruct gdand hence min polynomial\ntime via polynomial interpolation.\n2.4 An ˜O(√f)-Bit Labeling Scheme\nHigh-level Idea. The labeling scheme of Section 2.2 is non-constructive inasmuch as rule R4\ninfers that two P, P′are connected, not by finding a path between them, but by checking if their\nvolumes Degℓ(P),Degℓ(P′)> f/ϕ . In this section, we give a labeling scheme that is even more\nnon-constructive. We can sometimes infer that a part Pwith Degℓ(P)< f/ϕ is nonetheless in\na connected component CofG≤ℓ−Fwith Degℓ(C)> f/ϕ without explicitly knowing an edge\nincident to P.\nA key idea in the construction is to store a large volume of information about an interval of an\nEuler tour as code shares distributed across labels of “nearby” edges. Given a sufficient number of\ncode shares, we will be able to reconstruct the information about the interval.\nNotations. We shall assume without loss of generality that the graph has degree 3. Given any\nG′= (V′, E′) with irregular degrees, we form G= (V, E) by substituting for each v′∈VaDeg(v′)-\ncycle, then attach each edge incident to v′to a distinct vertex in the cycle, hence |V|=|E′|/2. Given\nlabelings LV:V→ {0,1}∗, LE:E→ {0,1}∗, we let LE′(e′) =LE(ϕ(e′)), LV′(v′) =LV(ϕ(v′)),\nwhere ϕ(e′)∈Eis the edge corresponding to e′andϕ(v′)∈Vis any vertex in the Deg(v′)-cycle\nofv′. Correctness is immediate, since F′⊂E′disconnects s, t∈V′iffϕ(F′)⊂Edisconnects\nϕ(s), ϕ(t)∈V.\nRecall T∗is the minimum spanning tree of Gwith respect to the level function. Fix a level ℓ.\nLetT∈ T≤ℓbe a tree spanning a component of G≤ℓ. For each v∈V(T), let\nwtℓ(v) =\n\n1 if vis incident to a level- ℓnon-tree edge,\n0 otherwise ,\n9and for each oriented tree edge ( u, v), let wtℓ(u, v) = 0. If Sis an interval of vertices and oriented\nedges in Euler (T),wtℓ(S) =P\nx∈Swtℓ(x).\nLet [α, β] denote the interval of Euler (T) starting at αand ending at β. Then distℓ(α, β) =\ndistℓ(β, α)def=P\nγ∈[α,β]\\{α,β}wtℓ(γ).3For any vertex/edge element αinEuler (T), the set of all\nvertices within distance ris:\nBallℓ(α, r) ={v∈V(T)|distℓ(α, v)≤r}.\nWe overload the Ball-notation for edges e={u, v}. Here ( u, v),(v, u) refer to the oriented occur-\nrences of ein an Euler tour, if eis a tree edge.\nBallℓ(e, r) =\n\nBallℓ((u, v), r)∪Ballℓ((v, u), r) when e∈E(T) is a tree edge,\nBallℓ(u, r)∪Ballℓ(v, r) when e̸∈E(T) is a non-tree edge.\nHenceforth, the only balls we consider have radius r,\nrdef=⌈p\nf/ϕ⌉.\nAssume, without loss of generality, that wt(Euler (T)) is a power of 2, by padding the end with\ndummy weight-1 elements if necessary. For every j≤jmaxdef=⌈log(f/ϕ)⌉, define Ijto be a partition\nofEuler (T) into consecutive intervals with weight 2j, each the union of two intervals from Ij−1.\nThe Scheme. The key idea of this labeling scheme is to focus on large gap edges . See Fig. 3.\nFigure 3: An interval Ij∈ I jwith wt(Ij) = 2j(j= 3). There are 12 level- ℓedges in\nE(Ij,Ij),{u1, v1}, . . . ,{u12, v12}, ordered by their non- Ijendpoint. The large gap edges of Ij\nare{u1, v1},{u4, v4},{u5, v5},{u7, v7},{u8, v8},{u9, v9},{u12, v12}.\nDefinition 2.11 (Large Gap Edges) .Fix an interval Ij∈ Ijand let Eℓ(Ij) := Eℓ(Ij,Ij) be all\nlevel- ℓedges with exactly one endpoint in Ij. We write Eℓ(Ij) ={{u1, v1},{u2, v2}, . . .}such that,\nfor all i,ui∈Ijandvi∈Ij. Order the edges according to vi, so\nDFS(v1)≤DFS(v2)≤ ··· ≤ DFS(v|Eℓ(Ij)|). (1)\n3We exclude the endpoints of the intervals from the sum just to avoid double counting at the endpoints when we\nsum distances of two adjacent intervals.\n10If, for q∈[1,|Eℓ(Ij)|),vq+1̸∈Ballℓ(vq, r), then {uq, vq},{uq+1, vq+1}are called large gap edges\nw.r.t. ℓandIj. The first and last edges {u1, v1},{u|Eℓ(Ij)|, v|Eℓ(Ij)|}are always large gap edges.\nDefine LGE ℓ(Ij)⊆Eℓ(Ij) to be the set of large gap edges and lgeℓ(Ij) =|LGE ℓ(Ij)|to be their\nnumber.\nRegard LGE ℓ(Ij) as a message mℓ(Ij)∈Flgeℓ(Ij)\nq , where q= poly( n) is large enough to encode\na single edge. We apply Theorem 2.10 with d= 2 to break mℓ(Ij) into code shares so that given\nany set of lgeℓ(Ij)/2 shares we can reconstruct mℓ(Ij). If{u, v} ∈LGE ℓ(Ij) is a large gap edge\nwith u∈Ijandv∈Ij, letCℓ,j(v, u) be the code share of {u, v}w.r.t. ℓandIj. Set Cℓ,j(v, u)def=⊥\nif{u, v}/∈LGE ℓ(Ij) is not a large gap edge. (Note that Cℓ,j(u, v) would be a different code share\nw.r.t. some interval I′\nj∋v.) To simplify notation, for each edge e={u, v}, we define the level- ℓ\ncode share of eas a bundle Cℓ(e) ={Cℓ,j(u, v), Cℓ,j(v, u)|j≤jmax}. Note that Cℓ(e) also indicates\nwhether eis a large gap edge w.r.t. all intervals Ij∋uandI′\nj∋v, for all j≤jmax.\nDefinition 2.12 (Shorter Deterministic Edge Labels) .AnOp\nf/ϕlog(f/ϕ) log2n\n-bit label\nLE(e) for each edge e={u, v}is constructed as follows.\n1. Store ( LV(u), LV(v),level(e)).\n2. For each ℓ∈[level(e), h] and all level- ℓedges e′={u′, v′}incident to Ballℓ(e, r) vertices,\n(a) store ( DFS(u′),DFS(v′)),\n(b) store the level- ℓcode share bundle Cℓ(e′).\n3. If e∈T∗, then for each ℓ∈[level(e), h], let Tℓ∈ T≤ℓbe the tree containing e. Write Euler (Tℓ)\nas\nEuler (Tℓ) =X·(u, v)·Y·(v, u)·Z.\n(a) For each W∈ {X, Y, Z }, store the labels of the first and last elements of W, and store\nthe labels of the first and last vertices in W(i.e. min u∈WDFS(u) and max v∈WDFS(v)).\n(b) For each j≤jmax, letI(1)\nj, I(2)\nj, I(3)\nj, I(4)\nj∈ Ijbe the closest intervals on either side of\n(u, v),(v, u) that do not contain ( u, v) or ( v, u). For each k∈ {1, . . . , 4}, store lgeℓ(I(k)\nj),\nand if lgeℓ(I(k)\nj)≤4r, store LGE ℓ(I(k)\nj).\nThe bit-length of the edge labeling is justified as follows. Item 1 has length O(logn). Since\nCℓ(e) uses O(jmaxlogn) bits by Theorem 2.10, we have that Item 2 has length O(hrjmaxlogn) =\nO(p\nf/ϕlog(f/ϕ) log2n). Item 3 has length h·(O(logn)+rjmaxO(logn)) =O(p\nf/ϕlog(f/ϕ) log2n)\nbits.\nThe Query Algorithm. We initialize Pℓ[T],T∈ T≤ℓ,F, exactly as in the proof of Theorem 2.5,\nand proceed to apply rules R1–R3as-is. Note that we can implement R1using Item 3a and R3\nusing Item 2a. R2is simply re-executing calls to Unite T′from those T′∈ T≤ℓ−1,Fsuch that T′⊂T.\nWe replace rule R4with the similar rule R4’.\nR4’. Suppose that Q ⊆ P ℓ[T] is such that for each P∈ Q,Pmust be in a connected component\nCofGℓ−Fwith Degℓ(C)> f/ϕ . Then, unite all parts of Qwith calls to Unite T.\n11To prove correctness, we recall the definition of J=J(T, F). Let F∩E(T) ={e1, . . . , e f0}be\nthe set of deleted tree edges of T, which we can enumerate using Item 3a of the edge labels. These\nedges break Euler (T) into a set of 2 f0+ 1 intervals denoted by J(T, F). Each part P∈ P ℓ[T]\nconsists of a collection of intervals from J(T, F). Our goal is to prove the following.\nLemma 2.13. For each interval J∈ J, we can either (i) list all other intervals J′∈ J adjacent\ntoJ, or (ii) infer that Jis in a connected component CofG≤ℓ−Fwith Degℓ(C)> f/ϕ .\nThe above lemma implies correctness of the algorithm as we can keep applying R3andR4’to\nobtain the correct Pℓ[T] at the end.\nConsider an interval J∈ J. Let the F-edges bounding Jbeα0, α1. Observe that we can\npartition Jinto less than 2( jmax+ 1) intervals from I0∪ ··· ∪ I jmax. We consider each of these\nintervals Ij∈ I jindividually. Below, we say that Freveals e′ife′is incident to a vertex in\nBallℓ(e, r), for some failed edge e∈F. Whenever Freveals e′, Item 2 of the edge labels gives us\nthe position of its endpoints and the code share bundle for e′. The following lemma is crucial.\nFigure 4: Illustration of Lemma 2.14. An interval Ij⊆Jis incident to J′.J, J′∈ J are bounded\nbyα0, α1∈Fandα′\n0, α′\n1∈F, respectively. Either β0is a large gap edge, and stored in either\nLE(α0) orLE(α1), or it is stored in LE(β1), where β1={x, y} ∈F(if it exists), or β1=α′\n0.\nLemma 2.14. Consider an interval Ij⊆J∈ J where Ij∈ Ij. If we have access to the set\nLGE ℓ(Ij)of large gap edges, then we can check if another interval J′∈ J is adjacent to Ij.\nProof. Suppose that J′∈ J is adjacent to Ij. Let β0={u, v} ∈E−Fbe the first level- ℓnon-\ndeleted edge with u∈Ij, v∈J′, when ordered by DFSnumber. We claim that either β0∈LGE ℓ(Ij)\nis a large gap edge or β0is revealed by F. In either case, we learn the endpoints of β0, which\ncertifies that J′is adjacent to Ij.\nLetJ′be bounded by F-edges α′\n0, α′\n1. Consider a level- ℓedge{x, y}that is the predecessor of\nβ0according to Equation (1). In particular, x∈Ijandy /∈Ijhas the largest DFS(y) such that\nDFS(y)≤DFS(v). Suppose β0/∈LGE ℓ(Ij). Then, v∈Ballℓ(y, r) by definition. Now, we claim there\nis aβ1∈Fwhere v∈Ballℓ(β1, r). Hence, β0is revealed by Fwhich would complete the proof.\nThere are just two cases.\n•Ify∈J′, then {x, y} ∈Fsince β0is the first non-deleted edge. We choose β1={x, y} ∈F\nand therefore v∈Ballℓ(β1, r).\n•Ify /∈J′, then distℓ(v, α′\n0)≤distℓ(v, y)≤rand therefore v∈Ballℓ(α′\n0, r). We set β1=α′\n0∈F\nsov∈Ballℓ(β1, r).\n12We are now ready to prove Lemma 2.13.\nProof of Lemma 2.13. There are three cases.\nCase 1: AnIj⊆Jhaslgeℓ(Ij)≤4r. By Item 3b of the label LE(α0) orLE(α1), we can access\nthe whole set LGE ℓ(Ij). So, by Lemma 2.14, we can list all intervals J′∈ Jadjacent to Ij.\nCase 2: AnIj⊆Jhaslgeℓ(Ij)>4r, and Freveals at least ( lgeℓ(Ij))/2 large gap edges in\nLGE ℓ(Ij). Given ( lgeℓ(Ij))/2 code shares, by Theorem 2.10, we can also reconstruct LGE ℓ(Ij). So,\nwe can again list all intervals J′∈ Jadjacent to Ij, by Lemma 2.14.\nCase 3: AnIj⊆Jhaslgeℓ(Ij)>4r, and Freveals at most ( lgeℓ(Ij))/2 large gap edges in\nLGE ℓ(Ij). In this case, we claim that the connected component CinG≤ℓ−Fcontaining Ijhas\nDegℓ(C)> f/ϕ . Observe that for each unrevealed large gap edge {u, v} ∈LGE ℓ(Ij) with u∈Ij, it\nmust be that Ballℓ(v, r)⊆Cbecause there is no failed edge e∈Fwithin distance rfrom v. Each\nBallℓ(v, r) has weight at least 2 r, and the sum of their weights can be at most four times the weight\nof their union. So Degℓ(C)>(2r/4)·(lgeℓ(Ij)/2)>(2r/4)·(4r/2) = r2≥f/ϕas desired.\n3 Deterministic Vertex Fault Connectivity Labels\nThis section is dedicated to proving Theorem 3.1 concerning labels for vertex faults.\nTheorem 3.1 (Improved Deterministic Vertex Labels) .Fix any undirected graph G= (V, E)withn\nvertices and integer f≥1. There are deterministic labeling functions LV:V→ {0,1}O(f4ϕ−1log7n)\nsuch that given any query ⟨s, t, F⟩,F⊂V,|F| ≤f, one can determine whether sandtare\nconnected in G−Fby inspecting only LV(s), LV(t),{LV(v)|v∈F}. The construction time is\nexponential when ϕ= 1and polynomial when ϕ= Ω(1 /√logn). The query time is poly( f,logn).\nTo prove Theorem 3.1, we first describe the underlying hierarchical structure of the algorithm\nin Section 3.2. This structure allows us to prove a divide-and-conquer lemma (Lemma 3.14) that\nis crucial for answering connectivity queries under vertex failures in a bottom-up manner on the\nhierarchy. Based on the divide-and-conquer lemma, in Section 3.3 we then describe how to answer\nconnectivity queries assuming access to primitives that return information about the hierarchy.\nFinally, we describe how to implement these primitives in a distributed manner by providing the\nlabeling scheme in Section 3.4.\n3.1 Overview and Challenges\nWe briefly discuss our approach at a very high level. We would like to highlight the specific\nchallenges that arise when tolerating vertex faults relative to edge faults.\nThe First Challenge. We start with the ideal scenario that the input graph is already a vertex\nexpander. The first challenge is how to obtain a stable connectivity certificate . Recall that in the\nedge fault scenario (also assuming the graph is an edge expander), we can simply take a spanning\ntree as a stable connectivity certificate. The removal of any fedges will only break the spanning\n13tree into f+ 1 subtrees. However, in general there is no upper bound on the number of subtrees\nwhen removing fvertices.\nThis is a natural barrier to handling vertex faults, and several previous works, e.g. [DP20, LS22,\nPPP24], follow the same idea to overcome it. Take a low-degree spanning tree as a stable connectiv-\nity certificate. A vertex expander indeed admits a low-degree spanning tree; this is formally stated\nin Lemma 3.6.\nUsing this idea, one can easily generalize our edge fault connectivity labeling scheme to obtain\naneO(f)-size vertex fault connectivity labeling scheme for vertex expander input graphs. Roughly\nspeaking, let Fbe the vertex faults. From the low-degree spanning tree T, we first obtain an initial\npartition PofG\\Fconsisting of the connected components of T\\F. Then we exploit the nature\nof aϕ-vertex expander G: all sets A∈ Ps.t.|A∪NG(A)|> f/ϕ —call them giant sets —must be\ninside the same connected component of G\\F. On the other hand, for each non-giant set A∈ P,\nits neighbor set NG(A) is of size at most f/ϕand we can obtain NG(A) explicitly by designing\nlabels on the Euler tour of the low-degree spanning tree. Therefore, we first merge all the giant\nsets of Ptogether, and then merge further using NG(A) for each non-giant A∈ P.\nThe Second Challenge. The second challenge arises when the input graph is nota vertex\nexpander. In fact, an input graph Gadmitting a two-level vertex expander hierarchy already\ncaptures this challenge. A graph Gadmits a two-level ϕ-vertex expander hierarchy if there is a\nseparator X⊆V(G) s.t. Xisϕ-expanding in G, and each connected component CofG\\Xis a\nϕ-vertex expander.\nLetFbe the vertex faults. We assume that we are given an initial partition PofV(G)\\F\nthat captures (1) the connectivity of C\\Ffor each connected component CofG\\X, and (2) the\nconnectivity of XinT\\Fcertified by the stable connectivity certificate T. For example, we can\nthink of\nP=PX∪[\ncomponents CofG\\X{components of C\\F},\nwhere PXis some partition of X\\Fwhich is with respect to the connectivity of XinG\\F, but\nmay not fully capture the connectivity of XinG\\F.\nClearly, we are done if we can further merge sets in Pusing edges incident to X, call them\nX-edges . Let us try the same algorithm and see how it breaks. The fact that Xisϕ-expanding in\nGtells us that all sets A∈ Ps.t.|(A∪NG(A))∩X|> f/ϕ (giant sets) must belong to the same\nconnected component of G\\F. Also, for each non-giant set A∈ P,NG(A)∩Xis of size at most\nf/ϕand we can obtain it explicitly with ˜O(f)-bit labels. Again, we first merge giant sets into one\ngiant group , and then for each A∈ P, merge it with each group intersecting NG(A)∩X. Let us\ntry to confirm the correctness of this merging procedure. We use {x, v}to denote an X-edge with\nx∈X.\n1. Any two giant sets A1, A2∈ Pare indeed merged.\n2. Suppose an X-edge{x, v}joins A1, A2∈ Pwith x∈A1, v∈A2, where A2is non-giant. Then\nwe will merge A1andA2because A1intersects NG(A2)∩X.\n3. Suppose an X-edge {x, v}joins A1, A2∈ P with x∈A1, v∈A2, but now A1is non-giant\nandA2is giant. Although A1intersects NG(A2)∩X, we are notguaranteed that A1andA2\nare merged because A2isgiant . In other words, X-edges in case 3 will not be detected by\nthis method.\n14This asymmetry is the major difference between the vertex-fault case and the edge-fault case.\nTo overcome it, the key observation is that if there exists a case-3 X-edge for a non-giant set A1,\ni.e. there exists an X-edge {x, v}such that x∈A1andvis in some giant set, then A1must be\nmerged with the giant group. In other words, for a non-giant A1, instead of knowing all case-3\nX-edges incident to A1, it suffices to check if any such case-3 X-edges exist.\nTherefore, we will count the number of case-3 X-edges for each non-giant set A1. Roughly\nspeaking, this is possible because this number is exactly δall−δnon-giant −δF, where\nδall= number of X-edges {x, v}s.t.x∈A1,\nδnon-giant = number of X-edges {x, v}s.t.x∈A1andvis in some non-giant A2,\nδF= number of X-edges {x, v}s.t.x∈A1andv∈F.\nWe will not elaborate now on how to count these numbers.\n3.2 The Structure\n3.2.1 The Basis: A Vertex Expander Hierarchy\nIn this section, we construct an expander hierarchy for vertex expansion similar to the edge expan-\nsion version from Section 2.1. This will be the basis of our structure.\nFor any graph G= (V, E), a vertex cut ( L, S, R ) is a partition of Vsuch that L, R̸=∅and\nthere is no edge between LandR. For any vertex set X⊆V, we say that Xisϕ-vertex-expanding\ninGif for every vertex cut ( L, S, R ) inG,\n|S| ≥ϕmin{|X∩(L∪S)|,|X∩(R∪S)|}.\nConsider a partition {V1, . . . , V h}ofV. We denote V≤ℓ:=S\ni≤ℓViandV>ℓ:=S\ni>ℓVi. Let G≤ℓbe\nthe graph induced by V≤ℓ.\nDefinition 3.2 (Vertex Expander Hierarchy) .Given a graph G= (V, E), a vertex-partition P=\n{V1, . . . , V h}ofVinduces an ( h, ϕ)-vertex-expander hierarchy if, for every level ℓ≤hand every\nconnected component Γ in G≤ℓ,Vℓ∩Γ isϕ-vertex-expanding in Γ. That is, for every vertex cut\n(L, S, R ) of Γ,\n|S| ≥ϕmin{|Vℓ∩(L∪S)|,|Vℓ∩(R∪S)|}.\nFromP, the connected components Γ in G≤ℓfor all levels ℓform a laminar family C. LetHbe\nthe tree representation of C. We also call ( C,H) an ( h, ϕ)-vertex-expander hierarchy of G.\nThe following theorem is analogous to Theorem 2.3.\nTheorem 3.3. There exists an algorithm that, given a graph G, computes an (h, ϕ)-vertex-expander\nhierarchy with h≤lognandϕ= 1 in exponential time, or h≤lognandϕ≥Ω(1/√logn)in\npolynomial time.\nLong and Saranurak’s [LS22] vertex expander hierarchy is weaker, both qualitatively and struc-\ntually. To be precise, the Long-Saranurak hierarchy only guarantees ϕ≥1/no(1), but it admits\nalmost-linear construction time. Furthermore, the expander components in the Long-Saranurak\nhierarchy may not form a laminar family. The proof of Theorem 3.3 follows immediately from the\nlemma below.\n15Lemma 3.4. There exists an exponential-time algorithm that, given a graph G= (V, E), computes\na vertex set Xsuch that every connected component of G\\Xcontains at most n/2vertices and\nXis1-vertex-expanding. In polynomial time, we instead guarantee that XisΩ(1/√logn)-vertex-\nexpanding.\nThe proofs of Theorem 3.3 and Lemma 3.4 follow in exactly the same way as how we proved\nthe analogous results in the edge version. We include them for completeness.\nProof. Initialize X←V. IfXis 1-expanding, we are done. Otherwise, we repeatedly update Xas\nfollows. Since Xis not 1-expanding, there exists a vertex cut ( L, S, R ) where |L| ≤n/2 such that\n|S|<min{|X∩(L∪S)|,|X∩(R∪S)|}. Update X←X\\(X∩L)∪S.\nLetX′denote Xafter the update. Observe that every connected component of G\\X′still\ncontains at most n/2 vertices because |L| ≤n/2. Moreover, |X′|<|X|because, while we added\nat most |S\\X|new vertices to X, we removed |X∩L|>|S\\X|vertices from Xwhere the\ninequality holds because |S∩X|+|S\\X|=|S|<|X∩(L∪S)|=|X∩L|+|S∩X|. Therefore,\nthere are at most |V|iterations before Xis 1-vertex-expanding. This concludes the proof of the\nexponential-time algorithm.\nTo get polynomial time, we instead apply the sparsest cut algorithm by [FHL05] that, given X,\neither guarantees that Xis Ω(1 /√logn)-vertex-expanding or returns a vertex cut ( L, S, R ) where\n|L| ≤n/2 such that |S|<min{|X∩(L∪S)|,|X∩(R∪S)|}.\nProof of Theorem 3.3. Given G, compute the vertex set Xfrom Lemma 3.4 and set Vh←X.\nTo compute Vh−1, Vh−2, . . . , V 1, we recurse on each connected component CofG\\X. We have\nh≤lognbecause each component Chas size |C| ≤n/2.\nNotation in subsequent sections. Let (C,H) be an ( h, ϕ)-vertex-expander hierarchy of G.\nFor each level- ℓcomponent Γ ∈ C, we define γ:=Vℓ∩Γ to be the core of Γ. The following\nObservation 3.5 is straightforward from the definition.\nObservation 3.5. We have the following.\n1. There is no edge connecting two disjoint components in C.\n2. For each component Γ∈ C, its core γisϕ-vertex-expanding in Γ.\n3. The cores {γ|Γ∈ C} partition V(G).\nBy convention, the core of a Γ decorated with subscripts, superscripts, and diacritic marks\ninherits those decorations, e.g., ˆ γj\niis the core of ˆΓj\ni. For two components Γ ,Γ′s.t. Γ′⪯Γ (resp.\nΓ′≺Γ), we also write γ′⪯γ(resp. γ′≺γ). For each component Γ, N(Γ) denotes the set of\nneighbors of Γ in V−Γ. Define Nˆγ(Γ) = N(Γ)∩ˆγ, which is only non-empty when γ≺ˆγ. We\ncall such Nˆγ(Γ)neighbor sets . For each vertex v∈V(G), we use γvto denote the unique core\ncontaining v, so Γ vdenotes the corresponding component of γv.\n3.2.2 The Initial Structure: Low-Degree Steiner Trees and Shortcut Graphs\nBased on the vertex expander hierarchy, we construct low-degree Steiner trees and shortcut graphs,\nboth of which will help answer connectivity queries.\n16Low-Degree Steiner Trees. For each component Γ ∈ C, using Lemma 3.6, we will compute a\nSteiner tree Tγwith maximum degree ∆ = O(1/ϕ) that spans the core γinG[Γ]. Sometimes, we\nwill call the vertices in Steiner tree Tγnodes , just to be consistent with the terminology of extended\nSteiner trees introduced later. In particular, each node u∈γ⊆V(Tγ) is a terminal node , and the\nother nodes V(Tγ)\\γareSteiner nodes . Observe that each vertex in Γ will correspond to at most\none node in Tγ, and vertices in γare in one-to-one correspondence with terminal nodes in Tγ.\nA hierarchy with such low-degree Steiner trees but without the vertex-expanding property was\nfirst introduced by Duan and Pettie [DP20] as the low-degree hierarchy , which has been shown\nto be useful for the vertex-failure connectivity problem in both the centralized [DP20, LS22] and\nlabeling scheme [PPP24] settings. Roughly speaking, these Steiner trees are useful because they\nserve as connectivity certificates. By the low-degree property, when fvertices fail, each Steiner tree\nwill be broken into at most O(f/ϕ) subtrees, each of them still being connected in the new graph.\nThe query algorithm need only look for edges that reconnect the subtrees rather than determine\nconnectivity from scratch.\nLong and Saranurak [LS22] gave an almost linear time algorithm to compute an O(logn/ϕ)-\ndegree Steiner tree spanning a ϕ-vertex expanding set AinG. We give an improved algorithm that\ncomputes an O(1/ϕ)-degree Steiner trees based on F¨ urer and Raghavachari [FR94], albeit with a\nslower running time. This improvement to the degree will shave logarithmic factors off our final\nlabel size. The algorithm below can be of independent interest. Its proof is deferred to Appendix A.\nLemma 3.6 (Low-degree Steiner Trees) .Given a graph Gsuch that a set A⊆V(G)isϕ-vertex-\nexpanding in G, there is an algorithm that computes an O(1/ϕ)-degree Steiner tree that spans Ain\nG. The running time is O(mnlogn).\nThe Neighborhood Hitter S.We want the Steiner trees to have low degree ∆ so that fvertex\nfailures generate at most f∆ subtrees. This argument only requires that failed vertices have low\ndegree. Following [PPP24], we generate a partition S= (S1, . . . , S f+1) of the vertex set, and build\na version of the data structure for each Si∈ S, which one can think of as vertices that are not\nallowed to fail. By the pigeonhole principle, for any failure set Fthere exists an S=Sisuch that\nS∩F=∅. Thus, it is fine if, in the data structure with failure-free set S, all S-vertices have\nunbounded degrees.\nThe main benefit of having a failure-free Sis to effectively reduce neighborhood sizes, as follows.\nIf we were to generate the partition Srandomly, then with high probability either (i) Nˆγ(Γ)∩S̸=∅\nor (ii) |Nˆγ(Γ)| ≤λnbdef=O(flogn). In case (i) we can link TˆγandTγwithout increasing the degrees\nof non- Svertices by much (see extended cores below), and in case (ii) we have a good upper bound\non|Nˆγ(Γ)|. In fact, it is possible to achieve this guarantee deterministically using the method of\nconditional expectations [PPP24]. Concretely, we just compute Sby invoking Lemma 3.7 with all\nsuch neighbor sets Nˆγ(Γ) as the inputs.\nLemma 3.7 ([PPP24, Lemma 8.1]) .Given a graph Gwith a polynomial number of vertex sets\n{Bk⊆V|1≤k≤poly( n)}, there is a deterministic algorithm that computes a partition S=\n{S1, ..., S f+1}ofV(G)s.t. for each SiandBk, either Si∩Bk̸=∅or|Bk| ≤O(flogn). The running\ntime is polynomial.\nHenceforth we use Sto refer to an arbitrary part of the partition S. In the preprocessing phase\nwe generate a data structure for each S∈ S, but in the context of a query ⟨s, t, F⟩,Srefers to any\npart for which S∩F=∅.\n17Extended Cores and Extended Steiner Trees. Each component Γ ∈ Chas an extended core\nγextdefined as follows:\nγextdef=γ∪[\nγ′≺γ\ns.t.Nγ(Γ′)∩S̸=∅γ′.\nObserve that if γ′⊈γext, then |Nγ(Γ′)| ≤λnb=O(flogn). Whenever Nˆγ(Γ)∩S̸=∅is non-empty,\nletsˆγ(Γ)∈Nˆγ(Γ)∩Sbe an arbitrary representative in its neighborhood set.\nJust as each core γhas a Steiner tree Tγ, the extended core γexthas an extended Steiner tree\nTγext. Each tree node in V(Tγext) is either a terminal node orSteiner node . As we will see in the\nconstruction, the terminal nodes are one-one corresponding to vertices in γext. Each Steiner node\ncorresponds to exactly one vertex in Γ, while each vertex in Γ can correspond to arbitrary numbers\nof Steiner node in V(Tγext).\nConstruction of Tγext.The construction of Tγextis as follows.\n1. First, we make a copy of Tγ, and for each strict descendant γ′⊆γext, make a copy of Tγ′.\n2. Let Pγ′→γbe a copy of an arbitrary simple path in the graph G[Γ′∪{sγ(Γ′)}] connecting the\nvertex sγ(Γ′)∈γ(which corresponds to the terminal node sγ(Γ′)∈V(Tγ)) to some vertex\nv′∈Γ′such that v′corresponds to some tree node in V(Tγ′).\n3. Finally, we obtain Tγextby attaching the copy of Tγ′(for all strict descendants γ′⊆γext)\nto the copy of Tγusing the path Pγ′→γ. That is, we glue the endpoint sγ(Γ′) ofPγ′→γto\nthe terminal node sγ(Γ′)∈V(Tγ), and glue the other endpoint v′ofPγ′→γto the tree node\nv′∈V(Tγ′).\nBy the construction, V(Tγext) is made up of V(Tγ),V(Tγ′) of each strict descendant γ′⊆γext,\nand the internal nodes of each path Pγ′→γ. We define the terminal nodes in V(Tγext) to be\n•the terminal nodes in V(Tγ) (they one-one correspond to vertices in γ), and\n•the terminal nodes in V(Tγ′) for each strict descendant γ′⊆γext(they one-one correspond\nto vertices in γ′).\nOther tree nodes in V(Tγext) are Steiner nodes. By definition, the terminal nodes in V(Tγext)\none-one correspond to vertices in γext.\nProperties of Tγext.First, Tγexthas some kind of low degree guarantee of non- Svertices, as shown\nin Lemma 3.8.\nLemma 3.8. For each vertex v∈Γ\\S, the tree nodes corresponding to vhave total Tγext-degree\nat most O(h∆).\nProof. Recall that V(Tγext) is made up of V(Tγ),V(Tγ′) of each strict descendant γ′⊆γext, and\nthe internal nodes of each path Pγ′→γ.\n•vcan correspond to at most one tree node in V(Tγ). This tree node have degree at most ∆\ninTγextbecause it is not an endpoint of any path Pγ′→γ(since v /∈S).\n18•For each strict descendant γ′⊆γext, ifv∈Γ′,vcan correspond to at most one tree node in\nV(Tγ′) (note that if v /∈Γ′,vmust correspond to no tree node in V(Tγ′) since V(Tγ′)⊆Γ′).\nThis tree node have Tγext-degree at most ∆ + 1 because it has degree at most ∆ in Tγ′and\nit has degree 1 in Pγ′→γif it is an endpoint of Pγ′→γ.\nThe number of such γ′is at most hsince the number of components containing vis at most\nh. Therefore, this part contributes at most h(∆ + 1).\n•For each path Pγ′→γ, ifv∈Γ′,vcan correspond to at most one internal node of Pγ′→γ(note\nthat if v /∈Γ′,vwill correspond to no internal node of Pγ′→γsince all internal nodes are in\nΓ′). This node has Tγext-degree 2.\nAgain the number of such path Pγ′→γis at most h, and this part contributes at most 2 h.\nThe second property is the simple Observation 3.9. We will exploit it in the proof of Lemma 3.13\nand Section 3.3.\nObservation 3.9. For each γ′≺γsuch that γ′⊆γext, its Steiner tree Tγ′, or even Tγ′∪Pγ′→γ,\nis a subtree of Tγext, where Tγ′∪Pγ′→γdenote the tree obtained by gluing the endpoint v′ofPγ′→γ\nto the tree node v′∈V(Tγ′).\nLemma 3.8 shows that when fvertices fail, they break Tγextinto at most O(fh∆) = O(flogn/ϕ)\nsubtrees, since S-vertices are not allowed to fail. The analogue of Lemma 3.8 in [PPP24] creates\nextended Steiner trees with degree ∆ + hrather than O(h∆), but might not satisfy the property\nthatTγ′is a subtree of Tγext, which is used in our labeling scheme.\nThe Shortcut Graphs. Theglobal shortcut graph ˆGis also defined w.r.t. an arbitrary S∈ S. It\nis formed by adding shortcut edges toG, each with an assigned type.4For each component Γ ∈ C\nand each strict ancestor ˆΓ of Γ, we define\nˆNˆγ(Γ) =\n\nNˆγ(Γ) if Nˆγ(Γ) is disjoint from S,\n{sˆγ(Γ)}ifNˆγ(Γ) intersects S.\nˆN(Γ) =[\nˆγˆNˆγ(Γ).\nˆGis atyped multigraph with the same vertex set as Gand\nE(ˆG) =E(G)∪[\nΓClique (ˆN(Γ)),\nwhere all edges in E(G) have type original and all edges in the clique Clique (ˆN(Γ)) have type γ.\nThe shortcut graph w.r.t. Γ∈ C, denoted by ˆGΓis the subgraph of ˆGinduced by edges with\nboth endpoints in Γ and at least one in the core γ.\n4Previous papers call a shortcut edge an artificial edge and call a shortcut graph an auxiliary graph. We change\nthe names to make them more descriptive.\n19The idea of adding shortcut edges has appeared in prior works [DP20, LS22, PPP24, CPR11]\non the vertex-failure connectivity problem. Intuitively, the simplest way to add shortcut edges is\nto add a clique on N(Γ) for each component Γ. With the shortcut edges, when failed vertices\ncome, if some component Γ is unaffected (it has no failed vertices) the query algorithm can ignore\nvertices in Γ, and use the shortcut edges to capture the connectivity provided by Γ. However,\ngenerally the performance of the algorithm depends on the sparsity of the shortcut edges, so this\nnaive construction will not give good algorithms. Indeed, most prior work [DP20, LS22, PPP24]\nintroduced different sparsification techniques on shortcut edges. In our work, we sparsify the\nshortcut edges by adding a clique on the sparsified neighbor set ˆN(Γ) instead of the original one\nN(Γ).\n3.2.3 Structures Affected by Queries\nIn this subsection, we will define notations and terms related to a particular query ⟨s, t, F⟩, and\nthen introduce the query strategy from a high level. Recall that S∈ Srepresents any part of the\npartition disjoint from F.\nAffected Components/Cores, Affected Edges, and Query Graphs. We introduce the\nfollowing notations and terms.\n•For each component Γ ∈ C, if Γ intersects F∪ {s, t}, we say Γ is an affected component and\nγis an affected core , otherwise they are unaffected .\n•For each edge e={u, v} ∈E(ˆGΓ) in the shortcut graph w.r.t. Γ, it is an affected edge if the\ntype of eisγ′for some affected γ′. Let ˆEΓ,aff⊆E(ˆGΓ) collect all affected edges in ˆGΓ, and\nletˆEΓ,unaff=E(ˆGΓ)\\ˆEΓ,affbe the set of unaffected edges.\n•For each affected component Γ, its query set isQΓ=γ∪S\naffected γ′≺γγ′and its extended\nquery set isQext\nΓ=γext∪S\naffected γ′≺γγ′.\n•We define the query graph ˆGqry\nΓof Γ to be ˆGqry\nΓ=ˆGΓ[Qext\nΓ]\\ˆEΓ,aff. Namely, the query graph\nˆGqry\nΓis the subgraph of ˆGΓinduced by the extended query set Qext\nΓ, excluding all affected\nedges.\nObservation 3.10. The number of affected components is at most h(f+ 2).\n3.2.4 A Divide-and-Conquer Lemma\nNext, we state the key lemma, Lemma 3.11, saying the connectivity after failures can be captured\nby the structure we defined in previous sections. Roughly, for any affected component Γ, the\nconnectivity between vertices can be captured by either (1) shortcut edges in Γ, (2) extended Steiner\ntrees Tγext, or (3) the recursive structure on affected children of Γ. Naturally, this equivalence hints\nat a divide-and-conquer strategy by querying bottom-up from the hierarchy. We will formally\ndescribe this strategy in Section 3.3.\nBefore stating Lemma 3.11, we introduce some notations. For an undirected graph Hand a\nsubset of vertices A⊆V(H), we define Conn (A, H) to be an undirected graph on vertices As.t. an\nedge ( u, v) exists in Conn (A, H) if and only if uandvare connected in H. We note that when H\n20refers to an extended Steiner tree and A⊆V(G) refers to a set of original vertices, this notation\nConn (A, H) is still well-defined as long as each vertex in Acorresponds to exactly one terminal\nnode in H. For an extended Steiner tree Tγext, we use Tγext\\Fto denote the forest by removing\nall nodes corresponding to vertices in F.\nLemma 3.11. LetΓ∈ C be an affected component. Each pair of vertices x, y∈QΓ\\Fare\nconnected in G[Γ]\\Fif and only if they are connected in the union of\n1.Conn (Qext\nΓ\\F,ˆGqry\nΓ\\F),\n2.Conn (γext\\F, T γext\\F), and\n3.S\nΓchildConn (QΓchild\\F, G[Γchild]\\F), where the union is over all affected children Γchildof\nΓ.\nProof. It is relatively simple to see that x, yare connected in GΓ\\Fif they are connected in the\nunion, because each of ˆGqry\nΓ\\F,Tγext\\FandG[Γchild]\\Fonly use valid connectivity in G[Γ]\\F.\nTo be precise, for the graph ˆGqry\nΓ\\F, consider an edge e={u, v}in it.\n•Ifehas type original then ealso exists in G[Γ]\\F.\n•Otherwise, eis a shortcut edge with some type γ′such that γ′is unaffected. By definition,\nu, v∈N(Γ′) and Γ′is disjoint from F, hence u, vare connected in G[Γ]\\F.\nSimilarly, Tγext\\Fis a subgraph of G[Γ]\\FandG[Γchild]\\Fis obviously a subgraph of G[Γ]\\F.\nFrom now we focus on proving the other direction. Let Pxybe a simple path connecting xand\nyinG[Γ]\\F. We can write PxyasPxy=P1◦P2◦ ··· ◦ Pℓwhere the endpoints ui, viofPiare the\nQΓ-vertices and each subpath Piare internally disjoint with QΓ. It suffices to show that for each\nsubpath Pi,uiandviare connected in the union.\nCase (a) . Suppose γui, γvi≺γ(recall that γui, γviare the cores containing ui, virespectively).\nThen there is a child Γ childof Γ s.t. γui, γvi⪯γchildand all vertices in Piare inside Γ child\\F. To see\nthis, assume for contradiction that Picontains two vertices from two different children Γ child,Γ′\nchild\nof Γ. However, by property 1 of the hierarchy, Pimust go through some vertex in γunder this\nassumption, contradicting that Piis internally disjoint from QΓ. Furthermore, we know γchildis\naffected because γuiandγviare affected (since γui, γvi⊆QΓandQΓonly collects affected cores).\nAlso, note that ui, vi∈QΓchild\\Fbecause QΓ∩Γchild=QΓchild. Putting it all together, we know\nuiandviare connected in Conn (QΓchild\\F, G[Γchild]\\F) (i.e. Part 3) by the existence of Pi.\nIn what follows, we will argue that arbitrary two vertices u, v∈QΓ\\Fare connected in the\nunion, if they satisfy\n(i)u∈γorv∈γ, and\n(ii) there is an original edge e={u, v} ∈E(G[Γ]) or there is an unaffected component Γ′≺Γ s.t.\nu, v∈N(Γ′).\nIndeed, for each above subpath Pinot in Case (a), its endpoints uiandvimust satisfy the conditions\n(i) and (ii). Condition (i) is easy to see. For condition (ii), if Pihas only one edge, that this edge\ne={ui, vi}is an original edge in G[Γ]. If Pihas more than one edge, all internal vertices of Pifall\n21in unaffected cores, because Piis internally disjoint from QΓ. Again by property 1 of the hierarchy,\nthere exists an unaffected component Γ′containing all internal vertices of Pi, soui, vi∈N(Γ′).\nCase (b). Suppose condition (ii) tells there is an original edge e={u, v} ∈E(G[Γ]). Then this\nedge is added to ˆGΓbecause u', 'raytos.r.bsinfotech@gmail.com', 'Yaowei Long, Seth Pettie, Thatchaphol Saranurak', '', '../pdf_files/671b4b83d0134-Connectivity Labeling Schemes for Edge and Vertex Faults via Expander Hierarchies.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(132, '5483354843', '1', 1, 1, 'Packing Short Cycles', '2024-10-25', '2024', 'Cycle packing is a fundamental problem in optimization, graph theory, and algorithms. Motivated by recent advancements in finding vertex-disjoint paths between a specified set of vertices that either minimize the total length of the paths [Bj¨ orklund, Husfeldt, ICALP 2014; Mari, Mukherjee, Pilipczuk, and Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021], we consider the following cycle packing problems: Min-Sum Cycle Packing and Shortest Cycle Packing. \r\nIn Min-Sum Cycle Packing, we try to find, in a weighted undirected graph, k vertex-disjoint cycles of minimum total weight. Our first main result is an algorithm that, for any fixed k, solves the problem in polynomial time. We complement this result by establishing the W[1]-hardness of Min-Sum Cycle Packing parameterized by k. The same results hold for the version of the problem where the task is to find k edge disjoint cycles. \r\nOur second main result concerns Shortest Cycle Packing, which is a special case of Min-Sum Cycle Packing that asks to find a packing of k shortest cycles in a graph. We prove this problem to be fixed-parameter tractable (FPT) when parameterized by k on weighted planar graphs. We also obtain a polynomial kernel for the edge-disjoint variant of the problem on planar graphs. Deciding whether Min-Sum Cycle Packing is FPT on planar graphs and whether Shortest Cycle Packing is FPT on general graphs remain challenging open questions.', 'Data Structures and Algorithms', 'Packing Short Cycles\nMatthias Bentert1, Fedor V. Fomin1, Petr A. Golovach1, Tuukka Korhonen2, William\nLochet3, Fahad Panolan4, M. S. Ramanujan5, Saket Saurabh6, and Kirill Simonov7\n1University of Bergen, Norway\n2University of Copenhagen, Denmark\n3CNRS, LIRMM, Universit´ e de Montpellier, France\n4School of Computer Science, University of Leeds, UK\n5University of Warwick, UK\n6Institute of Mathematical Sciences, HBNI, India\n7Hasso Plattner Institute, University of Potsdam, Germany\nAbstract\nCycle packing is a fundamental problem in optimization, graph theory, and algorithms. Motivated\nby recent advancements in finding vertex-disjoint paths between a specified set of vertices that\neither minimize the total length of the paths [Bj¨ orklund, Husfeldt, ICALP 2014; Mari, Mukherjee,\nPilipczuk, and Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021],\nwe consider the following cycle packing problems: Min-Sum Cycle Packing andShortest Cycle\nPacking .\nInMin-Sum Cycle Packing , we try to find, in a weighted undirected graph, kvertex-disjoint\ncycles of minimum total weight. Our first main result is an algorithm that, for any fixed k, solves\nthe problem in polynomial time. We complement this result by establishing the W[1]-hardness of\nMin-Sum Cycle Packing parameterized by k. The same results hold for the version of the problem\nwhere the task is to find kedge disjoint cycles.\nOur second main result concerns Shortest Cycle Packing , which is a special case of Min-Sum\nCycle Packing that asks to find a packing of kshortest cycles in a graph. We prove this problem\nto be fixed-parameter tractable (FPT) when parameterized by kon weighted planar graphs. We also\nobtain a polynomial kernel for the edge-disjoint variant of the problem on planar graphs. Deciding\nwhether Min-Sum Cycle Packing is FPT on planar graphs and whether Shortest Cycle Packing\nis FPT on general graphs remain challenging open questions.\nEmail addresses: matthias.bentert@uib.no, fedor.fomin@uib.no, petr.golovach@uib.no, tuko@di.ku.dk,\nwilliam.lochet@gmail.com, f.panolan@leeds.ac.uk, r.maadapuzhi-sridharan@warwick.ac.uk, saket@imsc.res.in,\nkirillsimonov@gmail.com\n1arXiv:2410.18878v1  [cs.DS]  24 Oct 20241 Introduction\nWe consider the following problem.\nInput: A graph Gwith a weight function w:E(G)→Z>0, an integer k≥1, and\nℓ∈Z≥0.\nTask: Decide whether there is a family (packing) of k(vertex-)disjoint cycles whose\ntotal length is at most ℓ.Min-Sum Cycle Packing\nWe also consider the variant of the problem, called Min-Sum Edge-Disjoint Cycle Packing , where\nthe task is to find a packing of edge-disjoint cycles of total length at most ℓ.\nMin-Sum Cycle Packing could be considered a “relaxation” of the notoriously difficult Min-Sum\nDisjoint Paths . Let us remind that in the Min-Sum Disjoint Paths problem, we are given a graph\nwith a set of terminal pairs ( s1, t1), . . . , (sk, tk). The task is either to connect all terminal pairs ( si, ti) by\npairwise vertex-disjoint paths of minimum total length or to decide that there is no set of pairwise disjoint\npaths. Of course, the existence of a polynomial-time algorithm solving Min-Sum Disjoint Paths for\nfixed kwould imply a polynomial-time algorithm solving Min-Sum Cycle Packing . Unfortunately,\nno such algorithm is known. Bj¨ orklund and Husfeldt [4] give an algorithm with running time O(n11) for\nfinding two disjoint si-ti-paths of minimal total length in an n-vertex graph. For k >2, the complexity of\nthe problem is a long-standing open problem. Whether the problem is polynomial-time solvable for k= 3\nremains open even on planar graphs. The main reason for our interest in Min-Sum Cycle Packing\nwas the lack of any progress on the complexity of Min-Sum Disjoint Paths .\nOur first theorem establishes the membership of Min-Sum Cycle Packing andMin-Sum Edge-\nDisjoint Cycle Packing in complexity class XP when parameterized by k. More precisely, we show\nthe following.\nTheorem 1. Min-Sum Cycle Packing andMin-Sum Edge-Disjoint Cycle Packing can be solved\ninnO(k6)time, where nis the number of vertices in the graph.\nFurther, we show that Theorem 1 can be generalized for the variant of the problem with individual\nconstraints on the length of the cycles in a packing. Formally, in Min-Vector Cycle Packing , we are\ngiven a graph G, a positive integer k, and kpositive integers ℓ1, . . . , ℓ k. Then the task is to find k(vertex)\ndisjoint cycles C1, . . . , C kso that the length of Ciis upper-bounded by ℓifor each i∈ {1, . . . , k }. We\nprove that Min-Vector Cycle Packing and the variant where we want the cycles to be edge-disjoint,\ncalled Edge-Disjoint Min-Vector Cycle Packing , can also be solved in nO(k6)time.\nWe complement Theorem 1 by a computational lower bound, showing that the existence of an FPT\nalgorithm for Min-Sum Cycle Packing is unlikely.\nTheorem 2. Min-Sum Cycle Packing isW[1] -hard in subcubic graphs with unit edge weights when\nparameterized by k.\nBecause the lower bound is obtained for subcubic graphs, the result also holds for Min-Sum Edge-\nDisjoint Cycle Packing .\nA special but still fascinating case of Min-Sum Disjoint Paths is the Disjoint Shortest Paths\nproblem. Here, we want to connect terminal pairs by vertex-disjoint shortest paths. Equivalently, this\nis the variant of Min-Sum Disjoint Paths , where we request to connect terminals by disjoint paths\nwhose total length does not exceedP\n1≤i≤kdist(si, ti).\nThe “relaxation” of Disjoint Shortest Paths as a cycle packing is the variant of Min-Sum Cycle\nPacking where all the cycles in the packing should be shortest cycles, that is, ℓ=kgwhere gis the\ngirth of G. (Let us remember that the girth of a weighted graph is the minimum length of its cycles.)\nInput: A graph Gwith a weight function w:E(G)→Z>0and an integer k≥1.\nTask: Decide whether there is a family (packing) of kvertex-disjoint cycles, each of\nminimum length.Shortest Cycle Packing\nFor example, if all edges of Gare of weight one and the girth of Gis three, then Shortest Cycle\nPacking becomes the Triangle Packing problem.\nBy Theorem 1, Shortest Cycle Packing is solvable in polynomial time for a fixed number k\nof cycles. We do not know whether it is W[1]-hard or FPT parameterized by k. Our next theorem\nestablishes the fixed-parameter tractability of Shortest Cycle Packing on planar graphs.\n2Theorem 3. Shortest Cycle Packing is solvable in time kO(k)·nO(1)on planar graphs with n\nvertices.\nWe do not know whether Shortest Cycle Packing admits a polynomial kernel on planar graphs.\nHowever, the methods developed for the proof of Theorem 3 allow establishing a polynomial kernel for\ntheEdge-Disjoint Shortest Cycle Packing problem, the version of Shortest Cycle Packing\nwhere the cycles should be edge-disjoint.\nTheorem 4. Edge-Disjoint Shortest Cycle Packing on planar graphs admits a polynomial kernel\nsuch that the output graph has O(k2)vertices.\nThe kernelization algorithm also implies that Edge-Disjoint Shortest Cycle Packing can be\nsolved in kO(k)·nO(1)time on planar graphs.\nDue to duality in planar graphs, Edge-Disjoint Shortest Cycle Packing in planar graphs\nis equivalent to finding kdisjoint minimum edge cuts; here we assume that two edge cuts ( X1, Y1)\nand ( X2, Y2) are assumed to be disjoint if E(X1, Y1)∩E(X2, Y2) =∅. Here, for each i∈[2], (Xi, Yi)\npartitions the vertex set and E(Xi, Yi) denotes the set of edges with exactly one endpoint in Xi. Thus,\nTheorem 4 implies the existence of a polynomial kernel for the problem of packing edge-disjoint minimum\ncuts. We observe that this problem parameterized by kon general graphs is W[1]-hard even when\nrestricted to graphs with unit edge weights.\nRemarks on impact of the weight function. Our algorithm in Theorem 1 is strongly polynomial for\neach k. This rules out standard modifications used for converting weighted problems to the unweighted\ncase, for instance, by subdividing edges according to their weight which could be exponential in the\ngraph size. In fact, we do not use the fact that the weights are integers and this result can easily be\ngeneralized to positive rationals (or even positive reals assuming the real RAM model). The same holds\nfor Theorem 3.\n1.1 Overview of the methods\nHere, we give a high-level overview over how we achieve the different results.\n1.1.1 Min-Sum Cycle Packing\nThe algorithms for Min-Sum Cycle Packing ,Min-Sum Edge-Disjoint Cycle Packing ,Min-\nVector Cycle Packing , and Edge-Disjoint Min-Vector Cycle Packing are based on a com-\nbinatorial result about the number of paths in graphs that are no-instances for the Min-Sum Cycle\nPacking problem. In particular, we prove that if an edge-weighted graph Gdoes not contain a collec-\ntion of kpairwise vertex-disjoint cycles of total length at most ℓ, then the number of paths of length\nat most ℓinGis at most nO(k5)(Lemma 3.6). Given this lemma, obtaining nO(k6)-time algorithms for\nthese problems is quite simple as shown in the next paragraph.\nIn the case of Min-Sum Cycle Packing , we start enumerating paths of length at most ℓ, and if\nthere are more than nΩ(k5)of them, then we know that it is a yes-instances. Otherwise, from the set of\nall paths of length at most ℓ, we obtain the set of all cycles of length at most ℓand then enumerate all\ncollections of kof them in time nO(k6). To generalize this to Min-Vector Cycle Packing , we assume\nthatℓ1is the smallest of the length bounds, apply the same enumeration strategy with the parameters ℓ1\nandk, and then branch on the nO(k5)enumerated cycles, to again obtain the nO(k6)running time. These\nalgorithms generalize to the edge-disjoint case simply by applying the same combinatorial result about\nvertex-disjoint cycles, but inserting the additional check when branching that the cycles we choose are\nedge-disjoint.\nThus, the main technical ingredient of the proof of Theorem 1 is the proof of this combinatorial result\n(Lemma 3.6). Let us sketch the ideas here. First, consider the case of k= 1. If Gdoes not contain a cycle\nof length at most ℓ, then the number of paths of length at most ℓ/2 inGis at most\0n\n2\n, because having\ntwo distinct paths of length at most ℓ/2 between the same pair of vertices would imply the existence\nof a cycle of length at most ℓ. Then, we observe that for any integer c≥1 and length-bound ℓ0, ifG\ncontains at most Npaths of length at most ℓ0, then Gcontains at most Ncpaths of length c·ℓ0, and\ntherefore conclude that Gcontains at most O(n4) paths of length at most ℓ.\nLet us now extend the above argument to the general case of k >1. First, let ˜Cbe a subgraph of G\ncomprising a maximal collection of pairwise vertex-disjoint cycles each of length at most ℓ/k. By our\nassumption, ˜Cconsists of at most k−1 cycles, and the graph G−V(˜C) does not contain a cycle of length\nat most ℓ/k. Let us then consider a path Pof length at most ℓinG. By considering how the path P\n3Root\nC3 C4 C5C1 C2\nC1 C2\nC3 C4 C5\nFigure 1: A solution C={C1, . . . , C 5}and the tree representing C.\nintersects with ˜C, we divide it into segments of two types: maximal subpaths of Pthat are internally\nvertex-disjoint with V(˜C), and maximal subpaths of Pthat are contained in ˜C.\nWe next argue that if the number of such segments is more than Ω( k4), then we can in fact construct\na family of kvertex-disjoint cycles of total length at most ℓ, contradicting the premise of the lemma. In\norder to do so, we show that if there is a cycle Cin˜Csuch that P“enters and exits” Cmore than Ω( k3)\ntimes, then we can find the claimed collection of kvertex-disjoint cycles in P∪C. The proof of this\nproceeds by “cleaning up” the interactions of PandCinto one of three cases with the help of the\nErd¨ os-Szekeres theorem, and then demonstrating a simple construction in each of the cases.\nAfter proving that Pdecomposes into O(k4) segments that are either internally vertex-disjoint with ˜C\nor contained in ˜C, it remains to show that there are only nO(k)possible choices for each segment and\nsince Pwas chosen arbitrarily, this would in turn allow us to bound the number of possibilities for P.\nFor subpaths internally vertex-disjoint with ˜Cwe use the property that V(G)−V(˜C) does not contain\na cycle of length at most ℓ/k, implying that G−V(˜C) contains at most nO(k)paths of length at most ℓ.\nFor subpaths contained in ˜C, it is simple to observe that there are at most O(n2) possible choices for\nthem, as each path in ˜Cis defined by the choice of two vertices and the choice of a side to travel inside\na cycle. This concludes the informal overview of the proof of Theorem 1.\n1.1.2 Cycle packing on planar graphs\nThe proof of Theorem 3 is based on constructing a laminar family of disjoint cycles representing all\nshortest cycles and decomposing this family into a tree. We use random separation on such trees to\n“filter out” the most “promising” parts and combine branching arguments with an FPT algorithm for\ncomputing Independent Set in map graphs. In more detail:\nLetGbe a weighted planar graph Gof (weighted) girth g. Without loss of generality, we can assume\nthat each vertex and edge of Gis included in a shortest cycle. Otherwise, we can preprocess the graph in\npolynomial time and delete vertices and edges that do not appear in a shortest cycle. Consider a plane\nembedding of G. Packing facial cycles of Gis equivalent to computing an Independent Set in a map\ngraph. Let us recall that a map graph is the intersection graph of connected and internally disjoint regions\nof the Euclidean plane [10]. Indeed, facial cycles of Gare vertex-disjoint if and only if the corresponding\nvertices in the map graph induced by Gare not adjacent. For computing an Independent Set in a\nmap graph, Chen [9] gave an EPTAS; the approximation algorithm of Chen immediately implies an FPT\nalgorithm for Independent Set on map graphs, and hence for packing shortest facial cycles. The first\nnatural approach to try would be to reduce Shortest Cycle Packing toIndependent Set in map\ngraphs. This approach fails because a solution may contain many non-facial cycles. The main challenge\nin obtaining the algorithm for Shortest Cycle Packing is identifying such cycles. However, we will\nuse Chen’s algorithm as a subroutine for an appropriate base case.\nIn order to handle non-facial cycles, we construct a rooted tree whose nodes are shortest cycles, called\naLaminar Shortest Cycle Tree (LSCT). Constructions with similar properties are used to approximate\nthe maximum size of cycle packings for uncrossable families of cycles [24, 36, 35], as well as for finding\nthe minimum cycle basis for a planar graph (see, e.g., [26]). However, our algorithm needs a new\ndecomposition with specific properties tailored to the properties of shortest cycles.\nSuppose that Cis a family of vertex-disjoint shortest cycles of G. Then Cis a laminar family of\ncycles. Some of these cycles may be nested. This means that a rooted tree can represent Cnaturally\n(see Figure 1). We assume that the leaves of the tree are facial cycles in the embedding.\nIt is convenient to assume that in the plane embedding of Gthe frontier of the external face is a\nshortest cycle. (It is not difficult to prove that such an embedding exists and it can be constructed in\npolynomial time.) We fix such an embedding and construct an LSCT tree T(G). The root of the tree is\nthe facial cycle of the external face. We construct the tree by recursively processing shortest cycles that\nare current leaves of the already constructed tree.\n4IfCis a facial cycle, it becomes a leaf of T(G). When Cis not a facial cycle, we consider two\npossibilities.\n(i)Ccontains two vertices sandt(called the poles ) that are at a distance g/2 from each other in C\nand such that there is an s-t-path Pof length g/2 whose edges and internal vertices are in the internal\nface of C. Then we say that Cis asplittable cycle and we create an S-node ofT(G) from C. We find\nan inclusion-maximal family P={P0, P1, . . . , P ℓ}of internally vertex-disjoint s-t-paths of length g/2\nwhere P0andPℓare the paths in Cand the other paths have their edges and internal vertices in the\ninternal face of C. We assume the paths are indexed in the clockwise order from s. We define the cycles\nformed by the consecutive paths in P(see Figure 3(a)) to be the children of C. We show that the poles\n(if they exist) must be unique, so this step is well defined.\n(ii) IfChas no poles, we call such cycles unsplittable and we make a U-node ofT(G) from C. We\nfind an inclusion-maximal laminar family C={C1. . . , C ℓ}of shortest cycles distinct from Csuch that\n(i) the cycles of Care inside Cin the sense that they have no elements in the external face of C, (ii) for\nevery i, j∈[ℓ], cycles CiandCjare outside each other, that is, Cjhas no elements in the internal face\nofCiand vice versa, and (iii) the cycles of Care maximal in the sense that for each i∈[ℓ], there is\nno shortest cycle C′distinct from CandCisuch that Ciis inside C′. We set the cycles of Cto be the\nchildren of CinT(G) (see Figure 3(b)).\nWe prove that an LSCT can be constructed in polynomial time and it contains all shortest cycles in\nthe following sense: every shortest cycle Cis either a node of T(G) or the tree has an S-node Swith\npoles sandtsuch that Cis formed by two distinct paths of Pconstructed for S.\nThe bottleneck in directly using LSCT at this point to find a solution, is dealing with S-nodes and\ncycles formed by paths of Pas these cycles are not nodes of the tree. To avoid having to consider such\ncycles in the solution, we argue that the random separation technique [8] can be used to highlight pairs\nof paths in the families Pthat could be cycles in a potential solution. We then modify T(G) in such a\nway that for the obtained tree T∗, every cycle of some potential solution is a node of T∗.\nFinally, we use a recursive branching algorithm to find a solution. First, we check in FPT time\nwhether there is a solution formed by the facial cycles using the algorithm for Independent Set on\nmap graphs. Otherwise, if we fail to find a solution formed by facial cycles, we conclude that for a\nyes-instance, there should be a cycle CinT∗and a solution containing Csuch that (i) the only cycles\nin this solution that are in the internal face of Care facial cycles and (ii) the solution contains k′≥1\nfacial cycles that are inside C. The crucial observation is that we can choose Cto be one of the lowest\nnodes in T∗having the property that there are k′vertex-disjoint facial cycles inside C, and we have at\nmost kpossibilities to choose Cfor a given k′. Here, again we can use the algorithm for Independent\nSeton map graphs as a black box. We branch on O(k2) possible choices of k′andC. For each branch,\nwe delete the vertices and edges of Gthat are in the inner face of Cand modify T∗respectively, decrease\nthe parameter by k′, and recurse. This results in the algorithm solving Shortest Cycle Packing in\ntime kO(k)·nO(1), which proves Theorem 3.\nIn the proof of Theorem 4 which provides a polynomial kernel for Edge-Disjoint Shortest Cycle\nPacking on planar graphs, we use a similar approach. In this case the solution is easier because when\nthe LSCT has at least 4 kleaves, that is, shortest facial cycles of G, the subgraph of the dual graph\ninduced by the shortest facial cycles of Ghas an independent set of size at least k(by the Four-Color\nTheorem). This means that ( G, k) is a yes-instance of Edge-Disjoint Shortest Cycle Packing . In\nthe case when the number of leaves is less than 4 k, we can mark O(k2) nodes of T(G) in such a way that\na yes-instance has a solution containing only marked shortest cycles or cycles formed by paths from P\nconstructed for S-nodes. The idea behind the marking is to choose the lowest “useful” cycles. This leads\nto a kernel for Edge-Disjoint Shortest Cycle Packing withO(k2) vertices and edges and proves\nTheorem 4.\n1.2 Related Work\nThe complexity of Min-Sum Disjoint Paths is widely open on general and planar graphs. Bj¨ orklund\nand Husfeldt [4] give a randomized algorithm with running time O(n11) for finding two disjoint si-ti-paths\nof minimum total length. It is not known whether the problem is polynomial-time solvable for k= 3. On\nplanar graphs, several polynomial-time algorithms are known for the special cases when the terminals\nbelong to two faces [7, 11, 13, 30]. Recently, Mari et al. [32] designed an algorithm for this problem with\nrunning time k2O(k)when the input graph is a grid.\nDisjoint Shortest Paths is NP-hard when kis part of the input [17] and W[1]-hard parameterized\nbyk[2]. Lochet [31] gives a polynomial-time algorithm for any fixed kin undirected graphs without\nweights, see also Bentert et al. [2] for an improvement of the running time of Lochet’s algorithm. Whether\nDisjoint Shortest Paths is FPT parameterized by kon planar graphs is an interesting open question.\n5Very little was known about the complexity of Min-Sum Cycle Packing andShortest Cycle\nPacking . Both problems are NP-complete when restricted to planar graphs [23, 25, 27] because they\ngeneralize the well-known triangle packing problem. Rautenbach and Regen [33] show that for graphs\nof girth g∈ {4,5},Shortest Cycle Packing andEdge-Disjoint Shortest Cycle Packing allow\npolynomial-time algorithms for instances with maximum degree 3 but are APX-hard for instances with\nmaximum degree 4. For each g≥6, both problems are APX-hard already for graphs with maximum\ndegree 3.\nApproximation algorithms of ratio (3 + ε) for Shortest Cycle Packing andEdge-Disjoint\nShortest Cycle Packing on planar graphs follow from the framework of Schlomberg et al. [36] for\nuncrossing families of cycles.\nWhen the sizes of the cycles are bounded, cycle packing is a special case of the subgraph packing\nproblem. For such problems a plethora of parameterized and kernelization algorithms are known [12].\nHowever, all these algorithms work only for cycles of constant sizes. For vertex-disjoint (or edge-disjoint)\ncycle packing (without conditions on the lengths of cycles), a polynomial kernel on planar graphs, as\nwell as more general classes of sparse graphs, are known [6, 21].\n2 Preliminaries\nFor a positive integer p, we use [ p] to denote the set {1, . . . , p }, [p]0for the set {0,1, . . . , p }and we\ndefine [ p, q] ={p, . . . , q }for integers p < q .\nGraphs. In this paper, we consider finite undirected graphs and refer to the textbook by Diestel [14]\nfor undefined notion. By default, the considered graphs are simple but we may allow multiple edges\nand loops in some occasions. Let G= (V, E) be a graph. We use V(G) and E(G) to denote the set of\nvertices and the set of edges of G, respectively. We use nandmto denote the number of vertices and\nedges in G, respectively, unless this creates confusion, in which case we clarify the notation explicitly.\nFor a vertex subset U⊆V, we use G[U] to denote the subgraph of Ginduced by the vertices in U\nandG−Uto denote G[V\\U]. For two graphs G1andG2, the intersection G=G1∩G2is the graph\nwith V(G) =V(G1)∩V(G2) and E(G) =E(G1)∩E(G2), and the union G=G1∪G2is the graph\nwith V(G) =V(G1)∪V(G2) and E(G) =E(G1)∪E(G2). A path P=v0···vℓis a graph with vertex\nset{v0, v1, . . . , v ℓ}and edge set {{vi−1, vi} |i∈[ℓ]}; the vertices v0andvℓare the endpoints ofPand\nthe other vertices are internal . For a path with endpoints sandt, we say that Pis an s-t-path. For\na path P, a subgraph RofPwith a single connected component is called a subpath ofPand we use\nthe notation R⊆Pto denote this. In the case of unweighted graphs, the length ofPis defined as the\nnumber of edges, and if we are given edge weights w:E(G)→Z>0then the length ofP=v0···vℓ\nisw(P) =Pℓ\ni=1w({vi−1, vi}). A cycle Cis a path along with an additional edge between the two\nendpoints. The length of a cycle is defined in the same way as the length of a path. The girth ofGis the\nminimum length of a cycle in G;g(G) = +∞ifGis a forest. An (edge) cut ofGis a partition ( X, Y)\nofV(G); the set of edges E(X, Y) ={{x, y} |x∈X, y∈Y}is the cut-set . IfGis a weighted graph\nthen the weight of a cut is the weight of its cut-set.\nA graph is planar if it can be drawn on the plane such that its edges do not cross each other. Such a\ndrawing is called a planar embedding of the graph and a planar graph with a planar embedding is called\naplane graph. The planarity of a graph can be tested and a planar embedding can be found (if it exists)\nin linear time by the results of Hopcroft and Tarjan [28]. The faces of a plane graph are the open regions\nof the plane bounded by a set of edges and that do not contain any other vertices or edges. The outer\nregion is the external face and the other faces are internal . The vertices and edges appearing on the\nclosed walk bounding the face form its frontier . Given a plane graph G, we use F(G) to denote its set of\nfaces. If a cycle CofGis the frontier of some face, then Cis afacial cycle . For a plane graph G, itsdual\ngraph G∗= (F(G), E∗) has the set of faces of Gas the vertex set, and for each e∈E(G),G∗has the\ndual edge e∗whose endpoints are either two faces having eon their frontiers or e∗is a self-loop at fife\nis in the frontier of exactly one face f(i.e., eis a bridge of G). Observe that G∗is not necessarily simple\neven if Gis a simple graph. If Gis a weighted graph then it is standard to define the weights of the\nedges of the dual graph by setting the weight of e∗to be equal to the weight of efor each edge e∈E(G).\nIt is well known that finding a shortest cycle for a plane graph is equivalent to computing a minimum\ncut for the dual graph. More precisely, Cis a shortest cycle in a weighted plane graph Gif and only if\nthe set {e∗|e∈E(C)}of dual edges is a cut-set of G∗of minimum weight. In a weighted graph, the\ndistance between two vertices is the weight of a minimum-weight path between them.\nThe celebrated four-color theorem [1, 34] implies the following observation about independent sets in\nplanar graphs.\n6Observation 2.1. Ann-vertex planar graph has an independent set of size at leastn\n4.\nAmap graph is the intersection graph of a finite family of simply connected and internally disjoint\nregions of the plane. In this paper, we assume that each map graph Gis given by its embedding, that\nis, by a plane graph Hsuch that V(G)⊆F(H) and two vertices f1, f2∈V(G) are adjacent if and only\nif the frontiers of the faces f1andf2ofHshare at least one point (a vertex or an edge of H). It was\nshown by Chen [9] that Independent Set is FPT on map graphs.1\nProposition 2.2 ([9]).It can be decided in 2O(k)· |V(H)|2time whether a map graph Ggiven by its\nembedding Hhas an independent set of size at least k.\nParameterized Complexity. We refer to the textbooks by Cygan et al. [12] and by Downey and\nFellows [16] for a detailed introduction. Here, we just briefly remind the main notions. A parameterized\nproblem is a language L⊆Σ∗×Nwhere Σ∗is a set of strings over a finite alphabet Σ. An input\nof a parameterized problem is a pair ( x, k) where xis a string over Σ and k∈Nis a parameter .\nA parameterized problem is fixed-parameter tractable (or FPT) if it can be solved in f(k)· |x|O(1)\ntime for some computable function f. The complexity class FPT contains all fixed-parameter tractable\nparameterized problems. A parameterized problem is in the class XP if it can be solved in |x|f(k)time\nfor a computable function f. Akernelization algorithm orkernel for a parameterized problem Lis a\npolynomial-time algorithm that takes as its input an instance ( x, k) ofLand returns an instance ( x′, k′)\nof the same problem such that (i) ( x, k)∈Lif and only if ( x′, k′)∈Land (ii) |x′|+k′≤f(k) for some\ncomputable function f:N→N. The function fis the sizeof the kernel; a kernel is polynomial iffis a\npolynomial.\nWe conclude this section with two auxiliary results used in our paper. We need the following classical\nresult of Erd˝ os and Szekeres [18].\nProposition 2.3 (Special case of Erd˝ os-Szekeres theorem [18]) .Each sequence of more than (r−1)2\ndistinct real numbers contains either an increasing subsequence of length ror a decreasing subsequence\nof length r.\nFor kernelization for Edge-Disjoint Shortest Cycle Packing on planar graphs, we use the algo-\nrithm of Frank and Tardos [22] to compress the weights as it is standard for kernelization algorithms [19].\nProposition 2.4 ([22]).There is an algorithm that, given a vector w∈Qrand an integer N, in\n(strongly) polynomial time finds a vector w∈Zrwith∥w∥∞≤24r3Nr(r+2)such that sign(w·b) =sign(w·b)\nfor all vectors b∈Zrwith∥b∥1≤N−1.\n3 Min-Sum Cycle Packing is in XP\nIn this section, we prove Theorem 1 and show that Min-Sum Cycle Packing andMin-Sum Edge-\nDisjoint Cycle Packing can be solved in nO(k6)time. The algorithms for these two problems are\nbased on the same argument. We therefore focus on Min-Sum Cycle Packing and then explain how\nto extend the algorithm for the case of edge-disjoint cyles.\nFirst, we show that if a path and a cycle intersect in a complicated way, then we can construct a\ncollection of many pairwise disjoint short cycles. Before this, let us introduce some notation about the\nintersection of a path and a cycle.\nLetPbe a path in GandCa cycle in Gso that PandCintersect in at least one vertex. A chord\nofPrelative to Cis a maximal non-empty subpath R⊆Pso that the endpoints of Rare in V(C), the\ninternal vertices of Rare disjoint from V(C), and E(R) is disjoint from E(C). A tailofPrelative to Cis\na maximal non-empty subpath T⊆Pwhose one endpoint is an endpoint of Pand is disjoint from V(C),\nthe other endpoint is in V(C), and all internal vertices are not contained in V(C). Note that Phas\nbetween zero and two tails relative to C. Note also that E(P) is the disjoint union of E(P)∩E(C), the\nedges of the chords of Prelative to C, and the edges of the tails of Prelative to C.\nObservation 3.1. The number of chords of Prelative to Cis the number of connected components\nofP∩Cminus one.\nLemma 3.2. Let(G, w)be an edge-weighted graph, Ca cycle in Gof length at most ℓ, and Pa path\ninGof length at most ℓ. IfPhas at least 128k3chords relative to C, then Gcontains a collection of k\npairwise vertex-disjoint cycles with total length at most ℓ.\n1The result of Chen [9] is stated as an EPTAS but the approximation algorithm immediately implies an FPT algorithm.\n7Proof. Let us assume that Phas at least 128 k3chords relative to Cand construct the desired collection\nof pairwise disjoint cycles.\nFirst, we select a collection Rof at least 64 k3chords of Pso that the chords in Rare vertex-disjoint.\nThis is done simply by following along Pand selecting every second chord. Now, let us index V(C) with\nintegers from 1 to |V(C)|, in an order following the cycle. Then we associate with each chord R∈ R\nthe pair ( s(R), t(R))∈[|V(C)|] of numbers such that s(R)< t(R) correspond to the two endpoints of R\n(which are in V(C)). Note that as the chords are vertex disjoint, all of the numbers associated to them\nare distinct.\nLetR1, R2∈ Rbe two chords with s(R1)< s(R2). We say that R1andR2are\n•consecutive ifs(R1)< t(R1)< s(R2)< t(R2),\n•crossing ifs(R1)< s(R2)< t(R1)< t(R2), and\n•parallel ifs(R1)< s(R2)< t(R2)< t(R1).\nNote that any two chords are either consecutive, crossing, or parallel.\nLet us then show that we can obtain a large enough subcollection of Rsuch that every pair of chords\nin this collection are related in the same way (i.e., one of consecutive, crossing, or parallel).\nClaim 3.3. There is R′⊆ R with|R′| ≥4kso that all chords in R′are either pairwise consecutive,\npairwise crossing, or pairwise parallel.\nProof of the claim. We say i∈[|V(C)|]touches a chord R∈ R ifs(R)≤i≤t(R). First, suppose that\nnoi∈[|V(C)|] touches more than 16 k2chords. Then, the greedy algorithm that repeatedly chooses\nchords Rwith the smallest t(R) and discards all other chords touched by t(R) manages to collect a set\nof at least 8 k≥4kpairwise consecutive chords.\nOtherwise, there is i∈[|V(C)|] that touches at least 16 k2+ 1 chords, implying that there is a\ncollection R1⊆ R of at least 16 k2chords Rwith s(R)< i < t (R) (recall that the chords in Rare\nvertex disjoint). By the Erd˝ os-Szekeres theorem (proposition 2.3), there exists a subcollection R2⊆ R 1\nof size at least 4 kso that when the chords in R2are sorted by s(R), the endpoints t(R) are either all in\nincreasing order, or all in decreasing order. In the former case, the chords in R2are pairwise crossing,\nand in the latter case, the chords in R2are pairwise parallel. ◁\nWe next consider the three cases arising from the above claim. First, if we have a collection R′of 4k\npairwise consecutive chords, then by forming for each chord R∈ R′a cycle consisting of Rand the path\ninCbetween s(R) and t(R), we obtain a collection of 4 kpairwise vertex-disjoint cycles. As the edges of\nthese cycles come from E(P)∪E(C), their total length is at most 2 ℓ, so by choosing the kshortest of\nthem we obtain a collection of kpairwise vertex-disjoint cycles with a total length at most ℓ/2.\nSecond, suppose we have a collection R′of 4kpairwise crossing chords. Let us index them R1, . . . , R 4k,\nso that s(Ri)< s(Rj) ifi < j . Note that now, s(R4k)< t(R1) and t(Ri)< t(Rj) whenever i < j . For\neach i∈[2k], we construct a cycle Ciby taking the union of R2i−1andR2i, and connecting them by\ntwo paths in C, the first between s(R2i−1) and s(R2i), and the second between t(R2i−1) and t(R2i).\nWe obtain a collection of 2 kpairwise vertex-disjoint cycles. The edges of these cycles are contained\ninE(P)∪E(C), and therefore their total length is at most 2 ℓ. By choosing the kshortest of them we\nobtain kpairwise disjoint cycles of total length of at most ℓ.\nFor the final case of R′comprising 4 kpairwise parallel chords, let us use the same indexing R1, . . . , R 4k\nas in the previous paragraph, so that s(Ri)< s(Rj) ifi < j . Note that now, s(R4k)< t(R4k)\nandt(Ri)> t(Rj) whenever i < j . We again construct a cycle Cifor each i∈[2k], by taking the\nunion of R2i−1andR2i, and connecting them by two paths in C, the first between s(R2i−1) and s(R2i),\nand the second between t(R2i) and t(R2i−1). We obtain a collection of 2 kpairwise vertex-disjoint cycles.\nThe edges of these cycles are contained in E(P)∪E(C), and therefore their total length is at most 2 ℓ\nand by choosing the kshortest of them we obtain kpairwise disjoint cycles with a total length of at\nmost ℓ.\nOur algorithm for Min-Sum Cycle Packing is based on a graph-theoretical lemma that bounds the\nnumber of paths of length at most ℓin no-instances. We first prove this lemma in the case when k= 1,\nwhich will be used in the proof of the general case.\nLemma 3.4. If an edge-weighted n-vertex graph (G, w)does not contain a cycle of length at most ℓ,\nthen the number of paths of length at most ℓ/2inGis at most\0n\n2\n.\n8Proof. Suppose there are two vertices a, b∈V(G) with two distinct (but not necessarily vertex- or edge-\ndisjoint) a-b-paths P1andP2inG, both of length at most ℓ/2. Now, the sum of edge weights in P1∪P2\nis at most ℓand must contain a cycle, that is, Gcontains a cycle of length at most ℓ. Hence, for each\npaira, b∈V(G), there is at most one a-b-path of length at most ℓ/2, and therefore the total number of\npaths of length at most ℓ/2 is at most\0n\n2\n.\nWe also note that such bounds on the number of paths of a certain length can be boosted to higher\nlengths.\nObservation 3.5. Let(G, w)be an edge-weighted graph, so that the number of paths of length at most ℓ\ninGis at most N. For any integer c≥1, the number of paths of length at most c·ℓinGis then at\nmost Nc.\nProof. Any path of length at most c·ℓcan be constructed as the union of at most cpaths of length at\nmost ℓ.\nWe are now ready to prove our main graph-theoretical lemma, which is at the heart of our algorithm.\nLemma 3.6. If an edge-weighted n-vertex graph (G, w)does not contain a collection of kpairwise\nvertex-disjoint cycles of total length at most ℓ, then the number of paths of length at most ℓinGis\ninnO(k5).\nProof. Let˜Cbe a subgraph of Gcomprising a maximal collection of vertex-disjoint cycles each of length\nat most ℓ/k. Note that ˜Cconsists of at most k−1 cycles as otherwise Gcontains kvertex-disjoint cycles\nof total length at most ℓ. Since G−V(˜C) does not contain a cycle of length at most ℓ/k, Lemma 3.4\nimplies that the number of paths of length at most ℓ/(2·k) inG−V(˜C) is at most\0n\n2\n≤n2. Finally,\nObservation 3.5 allows us to conclude that the number of paths of length at most ℓinG−V(˜C) is at\nmost n4k. This also implies that the number of paths of length at most ℓinGwhose internal vertices\nare disjoint from V(˜C) is at most n8k. Now, let Pbe a path in Gof length at most ℓ.\nClaim 3.7. The number of connected components of P∩˜Cis at most 128k4−1.\nProof of the claim. Suppose the number of connected components of P∩˜Cis more than 128 k3·(k−1).\nSince ˜Cis the union of at most k−1 cycles of length at most ℓ/keach, by the pigeonhole principle,\nthere is a cycle C⊆˜Csuch that the number of connected components of P∩Cis more than 128 k3.\nObservation 3.1 now implies that Phas at least 128 k3chords relative to Cand Lemma 3.2 therefore\nstates that Gcontains a collection of kpairwise vertex-disjoint cycles of total length at most ℓ, which is\na contradiction. ◁\nNow, Pcan be constructed as the union of the subpaths of Pthat are internally vertex-disjoint\nfrom V(˜C) and the connected components of P∩˜C, which are paths. Notice that the number of\nsubpaths of Pthat are internally disjoint with V(˜C) is by Observation 3.1 at most the number of the\nconnected components of P∩˜Cplus one, that is, at most 128 k4. On the other hand, the number of paths\nthat are subgraphs of ˜Cis at most n2. Hence, there are at most ( n2)128k4possible choices for subpaths\nofPthat are connected components of P∩˜Cand for each of the at most 128 k4chords and/or tails\nofPrelative to ˜C, there are at most n8kchoices for paths which are internally vertex-disjoint from ˜Cas\nnoted earlier. The number of paths of length at most ℓinGis therefore at most\n(n2)128k4·(n8k)128k4=n256k4n1024k5∈nO(k5).\nNow, we are ready to translate Lemma 3.6 into an algorithm for Min-Sum Cycle Packing . For\nthis, we need the following easy lemma.\nLemma 3.8. There is an algorithm that, given an edge-weighted n-vertex graph (G, w)and integers ℓ\nandN, in time N·nO(1)either returns all paths in Gof length at most ℓ, or concludes that the number\nof such paths is more than N.\nProof. The set of all paths of length 0 is easy to generate, as they are just the vertices of G. Now,\nleti≥1 and let Pi−1be the set of paths of length at most i−1 inG. Given Pi−1, we can generate in\ntime|Pi−1| ·nO(1)the set Piof all paths of length at most iby first generating |Pi−1| ·nO(1)candidates\nby trying to extend each path by one edge (and also including all paths in Pi−1), then filtering out\nthe obtained subgraphs that are not paths, and finally deduplicating the output by bucket sorting. By\nrepeating this until either i=ℓor|Pi|> N, we obtain the desired algorithm.\nWe now prove the main theorem of the section.\n9Theorem 1. Min-Sum Cycle Packing andMin-Sum Edge-Disjoint Cycle Packing can be solved\ninnO(k6)time, where nis the number of vertices in the graph.\nProof. We demonstrate an algorithm for Min-Sum Cycle Packing and then explain how to adapt it\nforMin-Sum Edge-Disjoint Cycle Packing .\nLet us first construct a decision algorithm, that given ( G, w, k, ℓ ), decides whether Gcontains a\ncollection of kpairwise vertex-disjoint cycles of total length at most ℓ. We first apply the algorithm of\nLemma 3.8 with N=n256k4n1024k5∈nO(k5)(as specified in the proof of Lemma 3.6). If it concludes\nthat the number of paths of length at most ℓis more than N, then we conclude that the answer\nis yes. Otherwise, we obtain the collection of all paths of Gof length at most ℓ, which has size at\nmost N∈nO(k5). By trying to extend each with an edge, we obtain the collection of size at most Nof\nall cycles of Gof length at most ℓ. Now, we try all possibilities of selecting kcycles from this collection,\nyielding the running time\0N\nk\n∈nO(k6).\nNow this algorithm can be turned into an algorithm that finds a collection of kpairwise vertex-disjoint\ncycles with total length at most ℓby self-reduction as follows. We repeatedly attempt to remove edges\nand check if the solution still exists after an edge is removed. These cause only a polynomial (in n)\noverhead in the running time. This concludes the proof for Min-Sum Cycle Packing .\nForMin-Sum Edge-Disjoint Cycle Packing , we observe that if the above algorithm for Min-Sum\nCycle Packing concludes that the graph contains kvertex-disjoint cycles of total length at most ℓ,\nthen these kcycles are also edge disjoint. Otherwise, we have that the number of cycles of length at\nmost ℓis at most Nand we can test for each selection of kof them whether they are edge-disjoint\ninNO(k)time. This concludes the proof.\nNext, we generalize Theorem 1 for Min-Vector Cycle Packing andEdge-Disjoint Min-Vector\nCycle Packing .\nTheorem 5. Min-Vector Cycle Packing andEdge-Disjoint Min-Vector Cycle Packing can\nbe solved in nO(k6)time.\nProof. Let us give a decision algorithm. This can be turned into an algorithm for finding a solution\nsimilarly as in the proof of Theorem 1.\nLet ( ℓ1, . . . , ℓ k) be the given vector, and assume without loss of generality that ℓ1≤ℓifor all i.\nSimilarly as in the proof of Theorem 5, we apply the combination of Lemma 3.6 and Lemma 3.8 with the\nparameters kandℓ1to, in time nO(k5), either conclude that Gcontains a collection of kpairwise (vertex-\nand edge-)disjoint cycles of total length at most ℓ1, or enumerate all (at most N∈nO(k5)) cycles of Gof\nlength at most ℓ1. In the former case, we are done as any such collection gives us a solution, and in the\nsecond case, we branch on the cycles to guess the first cycle, delete its vertices (or edges in the case of\nEdge-Disjoint Min-Vector Cycle Packing ) and recursively apply the algorithm to find the k−1\nother cycles. This branching algorithm runs in a total time of ( nO(k5))k=nO(k6).\n4 Lower bound for Min-Sum Cycle Packing\nIn this section, we prove our computational lower bound for Min-Sum Cycle Packing . For convenience,\nwe restate our result.\nTheorem 2. Min-Sum Cycle Packing isW[1] -hard in subcubic graphs with unit edge weights when\nparameterized by k.\nProof. We reduce from Multicolored Clique which is well-known to be W[1]-complete [12]. We recall\nthat the task of the problem is, given a graph Gwhose set of vertices is partioned into ℓsetsV1, . . . , V ℓ\n(called color classes ), to decide whether Ghas a clique of size ℓwith exactly one vertex from each color\nclass.\nLet ( G, ℓ) be an instance of Multicolored Clique and let Vi={vi\n1, vi\n2, . . . , vi\nνi}be the set of\nvertices of color ifor each i∈[ℓ]. Let νbe the maximum number of vertices of any color, let ∆ be\nthe maximal degree of G, and let γ= (ν−1)(3∆ + 1) −1. For each color i∈[ℓ], we create a vertex-\nselection gadget as follows. We start with 6 νvertices wi,1\na, ui,1\na, wi,2\na, ui,2\na, wi,3\na, and ui,3\nafor each a∈[ν].\nWe add an edge {wi,j\na, ui,j\na}for each i∈[ℓ],j∈[3], and each a∈[ν]. Next, for each i∈[ℓ],j∈[3],\na∈[ν], we add 3∆ −1 vertices vi,j\na,bwhere b∈[3∆−1]. We add the edge {vi,j\na,b, vi,j\na,b+1}for each i∈[ℓ],\nj∈[3], a∈[ν], and each b∈[3∆−2]. Moreover, we add the edges {ui,j\na, vi,j\na,1}and{vi,j\na,3∆−1, wi,j\na+1}for\neach i∈[ℓ],j∈[3],anda∈[ν−1] and the edges {ui,j\nν, vi,j\nν,1}and{vi,j\nν,3∆−1, wi,jmod 3+1\n1 }for each i∈[ℓ]\nand each j∈[3]. Note that the entire constructed cycle has length 3 ν(3∆ + 1). Finally, we add paths\n10wi,1\n1ui,1\n1\nwi,1\n2ui,1\n2\nwi,1\n3ui,1\n3\nwi,2\n1ui,2\n1\nwi,2\n2ui,2\n2wi,2\n3ui,2\n3wi,3\n1\nui,3\n1wi,3\n2\nui,3\n2wi,3\n3ui,3\n3\nFigure 2: An example of the vertex-selection gadget with ν= ∆ = 3 for one color i. The chords depict\npaths of length 2( ν−1)(3∆ −1) = 32 and one of the ways to pick three vertex-disjoint cycles using three\nchords is highlighted. This solution picks vertex vi\n3. Paths encoding two edges incident to vi\n3are shown\nby dashed and dotted lines, respectively.\nof length 2 γbetween all pairs of wanduvertices that have distance exactly ( ν−1)(3∆ + 1) −1 =γ.\nWe call these paths chords . Figure 2 gives an illustration of the above construction.\nNext, we encode the edges of the input graph. For each color i∈[ℓ] and each vertex vi\na∈Vi,\narbitrarily assign a distinct number from [∆] to each incident edge. Let f(vi\na, e) be the assigned number.\nFor each edge e={vi\na, vj\nb} ∈E, we add paths of length ⌈8\n5γ⌉between vi,1\na,3f(via,e)−2andvj,1\nb,3f(vj\nb,e)−2\nand between vi,1\na,3f(via,e)−1andvj,1\nb,3f(vj\nb,e)−1. We say that these two paths encode the edge e. Finally, we\nsetk= 3ℓ+\0ℓ\n2\n.\nSince the above construction takes polynomial time to compute, k≤4ℓ2, and each vertex has degree\nat most three, it only remains to prove that the input instance contains a multicolored clique (of size ℓ)\nif and only if the constructed graph contains kvertex-disjoint cycles of total length at most L= 9ℓγ+\0ℓ\n2\n2(⌈8\n5γ⌉+ 1). For the backward direction, note that all cycles that use vertices from more than one\nvertex-selection gadget have length at least 2( ⌈8\n5γ⌉+ 1) >3γ. Moreover, all cycles within one vertex-\nselection gadget that use more than one chord have length at least 4 γ. Hence, any solution of total\nlength at most Lcontains at least 3 ℓcycles of total length at most 9 ℓγ. By construction within one\nvertex-selection gadget, one can pick at most 3 vertex-disjoint cycles of average length at most 3 γand\nthis is only achievable if one picks three equally spaced chords and all vertices from the initial cycle\nof the vertex-selection gadget with the exception of three sets of vvertices between two consecutive w\nanduvertices as depicted in Figure 2. We say that such a solution avoiding the vvertices between wi,1\na\nandui,1\na+1(orui,2\n1ifa=ν)picks vertex vi\na. If we select a solution that picks a vertex for each vertex-\nselection gadget, then it remains to find\0ℓ\n2\nvertex-disjoint cycles that use vertices from at least two\nvertex-selection gadgets of total length at most\0ℓ\n2\n2(⌈8\n5γ⌉+ 1). Since each path between two vertex\nselection gadgets is of length ⌈8\n5γ⌉, each vertex in a vertex-selection gadget has at most one incident\nedge leaving the vertex-selection gadget, and two paths between vertex-selection gadgets have adjacent\nendpoints if and only if they encode an edge in G, it follows that any solution of total length at most L\ncontains\0ℓ\n2\npairs of paths encoding edges of G. By construction, this corresponds to a set of\0ℓ\n2\nedges\n11between ℓvertices of different colors, that is, to a multicolored clique (of size ℓ).\nFor the forward direction, note that if there exists a multicolored clique, then choosing the respective\nvertex in each vertex-selection gadget and taking the cycles encoding all edges between the chosen vertices\nresults in a set of kvertex-disjoint cycles of total length exactly L. This concludes the proof.\nSince two cycles in subcubic graphs are edge-disjoint if and only if they are vertex-disjoint, we can\ndefer the same hardness result for Min-Sum Edge-Disjoint Cycle Packing .\nCorollary 4.1. Min-Sum Edge-Disjoint Cycle Packing isW[1] -hard in subcubic graphs with unit\nedge weights when parameterized by k.\n5 Packings shortest cycles in planar graphs\nIn this section, we consider packings of disjoint shortest cycles in planar graphs and prove Theorems 3\nand 4. In Section 5.1, we construct a tree structure of a laminar family of shortest cycles that represent\nall minimum cycles. In Section 5.2, we prove Theorem 3 and Section 5.3 contains the proof of Theorem 4.\n5.1 Laminar decomposition for shortest cycles\nIn this subsection, we construct a laminar family of disjoint cycles representing all shortest cycles in\na planar graph and decompose this family into a tree. Throughout this subsection, we assume that\nconsidered graphs are not forests, that is, they have cycles.\nWe use the following folklore properties of shortest cycles which we prove for completeness. Given\ntwo distinct cycles C1andC2of a graph Gwith a nonempty intersection, we say that C1andC2touch\nifC1∩C2is a path (possibly trivial, that is, having a single vertex).\nLemma 5.1. LetGbe a weighted graph and let C1andC2be distinct shortest cycles with at least one\ncommon vertex. Then\n•either C1andC2touch,\n•orV(C1∩C2) ={s, t}for distinct sandtat distance g(G)/2in both cycles, and C1=P1∪P2and\nC2=Q1∪Q2where P1,P2,Q1, and Q2are distinct internally vertex-disjoint s-t-paths of length\ng(G)/2.\nProof. Since C1andC2do not touch, C1has two distinct internally vertex-disjoint paths P1andP2such\nthat the endpoints of these paths are in C2and the internal vertices and all the edges are outside C2.\nThen, the length of one of these paths, say, P1is upper-bounded by g(G)/2. Let sandtbe the endpoints\nofP1. Denote by Q1andQ2two distinct s-t-paths in C2. Since S1=P1∪Q1andS2=P1∪Q2are\ncycles, the length of S1andS2is at least g(G). Therefore, the paths P1,Q1, and Q2have the same\nlength g(G)/2. Also, we have that the length of P2isg(G)/2. Thus, P1,P2,Q1, and Q2are distinct\ninternally vertex-disjoint s-t-paths of length g(G)/2. This concludes the proof.\nWe need the following additional notation for plane graphs.\nDefinition 5.2 (Laminar family ).We say that two cycles C1andC2inGcross ifC1has at least one\nedge in the internal face of C2and, symmetrically, C2has at least one edge in the internal face of C1.\nA family Cof cycles is laminar if cycles in Cdo not cross.\nLetGbe a weighted plane graph. We introduce the following partial order on the family of all\nshortest cycles of G. For two shortest cycles C1andC2, we write C1≤C2if every vertex and edge of C1\nis a vertex or an edge of C2or is embedded in the internal face of C2. We also write C1<vC2ifC1≤C2\nandV(C1)∩V(C2) =∅(that is, C1is completely inside C2), and we write C1<eC2ifC1≤C2\nandE(C1)∩E(C2) =∅(i.e., C1andC2may share vertices but not edges).\nFor a cycle CinG, we denote by GCthe subgraph of Ginduced by the vertices of Cand the vertices\nofGembedded in the internal face of C. We say that Gisclean if each vertex and each edge of Gis\nincluded in some shortest cycle. We show that a clean graph always has a facial shortest cycle in the\nsame way as other uncrossable families [36].\nLemma 5.3. LetGbe a clean weighted plane graph. Then, there is an internal face f∈F(G)whose\nfrontier is a shortest cycle.\n12b)P0\nP1Pℓ\nC1Cℓ\nst\nC CC1\nC2C3C4\na)\nFigure 3: Construction of Ps(C) and Cs(C) for a splittable cycle (a) and construction of Cu(C) =\n{C1, C2, C3, C4}for an unsplittable cycle (b).\nProof. LetCbe a shortest cycle that is minimal with respect to the partial order ( ≤). We claim that the\ninternal face of Cis a face of G. For the sake of contradiction, assume that this is not the case. Then,\nGeither has a vertex vembedded in the internal face of Cor an edge ewith its endpoints in Cwhich\nis embedded in the internal face of C. In both cases, because Gis clean, there is a cycle C′containing\neither vore. Since Cis minimal, C′̸≤C. Therefore, CandC′cross and C′has either a vertex or an\nedge in the external face of C. By Lemma 5.1, V(C∩C′) ={s, t}for distinct sandtat distance g(G)/2\nin both cycles, and C=P1∪P2andC′=Q1∪Q2where P1,P2,Q1, and Q2are distinct internally\nvertex-disjoint s-t-paths of length g(G)/2. Notice that either Q1orQ2contain vore. By symmetry,\nassume that this holds for Q1. Because P1,P2, and Q1are distinct internally vertex-disjoint, we have\nthatQ1is drawn in the internal face of C. This means that S=P1∪Q1is a shortest cycle and S≤C.\nHowever, this contradicts the assumption that Cis minimal. This concludes the proof.\nLetCbe a shortest cycle in a weighted plane graph G. We say that Cissplittable if there are\ntwo vertices s, t∈V(C) at distance g(G)/2 from each other in Csuch that GChas an s-t-path Pof\nlength g(G)/2 distinct from the two s-t-paths in C; we say that Cisunsplittable , otherwise. We call s\nandtpoles. Notice that for poles sandton a splittable shortest cycle, the distance between them in G\nisg(G)/2. We need the following observation about splittable cycles.\nLemma 5.4. LetCbe a splittable shortest cycle in a weighted plane graph Gwith poles sandt. Then,\nany two distinct shortest s-t-paths in GCare internally vertex-disjoint and {s, t}is a unique pair of poles\nonC.\nProof. Suppose that P1andP2are distinct s-t-paths in GCof length g(G)/2. To show that P1andP2are\ninternally vertex-disjoint, note that if P1andP2have a common vertex distinct from sandtthen P1∪P2\nhas a cycle whose length is less than g(G). This proves that any two shortest s-t-paths in GCare internally\nvertex-disjoint.\nConsider the second property and let Pbe a shortest s-t-path in GCthat is distinct from the two s-t\npaths along C. Assume that there is a pair of vertices {s′, t′} ̸={s, t}onCat distance g(G)/2 such that\nthere is an s′-t′-path P′of length g(G)/2 inGCthat is not a path in C. Note that {s′, t′} ∩ {s, t}=∅.\nOtherwise, one of the two s-t-paths in Cor one of the two s′-t′-paths in Cis strictly shorter than g(G)/2.\nLetQbe the s-t-path in Ccontaining s′and let Q′be the s′-t′-path in Ccontaining s. By the first claim\nof the lemma, PandQare internally vertex-disjoint, and, similarly, P′andQ′are internally vertex-\ndisjoint as well. Then, S=P∪QandS′=P′∪Q′are shortest cycles. Notice that S∩S′contains\nans-s′-path in Cwhich is nontrivial (contains at least two vertices) because s̸=s′. Also, because P\nandP′are paths in GC, the paths have a common vertex vin the internal face of Cand, therefore,\nS∩S′is not a path. By Lemma 5.1, we have that SandS′intersect in exactly two vertices, implying\nthats=s′; a contradiction. This concludes the proof.\nLetCbe a splittable shortest cycle in a weighted plane graph Gwith poles sandt. We denote\nbyPs(C) ={P0, . . . , P ℓ}the inclusion-maximal family of distinct s-t-paths in GC. By Lemma 5.4,\nPs(C) is unique. We assume that the paths on Ps(C) are ordered in the clockwise order from the\nperspective of s(see Figure 3(a)) and C=P0∪Pℓ. For i∈[ℓ], we define the cycle Ci=Pi−1∪Pi, and\nsetCs(C) ={C1, . . . , C ℓ}. We use the following crucial property of splittable shortest cycles.\nLemma 5.5. LetCbe a splittable shortest cycle in a weighted plane graph G. Then, for any shortest\ncycle SinGC, either S=P∪Qfor two paths P, Q∈ Ps(C)orS≤Rfor some cycle R∈ Cs(C).\nProof. LetSbe a shortest cycle in GCand assume that S̸≤Rfor any R∈ Cs(C). Suppose that there\nisR∈ Cs(C) such that SandRcross. Then by Lemma 5.1, V(S∩R) ={s′, t′}for distinct s′andt′at\n13distance g(G)/2 in both cycles, and S=P1∪P2andR=Q1∪Q2where P1,P2,Q1, and Q2are distinct\ninternally vertex-disjoint s′-t′-paths of length g(G)/2. Because SandRcross, we can assume without\nloss of generality that the edges and internal vertices of P1are embedded in the internal face of Rand the\nedges and internal vertices of P2are in the external face of R. If{s′, t′}={s, t}then we have that P1is\nans-t-path in GCinternally vertex disjoint with the s-t-paths of Ps(C) forming R. Then P1is internally\nvertex disjoint with every path of Ps(C). However, this would contradict the maximality of Ps(C).\nThus, {s′, t′} ̸={s, t}. Moreover, note that {s′, t′}∩{s, t}=∅as otherwise, we would contradict the fact\nthat Q1andQ2are paths of length g(G)/2. But now, we have that sandtare embedded in distinct\nfaces of S. This is impossible because s, t∈V(C) and Cis the frontier of the external face of GC(recall\nthatScannot contain sortas it already contains s′andt′). This contradiction shows that SandRdo\nnot cross for any R∈ Cs(C).\nSince SandRdo not cross for any R∈ Cs(C), the definition of Cs(C) implies that S=P∪Qfor\ntwo paths P, Q∈ Ps(C). This concludes the proof.\nNow we deal with unsplittable shortest cycles. Consider an unsplittable shortest cycle Cin a weighted\nplane graph G. We define Cu(C) to be the set of all shortest cycles of GCdistinct from C, that are maximal\ncycles of this type with respect to ( ≤) (see Figure 3(b)). We use the following property of Cu(C).\nLemma 5.6. LetCbe an unsplittable shortest cycle in a weighted plane graph G. Then Cu(C)is laminar\nand for any shortest cycle S̸=CinGC,S≤Rfor some cycle R∈ Cu(C).\nProof. To show that Cu(C) is laminar, consider distinct R1, R2∈ Cu(C) and assume that R1andR2\ncross. By Lemma 5.1, V(R1∩R2) ={s′, t′}for distinct s′andt′at distance g(G)/2 in both cycles,\nandR1=P1∪P2andR2=Q1∪Q2where P1,P2,Q1, and Q2are distinct internally vertex-disjoint s′-t′-\npaths of length g(G)/2. Because R1andR2cross, we can assume without loss of generality that the edges\nand internal vertices of Q1are embedded in the internal face of R1and the edges and internal vertices\nofP2are in the external face of R2. Consider R=P1∪Q2. We have that R1≤RandR2≤R. Recall\nthatR1andR2are maximal with respect to ( ≤) shortest cycles distinct from C. Since R /∈ Cu(C),R=C.\nHowever, we have that s, t∈V(C) and GChas four internally vertex-disjoint s-t-paths of length g(G)/2.\nThis means that Cis splittable and contradicts our assumptions. Thus, Cu(C) is laminar.\nTo see the second claim, it is sufficient to observe that already by the definition of Cu(C), for any\nshortest S̸=CinGC,S≤Rfor some maximal (with respect to ( ≤)) shortest cycle of GCthat is\ndistinct from C. This concludes the proof.\nNow we are ready to construct a tree representing a laminar family of shortest cycles.\nLetGbe a clean planar weighted graph. Consider an arbitrary embedding of Gin the plane. By\nLemma 5.3, there is a face fin this embedding whose frontier is a shortest cycle C. Then, there is another\nplanar embedding of Gsuch that Cis a facial cycle of the external face of the embedded graph. We fix\nthis embedding and construct the rooted tree T(G), called the Laminar Shortest Cycle Tree (LSCT),\nwhose nodes are shortest cycles.\nWe start constructing T(G) from the facial cycle Cof the external face which is set to be the root.\nThen, we construct T(G) by the recursive analysis of shortest cycles Cthat are current leaves of the\nalready constructed tree.\n•IfCis a facial cycle for an internal face then we set Cto be a leaf of T(G).\n•IfCa splittable cycle then we construct Cs(C) and set the cycles of Cs(C) to be the children of C\ninT(G); we say that Cis an S-node in this case.\n•IfCis an unsplittable cycle then we construct Cu(C) and set the cycles of Cu(C) to be the children\nofCinT(G); we say that Cis aU-node.\nThe properties of LSCTs are summarized in the following lemma.\nLemma 5.7. Suppose that the LSCT T(G)is constructed for a clean planar weighted graph G. Then\nthe nodes of T(G)form a laminar family of shortest cycles such that\n(i) for any two nodes CandC′ofT(G),C≤C′in the planar embedding used in the construction of\nT(G)if and only if Cis a descendant of C′inT(G),\n(ii) for any shortest cycle CofG, either Cis a node of T(G)or there is an S-node RofT(G)and\ntwo paths P, Q∈ Ps(R)such that C=P∪Q,\n(iii) the facial shortest cycles of Gdistinct from the root of T(G)are the leaves of T(G).\nFurthermore, the LSCT can be constructed in polynomial time.\n14Proof. Properties (i)–(iii) follow directly from Lemma 5.5, Lemma 5.6, and the construction of T(G).\nTo prove that T(G) can be constructed in polynomial time, recall that a planar embedding Gcan be\nfound in linear time [28]. Then we can consider all the faces and find a face fwhose frontier is a shortest\ncycle C. This allows us to construct an embedding of Gwhere the frontier of the external face is a\nshortest cycle, in polynomial time. Then, following the steps of the algorithm, for each Cthat is a\ncurrent leaf of the already constructed tree, we verify whether Cis splittable or not. This can be done in\npolynomial time using Dijkstra’s algorithm [15]. If Cis splittable, then we construct the unique family\nof paths Ps(C) by greedily finding shortest s-t-paths. This allows us to construct Cs(C) in polynomial\ntime. If Cis unsplittable, then we can, for example, list all shortest cycles in GCusing the well-known\nfact that the number of such cycles is quadratic in the number of vertices and they can be enumerated\nin polynomial time (e.g., by using the algorithm of Karger and Stein [29] for the enumeration of all\nminimum cuts in the dual graph). Then, we can find all maximal shortest cycles with respect to ( ≤)\ndistinct from CinGCand obtain Cu(C) in polynomial time. Summarizing, we conclude that the overall\nrunning time is polynomial. This concludes the proof.\nWe conclude this section with some structural observations about solutions of Shortest Cycle\nPacking andEdge-Disjoint Shortest Cycle Packing on planar graphs. Let Gbe a clean weighted\nplanar graph and let kbe a positive integer. Recall that we assume that Ghas a fixed planar embedding\nwith the frontier of the external face being a shortest cycle. For LSCT T(G), we define special cycle\npackings.\nDefinition 5.8. A packing C={C1, . . . , C k}ofk(vertex/edge)-disjoint shortest cycles is T-maximal if\n(i) the number of facial cycles of internal faces in the packing is maximum,\n(ii) there is no packing C′={C′\n1, . . . , C′\nk}distinct from Csuch that C′\ni≤Cifor all i∈[k].\nOur algorithm uses the following property.\nLemma 5.9. Suppose that the LSCT T(G)is constructed for a clean weighted planar graph Gand\nassume that Gis embedded in the plane according to the construction of T. Let Cbe aT-maximal\npacking of k(vertex/edge)-disjoint shortest cycles. Then, Cis laminar and for each C∈ C, either Cis\na facial cycle of an internal face or there is a C′∈ Csuch that C′≤C.\nProof. IfC={C1, . . . , C k}is a packing of vertex-disjoint cycles, then Cis trivially laminar. Suppose\nthatCis a packing of edge-disjoint cycles and assume that there are distinct i, j∈[k] such that CiandCj\ncross. Then by Lemma 5.1, V(Ci∩Cj) ={s, t}for distinct sandtat distance g(G)/2 in both cycles,\nandCi=P1∪P2andCj=Q1∪Q2where P1,P2,Q1, and Q2are distinct internally vertex-disjoint s-t-\npaths of length g(G)/2. Since the cycles cross, we can assume without loss of generality that the edges\nand internal vertices of Q1are in the internal face of Ciand the edges and internal vertices of P2are\nin the internal face of Cj. Let C′\ni=P1∪Q1andC′\nj=P2∪Q2. Notice that CiandCjare not facial\ncycles and it holds that C′\ni≤CiandC′\nj≤Cj. Consider C′obtained by the replacement of CiandCj\nwith C′\niandC′\nj, respectively. We have that C′̸=Cis a packing of kedge-disjoint shortest cycles such\nthat the number of facial cycles is at most as large as in C. Moreover, because C′\ni≤CiandC′\nj≤Cj,\nthe existence of C′contradicts that Cis aT-maximal packing. Thus, Cis laminar.\nTo prove the second claim, suppose that Ci∈ Cis not a facial cycle of an internal face of Gfor\nsome i∈[k] and there is no j∈[k] distinct from isuch that Cj≤Ci. Consider GCi. Then by\nLemma 5.3, there is an internal face fofGCiwhose frontier is a shortest cycle. Denote by C′\nisuch a\ncycle. We have that C′\ni̸=CiandC′\ni≤Ci. Furthermore, because Cis laminar by the already proved\nfirst claim, C′obtained from Cby the replacement of Ciwith C′\niis a packing of disjoint cycles. However,\nthe number of facial cycles of internal faces in C′is bigger than the number of such cycles in C. This\ncontradicts the assumption that CisT-maximal. This proves the second claim and completes the proof\nof the lemma.\n5.2 FPT algorithm for Shortest Cycle Packing\nIn this subsection, we prove Theorem 3 which we restate here.\nTheorem 3. Shortest Cycle Packing is solvable in time kO(k)·nO(1)on planar graphs with n\nvertices.\nProof. Let ( G, w, k ) be an instance of Shortest Cycle Packing where Gis a planar graph. If Gis\na forest, then we have a trivial no-instance. Thus, we assume that this is not the case. Then, we\npreprocess Gand delete every edge and every vertex that is not included in a shortest cycle as these\nedges and vertices are irrelevant for our problem. From now on, we assume that Gis clean.\n15Next, we construct a planar embedding of Gsuch that the frontier of the external face is a shortest\ncycle. From this point, we assume that Gis a plane graph. We then construct the LSCT T(G). Our\naim is to find a T-maximal solution by using the properties given by Lemma 5.9.\nBy Lemma 5.7 (ii), for any shortest cycle CofG, either Cis a node of T(G) or there is an S-node R\nofT(G) and two paths P, Q∈ Ps(R) such that R=P∪Qwhere C̸=P∪QandP∪Q /∈ Cs(R). IfC\nis a shortest cycle of the second type, then we say that Cis anon-tree cycle.\nIn the following, we wish to achieve the property that each cycle of a solution is a node of the tree.\nSince this may not always be the case, we ensure this property by modifying the tree at selected nodes.\nLetCbe an S-node of T(G). We say ', 'raytos.r.bsinfotech@gmail.com', 'Matthias Bentert, Fedor V. Fomin, Petr A. Golovach, Tuukka Korhonen, William Lochet, Fahad Panolan, M. S. Ramanujan, Saket Saurabh, Kirill Simonov', '', '../pdf_files/671b4be6d472e-Packing Short Cycles.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(133, '2903777565', '1', 1, 1, 'Deterministic Edge Connectivity and Max Flow using Subquadratic Cut Queries', '2024-10-25', '2024', 'We give the first deterministic algorithm that makes sub-quadratic queries to find the global min-cut of a simple graph in the cut query model. Given an n-vertex graph G, our algorithm makes e O(n5/3) queries to compute the global min-cut in G. As a key ingredient, we also show an algorithm for finding s-t max-flows of size e O(n) in e O(n5/3) queries. We also show efficient cut-query implementations of versions of expander decomposition and isolating cuts, which may be of independent interest.', 'Data Structures and Algorithms', 'arXiv:2410.18704v1  [cs.DS]  24 Oct 2024Deterministic Edge Connectivity and Max Flow\nusing Subquadratic Cut Queries\nAditya Anand∗Thatchaphol Saranurak†Yunfan Wang‡\nOctober 25, 2024\nAbstract\nWe give the ﬁrst deterministic algorithm that makes sub-quadratic q ueries to ﬁnd the global\nmin-cut of a simple graph in the cut query model. Given an n-vertex graph G, our algorithm\nmakes/tildewideO(n5/3) queries to compute the global min-cut in G. As a key ingredient, we also show\nan algorithm for ﬁnding s-tmax-ﬂows of size /tildewideO(n) in/tildewideO(n5/3) queries. We also show eﬃcient\ncut-query implementations of versions of expander decomposition and isolating cuts, which may\nbe of independent interest.\n∗University of Michigan Ann Arbor, adanand@umich.edu .\n†University of Michigan Ann Arbor, thsa@umich.edu . Supported by NSF grant CCF-2238138. Partially funded\nby the Ministry of Education and Science of Bulgaria’s suppo rt for INSAIT, Soﬁa University “St. Kliment Ohridski”\nas part of the Bulgarian National Roadmap for Research Infra structure.\n‡Tsinghua University, Institute for Interdisciplinary Inf ormation Sciences, yunfan-w20@mails.tsinghua.edu.cn .Contents\n1 Introduction 1\n2 Technical Overview 2\n3 Preliminaries 4\n4 Flow Algorithm 5\n4.1 Simple Primitives using BIS Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n4.2 Reminder of Dinitz’s Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n4.3 Implementing Dinitz’s Algorithm via BIS Queries . . . . . . . . . . . . . . . . . . . . 8\n5 Global Min-cut Algorithm 9\n5.1 Dominating Sets are Separated by Small Cuts . . . . . . . . . . . . . . . . . . . . . . 10\n5.2 Computing a Dominating Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n5.3 Computing Minimum Isolating Cuts . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n5.4 Unbalanced Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n5.5 Balanced Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n6 Conclusion 18\nA Computing Expander Decomposition: Proof of Lemma 5.18 211 Introduction\nComputing a global min-cut, also known as edge connectivity of a graph, is one of the most\nextensively studied problems in algorithmic graph theory [ GH61 ,Gab91 ,NI92 ,HO94 ,Kar94 ,\nKS96 ,Kar00 ,KT18 ,HRW20 ,LP20 ,Li21,HLRW24 ]. In this problem, given an undirected graph\nG= (V,E), we need to ﬁnd a smallest set of edges F⊂Esuch that G\\Fis not connected.\nThe problem has also been explored in various computational models, including dynamic algo-\nrithms [ Tho07 ,GHN+23,JST24 ], parallel algorithms [ KM94 ,GG18 ,AB23 ], distributed algorithms\n[DHNS19 ,MN20 ,DEMN21 ,GZ22 ], and streaming algorithms [ MN20 ,AD21 ].\nOne model which has attracted signiﬁcant attention recentl y is the cut-query model. In this\nmodel, the edge set Eis not known, instead we are allowed to make cut queries . A query is a set\nS⊆V, and an oracle returns Cut(S), the number of edges across the cut ( S,V\\S).\nA straightforward algorithm is to learn the entire graph in /tildewideO(n2) queries.1Rubinstein, Schramm,\nand Weinberg [ RSW18 ] initiated the study of global min-cut in the cut-query mode l and showed a\ncut-query algorithm for simple graphs with only /tildewideO(n) queries. Mukhopadhyay and Nanongkai [ MN20 ]\nthen matched this result for general weighted graphs. Recen tly, Apers et al. [ AEG+22] improved\nthis result to only O(n) queries. However, all these algorithms are Monte Carlo ran domized algo-\nrithms.\nHence, both [ RSW18 ] and [ AEG+22] posed the question if their algorithms can be made de-\nterministic – the only known lower bound for deterministic c ut queries is Ω( n) [HMT88 ,Har08 ].\nHowever, the best known deterministic algorithm for edge co nnectivity (or global min-cut) [ GK00 ]\nstill takes O(n2/logn) queries to learn the whole graph . This only slightly improves upon the trivial\nalgorithm, which makes /tildewideO(n2) queries. Thus, there remains a big gap for deterministic al gorithms,\nand the following conceptual question is still open:\nCan we deterministically compute the edge connectivity of a g raph\nwithout learning the whole graph?\nIn this work, we make signiﬁcant progress towards this probl em by showing two results. We show\nthe ﬁrst deterministic cut-query algorithm for global min- cut in simple graphs with a sub-quadratic\nnumber of queries.\nTheorem 1.1. Given a simple undirected graph G, there is a deterministic algorithm that com-\nputes the global minimum cut in Gusing/tildewideO(n5/3)cut queries.\nAs a key ingredient, we show how to compute s-tmax-ﬂow using /tildewideO(n5/3) queries.\nTheorem 1.2. Given a capacitated undirected graph Gwith integral edge weights bounded by W,\nand two vertices s,t∈V, there exists a deterministic algorithm that computes an s,tmax-ﬂow in\n/tildewideO(n5/3W)cut-queries.\nIn particular, Theorem 1.2implies that we can deterministically compute s-tmax-ﬂow in simple\nunweighted graphs in /tildewideO(n5/3) cut queries. The previous algorithm for the same problem [ RSW18 ]\nobtained this bound using a randomized Monte Carlo algorith m.\nTowards obtaining these results we show eﬃcient determinis tic cut-query implementation of\nseveral tools: a version of expander decomposition, isolat ing cuts [ LP20 ] and a deterministic algo-\nrithm that obtains a dominating set of size /tildewideO(n\nδ) in a graph with minimum degree δ. We believe\n1Throughout the paper, we use /tildewideO(·) to hide a polylog( n) factor.\n1that the cut-query version of these simple and powerful tool s, some of which have formed the basis\nfor several fast algorithms in the last decade, may be of inde pendent interest.\nOther Query Models. Query models are widely studied in other settings as well. Ma ny query\nmodels can be viewed as learning the properties of a matrix Mthrough vector-matrix-vector uTMv\nqueries. Diﬀerent query models and the problems of concern wi thin each model are introduced in\n[RWZ20 ].\n[ACK21 ] considered a diﬀerent setting; they studied the query compl exity when we cannot use\nadaptive algorithms and can only perform a limited number of adaptive operations. [ AAL21 ] gave\na quantum minimum s-tcut algorithms using /tildewideO(√mn2\n3W1\n3) queries to the adjacency list of G,\nwith integral edge weights bounded by W. [AL21 ] studied the query complexity of the connectivity\nproblem for a graph G under the quantum query model.\nConnectivity Edge Connectivity\nLower Upper Lower Upper\nDeterministicΩ(n)\n[HMT88 ]O(nlogn\nloglogn)\n[LC24 ]Ω(n)\n[HMT88 ]˜O(n5/3)\n(This paper)\nZero-error, RandomizedΩ(nloglog(n)\nlogn)\n[RS95 ]O(n)\n[AEG+22]Ω(n)˜O(n5/3)\n(This paper)\nBounded Error, RandomizedΩ(n\nlogn)\n[BFS86 ]O(n)\n[AEG+22]Ω(nloglog(n)\nlogn)\n[AD21 ]O(n)\n[AEG+22]\nQuantum Ω(1)O(log5(n))\n[AL21 ]Ω(1)˜O(√n)\n[AEG+22]\nTable 1: The cut query complexity of connectivity and edge co nnectivity on simple graphs in various\nmodels. Before our work, the best deterministic and zero-er ror upper bound was from [ GK00 ], they\nuseO(n2/logn) queries by learning the entire graph. Additionally, the lo wer bound for zero-error\nedge connectivity comes from an unpublished article by Troy Lee and Adi Shraibman: “On the\ncommunication complexity of edge connectivity”. For more d etails, see [ AEG+22].\n2 Technical Overview\nMaximum s-tﬂow: In this overview, we assume W= 1. That is, the input graph Ghas unit\ncapacities, and the value of s-tmaximum ﬂow is at most /tildewideO(n). Our algorithm is based on the\nclassical Dinitz’s algorithm [ Din06 ], which we recall below.\nThe algorithm maintains a ﬂow fand proceeds in iterations. In each iteration, we ﬁrst const ruct\nthe (directed) residual graph Gffor the ﬂow f. Next, we obtain the layered graph GLfromGf.\nThe vertex set of GLisV. Deﬁne layers L0,L1..., whereLiis the set of vertices at distance ifrom\nsinGf. The edge set of the layered graph is the set of edges {u,v}inE(Gf), such that u∈Liand\nv∈Li+1for some i. Ablocking ﬂow f′is then a ﬂow from stotinGL, such that on every ﬂow\npath, some edge is saturated (that is, the ﬂow through the edg e equals its capacity). Let dist( s,t)\n2denote the length of the shortest (directed) path from stotinGL. Finally, we ﬁnd a blocking ﬂow\nf′and augment the ﬂow fwithf′, and proceed to the next iteration. The crucial property of t he\nalgorithm is that, after each iteration, dist( s,t) must strictly increase. Once we reach an iteration\nwhere a blocking ﬂow of non-zero value does not exist, the obt ained ﬂow fis maximum. We will\nuse the standard fact that once dist( s,t)≥n2/3, the total additional units of ﬂow that can be sent\nin subsequent iterations is at most O(n2/3).\nTo make only sub-quadratic cut queries, our key contributio n is to show how to compute a\nblocking ﬂow f′using only /tildewideO(n+ val(f′)dist(s,t)) queries where val( f′) denotes the value of f′.\nOur algorithm then keeps augmenting the ﬂow via our blocking ﬂow subroutine until the resulting\nﬂow is maximum.\nTo analyze the query complexity, we divide the algorithm int o two phases. The ﬁrst phase con-\ntains all iterations when dist( s,t)≤n2/3, and the second phase contains all subsequent iterations.\nIn the ﬁrst phase, we make /tildewideO(n·n2/3+n·n2/3) =/tildewideO(n5/3) queries because (1) there are at most n2/3\niterations since, after that, we must have dist( s,t)> n2/3, (2) the total value of ﬂow augmented\nduring these iterations at most the maximum ﬂow value, which we assumed to be at most /tildewideO(n),\nand (3) dist( s,t)≤n2/3. In the second phase, we again make /tildewideO(n·n2/3+n2/3·n) =/tildewideO(n5/3) queries\nbecause (1) there are at most n2/3iterations since, after that, fmust already be maximum, (2) the\ntotal value of ﬂow augmented during these iterations is at mo stO(n2/3), and (3) dist( s,t)≤n.\nGlobal minimum cut: The starting point of our global min-cut algorithm is the alg orithm of\n[LP20 ]. We give a high-level description of this algorithm below.\nGiven a set of terminals T, a Steiner min-cut is a minimum cut that separates some pair o f\nterminals, i.e., a minimum size cut ( C,V\\C) that satisﬁes C∩T,T\\C/\\e}atio\\slash=∅. Note that a Steiner min-\ncut when T=V(G) is a global min-cut. Suppose ( C,V\\C) is the minimum Steiner Cut in the graph\nG. The algorithm of [ LP20 ] is divided into two cases: one where min {|T∩C|,|T\\C|}≤ polylog(n),\nand the other where min {|T∩C|,|T\\C|}≥ polylog(n).\nIn the ﬁrst case, they ﬁnd the Steiner min-cut using the isolating cuts technique and ﬁnish. In\nthe second case, they compute an expander decomposition and replaceTby a smaller set T′⊆T\nwith|T′| ≤|T|\n2, such that some minimum Steiner cut CforTstill separates T′. Then they\nrecursively run the same procedure with T′. Since they do not know which case actually happens,\nthey run the isolating cut subroutine at every recursion, wh ile continuing to sparsify T. There can\nbe onlyO(log|T|) recursions since the size of Tdecreases by half after each recursion. Observe\nthat if the initial terminal set T=V(G), the algorithm must ﬁnd a global mincut at some point.\nSeveral challenges arise when implementing this algorithm in the cut-query model. First of all,\none needs to compute isolating cuts and expander decomposit ion in this model. But, superﬁcially,\nwe can be hopeful because the common primitive for these tech niques is a s-tmax-ﬂow algorithm,\nand we have a new eﬃcient algorithm when the max-ﬂow value is a t most/tildewideO(n).\nUnfortunately, the ﬂow instances when computing isolating cuts and expander decomposition\nmay have max-ﬂow value Ω( m), where mis the number of edges, even when the input graph is\nsimple. For example, the ﬂow instances for computing isolat ing cuts have the following structure:\nThe super source sconnects to many terminals v, and the capacity of edge ( s,v) is the degree of\nthe vertex v. This is similar for the super sink t. WhenT=V(G), for example, the max-ﬂow value\nof this ﬂow instance can be as large as Ω( m).\nTo overcome the above challenge, our solution is that we choo se the initial terminal set Tto be,\ninstead of the whole vertex set V(G), a dominating set Dof size/tildewideO(n/δ), where δis the minimum\n3degree. The correctness of this is based on our new and simple structural lemma (Lemma 5.3):\nevery cut ( C,V\\C) of size at most δ−1 must separate D, i.e., we must have D∩C,D\\C/\\e}atio\\slash=∅.\nTherefore, assuming that global min-cut has size at most δ−1 (otherwise, it has size δ, which is\ntrivial to compute), we conclude that the minimum Steiner Cu t with respect to Dis the global\nmin-cut. To initialize our terminal set as D, we show how to compute Dusing/tildewideO(n) queries.\nWhy does starting with Dhelp? This is because we will set up all ﬂow instances such tha t only\nvertices in Dare connected to super source sor super sink tand the capacity of each edge incident\ntosandtis at most δ+ 1.2\nSo the max-ﬂow value is only /tildewideO(n/δ)·(δ+ 1) =/tildewideO(n), but we prove that this new ﬂow instance\ncan still be used for computing isolating cuts and expander d ecomposition (in Section 5.3and ap-\npendix Arespectively). Therefore, we can employ our max-ﬂow algori thm with /tildewideO(n5/3) queries to\ncompute both isolating cuts and a version of expander decomp osition in only /tildewideO(n5/3) queries.\n3 Preliminaries\nIn this section, we will formally deﬁne terms and notations w hich we shall adopt throughout the\npaper.\nGraphs: Given an undirected simple graph G= (V(G),E(G)), we deﬁne δGto be the minimum\ndegree ofGandλGto be the size of the minimum cut inG. For a vertex set S⊆V, we letG[S]\ndenote the subgraph induced on the set of vertices S. For a set of vertices S, we denote by ∂G(S) the\nset of edges with exactly one endpoint in S. For a vertex u, we denote by NG(u) the set of vertices\nvwith{u,v}∈E(G). For a set of vertices U, we denote by NG(U) the set/uniontext\nu∈UNG(u)\\U, the\nset of neighbors of vertices in UoutsideU. We denote a cut in Gusing the notation ( S,V(G)\\S)\nforS⊆V(G). For simplicity, we shall refer to V(G)\\SasS. We say that a vertex set S⊆V(G)\nis adominating set ofGif, for any vertex v∈V(G), either v∈Sorvhas at least one neighbor in\nS.\nGiven a directed graph H, we use dist H(s,t) to represent the distance (length of the shortest\npath) between two vertices s,t∈V(H). We drop the subscripts when the graph is clear from the\ncontext.\nFlows and residual graphs: For a ﬂow ffromstot, we use val( f) to denote the size of\nthe ﬂow f. We describe the ﬂow by ﬂow values f(u,v),f(v,u) for every edge {u,v}∈Ewith\nf(u,v) =−f(v,u). Given a graph Gwith non-negative edge capacities c:E→R≥0and a\nﬂowf, we deﬁne the residual graph as the directed capacitated gra phGf, whose vertex set is\nV(Gf) =V. For an edge{u,v}∈Ewith ﬂow 0≤f(u,v)≤c(u,v), theresidual capacity is deﬁned\nascf(u,v) =c(u,v)−f(u,v)≥0. We also deﬁne cf(v,u) =c(v,u) +f(u,v). Then we add two\nedges in Gf: ifcf(u,v)>0, we add an edge from utovwith capacity cf(u,v) and ifcf(v,u)>0,\nwe add an edge from vtouwith capacity cf(v,u).\nTypes of queries: Next, we formally deﬁne cut queries and bipartite independe nt set queries.\n2Strictly speaking, our max-ﬂow algorithm takes /tildewideO(n5/3) queries only if edges have unit capacity. But, we can\nsimulate an edge from super source sto vertex aof capacity τby replacing it with τpaths:s→v1→a,...,s→\nvτ→a. We do similarly for the super sink t. The total number of newly added vertices is /tildewideO(n/δ)·(δ+1) =/tildewideO(n).\n4Deﬁnition 3.1 (Cut Query) .For an undirected capacitated graph Gwith capacities c:E(G)→\nR+∪{0}, given a set S⊆V(G), the cut query oracle for graph Greturns the total capacity of\ncut-edges Cut(S) :=c(S,S) =/summationtext\na∈S,b∈Sc(a,b).\nDeﬁnition 3.2 (Bipartite Independent Set (BIS) Query) .Given a (possibly directed) capacitated\ngraphHwith capacities c:E(H)→R+∪{0}, setsA,B⊆V(H) as input such that A∩B=∅,\nthe bipartite independent set query oracle returns the bool ean value which indicates if c(A,B) =/summationtext\na∈A,b∈Bc(a,b)>0.\nBIS queries were introduced by [ BHPNR+18] and have been extensively studied in the context\nof problems on undirected graphs. In an undirected graph H, a BIS query between AandBcan\nbe simulated with 3 cut queries since\nc(A,B) =1\n2(Cut(A) +Cut(B)−Cut(A∪B))\nWe will require BIS queries on the residual graph for our maxi mum ﬂow algorithm. The following\nlemma demonstrates how to simulate BIS queries on the residu al graph using cut queries.\nLemma 3.3. Given an undirected capacitated graph Gand an explicit ﬂow f, we can simulate a\nBIS query on the residual graph Gfby using 3cut queries in G.\nProof. GivenA,B⊆V, the BIS query on Gfwill return whether there exists a∈A,b∈Bsuch\nthatcf(a,b)>0. This is equivalent to\n/summationdisplay\na∈A/summationdisplay\nb∈Bcf(a,b)>0\nNotice that\n/summationdisplay\na∈A/summationdisplay\nb∈Bcf(a,b) =/summationdisplay\na∈A/summationdisplay\nb∈Bc(a,b)−f(a,b)\n=/summationdisplay\na∈A/summationdisplay\nb∈Bc(a,b)−/summationdisplay\na∈A/summationdisplay\nb∈Bf(a,b)\n=1\n2[Cut(A) +Cut(B)−Cut(A∪B)]−/summationdisplay\na∈A/summationdisplay\nb∈Bf(a,b)\nWe can use 3 cut queries to get Cut(A),Cut(B) andCut(A∪B). Since fis explicit, we can\nobtain/summationtext\na∈A/summationtext\nb∈Bf(a,b) in zero queries. Therefore, a BIS query in Gfcan be simulated by 3 cut\nqueries in G.\n4 Flow Algorithm\nIn this section, we prove our result on computing an s-tmax ﬂow of bounded size (Theorem 1.2).\nSection 4.1describes how to obtain simple primitives of the graph using BIS queries. Section 4.2\nrecalls Dinitz’s algorithm and its analysis. Section 4.3describes how to implement Dinitz’s algorithm\nvia BIS queries.\n54.1 Simple Primitives using BIS Queries\nLemma 4.1. Given a graph Gand a ﬂow finG, for two disjoint subsets A,B⊆V(G), if\nEGf(A,B)/\\e}atio\\slash=∅, we can ﬁnd a neighbor of AinB(a vertex b∈Bsuch that there exists a vertex\na∈Awith (a,b)∈E(Gf)) in the residual graph GfinO(log|B|)BIS queries on Gf.\nProof. Do a binary search on B. Divide Binto two parts B1,B2with roughly equal size, i.e.\n|B1|≈|B2|. We know that either EGf(A,B1)/\\e}atio\\slash=∅orEGf(A,B2)/\\e}atio\\slash=∅becauseEGf(A,B)/\\e}atio\\slash=∅. We\ncheck which one of these is true using one BIS query. If EGf(A,B1)/\\e}atio\\slash=∅, then we recursively ﬁnd\na neighbor in B1. Otherwise, we recurse on B2. So, we useO(log|B|) BIS queries on Gf.\nCorollary 4.2. For a vertex u∈Vor a set of vertices U⊆V, we can learn NGf(u)andNGf(U)\nin/tildewideO(|NGf(u)|)and/tildewideO(|NGf(U)|)BIS queries on Gf, respectively.\nProof. We ﬁrst show this for a single vertex u. LetB=V\\{u}. By Lemma 4.1we can ﬁnd\na neighbor of uinBinGfusingO(logn) BIS queries. Next, delete vby setting B=B\\{v},\nand invoke Lemma 4.1to ﬁnd another neighbor of u. Inductively, we learn the set NGf(u) using\nO(|NGf(u)|logn) BIS queries.\nThe argument for a set of vertices Uis obtained by treating the set Uas one super vertex.\nCorollary 4.3. Given graph Gand a ﬂow f, we can ﬁnd a BFS tree in Gfwith root sin/tildewideO(n)\nBIS queries on Gf.\nProof. We build the tree Tin layers. Let V(T) ={s}, andE(T) =∅. Additionally, we will\nmaintain the distance from sfor each vertex u∈V, denoted by d(u). We initialize d(s) = 0, and\nd(u) =∞for every other vertex.\nIn every iteration, we ﬁnd a vertex in V(T) with the smallest distance to s, sayu. We ﬁnd all\nneighbors u′ofuinV\\V(T) using Corollary 4.2. For each such neighbor u′ofu, we update the\ndistance as d(u′) =d(u)+1, and add u′toV(T) and the edge ( u,u′) toE(T). Letxbe the number\nof neighbors of u(inGf) inV\\V(T). Then we spend /tildewideO(x) queries for this step. We charge these\nqueries to the xvertices which are added to V(T) in this step. Repeating the same process for at\nmostn−1 iterations, we correctly obtain the BFS tree T.\nNote that each vertex v∈V(T) receives O(1) charge, and the number of vertices in Tisn.\nTherefore, the total query complexity is /tildewideO(n).\n4.2 Reminder of Dinitz’s Algorithm\nHere we recall Dinitz’s blocking ﬂow algorithm [ Din06 ] and its analysis.\nDeﬁnition 4.4 (Layered Graph) .LetGbe an undirected graph and let sandtbe source and\nsink vertices in V(G). Further, suppose that fis as-tﬂow inG, and let Gfbe the residual graph\nofGwith respect to f. The layered graph GLofGwith respect to fis the decomposition of the\nvertices of Ginto layers deﬁned by their distance from the source in Gf. Thei-th layer is deﬁned\nasLi={v|distGf(s,v) =i}. The vertex set of the layered graph is V(GL) =V(G), and the edge\nset is the set of edges ( u,v) ofGfsuch that u∈Liandv∈Li+1for some layer i.\nNote that we always have L0={s}. For simplicity, we will assume that the last layer contains\nonly the sink vertex t- if there are other vertices in this layer, we will drop them.\n6Deﬁnition 4.5 (Blocking Flow) .Given a graph G, the source and sink vertices vertex s,t, and an\ns-tﬂowfinG, letGLbe the layered graph GLofGwith respect to f. Ans-tﬂowf′inGLis\ncalled a blocking ﬂow, if for every s-tpath inGL, some edge is saturated by f′\nAlgorithm 1 Dinitz’s blocking ﬂow algorithm[ Din06 ]\nInput: GraphG, two vertices sandt\nOutput: Ans-tmaximum ﬂow finG\n1:Initialize an empty ﬂow ffromstot.\n2:Construct the residual graph GffromGandf\n3:Construct the layered graph GLfromGfand the source vertex s.\n4:ifdistGL(s,t)> nthen\n5: Terminate and output the ﬂow f.\n6:else\n7: Find a blocking ﬂow f′fromstotinGL\n8: Augment fbyf′to obtain a new ﬂow f′′. Update f←f′′, and repeat step 2.\n9:end if\nThe next lemma gives some simple facts about maximum ﬂows whi ch will be useful for the\nsubsequent analysis.\nFact 4.6. We have the following:\n1. A ﬂow fis maximum if and only if there is no augmenting path in the res idual graph Gf.\n2. If there is an s-tcut of capacity BinGf, then\nthe maximum ﬂow from stotinGis at most val(f) +B.\nNext, we need the following property of Dinitz’s algorithm ( Algorithm 1).\nLemma 4.7 ([Din06 ]).After augmenting the ﬂow fwith a blocking ﬂow f′to obtain a new ﬂow\nf′′, the distance from stotin the residual graph increases by at least 1. Concretely, distGf′′(s,t)≥\ndistGf(s,t) + 1.\nThus Dinitz’s algorithm must terminate after niterations of blocking ﬂow and give us a maxi-\nmum ﬂow, as after these many iterations, there cannot be an s-tpath of length n. However, this\nis too expensive for us. Instead, we will use a standard optim ization that actually shows that the\nalgorithm terminates in O(n2/3W) iterations. We provide the proof here for completeness.\nLemma 4.8. Given a capacitated graph Gwhere each edge weight is an integer in the range [1,W]\nand two vertices s,t, Algorithm 1ﬁnds an s-tmaximum ﬂow after O(n2/3W)iterations of blocking\nﬂow.\nProof. For the purpose of analysis, consider the s-tﬂowfiobtained after iiterations, where iis the\nsmallest subscript such that dist Gfi(s,t)> d:=n2/3. By Lemma 4.7, since the distance between\nsandtin the residual graph after iiterations exceeds d, it follows that i≤d. This bounds the\nnumber of iterations required.\nSince the graph contains nvertices and there are at least dlayers in the layered graph GL, by\nthe pigeonhole principle, there must exist a pair of consecu tive layers LjandLj+1such that|Lj|+\n7|Lj+1|≤O(n\nd). Therefore, the total edge weight between these layers is b ounded by O((n\nd)2W) =\nO(n2/3W). By the deﬁnition of the layered graph, the set of edges E(Lj,Lj+1) forms a cut between\nsandtinGfi. Thus, by Fact 4.6, the total ﬂow from stotis at most val( fi) +O(n2/3W).\nConsequently, the remaining ﬂow size in the residual graph Gfiis at most O(n2/3W). Since\neach iteration of blocking ﬂow increases the ﬂow value by at l east 1, it follows that the algorithm\ncan perform at most O(n2/3W) additional iterations before termination. Therefore, th e algorithm\nterminates after at most O(n2/3W) iterations in total.\n4.3 Implementing Dinitz’s Algorithm via BIS Queries\nNow we implement Dinitz’s blocking ﬂow algorithm [ Din06 ] in the cut query model.\nClaim 4.9. Given a ﬂow fsuch that distGf(s,t) =d′, we can compute a blocking ﬂow f′, augment\nthe ﬂow fwithf′, and recompute the residual graph using /tildewideO(n+d′·val(f′))BIS queries on Gf.\nProof. We ﬁrst construct the layered graph GLofGfby running BFS in /tildewideO(n) queries using\nCorollary 4.3. This gives us L0={s},...,Ld′={t}. The goal is to ﬁnd an s-tpath inGLeﬃciently\nusing a stack-based method.\nNext, we maintain a stack to track our search for an s-tpath. Initially, the stack contains {s}.\nAt each step, let the top element of the stack be u, whereu∈Li. We then attempt to ﬁnd v∈Li+1\nsuch that cf(u,v)>0. If such vexists, we can ﬁnd it using /tildewideO(1) queries by Lemma 4.1, and we\npushvonto the stack. If no such vexists, we pop ufrom the stack and remove ufrom the layered\ngraph, as ucannot send any ﬂow to the next layer.\nWhen the stack reaches a length of d′+ 1, this indicates that we have found an s-tpath. We\nadd this ﬂow path to f′, adjust the residual capacities along the path, and then res et the stack to\n{s}to search for another path. The process terminates when the s tack is empty, meaning there is\nno further ﬂow from sto any vertex in the next layer.\nNow we analyze the query complexity. In each step, we either p ush a new vertex onto the stack\nor pop one oﬀ and remove it from the graph. Each push or pop requ ires/tildewideO(1) queries. Whenever\nthe stack reaches length d′+1, we send ﬂow from stot, and the stack is reset, reducing its length by\nd′. The total length of the stack can increase by at most n+O(d′)·val(f′), as this is the maximum\nnumber of vertices and ﬂow pushes in the layered graph. There fore, the total number of queries is\nat most /tildewideO(n+d′·val(f′)).\nWe are now ready to prove the main result, Theorem 1.2.\nProof of Theorem 1.2.By Claim 4.9, a single blocking ﬂow iteration requires /tildewideO(n+d′·val(f′))\nqueries, where val( f′) represents the current ﬂow value, and d′is the distance from stotin the\nlayered graph. Therefore, to analyze the algorithm’s query complexity, we should consider three\nfactors: the total number of iterations, the ﬂow value, and t he distance. Balancing these factors is\nessential for optimizing the overall query complexity.\nBy Lemma 4.8, we know that the number of iterations is at most O(n2/3W). When the distance\nis less than n2/3, the ﬂow value is at most O(nW). Conversely, when the distance exceeds n2/3,\nthe remaining ﬂow value is at most O(n2/3W).\nThus, the total query complexity can be expressed as:\n/summationdisplay/tildewideO(n+d′·val(f′))≤O(n2\n3W)·/tildewideO(n) +/summationdisplay/tildewideO(d′·val(f′))\n8Breaking it down further:\n=/tildewideO(n5\n3W) +/summationdisplay\nd′<n2\n3/tildewideO(d′·val(f′)) +/summationdisplay\nd′≥n2\n3/tildewideO(d′·val(f′))\nFor the two cases:\n1. Ford′< n2\n3, we have\n/summationdisplay\nd′<n2\n3/tildewideO(d′·val(f′))≤n2\n3·O(nW) =/tildewideO(n5\n3W)\n2. Ford′≥n2\n3, we have\n/summationdisplay\nd′≥n2\n3/tildewideO(d′·val(f′))≤n·O(n2\n3W) =/tildewideO(n5\n3W)\nIt now follows that the total query complexity is at most /tildewideO(n5/3W), which proves the result.\n5 Global Min-cut Algorithm\nIn this section, we present our algorithm for ﬁnding global m in-cut, proving Theorem 1.1. We will\nfocus on obtaining the following threshold version of the re sult.\nTheorem 5.1. Given a graph Gand a parameter τ≤δ−1, there is an algorithm that either\n•returns a cut (C,V\\C)with size|∂C|at mostτ, or\n•certiﬁes that the global min-cut in Gmust have a size larger than τ\nin/tildewideO(n5/3)cut queries.\nNote that Theorem 1.1now follows immediately by binary search. If the global min- cut has size\nδ, we simply return the cut corresponding to of the minimum-de gree vertex. We ﬁx the parameter\nτthroughout this section.\nThe rest of this section is dedicated to proving Theorem 5.1. We ﬁrst give a crucial yet simple\nobservation that any dominating set must be separated by eve ry cut of size at most δ−1 in\nSection 5.1, and show how to eﬃciently compute the dominating set in Sect ion5.2. Then, we show\nhow to eﬃciently compute minimum isolating cuts of size at mo stτin the cut query model in\nSection 5.3.\nGiven these three subsections, we are ready to implement the global minimum cut algorithm of\n[LP20 ] in the cut query model. In high level, the algorithm starts b y computing a dominating set\nRand has two cases. If the minimum cut is unbalanced with respe ct toR, then we will compute\nminimum isolating cuts with respect to subsets of R(Section 5.4). Otherwise, if the minimum cut\nis balanced with respect to R, then we will compute expander decomposition with respect t oR\nin the cut query model (Appendix A) and use the decomposition to “sparsify” Rto be a smaller\nsubsetR′⊆Rthat is still separated by minimum cuts (Section 5.5).\n95.1 Dominating Sets are Separated by Small Cuts\nBelow, we show a simple and crucial observation: any dominat ing set must be separated by a cut\nof size at most δ−1.\nDeﬁnition 5.2. Given a graph G, a vertex R⊆Visc-separated if for every cut ( C,V\\C) of size\n|∂C|≤c, we have C∩R,R\\C/\\e}atio\\slash=∅. That is, Rhits both sides of the cut C.\nLemma 5.3. For any dominating set R⊆V,Risδ−1-separated, where δis the minimum degree.\nProof. Suppose for contradiction that this is not the case. Then the re is a cut ( C1,C2=V\\C1)\nof size at most δ−1 where R⊆C1. Now we have δ−1≥|E(C1,C2)|≥|E(R,C2)|≥|C2|\nwhere the last inequality is because Ris dominating. But every vertex in C2has degree at least δ,\ntherefore we must have |E(C1,C2)|≥|C2|(δ−(|C2|−1))≥δfor 1≤|C2|≤δ−1, which leads to\na contradiction.\nWe remark that the above lemma is the crucial place where we ex ploit that the graph is simple.\n5.2 Computing a Dominating Set\nIn this section, we show how to compute a dominating set eﬃcie ntly in the cut-query model.\nTheorem 5.4. There is a deterministic algorithm that ﬁnds a dominating set R⊆Vof size\n|R|≤/tildewideO(n\nδ)using/tildewideO(n)cut-queries.\nProof. We will ﬁrst state our algorithm, then prove its correctness , and ﬁnally analyze its complexity\nunder the cut query model.\nAlgorithm We construct Riteratively. Initially, we set G′=G,R=∅. We ﬁrst apply the\nfollowing reduction rule – as long as there is a vertex in v∈G′whose degree in G′is larger than\nδ\n2, we add it into Rand delete v∪NG′(v) fromG′.\nAfter exhaustively applying the above reduction rule, if V(G′)/\\e}atio\\slash=∅and there is no vertex in\nG′with a degree larger thanδ\n2, then we do the following. Consider the bipartite graph Hwhose\nvertex set is the bipartition W1∪W2, whereW1=NG(R) andW2=V(G′). The edge set of His\nthe edge set of Grestricted to the edges between W1andW2.\nFirst, observe that ∀u∈W2,|E(W1,u)|= deg(u)−|E(u,W2\\{u})|≥δ\n2, otherwise, this vertex\nwould have been considered in the previous step. Thus, we hav e|E(W1,W2)|=/summationtext\nu∈W2|E(W1,u)|≥/summationtext\nu∈W2δ\n2≥|W2|δ\n2. Then there exists a v∈W1such that|E(v,W2)|≥|E(W1,W2))|\n|W1|≥|W2|δ\n2|W1|≥|W2|δ\n2n.\nWe addvintoRand delete all its neighbors in G′. We repeat until V(G′) =∅, henceRmust be a\ndominating set.\nCorrectness It remains to bound the size of R. When there is a vertex in G′with degree larger\nthanδ\n2, we reduce|V(G′)|by at leastδ\n2each time. So we can add at most2n\nδsuch vertices into R.\nWhen no vertex in Ghas degree larger thanδ\n2, we remove at least |V(G′)|δ\n2nvertices from G′.\nThus the size of G′reduces by at least a 1 −δ\n2nfraction. Thus after O(n\nδ) iterations, the size of\nG′reduces by a constant factor, and hence this step can happen a t mostO(n\nδlogn) =/tildewideO(n\nδ) many\ntimes. In total, we have |R|≤2n\nδ+O(n\nδlog(n\nδ)) =/tildewideO(n\nδ).\n10Complexity First, we want to ﬁnd a vertex vwhose degree in G′is at leastδ\n2. Given a vertex\nw, we can ﬁnd the degree of winG′inO(1) queries. We enumerate each vertex w∈V(G′), and\nﬁnd its degree deg( w). If deg( w)<δ\n2, then we mark was irrelevant and continue. If deg( w)>δ\n2,\nthen we ﬁnd all its neighbors in G′using/tildewideO(deg(w)) queries using Lemma 4.1. Note that we delete\nall these neighbors of wfromG′. Let us charge the query cost uniformly to each vertex in deg( w),\nand note that each vertex receives a charge of /tildewideO(1). Observe that the degree of a vertex in G′is\nnon-increasing, thus irrelevant vertices remain irreleva nt.\nNow it remains to analyze the case when no vertex of G′has degree >δ\n2inG′. Recall that we\nwant to ﬁnd a vertex v∈W1such that|E(v,W2)|≥|E(W1,W2))|\n|W1|. We will use binary search. Divide\nW1into two (roughly) equal sized groups W11andW12. By Lemma 4.1, using/tildewideO(1) queries, we can\nﬁnd both E(W11,W2) andE(W12,W2). By simple averaging, either E(W11,W2)≥|E(W1,W2))|\n|W1||W11|\norE(W12,W2)≥|E(W1,W2))|\n|W1||W12|. Without loss of generality, assume the former. We now recur se\nonW11, and repeat the same process, till we reach a singleton verte xv∈W1, which must satisfy\n|E(v,W2)|≥|E(W1,W2))|\n|W1|.\nThe total number of cut queries is at most /tildewideO(1), since in each iteration we use /tildewideO(1) queries and\nthere are at most /tildewideO(1) iterations of the binary search. Therefore, the total qu ery complexity of\nﬁnding the dominating set is dominated by the query complexi ty of the reduction rule, and hence\nis at most /tildewideO(n).\n5.3 Computing Minimum Isolating Cuts\nThis section shows an eﬃcient algorithm for computing a mini mum isolating cut. Let us ﬁrst recall\nits deﬁnition below.\nDeﬁnition 5.5 (Minimum Isolating Cut) .For any set of vertices R⊆Vandr∈R, the minimum\nisolating cut of ris an{r}-(R\\{r}) min-cut. The minimum isolating cut (of R) is the minimum\nsized cut among the minimum isolating cuts over all r∈R.\nTheorem 5.6. Given an unweighted graph Gand a set of vertices R⊆Vsuch that|R|is at most\n/tildewideO(n\nτ), there is an algorithm that either\n•outputs a minimum isolating cut of Rof size at most τ, or\n•certiﬁes that the minimum isolating cut of Rhas a size larger than τ\nin/tildewideO(n5/3)cut queries.\nWe remark that the algorithm can be modiﬁed easily to output a n isolating cut for each r∈R\nwhose min-isolating cut has size at most τ.\nProof. First, we will state the algorithm, which follows the approa ch of [ LP20 ], adapted to our\nsetting. Then we will discuss its correctness, and ﬁnally ar gue about implementation and the query\ncost. We will use the concept of closest min-cuts . For two sets SandT, we say that an S-Tmin-cut\n(X,V\\X) is closest to Sif for any other S-Tmin-cut ( X′,V\\X′), we have X⊆X′.\n11Algorithm: Encode each vertex in Rusing a uniqueO(log|R|) dimensional bit vector. Next,\ncompute O(log|R|) diﬀerent bi-partitions of the vertices in R, where each bi-partition is obtained\nby selecting a coordinate cof the bit vector and grouping the vertices based on whether t hey have\n0 or 1 in the cthcoordinate. LetCbe the set of these bi-partitions. Note that each pair of dist inct\nverticesu,v∈Rwill be separated by at least one bi-partition in C.\nFor each of these O(log|R|) bi-partitions ( A,B)∈CofR,A∩B=∅, set up the following ﬂow\nproblem. Add two vertices ssource,ssinkto the vertex set of G. For each vertex a∈A, add an edge\n(ssource,a) with capacity τ+ 1. Similarly, for each b∈B, add an edge ( b,ssink) with capacity τ+ 1.\nEvery edge of Ghas a capacity of 1. Call the modiﬁed graph H. Find an ssource -ssinkmax-ﬂow in\nH.\nLetfA,Bbe this max-ﬂow and ( CA,CB=V(G)\\CA) be the restriction of the minimum cut\ncorresponding to this maximum ﬂow to G(we simply remove sandtfrom the cut to obtain CA,CB).\nConsider the graph G′after deleting every such cut, that is, we delete the edges ∂CAfor every\nbi-partition ( A,B)∈C. For each r∈R, deﬁneTr⊆V(G) to be the set of vertices reachable from\nrinG′. Further, let R′⊆Rbe the set of r∈Rwhich satisfy the following property – for every\nbi-partition ( A,B)∈C, ifr∈A, thenr∈CA, and ifr∈B, thenr∈CB. In other words, R′is\nthe subset of Rwhose edges to ssource orssinkare not saturated in any max-ﬂow fA,Bacross all\n(A,B)∈C(see Claim 5.7).\nLetT′\nr={r}∪(Tr\\R) for each r∈R′, we obtain a new capacitated graph GrfromGas follows.\nContract all vertices of V\\T′\nrinto vertex srwhile keeping parallel edges. Then, we compute the\nmin-cut between randsrinGr. We check if it is an isolating cut for r. Letλrbe the size of this\ncut (and let λr=∞if no such cut exists). Then we check if there exists an r∈R′withλr≤τ. If\nso, we output the corresponding cut. Otherwise, we declare t hat the minimum isolating cut for R\nhas a size larger than τ. This concludes the description of the algorithm.\nCorrectness: We now show the correctness of our algorithm. Note that our al gorithm is similar\nto [LP20 ], but we need to argue its correctness a bit more carefully si nce whenever we compute an\nA,Bmin-cut for a bi-partition, we set the capacities of the edge s incident to the source and sink\nvertices as τ+ 1 (instead of∞as in their setting). On a high level, this still works since w e are\nonly interested in the isolating cuts of size at most τ; if there is no isolating cut of size ≤τ, we\nwill simply output that this is the case. The next few lemmas f ormally show that our algorithm is\nindeed correct.\nClaim 5.7. For any bipartition (A,B)∈Cand any a∈A, we say that ais saturated if in the\nmaximum ﬂow fA,B, the edge (ssource,a)is saturated. Then if ais not saturated by fA,B, then\na∈CA. The same holds analogously for any b∈B.\nProof. Ifa /∈CA, then the edge ( ssource,a) is cut by the ( ssource,ssink) min-cut. But since a min-cut\nis saturated in any max-ﬂow, this means that amust be saturated, which is a contradiction.\nClaim 5.8. For each bi-partition (A,B),(CA,CB)is a minimum cut in Gthat separates CA∩A\nandCB∩B.\nProof. Since (CA,CB) is a restriction of the ssource -ssinkmin-cut, it follows that there exists a\nfeasible ﬂow in Gfrom vertices of CA∩Ato vertices of CB∩Bsaturating every edge of ∂CA. This\nﬂow certiﬁes that ( CA,CB) must be a minimum cut between CA∩AandCB∩BinG.\n12Claim 5.9. Consider some terminal r∈Rand let (Cr,V\\Cr)be the min-cut between {r}and\nR\\{r}wherer∈Cr, which is closest to r(that is, the closest isolating cut for r). If|E(Cr,V\\Cr)|≤\nτ, then the following statements must hold for every bipartit ion(A,B)∈C.\n•rcannot be saturated in the ﬂow fA,B.\n•Ifr∈A,Cr⊆CA. Likewise, if r∈B, we must have Cr⊆CB.\nProof. Consider a bi-partition ( A,B)∈C. Let us assume without loss of generality that r∈A,\nthe other case is symmetric. Since ( Cr,V\\Cr) is a cut of size at most τbetween randR\\{r},r\ncannot be saturated. Therefore, by Claim 5.7, we have r∈CA.\nNow, we will show that Cr⊆CA. Suppose, for the sake of contradiction, that this is not the\ncase. Then by submodularity of cuts, we have:\n∂(Cr) +∂(CA)≥∂(Cr∩CA) +∂(Cr∪CA).\nSinceCris the minimum cut separating randR\\{r}, it follows that ∂(Cr)≤∂(Cr∩CA). Similarly,\nsince (CA,CB=V\\CA) is the minimum cut separating CA∩AandCB∩B(see Claim 5.8), we\nmust have ∂(CA)≤∂(Cr∪CA). Combining these results, we obtain the equalities:\n∂(Cr) =∂(Cr∩CA) and∂(CA) =∂(Cr∪CA).\nThis implies that Cr∩C(A), which is a subset of Cr, is also a minimum cut separating rfrom\nR\\{r}. This contradicts the fact that Cris the minimum cut between randR\\{r}that is closest\ntor.\nThe following lemma shows that across all vertices r∈R′, the sets Trare disjoint.\nLemma 5.10. For every distinct vertices r,r′∈R′, we have Tr∩Tr′=∅,r∈Tr, andr′∈Tr′.\nProof. Recall that each pair of distinct vertices in R′is separated by at least one of the bi-partitions\ndeﬁned by bit vectors. Without loss of generality, we can ass ume that there exists a bi-partition\n(A,B)∈Csuch that r∈Aandr′∈B. Sincerandr′are not saturated, by Claim 5.7, we have\nr∈CAandr′∈CB. But then the ( CA,CB) min-cut separates rfromr′, and hence Tr⊆CAad\nTr′⊆CB. It follows that Tr∩Tr′=∅.\nWe are now ready to prove the correctness of our algorithm. Su ppose there exists a terminal\nr∗∈Rwhose minimum isolating cut ( Cr∗,V\\Cr∗) satisﬁes E(Cr∗,V\\Cr∗)≤τ. Using Claim 5.9, it\nfollows that we must have Cr∗⊆Tr∗(Recall that Tr∗is deﬁned as the set of vertices reachable from\nr∗in the graph obtained after deleting the minimum cuts for eve ry bi-partition in C). Furthermore,\nby the deﬁnition of isolating cut, we know that Cr∗∩R={r∗}, therefore Cr∗⊆T′\nr∗Hence, the\nminimum r∗-sr∗cut inGr∗is of size at most τ. Also by the deﬁnition of R′, we must have r∗∈R′.\nSince our algorithm ﬁnds an r-srmin-cut for each r∈R′, and we have r∗∈R′, the output cut\nmust be a minimum isolating cut for some r∈Rof size at most τ.\n13Query complexity: For each bi-partition ( A,B)∈C, we construct the auxiliary graph Hand\ncompute an ssource -ssinkmaximum ﬂow. For each edge ( ssource,a),a∈Awith capacity τ+ 1, we\nreplace it with τ+ 1 parallel edges each with capacity 1. We then sub-divide ea ch of these edges\nby adding an additional vertex. For each edge ( b,ssink) whereb∈B, we do the same. Then the\nresulting graph is simple, has at most O(n+|R|τ) =O(n) nodes, and every edge has unit capacity.\nBy Theorem 1.2, we can compute an ssource -ssinkmax-ﬂow in this graph using /tildewideO(n5/3) queries.\nThe (restriction to Gof the) min-cut ( CA,CB) can be obtained as follows. Once we obtain a\nmaximum ﬂow fA,Bwe letCAbe the set of vertices reachable from sin the residual graph GfA,B,\nand letCB=V(G)\\CA. We can obtain CAby applying Corollary 4.3to ﬁnd a BFS tree with root\nnodessource inGfA,Bwith/tildewideO(n) queries. Once we know ( CA,CB) for each bi-partition ( A,B)∈C,\nwe can ﬁnd the sets Trfor each r∈R. We can then identify the set R′. For each r∈R′we\nconstruct the graph Gr, and ﬁnd an r-srclosest min-cut in Gr. To ﬁnd this min-cut, we obtain a\nmax-ﬂow and ﬁnd the set of vertices reachable from r. The next lemma shows that we can do this\nwithout using too many queries.\nLemma 5.11. We can compute r-srmax ﬂow (min cut) in Grusing/tildewideO(|T′\nr|5/3)queries.\nProof. All ﬂow goes from rtosrcan be divided into two cases\n1. Directly goes from rtosrthrough edge ( r,sr)\n2. First go through an edge ( r,u), where u∈T′\nr\\{r}, and then goes from utosr\nIt’s relatively easy to compute the ﬂow in the ﬁrst case by cal culating the weight of ( r,sr),\nwhich is|E(r,V\\Tr)|and can be determined with O(1) queries. Notice that in the residual graph,\nall ﬂows are the second case. The ﬂow size of the second case is at most|E(r,T′\nr\\{r})|≤|T′\nr|−1,\nsince each ﬂow must use an edge between rtoCr\\{r}. Then by Theorem 1.2, we can compute it\nin/tildewideO(|T′\nr+ 1|5/3) =/tildewideO(|Tr|5/3) queries.\nBy Lemmas 5.10 and5.11, the total query complexity for ﬁnding r-srmin-cuts for every r∈R′\nis bounded by/summationtext\nr∈R′/tildewideO(|Tr|5/3) =/tildewideO(n5/3). The ﬁnal equality holds since the sets Tr,r∈R′, are\ndisjoint from each other, ensuring/summationtext\nr|Tr|≤n. This concludes the proof of Theorem 5.6.\n5.4 Unbalanced Case\nIn this section, we show how to ﬁnd a cut of size at most τwhen this cut is unbalanced with respect\nto a given terminal set R⊆Vthat isτ-separated.\nDeﬁnition 5.12 (Unbalanced/Balanced Cut) .For any set of vertices R⊆V, a cutC= (C1,C2=\nV\\C1) with size at most τ, and a parameter φ≥poly(1\nlogn), we say that Cisφ-unbalanced for R\nif min{|C1∩R|,|C2∩R|}≤ (1\nφ)3+1\nφ, otherwise we say that Cisφ-balanced for R.\nThe goal of this subsection is to prove the following theorem .\nLemma 5.13. LetR⊆Vbeτ-separated and|R|≤/tildewideO(n\nτ). If there is a cut (C,V\\C)of size at\nmostτthat isφ-unbalanced for Rfor some φ≥poly(1\nlogn), then we can ﬁnd a cut with size at\nmostτin/tildewideO(n5/3)queries.\nWe need the following tool called splitter for essentially deterministic subsampling vertices.\n14Lemma 5.14 (Theorem 4.3 from [ LP20 ]).For every positive integer nandk < n, there is a\ndeterministic algorithm that constructs a family Fof subsets of [n]such that, for each subset\nS⊆[n]of size at most k, there exists a set S′∈Fwith|S∩S′|= 1. The familyFhas size\nkO(1)lognand contains only sets of size at least 2.\nProof of Lemma 5.13.LetFbe the family of subsets of Rfrom Lemma 5.14 such that, for any\nunbalanced cut C, there is a R∗∈Fwith|R∗∩C|= 1. Note that|F|= [(1\nφ)3+1\nφ]O(1)log|R|=/tildewideO(1).\nThen we run the algorithm of Theorem 5.6for each set inF. SinceR∗∈F, the algorithm will\nsuccessfully conclude that the isolating cut for R∗is of size at most τ. The total number of queries\nis|F|·/tildewideO(n5/3) =/tildewideO(n5/3).\n5.5 Balanced Case\nWe say that Risφ-balanced if every cut ( C,V\\C) of size|∂C|≤τisφ-balanced for R. In the\nprevious section, if Risτ-separated, but not φ-balanced, then Lemma 5.13 will ﬁnd a cut of size\nat mostτfor us. In this section, we handle the case when Risτ-separated and φ-balanced using\nthe following lemma.\nLemma 5.15. Suppose that Risτ-separated and φ-balanced. Then, we can make /tildewideO(n5/3)cut\nqueries and either\n•ﬁnd a set /tildewideRsuch that|/tildewideR|≤O(φ|R|log6n) +|R|\nlognand/tildewideRisτ-separated, or\n•ﬁnd a cut in Gwith cut-size at most τ.\nTowards proving this key lemma, we begin by introducing the n otion of expanders and expander\ndecomposition that we need.\nDeﬁnition 5.16 ((φ,R)-expander) .Given a graph Gand a terminal set R⊆V,Gis a (φ,R)-\nexpander if for every cut ( S,V\\S), we have\nΦ(S) =|∂S|\nmin{|R∩S|,|R\\S|}≥φ(τ+ 1)\nWe work with graphs with a slightly weaker notion of expansio n, which we call ( φ,R)-almost\nexpanders.\nDeﬁnition 5.17. Given a graph G= (V,E) and a terminal set R⊆V,Gis a (φ,R) almost-\nexpander with core R′ifR′⊆R,|R′|≥|R|(1−1\nlogn), and for any cut ( S,V\\S) inG, we have\nΦ(S) =|∂S|\nmin{|R′∩S|,|R′\\S|}≥φ(τ+ 1)\nOur next and crucial step in this section is to obtain a decomp osition into ( φ,R)-almost ex-\npanders. We defer this proof to Appendix Asince this proof is mostly standard.\nAt a high level, the algorithm combines an implementation of the cut-matching game [ KKOV07 ]\ntogether with the expander pruning technique [ SW19 ]. The cut player trivially needs zero queries\nsince the auxiliary graph will be explicitly maintained. Th e matching player applies our algorithm\nfors-tmaximum ﬂow. This takes /tildewideO(n5/3) queries. Similar to the ﬂow instance in Theorem 5.6,\nwe send ﬂow between terminal set Rof size/tildewideO(n\nτ) and each terminal sends at most τ+ 1 units of\nﬂow. So the maximum ﬂow is at most /tildewideO(n) and, hence, our ﬂow algorithm from Theorem 1.2uses\n/tildewideO(n5/3) queries. The formal statement is summarized below:\n15Lemma 5.18. Given a graph G= (V,E)and a terminal set R⊆Vwith|R|≤/tildewideO(n\nτ)and a\nparameter φ= poly(1\nlogn), one can ﬁnd a partition of the vertex set Vinto subsets V1,V2,...,V k,\nwhereRi=Vi∩Rfor each i∈[k], and further obtain sets R′\n1⊆R1,R′\n2⊆R2,...,R′\nk⊆Rkusing\n/tildewideO(n5/3)queries such that\n1. Each G[Vi]is a(φ,Ri)almost expander with core R′\ni.\n2. The number of crossing edges/summationtext\ni/\\e}atio\\slash=jE(Vi,Vj) =O(φ|R|(τ+ 1) log6n).\nAfter obtaining this decomposition, we classify each part a s follows.\nDeﬁnition 5.19. For each set Vi,i∈[k], we say that Viis\n1. empty, if R′\ni=∅\n2. small, if 1≤|R′\ni|≤(1\nφ)2\n3. large, if|R′\ni|>(1\nφ)2\nNow, we construct /tildewideRas follows:\n1. Include every vertex of Ri\\R′\niin/tildewideR, for each i∈[k].\n2. For each Vi,i∈[k],\n•if it is empty, do nothing;\n•if it is small, add an arbitrary vertex of R′\nito/tildewideR;\n•else if it is large, add 1 +1\nφarbitrary vertices of R′\nito/tildewideR.\nLemma 5.20. Suppose that Risτ-separated and φ-balanced. If|∂Vi|≥τ+ 1for each Vi, then\n|/tildewideR|≤O(φ|R|log6n) +|R|\nlognand/tildewideRisτ-separated.\nProof. Since|∂Vi|≥τ+ 1 and/summationtext\ni/\\e}atio\\slash=jE(Vi,Vj) =O(φ|R|(τ+ 1) log6n), the number of subsets is\nbounded by k≤O(φ|R|log6n). Therefore, the total number of vertices in /tildewideR∩R′\niacross all small\nViis at most O(φ|R|log6n).\nFor each large Vi, observe that we pick only an O(φ) fraction of R′\nito add to /tildewideR. Additionally,\nfor each i, we have|Ri\\R′\ni|≤|Ri|\nlogn. Combining these results, we have\n|/tildewideR|≤|R|\nlogn+O(φ|R|log6n)\nas desired. Now we show that /tildewideRmust be τ-separated.\nAssume, for the sake of contradiction, that /tildewideRis notτ-separated. This implies the existence of\na cutC= (C1,C2=V(G)\\C1) with cut-size ∂C≤τsuch that /tildewideR⊆C1. We will demonstrate that\nthis cutCmust be φ-unbalanced for R, contradicting our assumption that Risφ-balanced.\nBefore we proceed further, we will show that, in this case, C2must contain the “smaller” side\nof every large Vi. The next lemma will clarify this point.\nClaim 5.21. IfC2∩/tildewideR=∅, then for any large Vi,i∈[k], we must have|R′\ni∩C2|≤|R′\ni∩C1|.\n16Proof. SinceViis a (φ,Ri) almost-expander with core R′\niand (C1,C2) is a cut with cut-size at\nmostτ, we must have min {|R′\ni∩C1|,|R′\ni∩C2|}≤τ\nφ(τ+1)≤1\nφ.\nThus if|R′\ni∩C1|≤|R′\ni∩C2|, then|R′\ni∩C1|≤1\nφ. Recall that we picked 1 +1\nφvertices from\nR′\niand added them to /tildewideR. It then follows that at least one vertex of R′\ni∩C2was added to /tildewideR, and\nhence/tildewideR∩C2/\\e}atio\\slash=∅, which is a contradiction.\nNow, we show that Cisφ-unbalanced for R. First, observe that/summationtext\nlargeVi|R′\ni∩C2| ≤1\nφ;\notherwise,\n|∂C|≥/summationdisplay\nlargeViφ(τ+ 1) min{|R′\ni∩C1|,|R′\ni∩C2|}=φ(τ+ 1)/summationdisplay\nlargeVi|R′\ni∩C2|≥τ+ 1.\nwhere equality holds by Claim 5.21.\nSecond, the number of small Visatisfying R′\ni∩C2/\\e}atio\\slash=∅must be at most1\nφ; otherwise,\n|∂C|≥/summationdisplay\nsmallViφ(τ+ 1) min{|R′\ni∩C1|,|R′\ni∩C2|}≥/summationdisplay\nsmallVi,R′\ni∩C2/\\e}atio\\slash=∅φ(τ+ 1)≥τ+ 1\nwhere we use the fact that |R′\ni∩C1|≥1, otherwise we must pick a vertex in R′\ni∩C2into ˜R, which\nis a contradiction.\nIn total, we have\n|R∩C2|=/summationdisplay\ni∈[k]|R′\ni∩C2|≤/summationdisplay\nlargeVi|R′\ni∩C2|+/summationdisplay\nsmallVi,|R′\ni∩C2|/\\e}atio\\slash=∅|R′\ni∩C2|≤1\nφ+ (1\nφ)3\nwhere the equality holds because ( Ri\\R′\ni)∩C2=∅for anyi∈[k]; otherwise, we have C2∩/tildewideR/\\e}atio\\slash=∅.\nThis implies that Cisφ-unbalanced for R, contradicting that Risφ-balanced.\nWe are now ready to prove Lemma 5.15.\nProof of Lemma 5.15.First, we compute a ( φ,R) almost-expander decomposition using Lemma 5.18,\nwhich results in the sets V1,V2,...,V k,R1,R2,...,R kand the cores R′\ni⊆Rifor each i∈[k].\nNext, we make /tildewideO(n) queries to determine if there exists a set Visuch that|∂Vi|≤τ. If such a\nset exists, we return this cut and terminate.\nIf no such set exists, we construct /tildewideR⊆Ras described previously. In this case, since |∂Vi|≥τ+1\nfor eachi∈[k], Lemma 5.20guarantees that|/tildewideR|≤O(1\nφ|R|log6n)+|R|\nlognand that /tildewideRisτ-separated.\nThen, we can return /tildewideRas desired.\nTheorem 5.1now follows by combining Lemma 5.13 and Lemma 5.15.\nProof of Theorem 5.1.We begin by computing a dominating set Rusing Theorem 5.4.\nNow let φ= 1/log10n. Using both Lemmas 5.13 and5.15 with the set Ras the terminal set,\nwe proceed in one of two ways: if we ﬁnd a cut with size at most τin/tildewideO(n5/3) queries, then we are\ndone. Otherwise, if we ﬁnd a subset R′⊆Rsuch that|R′|≤1\n2|R|andR′is stillτ-separated. We\nreplaceRbyR′and recursively continue the algorithm till we either ﬁnd a c ut of size at most τ,\nor conﬁrm that no such cut exists.\n17Since at each step |R′|≤1\n2|R|by the choice of φ, so the recursion can proceed for at most\nO(log|R|) =/tildewideO(1) iterations. This process guarantees that we will eventu ally ﬁnd a cut of size at\nmostτor declare that no such cut exists. Finally, note that the tot al query complexity is /tildewideO(n5/3)\nsince we make at most /tildewideO(1) calls to the subroutines in Lemmas 5.13 and5.15.\n6 Conclusion\nWe show the ﬁrst subquadratic deterministic algorithms for thes-tminimum cut and global mini-\nmum cut problems in simple graphs, both using /tildewideO(n5/3) cut queries. Nevertheless, there remains\na considerable gap between our results and the current lower bound of Ω( n) [HMT88 ]. Improving\nthe lower bound to ω(n) is very interesting as it would separate deterministic and randomized cut\nquery complexity for the global min-cut problem.\nFor the upper bound side, algorithms using /tildewideO(n) queries would be exciting. This algorithm\nmust be very diﬀerent from ours because we explicitly compute a maximum s-tﬂow and the ﬂow\nof value νmay have representation size as large as Ω( n√ν) = Ω(n1.5) even on simple unweighted\ngraphs. In fact, it is known that, given any simple unweighted graph Gwhere the maximum s-t\nﬂow value is ν, there exists a subgraph H⊆GwithO(n√ν) edges such that the maximum s-tﬂow\ninHhas the same value as the one in Gand this bound is tight (see, e.g., [ KL98 ,RSW18 ]). Thus,\nit is interesting whether there is a (near-optimal) algorit hm for explicitly computing maximum s-t\nﬂow in a simple unweighted graph using /tildewideO(n√ν) cut queries. Through our framework, this would\nimmediately imply a global min-cut algorithm using /tildewideO(n1.5) cut queries, reaching the barrier of\nthis approach.\nIt is interesting to generalize our result to weighted graph s or just non-simple unweighted graphs.\nOur technique does not work because Lemma 5.3is speciﬁc to simple unweighted graphs.\nReferences\n[AAL21] Simon Apers, Arinta Auza, and Troy Lee. A sublinear t ime quantum algorithm for\nst minimum cut on dense simple graphs. arXiv preprint arXiv:2110.15587 , 2021. 2\n[AB23] Daniel Anderson and Guy E Blelloch. Parallel minimum cuts in o (m log2 n) work\nand low depth. ACM Transactions on Parallel Computing , 10(4):1–28, 2023. 1\n[ACK21] Sepehr Assadi, Deeparnab Chakrabarty, and Sanjeev Khanna. Graph connectivity\nand single element recovery via linear and or queries. In 29th Annual European\nSymposium on Algorithms (ESA 2021) . Schloss-Dagstuhl-Leibniz Zentrum f¨ ur Infor-\nmatik, 2021. 2\n[AD21] Sepehr Assadi and Aditi Dudeja. A simple semi-stream ing algorithm for global\nminimum cuts. In Symposium on Simplicity in Algorithms (SOSA) , pages 172–180.\nSIAM, 2021. 1,2\n[AEG+22] Simon Apers, Yuval Efron, Pawe/suppress l Gawrychowski, Troy Lee , Sagnik Mukhopadhyay,\nand Danupon Nanongkai. Cut query algorithms with star contr action. In 2022\nIEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS) , pages\n507–518. IEEE, 2022. 1,2\n18[AL21] Arinta Auza and Troy Lee. On the query complexity of co nnectivity with global\nqueries. arXiv preprint arXiv:2109.02115 , 2021. 2\n[ARV09] Sanjeev Arora, Satish Rao, and Umesh Vazirani. Expa nder ﬂows, geometric em-\nbeddings and graph partitioning. Journal of the ACM (JACM) , 56(2):1–37, 2009.\n23\n[BFS86] L´ aszl´ o Babai, Peter Frankl, and Janos Simon. Comp lexity classes in communication\ncomplexity theory. In 27th Annual Symposium on Foundations of Computer Science\n(sfcs 1986) , pages 337–347. IEEE, 1986. 2\n[BHPNR+18] Paul Beame, Sariel Har-Peled, Sivaramakrishnan Natara jan Ramamoorthy, Cyrus\nRashtchian, and Makrand Sinha. Edge estimation with indepe ndent set oracles. In\n9th Innovations in Theoretical Computer Science Conference (ITCS 2 018). Schloss\nDagstuhl-Leibniz-Zentrum fuer Informatik, 2018. 5\n[DEMN21] Michal Dory, Yuval Efron, Sagnik Mukhopadhyay, an d Danupon Nanongkai. Dis-\ntributed weighted min-cut in nearly-optimal time. In Proceedings of the 53rd Annual\nACM SIGACT Symposium on Theory of Computing , pages 1144–1153, 2021. 1\n[DHNS19] Mohit Daga, Monika Henzinger, Danupon Nanongkai, and Thatchaphol Saranurak.\nDistributed edge connectivity in sublinear time. In Proceedings of the 51st Annual\nACM SIGACT Symposium on Theory of Computing , pages 343–354, 2019. 1\n[Din06] Yeﬁm Dinitz. Dinitz’algorithm: The original versi on and even’s version. In Theoreti-\ncal Computer Science: Essays in Memory of Shimon Even , pages 218–240. Springer,\n2006. 2,6,7,8\n[Gab91] Harold N Gabow. A matroid approach to ﬁnding edge con nectivity and packing\narborescences. In Proceedings of the twenty-third annual ACM symposium on Theor y\nof computing , pages 112–122, 1991. 1\n[GG18] Barbara Geissmann and Lukas Gianinazzi. Parallel mi nimum cuts in near-linear\nwork and low depth. In Proceedings of the 30th on Symposium on Parallelism in\nAlgorithms and Architectures , pages 1–11, 2018. 1\n[GH61] Ralph E Gomory and Tien Chung Hu. Multi-terminal netw ork ﬂows. Journal of the\nSociety for Industrial and Applied Mathematics , 9(4):551–570, 1961. 1\n[GHN+23] Gramoz Goranci, Monika Henzinger, Danupon Nanongkai, T hatchaphol Saranurak,\nMikkel Thorup, and Christian Wulﬀ-Nilsen. Fully dynamic exa ct edge connectivity\nin sublinear time. In Proceedings of the 2023 Annual ACM-SIAM Symposium on\nDiscrete Algorithms (SODA) , pages 70–86. SIAM, 2023. 1\n[GK00] Vladimir Grebinski and Gregory Kucherov. Optimal re construction of graphs under\nthe additive model. Algorithmica , 28:104–124, 2000. 1,2\n[GZ22] Mohsen Ghaﬀari and Goran Zuzic. Universally-optimal distributed exact min-cut.\nInProceedings of the 2022 ACM Symposium on Principles of Distri buted Computing ,\npages 281–291, 2022. 1\n19[Har08] Nicholas James Alexander Harvey. Matchings, matroids and submodular functions .\nPhD thesis, Massachusetts Institute of Technology, 2008. 1\n[HLRW24] Monika Henzinger, Jason Li, Satish Rao, and Di Wang . Deterministic near-linear\ntime minimum cut in weighted graphs. In Proceedings of the 2024 Annual ACM-\nSIAM Symposium on Discrete Algorithms (SODA) , pages 3089–3139. SIAM, 2024.\n1\n[HMT88] Andr´ as Hajnal, Wolfgang Maass, and Gy¨ orgy Tur´ an . On the communication com-\nplexity of graph properties. In Proceedings of the twentieth annual ACM symposium\non Theory of computing , pages 186–191, 1988. 1,2,18\n[HO94] JX Hao and James B Orlin. A faster algorithm for ﬁnding the minimum cut in a\ndirected graph. Journal of Algorithms , 17(3):424–446, 1994. 1\n[HRW20] Monika Henzinger, Satish Rao, and Di Wang. Local ﬂow partitioning for faster edge\nconnectivity. SIAM Journal on Computing , 49(1):1–36, 2020. 1\n[JST24] Wenyu Jin, Xiaorui Sun, and Mikkel Thorup. Fully dyn amic min-cut of supercon-\nstant size in subpolynomial time. In Proceedings of the 2024 Annual ACM-SIAM\nSymposium on Discrete Algorithms (SODA) , pages 2999–3026. SIAM, 2024. 1\n[Kar94] David R Karger. Random sampling in cut, ﬂow, and netw ork design problems. In\nProceedings of the twenty-sixth annual ACM symposium on Theor y of computing ,\npages 648–657, 1994. 1\n[Kar00] David R Karger. Minimum cuts in near-linear time. Journal of the ACM (JACM) ,\n47(1):46–76, 2000. 1\n[KKOV07] Rohit Khandekar, Subhash Khot, Lorenzo Orecchia, and Nisheeth K Vishnoi. On\na cut-matching game for the sparsest cut problem. Univ. California, Berkeley, CA,\nUSA, Tech. Rep. UCB/EECS-2007-177 , 6(7):12, 2007. 15,22\n[KL98] David R Karger and Matthew S Levine. Finding maximum ﬂ ows in undirected\ngraphs seems easier than bipartite matching. In Proceedings of the thirtieth annual\nACM symposium on Theory of computing , pages 69–78, 1998. 18\n[KM94] David R Karger and Rajeev Motwani. Derandomization t hrough approximation:\nAn nc algorithm for minimum cuts. In Proceedings of the twenty-sixth annual ACM\nsymposium on Theory of Computing , pages 497–506, 1994. 1\n[KS96] David R Karger and Cliﬀord Stein. A new approach to the m inimum cut problem.\nJournal of the ACM (JACM) , 43(4):601–640, 1996. 1\n[KT18] Ken-ichi Kawarabayashi and Mikkel Thorup. Determin istic edge connectivity in\nnear-linear time. Journal of the ACM (JACM) , 66(1):1–50, 2018. 1\n[LC24] Hang Liao and Deeparnab Chakrabarty. Learning spann ing forests optimally in\nweighted undirected graphs with cut queries. In International Conference on Algo-\nrithmic Learning Theory , pages 785–807. PMLR, 2024. 2\n20[Li21] Jason Li. Deterministic mincut in almost-linear tim e. InProceedings of the 53rd\nAnnual ACM SIGACT Symposium on Theory of Computing , pages 384–395, 2021.\n1\n[LP20] Jason Li and Debmalya Panigrahi. Deterministic min- cut in poly-logarithmic max-\nﬂows. In 2020 IEEE 61st Annual Symposium on Foundations of Computer Sci ence\n(FOCS) , pages 85–92. IEEE, 2020. 1,3,9,11,12,15\n[MN20] Sagnik Mukhopadhyay and Danupon Nanongkai. Weighte d min-cut: sequential, cut-\nquery, and streaming algorithms. In Proceedings of the 52nd Annual ACM SIGACT\nSymposium on Theory of Computing , pages 496–509, 2020. 1\n[NI92] Hiroshi Nagamochi and Toshihide Ibaraki. A linear-t ime algorithm for ﬁnding\na sparse k-connected spanning subgraph of ak-connected gra ph.Algorithmica ,\n7(1):583–596, 1992. 1\n[RS95] Ran Raz and Boris Spieker. On the “log rank”-conjectu re in communication com-\nplexity.Combinatorica , 15:567–588, 1995. 2\n[RSW18] Aviad Rubinstein, Tselil Schramm, and S Matthew Wei nberg. Computing exact min-\nimum cuts without knowing the graph. In 9th Innovations in Theoretical Computer\nScience Conference (ITCS) , 2018. 1,18\n[RWZ20] Cyrus Rashtchian, David P Woodruﬀ, and Hanlin Zhu. Ve ctor-matrix-vector\nqueries for solving linear algebra, statistics, and graph p roblems. In Approximation,\nRandomization, and Combinatorial Optimization. Algorithm s and Techniques (AP-\nPROX/RANDOM 2020) . Schloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2020 .\n2\n[SW19] Thatchaphol Saranurak and Di Wang. Expander decompo sition and pruning: Faster,\nstronger, and simpler. In Proceedings of the Thirtieth Annual ACM-SIAM Sympo-\nsium on Discrete Algorithms , pages 2616–2635. SIAM, 2019. 15,24\n[Tho07] Mikkel Thorup. Fully-dynamic min-cut. Combinatorica , 27(1):91–127, 2007. 1\nA Computing Expander Decomposition: Proof of Lemma 5.18\nDeﬁnitions. Given a graph H= (V(H),E(H)), deﬁne the sparsity of a cut ( S,V(H)\\S) as\n|E(H,V(H)\\S)|\nmin{|S|,|V(H)\\S|}. Further, given a terminal set R, we deﬁne the sparsity with respect to Rof a cut\n(S,V(H)\\S) as|E(H,V(H)\\S)|\nmin{|S∩R|,|(V(H)\\S)∩R|}. We say that the set Risφ-expanding in Hif there is no\ncut (S,V(H)\\S) inHwhich has sparsity at most φwith respect to R. Further, Hisφ-expanding\nifV(H) isφ-expanding in H. We say that a cut ( S,V(H)\\S) isb-balanced with respect to Rif\nbothS∩Rand (V(H)\\S)∩Rhave size at least b|R|. For a set of vertices S⊆V(H), we deﬁne\nthe volume of S, volH(S), as the sum of the degrees of the vertices in SinH. The conductance\nof a cut ( S,V\\S) inHis deﬁned asE(S,V\\S)\nmin{volH(S),volH(V\\S)}. The conductance of His the minimum\nconductance across all such cuts. We drop the subscripts whe n the graph His clear from the\ncontext.\n21The following is the key subroutine we need for ﬁnding a decom position into ( φ,R) almost-\nexpanders.\nLemma A.1 (One-step of Expander Decomposition) .Given a graph G= (V,E), terminal set\nR⊆Vand parameters φ= poly(1\nlogn)andτ≥1such that|R|≤/tildewideO(n\nτ), using/tildewideO(n5\n3)queries we\ncan either\n•return a cut (S,S)that is (1\nlog5n)-balanced and (φτ)-sparse with respect to R.\n•return a set R′⊆Rof size|R′|≥(1−1\nlogn)|R|such that R′isφτ\nlog5n-expanding in G.\nBefore showing this crucial lemma, let us ﬁrst show why it imp lies Lemma 5.18.\nProof of Lemma 5.18.We start with the input graph Gand run the algorithm of Lemma A.1.\nIf Lemma A.1returns a cut ( S,S), then we recursively apply Lemma A.1onG[S] andG[S]. On\nthe other hand, if Lemma A.1returns a set R′, thenGis a (φ,R) almost expander with core R′.\nThe recursion depth for the ﬁrst case is at most log5nlog|R|, and every leaf of the recursion tree,\nwhere the second case occurs, together give us the decomposi tion into ( φ,R) almost expanders.\nThe argument about the number of crossing edges is a standard charging argument: Every time\nwe obtain a cut ( S,S), that is1\nlog5nbalanced and φ(τ+ 1) sparse with respect to R, we charge the\nnumber of cut edges to the terminals on the side of the cut with smaller number of terminals. Since\neach cut is φ(τ+ 1) sparse, each terminal r∈Rreceives a charge of at most φ(τ+ 1). Since every\ncut we ﬁnd is1\nlog5nbalanced, the recursion depth is at most log5nlog|R|, and hence a terminal is\ncharged at most log5nlog|R|≤log6ntimes. It follows that the number of cut edges is at most\nO(φ|R|(τ+ 1) log6n).\nWe now proceed to prove Lemma A.1. The key ingredient is the cut-matching game of\n[KKOV07 ]. Here, we state the cut-matching game where in ', 'raytos.r.bsinfotech@gmail.com', 'Aditya Anand, Thatchaphol Saranurak, Yunfan Wang', '', '../pdf_files/671b4c21d7e28-Deterministic Edge Connectivity and Max Flow using Subquadratic Cut Queries.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(134, '3500495012', '1', 1, 1, 'Recognizing Sumsets is NP-Complete', '2024-10-25', '2024', 'Sumsets are central objects in additive combinatorics. In 2007, Granville asked whether one can efficiently recognize whether a given set S is a sumset, i.e. whether there is a set A such that A +A = S. Granville suggested an algorithm that takes exponential time in the size of the given set, but can we do polynomial or even linear time? This basic computational question is indirectly asking a fundamental structural question: do the special characteristics of sumsets allow them to be efficiently recognizable? In this paper, we answer this question negatively by proving that the problem is NP-complete. Specifically, our results hold for integer sets and over any finite field. Assuming the Exponential Time Hypothesis, our lower bound becomes 2Ω(n1/4).', 'Data Structures and Algorithms, Computational Complexity, Discrete Mathematics', 'Recognizing Sumsets is NP-Complete\nAmir Abboud∗Nick Fischer†Ron Safier‡Nathan Wallheimer§\nAbstract\nSumsets are central objects in additive combinatorics. In 2007, Granville asked whether one\ncan efficiently recognize whether a given set Sis a sumset, i.e. whether there is a set Asuch\nthat A+A=S. Granville suggested an algorithm that takes exponential time in the size of\nthe given set, but can we do polynomial or even linear time? This basic computational question\nis indirectly asking a fundamental structural question: do the special characteristics of sumsets\nallow them to be efficiently recognizable? In this paper, we answer this question negatively by\nproving that the problem is NP-complete. Specifically, our results hold for integer sets and over\nany finite field. Assuming the Exponential Time Hypothesis, our lower bound becomes 2Ω(n1/4).\n1 Introduction\nAdditive combinatorics has been rising steadily towards becoming one of the most important\nbranches of mathematics for (theoretical) computer scientists. Its insights have catalyzed ma-\njor advances in diverse topics such as communication complexity [7, 34], randomness extractors [6],\ncoding theory [8], property testing [3, 38], graph sparsification [29, 1], worst-case to average-case\nreductions [5], fine-grained hardness of approximation [33, 2], and also in algorithm design for\nSubset-Sum [17, 12, 14], Knapsack [19, 11, 32], 3-SUM [18], and sparse convolutions [13]. The\nsurveys [40, 42, 9, 36] include many other references and applications.\nThesumset of a set Ais the set of all pairwise sums A+A:={a+b:a, b∈A}, and a set S\nis called a sumset if there exists a set Asuch that A+A=S. Sumsets are a central object in\nadditive combinatorics; a field that is often defined (e.g. in Wikipedia) “by example” while referring\nto fundamental results relating the properties of sets to those of their sumsets.\nIn this work, we are interested in computational problems in additive combinatorics. Perhaps\nthe first question one might ask is whether a given set is a sumset.\nDefinition 1.1 (The Sumset Recognition Problem) .Given a set S⊆Gover a group Gof size n\n(e.g. the integers {1, . . . , n }orFd\npwhere pd=n) decide whether there exists a set A⊆Gsuch that\nS=A+A.\nIn 2007, the additive combinatorics community published a document enumerating dozens of\nopen questions [23]. The only computational question on the list, suggested by Andrew Granville,\nconcerns the Sumset Recognition problem (Problem 4.11, “Recognizing sumsets algorithmically”).\n∗Weizmann Institute of Science and INSAIT, Sofia University “St. Kliment Ohridski”. This work is part of the\nproject CONJEXITY that has received funding from the European Research Council (ERC) under the European\nUnion’s Horizon Europe research and innovation programme (grant agreement No. 101078482). Supported by an\nAlon scholarship and a research grant from the Center for New Scientists at the Weizmann Institute of Science.\n†INSAIT, Sofia University “St. Kliment Ohridski”. Partially funded by the Ministry of Education and Science of\nBulgaria’s support for INSAIT, Sofia University “St. Kliment Ohridski” as part of the Bulgarian National Roadmap\nfor Research Infrastructure. Parts of this work were done while the author was at Weizmann Institute of Science.\n‡Weizmann Institute of Science.\n§Weizmann Institute of Science.\n1arXiv:2410.18661v1  [cs.DS]  24 Oct 2024Granville’s Question. Is there an efficient algorithm for the Sumset Recognition problem?\nA naive algorithm solves the problem in exponential 2n·n2time by enumerating all 2nsub-\nsetsA⊆Gof the group, computing their sumset A+Ain quadratic time, and checking whether it\nequals the given set S. When raising the question, Granville observed that one can limit the search\nspace to subsets of the given set, which leads to a 2|S|upper bound. But does there exist a much\nfaster strategy? Is there a polynomial time, or even a linear time algorithm?\nWhile being a purely computational question, Granville is asking a fundamental question about\nthe structure of sumsets, as pointed out in a joint paper [4] with Alon and Ubis: “ Perhaps (though\nthis seems unlikely) any sumset contains enough structure that is quickly identifiable? Perhaps most\nnon-sumsets are easily identifiable in that they lack certain structure? ”\nDespite the piquing interest in additive combinatorics among computer scientists, including the\nbreakthrough by computer scientists [35] on a central (non-computational) question of the field,1\nGranville’s question has remained open and was recently raised again in a MathOverflow post [41].\nOne intuitive explanation for the difficulty in settling the complexity of Sumset Recognition is\nthat it is a factoring -type of problem. In theFactoring problem, which is famously elusive of the\nP vs. NP-Hard classification, we are given an integer x=p·q, where p, qare unknown primes,\nand are asked to find p, q. Replacing the multiplication operation over integers with the sumset\noperation (or Minkowski sum ) over sets, we get a variant of our problem.2How does changing the\noperation affect the complexity?\n1.1 Results\nThis paper gives a negative answer to Granville’s question, proving that the Sumset Recognition\nproblem is NP-hard. This gives formal support for the intuition of Alon, Granville, and Ubis that\nsumsets are not structured enough to allow for fast identification.\nTheorem 1.2. The Sumset Recognition problem over Zis NP-complete.\nWhile the proof can be viewed as yet another “gadget reduction”, its high-level structure and\nimplementation level gadgets are quite novel and specific to the special structure of sumsets. In\nparticular, we rely crucially on results from additive combinatorics such as constructions of Sidon\nsets; while such tools have become commonplace in theoretical computer science (e.g. in the\naforementioned areas) we are not aware of any previous NP-completeness reduction that uses\nthem.3We are hopeful that our reduction framework will spur more results on the complexity\nof additive combinatorics questions.\nThe proof is via a reduction from 3-SAT on Nvariables and clauses to Sumset Recognition\non a set of |S|=O(N4) integers in an interval of size |G|=O(N4). This not only proves the\nNP-hardness in terms of the parameter n=|S|but also in terms of n=|G|as in Definition 1.1,\nwhich is a stronger statement.\nThe next theorem shows that the reduction can be implemented with additions in any finite\nfield; which are the most standard abelian groups in additive combinatorics.\nTheorem 1.3. For any prime p, the Sumset Recognition problem over Fd\npis NP-complete.\n1Notably, the result by Kelley and Meka [35] on 3-term arithmetic-progression-free sets resolves the very first\nproblem in the aforementioned list [23].\n2We get the variant where given S=A+Bwe are asked to return A′, B′̸={0}such that A′+B′=S. For\nconciseness, we focus this paper on the basic A+Aversion of Granville’s question (and on recognition rather than\nfactoring). Intuitively, the other variants are only harder.\n3The related Behrend sets have been used in some fine-grained hardness reductions from the 3-SUM problem [26]\nand in a barrier for compressing SAT instances [25] but these settings are very different.\n2The proof uses a similar high-level approach to the one for integers, but the different properties\nof fields compared to integers (e.g. that there might be elements xwith 2 x= 0) cause significant\nnew challenges at the implementation level.\n1.2 Related Work\nThe question of covering a set Sby a sumset A+Awith an Athat has minimal size has received\nconsiderable attention in the literature, both mathematically where the minimal size to cover the\nintegers {1, . . . , n }is not known [37, 15], and algorithmically where parameterized and approxi-\nmation algorithms have been studied [28, 15]. A related problem that has arisen in applications\nrelated to radiation therapy is to cover a given set Swith the set of all subset sums of a set Xof\nminimal size [22]. Both aforementioned problems were shown to be NP-Hard by reductions that\nare much less involved than ours, heavily utilizing that one is looking for the minimal set.\nA very recent paper by Chen, Nadimpalli, Randolph, Servedio, and Zamir [20] studies the query\ncomplexity of the same problem from Granville’s question, in the property testing model. They\nprove a lower bound of Ω(√n) on the number of element queries to a set Sin an abelian group\nof size nthat are required to test whether Sis a sumset or ε-far from being one. Needless to say,\ntheir (sublinear) result does not say whether the computational time complexity of the problem is\nlinear, polynomial, or exponential.\n1.3 Technical Overview\nIn this section, we give an intuitive overview of the new ideas leading to our results. We will\nmainly focus on the NP-hardness of the integer Sumset Recognition problem, which already requires\nmany of our insights. As may be expected, we prove NP-hardness by designing a polynomial-time\nreduction from the classical 3-SAT4problem to Sumset Recognition. That is, given a 3-SAT\nformula ϕonnvariables, our task is to create a set Xϕ⊆[poly( n)] such that we can express\nXϕ=A+A, for some set A, if and only if ϕis satisfiable.\nWe will present a conceptually natural approach that, as we will see later, requires significant\ntechnical work to work out. The baseline idea is to construct a set Xϕsuch that each feasible set A,\nin the sense that A+A=Xϕ, encodes an assignment. Then, in a second step, we will modify\nthis construction in accordance with the input formula, such that only the sets Acorresponding to\nsatisfying assignments remain.\nStep 1: Encoding Assignments. Following this general idea, the first step is to construct a\nvariable gadget, which is a constant-sized set Vthat can be expressed as the sumset of exactly two\nsetsV0andV1(i.e., V=V0+V0=V1+V1). We will interpret V0as the 0-assignment and V1as\nthe 1-assignment of a variable. For technical reasons that will become clear later, we also require\nthat there are two elements v0∈V0\\V1andv1∈V1\\V0.5Then, we assemble Xϕto be a set of n\n4We quickly recall the 3-SAT problem: The input consists of a 3-CNF formula ϕonnvariables x1, . . . , x n. That\nis,ϕconsists of mclauses , each of which consists of three literals taking form xiorxi. An assignment α∈ {0,1}n\nsatisfies a positive literal xiifαi= 1 and a negative literal xiifαi= 0. The assignment satisfies a clause if it satisfies\nat least one of its literals, and it satisfies ϕif it satisfies all clauses. The 3-SAT problem is to decide whether there is\na satisfying assignment of ϕ.\n5Using a computer search, we have identified the smallest gadget that fits these requirements: V={0, . . . , 18}\\{5},\nV0={0,1,2,6,7,8,9},V1={0,1,3,6,7,8,9},v0= 2 and v1= 3. However, equipped with the “positioning” and\n“masking” tools that we develop soon, we can find a significantly simpler and understandable gadget. See Section 5\nfor more details.\n3appropriately shifted copies of V:\nXϕ=[\ni∈[n](V+ 2si).\nThe hope is that the sumset roots of Xϕare in one-to-one corresponds with assignments α∈ {0,1}n,\nand have the form\nAα=[\ni∈[n](Vαi+si).\nThis looks promising, as indeed the shifted set V+2sihas two unique sumset roots, namely V0+si\nandV1+si. However, a major problem with this approach is that Aα+Aαalso contains cross terms\nof the form si+sj+Vαi+Vαj, fori̸=j. These cross terms also have to be included into Xϕ—but\nof course, we cannot “hardcode” any variable assignment Vαi. That is, for each i, jwe need to add\nsi+sj+Vαi+VαjtoXϕwithout knowing whether each of VαiandVαjisV0orV1. This puts us\nin a precarious situation: In order to build Xϕoblivious to the assignment, we would have to find\na variable gadget Vwith sumset roots V0andV1, i.e. V=V0+V0=V1+V1, which additionally\nsatisfies that V=V0+V1. If we could do this, we could simply add si+sj+VtoXϕfor all i, j.\nUnfortunately, this seems too much to ask for, and we could not find such a gadget. Our actual\nsolution for the cross terms is significantly more involved and uses non-trivial constructions from\nadditive combinatorics. We will describe it towards the end of this overview; for now, let us ignore\nthe problematic cross terms and continue with the general picture.\nStep 2: Enforcing Satisfying Assignments. The second step is to include the mclauses into\nthe construction of Xϕto make sure that only the roots Aαcorresponding to satisfying assign-\nments αsurvive. Our approach is as follows: Let t1, . . . , t mdenote a fresh set of shifts. To encode\nthe clauses, we would like to force Aαto also include the sets Ckdefined as follows:\nCk=[\nxiappears\npositively in\nthek-th clause.{tk−si−v1} ∪[\nxiappears\nnegatively in\nthek-th clause.{tk−si−v0}\nNote that these sets depend on the formula ϕbut not on the assignment α. While in the reduction we\ncontrol Xϕbut not Aα, we would like to add certain elements to Xϕthat will force any feasible Aα\nto include all Ck’s. At the very least, we have to add all elements inS\nk,ℓ(Ck+Cℓ) toXϕ. In\naddition, and this is key, we insert all elements t1, . . . , t mintoXϕ. Our intention is to force that\ntk∈Aα+Aαif and only if αsatisfies the k-th clause. Indeed, if the k-th clause is satisfied by a\npositive literal xi(i.e.,αi= 1), then, recalling that si+v1∈Aα, we have tk= (v1+si)+(tk−si−v1)∈\nAα+Aα. And similarly, if it is satisfied by a negative literal xi(i.e., αi= 0) then since si+v0∈Aα\nwe have that tk= (v0+si) + (tk−si−v0)∈Aα+Aα.\nIdeally, this should complete the description of our reduction—however, due to various inter-\nesting challenges, the story does not end here. Specifically, we face two major problems, which we\nwill describe, along with our solutions, in the following paragraphs. For both of these problems,\nwe managed to find surprisingly clean, modular solutions in terms of the upcoming Lemmas 1.4\nand 1.5.\nProblem 1: Positioning. The first issue in this outline is how to prove the “completeness”\ndirection. I.e., given a set Awith Xϕ=A+A, can we guarantee that ϕis satisfiable? If the set A\n4takes the form Aαfrom before, for some assignment α, then this is plausible: We merely have\nto ensure that we can never spuriously express tjas the sum of two unrelated elements from Aα.\nThis can be achieved by choosing the set of shifts {s1, . . . , s n, t1, . . . , t m}to be a (slightly modified)\nSidon set , i.e., a set without non-trivial solutions to the equation a+b=c+d. See Section 5 for\nmore details.\nHowever, the more serious issue is that it is a priori not clear that Alooks like Aα. Could it\nnot happen that Alooks entirely obscure? To rule this out, we conceptually would like to enforce\nthat Aincludes only certain elements by requiring that A⊆Ufor some prespecified set U; we\nloosely refer to this constraint as “positioning A”. Then we could strategically choose Uto be in\nline with the sets Aα—and only these sets—by\nU=[\ni∈[n]((V0∪V1) +si)∪[\nk∈[m]Ck.\nAnd indeed, we show that the superset condition A⊆Ucan be enforced by suffering only constant\nblow-up in the universe size. Formally, we prove the following lemma:\nLemma 1.4 (Positioning for Z).LetX, U⊆ {0, . . . , n }. There is a set X′⊆ {0, . . . , 224n}that\ncan be constructed in time poly( n)and satisfying that:\n∃A⊆U:X=A+A if and only if ∃A′⊆Z:X′=A′+A′.\nThe idea behind the proof of Lemma 1.4 is as follows: We first design a skeleton set I⊆ {0, . . . , c }\nover some constant-size universe (in the lemma, c= 224). We require that (i) Iisprimitive , i.e.\nthat its sumset I+Icannot be expressed as J+Jfor some other set J. And (ii), Ishall contain\na specific constellation of integers tailored towards the following approach.\nIn the reduction, we will partition {0, . . . , cn }intocsuccessive length- nintervals and use the\nskeleton set Ifor determining which of these intervals should be non-empty in the set X′. Let X′\ni\ndenote the part of X′that falls into the i-th interval, and similarly define A′\ni. Then (i) implies that\nby choosing X′as a subset of the intervals associated to I+I(i.e., X′\ni̸=∅if and only if i∈I+I),\nwe can ensure that any set A′with X′=A′+A′is a subset of the intervals associated to I\n(i.e., A′\ni̸=∅if and only if i∈I).\nNext, in order to enforce that A⊆Uin addition to A+A=X, we will place copies of X,U,{0},\nand [2 n] at appropriately chosen intervals in X′that are informed by the property (ii) of the skeleton\nsetI. This, in turn, will force us to appropriately place copies of A, U,{0}, and [ n] inA′. In a\nbit more detail about property (ii), our skeleton set Icontains the constellation a, u, s −a, s−u\nfor some integers a, u, s that act independently (i.e., that satisfy no non-trivial equations, e.g.\ntheir pairwise sums are distinct) and that cannot be represented as the pairwise sum of elements\nfrom I. The insight is that by setting X′\n2a=XandX′\n2s−2a={0}andX′\ns=U, we in turn force\nthatA′\na+A′\na=XandA′\ns−a={0}and\n(A′\na+A′\ns−a)∪(A′\nu+A′\ns−u) =A′\na∪(A′\nu+A′\ns−u) =U.\nThe latter effectively enforces that A′\na⊆U; to get the equality the solution separately ensures\nthat ( A′\nu+A′\ns−u) =U. In particular, the set A=A′\nasatisfies exactly the two conditions X=A+A\nandA⊆U. We omit further details here, and instead refer to Section 3. Let us finally emphasize\nthat throughout, we have not optimized most constants and that the specific constant 224can likely\nbe dramatically lowered.\n5Problem 2: Masking (And Stopping the Infinite Game). The second major problem we\nhave to deal with is the problematic cross terms we encountered before. Recall that the issue was\nthat the set Aαas constructed before consists of several copies of variable and clause gadgets. In\nthe sumset Aα+Aα, our intention is that certain variables and clause gadgets interact (in the\nsense that the sums they cause are meaningful). However, the set Aα+Aαalso contains the cross\nterms caused by variable-variable, variable-clause, and clause-clause combinations. And even for\nthe relevant variable-clause combinations, we have to cover the elements tk±1, which might or\nmight not be present. For concreteness, focus again on the cross term Vαi+Vαj+si+sjfrom before,\ncaused by two variable gadgets. As already argued, we cannot simply include this set into Xϕas\nthis would force fixed values for the variables iandj.\nInstead, we follow a different idea, which we call “masking”: We will add to Aαeven more\nsetsM1, . . . , M s(so-called “masks”). The goal is that each cross term, say, Vαi+Vαj+si+sj, is\ncontained in a sumset Ma+Mb. In the simplest form, we choose the masks to be singleton sets and\nhit all unwanted cross term elements one by one. This requires some bookkeeping to make sure\nthat the masks do not interfere with the relevant positions, like tj.\nDisregarding these details, there is a fundamental conceptual flaw in this idea: By including\nmasks into Aα, we also introduce new cross terms involving these masks, e.g., Vαi+si+Ma. To\ncover these new cross terms, we would have to introduce even more masks, which in turn cause\nmore cross terms—and this game continues infinitely. Is this inherent, or is there any hope to\nsalvage this idea and stop the infinite game?\nPerhaps surprisingly, it turns out that by choosing the masks appropriately—singletons in the\nfirst iteration of the game and intervals in the second iteration—we can stop the game after two\niterations. The insight is that, with some extra work, after the first iteration all cross terms become\npredictable in the sense that we can determine their minimum and maximum elements. Then, using\nthat for any set A⊆ {0, . . . , n }we have A+{0, . . . , n }={min(A), . . . , max( A)+n}, after the second\niteration we can simply include all cross terms into Xϕwithout introducing new masks. The details\nof this idea turn out to be extremely technical.\nIn summary, we prove the following lemma:\nLemma 1.5 (Masking for Z).LetX, Y, U ⊆ {0, . . . , n }. There are sets X′, U′⊆ {0, . . . , 217n2}\nthat can be constructed in time poly( n)and satisfying that:\n∃A⊆U:X⊆A+A⊆Y if and only if ∃A′⊆U′:X′=A′+A′.\nThis lemma should be understood as follows: The Sumset Recognition problem is equivalent\nto the problem of detecting the existence of a set Asuch that A+Adoes not have to precisely\nmatch X. Rather, there are positions Y\\Xthat we don’t care about (and that are masked in the\nreduction). See Section 4 for more details and the proof of Lemma 1.5.\nAdditional Challenges for Fd\np.In contrast to many other settings in additive combinatorics,\nin our context, dealing with integers is simpler than dealing with, say, Fd\n2orFd\n3. Even seemingly\nsimple tasks like the construction of primitive sets are significantly more involved for Fd\n2andFd\n3\n(see Section 3.2). This is mainly, but not exclusively, due to a special role that Fd\n2takes here: In\ncontrast to the integers and finite fields of odd order, there are order-2 elements a(i.e., satisfying\nthat 2 a= 0); in fact all nonzero elements have order 2. This has several complicating consequences:\nFor instance, there are no sets with a unique sumset representation, as whenever X=A+Athen\nalsoX= (A+a) + (A+a). Another complication is that in the positioning step we relied on the\nfact that 2 a̸= 0; over Fd\n2we have to take a different route which leads to weaker positioning and\nmasking constructions (see Lemmas 3.6 and 4.2) where we replace the conditions that X=A+A\n6andX⊆A+A⊆Yby respectively X=A+BandX⊆A+B⊆Y. Nevertheless, even these\nweaker versions are ultimately sufficient to prove NP-hardness.\n1.4 Conclusions and Open Questions\nIn this paper, we have proven the NP-completeness of what may be considered the most basic\ncomputational question related to additive combinatorics. This opens up the door to investigating\nthe time complexity of many other problems related to sumsets. Let us conclude with three specific\nquestions that we find interesting.\nFirst, while we have shown that it is not possible to recognize sumsets quickly , it is still open\nto determine the extent to which non-trivial algorithmic strategies are helpful. In other words, we\nwould like to know the fine-grained complexity of the Sumset Recognition problem. Our reduction\ntakes a 3-SAT instance on nvariables and produces a set of integers in an interval of size O(n4). This\nleads to a conditional 2Ω(n1/4)lower bound; could there be a sub-exponential 2O(n0.99)algorithm?\nTheorem 1.6 (ETH-Hardness over Z).The Sumset Recognition problem over Zcannot be solved\nin time 2o(n1/4), unless the Exponential Time Hypothesis fails.\nA second question concerns the average case complexity of Sumset Recognition (and factoring).\nCan we generate hard instances by taking a random set A, and asking the algorithm to retrieve A\nfrom the set A+A?\nFinally, it would be interesting to study the approximability of the problem: given a set S, find\nthe largest S′⊆Ssuch that S′is a sumset.\n2 Preliminaries\nThroughout, we write [ n] ={1, . . . , n }and [ a, b] ={a, a+ 1, . . . , b }where a < b are integers. We\nwrite C=A⊔Bwhenever Cis the union of disjoint sets AandB. For a subset A⊆Fd\np, and v∈Fd\np,\nwe write v⊥Aifv·u= 0 for all u∈A. For subsets A, B⊆Gof some abelian group, we define\ntheir sumset A+B={a+b:a∈A, b∈B}. We write rA+B(x) =|{(a, b)∈A×B:a+b=x}|\nto denote the number of representations of xin the sumset A+B. Over finite fields, the following\nwell-known fact about the size of A+Bwill turn out useful; see e.g. [39, Theorem 5.4].\nLemma 2.1 (Cauchy-Davenport [16, 24]) .LetA, B⊆Fp. Then |A+B| ≥min(p,|A|+|B| −1).\nWe also introduce some new terminology. Inspired by the analogy to factoring, we call a set A\nirreducible if it cannot be expressed as A=B+Cfor sets of size |B|,|C| ≥2. Let us call a set A\nprimitive if, whenever we can express A+A=B+B, then B=A+xfor some group element x\nof order 2, i.e., 2 x= 0. That is, up to trivial shifts x, for a primitive set Athe representation as\nthe sumset A+Ais unique.\n3 Positioning\nIn this section, we establish the first step in our chain of reductions and prove that the Sumset Recog-\nnition problem is equivalent to testing whether a set Xcan be expressed as a sumset X=A+A\nwhere A⊆Uis constrained by some prespecified superset U(i.e., we “position” A). For the\nintegers, we formally prove the following lemma:\n7Lemma 1.4 (Positioning for Z).LetX, U⊆ {0, . . . , n }. There is a set X′⊆ {0, . . . , 224n}that\ncan be constructed in time poly( n)and satisfying that:\n∃A⊆U:X=A+A if and only if ∃A′⊆Z:X′=A′+A′.\nIn Section 3.1, we provide a proof of Lemma 1.4. This can also be considered as a “warm-up”\nfor the analogous, considerably more involved positioning lemma over Fd\nppresented in Section 3.2.\nSpecifically, the advantage of the integers here is that we can solve many problems simply by\nchoosing sufficiently large constants. This fails, for obvious reasons, over Fd\np.\n3.1 Positioning for Z\nThe idea behind our proof is that we first construct an appropriate “skeleton set” I(see the\ndiscussion around Lemma 1.4 in Section 1.3). We will then identify certain length- nintervals in Z\nwith elements in the skeleton set, and construct X′in such a way that whenever X′=A′+A′, an\ninterval in A′is nonempty if and only if the corresponding element is present in the skeleton set.\nThis forces A′to have a lot of structure, which we will exploit to impose the superset condition.\nThe precise structure we require is specified in the following lemma; while these conditions might\nappear obscure at first, we hope that they will become understandable in following the proof of\nLemma 1.4.\nLemma 3.1 (Skeleton Set for Z).There are distinct elements a, u, s ∈[0,221]and a set I′′⊆[0,221]\nsatisfying the following conditions for I′={a, u, s −a, s−u}:\n(i)I=I′⊔I′′is primitive.\n(ii)rI+I(2a) =rI+I(2s−2a) =rI+I(2s−2u) = 1 andrI+I(s) = 4 .\n(iii) (I′+I′)\\ {2a,2s−2a,2s−2u, s} ⊆I′′+I′′.\nIn other words, the second item postulates that 2 ahas a unique representation in the sumset\nI+I, namely, 2 a=a+a. The same holds for 2 s−2aand 2 s−2u. The element shas four\nrepresentations: s=a+ (s−a),s=u+ (s−u), and the two symmetric representations obtained\nby swapping the two summands; in the following, we will often neglect these symmetric options for\nsimplicity.\nProof of Lemma 1.4. For convenience, let us modify the input so that min( U) = min( X) = 0\nand that max( U) =nand max( X) = 2 n(by removing all elements larger than max( X)/2 from U\nand shifting the sets if necessary; this transformation only decreases n). Let a, u, s, I, I′, I′′be as\nin the previous lemma and write m= 221. We choose X′={i·4n+x:i∈I+I, x∈X′\ni}, where\nthe sets X′\ni⊆[0,2n] are defined as follows:\nX′\ns =U+{0, n},\nX′\n2a=X,\nX′\n2s−2a=X′\n2s−2u={0, n,2n},\nX′\ni = [0,2n] (for i∈I+I′′).\nLemma 3.1 (iii) guarantees that these four cases indeed cover for all i∈I+I. This completes the\ndescription of X′; as claimed we have that max( X′)≤(4m+ 2)n <224n.\n8Soundness. Assume that there is a set A⊆Uwith X=A+A; our goal is to show that there\nis some set A′⊆Zsuch that X′=A′+A′. To this end, we pick A′={i·4n+x:i∈I, x∈A′\ni},\nwhere the sets A′\ni⊆[0, n] are defined as follows:\nA′\na=A,\nA′\nu=U,\nA′\ns−a=A′\ns−u={0, n},\nA′\ni= [0, n] (for i∈I′′).\nAs the first step, we verify that A′+A′⊆X′. To this end, it suffices to check that A′\ni+A′\nj⊆X′\ni+j\nfor all pairs i, j∈I. This is obvious whenever i+j∈I+I′′since then X′\ni+j= [0,2n]. By\nLemma 3.1 (iii) the only other relevant cases are when i+j∈ {2a,2s−2a,2s−2u, s}. By\nLemma 3.1 (ii) the following cases are exhaustive:\nA′\na+A′\na =A+A=X=X′\n2a,\nA′\ns−a+A′\ns−a={0, n}+{0, n}={0, n,2n}=X′\n2s−2a,\nA′\ns−u+A′\ns−u={0, n}+{0, n}={0, n,2n}=X′\n2s−2u,\nA′\na+A′\ns−a=A+{0, n} ⊆U+{0, n}=X′\ns,\nA′\nu+A′\ns−u=U+{0, n}=X′\ns.\nNext, we verify that X′⊆A′+A′. To this end, we verify that for each k∈I+Ithere exists\nsome pair i, j∈Isuch that X′\nk⊆A′\ni+A′\nj. First, consider k∈I+I′′. Observe that {0, n} ⊆A′\ni\nfor all i∈I. Recall that further A′\nj={0, . . . , n }for all j∈I′′, and hence,\nX′\nk⊆[0,2n] ={0, n}+ [0, n].\nBy Lemma 3.1, these are the only remaining cases:\nX′\n2a =X=A+A=A′\na+A′\na,\nX′\n2s−2a={0, n,2n}={0, n}+{0, n}=A′\ns−a+A′\ns−a,\nX′\n2s−2u={0, n,2n}={0, n}+{0, n}=A′\ns−u+A′\ns−u,\nX′\ns =U+{0, n}=A′\nu+A′\ns−u.\nCompleteness. Assume that there is a set A′⊆Zsatisfying that X′=A′+A′. We construct a\nsetA⊆Uwith X=A+A. The first insight is that since X′⊆S\nk∈I+I[k·4n, k·4n+ 2n], we have\nA′⊆[\n0≤i≤m[i·2n, i·2n+n].\nImportantly, A′cannot contain elements from [ i·2n, i·2n+n] and [ j·2n, j·2n+n] at the same time\nwhen iandjhave different parity. Since the smallest relevant iis even (as otherwise we cannot\ncover [ k·4n, k·4n+ 2n] where k= min( I+I) is even), all relevant indices imust be even. By\nrescaling all indices by 2, we can thus express\nA′=[\n0≤i≤m(4n·i+A′\ni),\n9for some sets A′\ni⊆[0, n]. Moreover, we can rewrite the condition X′=A′+A′as\nX′\nk=[\n0≤i,j≤m\ni+j=k(A′\ni+A′\nj).\nThus, letting J={i:A′\ni̸=∅}we must have that I+I=J+J. Since the set Iis primitive by\nLemma 3.1 (i), we conclude that I=J. Next, recall that rI+I(2a) = 1 by Lemma 3.1 (ii), and thus\nX=X′\n2a=A′\na+A′\na.\nLemma 3.1 (ii) further guarantees that 2 s−2ahas a unique representation, and so\n{0, n,2n}=X′\n2s−2a=A′\ns−a+A′\ns−a,\nentailing that A′\ns−a={0, n}. We finally use that\nA′\na+{0, n}=A′\na+A′\ns−a⊆X′\ns=U+{0, n},\nwhich implies that A′\na⊆U. In summary, the set A:=A′\nasatisfies both conditions that X=A+A\nand that A⊆U.\nRunning Time. Let us finally comment on the running time. The set Ias provided by Lemma 3.1\nhas constant size, and its construction time can thus be neglected. Given this, the set Xcan easily\nbe constructed in polynomial time by appropriately shifting and copying XandU.\nIt remains to prove Lemma 3.1. This involves, in particular, the construction of a primitive set,\nand for this purpose, the following lemma will turn out useful:\nLemma 3.2. For any set A⊆[0, n], the set A∪ {4n}is primitive.\nProof. Write A∗=A∪ {4n}, and suppose that A∗+A∗=B+B. We show that B=A∗. First,\nobserve that since\nA∗+A∗= (A+A)∪(A+ 4n)∪ {8n} ⊆[0,2n]∪[4n,5n]∪ {8n},\nwe can only have that B⊆[0, n]∪[2n,⌊5\n2n⌋]∪ {4n}. Clearly, 4 n∈Bas otherwise, we cannot\ngenerate 8 n∈B+B. Hence, Bcannot contain any element in [2 n,⌊5\n2n⌋] as otherwise B+B\nwould contain an element in [6 n,⌊13\n2n⌋]. In summary, we can write B=B0∪ {4n}for some set\nB0⊆[0, n]. Finally, expand B+B= (B0+B0)∪(B0+ 4n)∪ {8n}and observe that the middle\nterm implies that B0=Aand thus B=A∗.\nProof of Lemma 3.1. We choose ( j1, . . . , j 5, a, u, s ) := (50,51, . . . , 57); our intention behind this\nchoice is that any multi-subset of {j1, . . . , j 5, a, u, s }with multiplicity at most 4 sums to a unique\nvalue. Let E= (I′+I′)\\ {2a,2s−2a,2s−2u, s}. Then, noting that |I′+I′|= 9 (as all pairs of\nelements in the size-4 set I′sum up to unique values except for sthat can be expressed as ( s−u)+u\nand ( s−a)+a), it follows that |E|=|I′+I′| −4 = 9−4 = 5. By arbitrarily identifying Eand [1 ,5]\nwe choose\nI′′={e−je, je:e∈E} ∪ { 4·58}.\nIt is easy to verify that max( I) = 4·58≤221. In the following, we argue that the properties (i), (ii),\nand (iii) hold.\n10(i) Note that I=I′⊔I′′can be written as A⊔ {4·58}where A⊆[0,58]. By Lemma 3.2, Iis\nthus indeed primitive.\n(ii) The goal is to show that 2 a, 2s−2a, 2s−2ucan be uniquely expressed in I+I, and that\ns=a+ (s−a) =u+ (s−u) has exactly these two representations (up to exchanging the\nsummands). This can easily be checked using that any multi-subset of Iwith multiplicity at\nmost 4 sums to a unique value. (In particular, I′′cannot participate.)\n(iii) This property equivalently states that E⊆I′′+I′′. And indeed, each e∈Ecan be expressed\nase= (e−je) +je∈I′′.\nWe remark that we made no attempt to optimize the constants in Lemma 3.1, but rather aimed\nfor a proof that is as simple as possible.\n3.2 Positioning for Fd\np\nIn this section, we will rework the entire positioning proof and present its adaption to Fd\np. We\nencourage the reader to skip this section at first reading and to continue reading the overall reduction\nin Sections 4 and 5.\nThe additional difficulty for Fd\npis mostly due to the cases Fd\n2andFd\n3. In both cases, it becomes\nsomewhat more involved to construct primitive sets (see the following two lemmas). However, the\nmore bothersome difficulty is that over Fd\n2we cannot easily require that X=A+Awith the same\nproof strategy. Specifically, in the language of Lemma 1.4 the issue is that if we want to place Aat\nsome position A′\na, then A+Ais placed at A′\n0. However, all sorts of garbage terms are also placed\natA′\n0, making the constraint void. We deal with this issue by designing a weaker positioning\nreduction involving two sets AandB; see Lemma 3.6.\nLemma 3.3. LetA⊆Fd\npwith|A| ≥2, and let v⊥A. Then A∪ {v}is irreducible.\nProof. Suppose that A∪ {v}=B+C; we show that |B| ≤1 or|C| ≤1. Let V⊆Fd\npdenote the\nsubspace orthogonal to v, and for i∈Fplet\nBi={x∈V:x+iv∈B},\nCi={x∈V:x+iv∈C}.\nNote that A∪ {v}=B+Ccan be rewritten in terms of the following three conditions:\nA=[\ni,j∈Fp\ni+j=0(Bi+Cj),\n{0}=[\ni,j∈Fp\ni+j=1(Bi+Cj),\n∅=[\ni,j∈Fp\ni+j̸=0,1(Bi+Cj).\nNote further that |B|=P\ni|Bi|and that |C|=P\ni|Ci|.\nWe first establish that |Bi|,|Ci| ≤1. Suppose for contradiction that |Bi| ≥2. Then by the\nsecond and third conditions, we have |Cj|= 0 for all j̸=−i. If|C−i| ≤1 then also |C| ≤1 and we\n11are done. Instead, assume that |C−i| ≥2. Then by the symmetric argument, we have that |Bj|= 0\nfor all j̸=i. But this violates the second condition asS\ni+j=1(Bi+Cj) =∅.\nTo complete the proof, let I={i:Bi̸=∅}andJ={i:Ci̸=∅}. In order to satisfy the three\nprevious conditions, we must have that I+J={0,1}. The Cauchy-Davenport theorem implies that\neither |I| ≤1 or|J| ≤1 orp= 2. In the former two cases we are done, as then |B|=P\ni∈I|Bi| ≤1\nor|C|=P\ni∈J|Cj| ≤1. In the latter case, if p= 2, there are elements x, ysuch that B0, C1⊆ {x}\nandB1, C0⊆ {y}in order to satisfy the second condition. But this implies that A⊆ {x+y},\ncontradicting the assumption that |A| ≥2.\nLemma 3.4. LetA⊆Fd\npbe irreducible with |A| ≥2and let v⊥A. Then A∪ {v}is primitive.\nProof. Write A∗=A∪ {v}and suppose that B+B=A∗+A∗= (A+A)∪(v+A)∪ {2v}; we\nshow that B=A∗+tfor some shift twith 2 t= 0. Let Vdenote the ( d−1)-dimensional subspace\northogonal to v, and for i∈Fpwrite Bi={x∈V:x+iv∈B}. Using this notation, observe that\nthe assumption B+B=A∗+A∗can be rewritten as\nA+A=[\ni,j∈Fp\ni+j=0(Bi+Bj),\nA=[\ni,j∈Fp\ni+j=1(Bi+Bj),\n{0}=[\ni,j∈Fp\ni+j=2(Bi+Bj) (only relevant if p >2),\n∅=[\ni,j∈Fp\ni+j̸=0,1,2(Bi+Bj) (only relevant if p >3).\nWe distinguish three cases for p:\n•p= 2: In this case the second identity states that A=B0+B1. By the irreducibility of A,\nthere is some shift ssuch that either B0=A+sandB1={s}, orB0={0}andB1=A+s.\nLett=sin the former case and t=s+vin the latter case. Then, since B=B0∪(v+B1),\nwe indeed have B=A∗+t.\n•p= 3: The third condition implies that B1+B1⊆ {0}and hence B1⊆ {0}. It also implies\nthatB0+B2⊆ {0}, which can only be satisfied in the following three cases:\n–|B0|=|B2|= 1: In this case the first identity implies that |A+A| ≤2. But recall that\n|A| ≥2, and thus |A|=|A+A|= 2. This can only happen when Ais a 1-dimensional\nsubspace of Fd\n2. But then A=A+A, which contradicts the irreducibility of A.\n–|B0|= 0: Then the second identity implies that A=B2+B2. This again contradicts\nthe irreducibility of A.\n–|B2|= 0: Then the second inequality implies that B0=Aand that B1={0}. Putting\nthese together, we find that B=A∗as claimed.\n•p > 3: Let I={i:Bi̸=∅}and note that I+I={0,1,2}. The Cauchy-Davenport\ntheorem implies that |I| ≤2—in fact, the only feasible solution is I={0,1}.6Therefore, and\n6To see this, first observe that Ican only consist of 0, 1 and 2−1. Setting I={0,2−1}fails as we need that\n0 + 2−1= 2 (which is only satisfied for p= 3). Similarly, setting I={1,2−1}fails as we require that 1 + 2−1= 0\n(which again is only satisfied for p= 3).\n12asB1⊆ {0}by the third identity, the second identity implies that B0=AandB1={0}.\nThis shows that B=A∗as claimed.\nPutting these two lemmas together, we can make an arbitrary set Aprimitive by including two\nvectors v1, v2satisfying the orthogonality constraints. Conversely, we remark that there are indeed\nexamples where twoorthogonal vectors v1, v2are necessary to make Aprimitive. For instance, take\na (d−1)-dimensional subspace V⊆Fd\n3orthogonal to some nonzero vector v. Then the set A∪v\nis not primitive as ( A∪ {v}) + (A∪ {v}) =B+Bwhere B= (A−v)∪ {v}.\nLemma 3.5 (Skeleton Set for Fd\np).For any prime p, there are distinct elements a, b, u, v, s, t ∈F40\np\nand a set I′′⊆F40\npsatisfying the following conditions for I′={a, b, u, v, s −a, s−u, t−b, t−v}:\n(i)I=I′⊔I′′is primitive.\n(ii)rI+I(a+b) =rI+I(s−a+t−u) = 2 andrI+I(s) =rI+I(t) = 4 .\n(iii) (I′+I′)\\ {a+b, s−a+t−u, s, t} ⊆I′′+I′′.\nPut in words, the second condition guarantees that a+band ( s−a) + (t−u) can be uniquely\nrepresented in the sumset I+I(up to exchanging the summands), and that sandthave exactly\ntwo representations (namely, s=a+ (s−a) and s=u+ (s−u), and similarly for t).\nProof. Leta, b, u, v, s, t, j 1, . . . , j 32, v1, v2∈F40\npdenote pairwise orthogonal nonzero vectors, and\nwrite E= (I′+I′)\\ {a+b, s−a+t−u, s, t}; note that |E| ≤\0|I′|+1\n2\n−4 =\09\n2\n−4 = 32. By\narbitrarily identifying Ewith [1 ,32], we let\nI′′={e+je,−je:e∈E} ⊔ {v1, v2}.\nIn the following, we argue that the properties (i), (ii) and (iii) hold.\n(i) Note that we can write I=A⊔ {v1, v2}where clearly |A| ≥2 and A⊥v1, v2andv1⊥v2.\nThus, by Lemma 3.3 the set A⊔ {v1}is irreducible, and by Lemma 3.4 the set A⊔ {v1, v2}\nis primitive.\n(ii) Condition (ii) enforces specific multiplicities for exactly the elements in x∈(I′+I′)\\E. For\nany such element x, it can easily be verified that x̸∈I′′+I′(since all elements in I′′have\na nontrivial component je, but je⊥I′) and that x̸∈I′′+I′′(by construction we can only\nexpress the elements in Ein this way). It follows that rI+I(x) =rI′+I′(x). Having this in\nmind, we can verify condition (ii) by hand: The sums a+band ( s−a) + (t−b) are unique,\nsappears exactly two times as s=a+ (s−a) =u+ (s−u) and similarly tappears exactly\ntwo times as t=b+ (t−b) =v+ (t−v).\n(iii) This condition is trivial by construction: We can express e=e+je−je∈I′′+I′′for all\nelements e∈E.\nLemma 3.6 (Positioning for Fd\np).Letpbe a prime and let X, U, V ⊆Fd\np. In time poly( pd)we can\nconstruct a set X′⊆Fd′\np, where d′=d+ 40, such that:\n∃A⊆U, B⊆V:X=A+B if and only if ∃A′⊆Fd′\np:X′=A′+A′.\n13Proof. We start with the construction of X′. Let a, b, u, v, s, t, I, I′, I′′be as in the previous lemma.\nWe view Fd′\np=F40\np×Fd\npand set X′={(i, x) :i∈I+I, x∈X′\ni}, where the sets X′\ni⊆Fd\npare defined\nas follows:\nX′\na+b =X,\nX′\ns =U,\nX′\nt =V,\nX′\ns−a+t−b={0},\nX′\ni =Fd\np (fori∈I+I′′).\nLemma 3.5 (iii) guarantees that these four cases indeed cover for all i∈I+I.\nSoundness. Assume that there are sets A⊆UandB⊆Vwith X=A+B. We show that there\nis some set A′⊆Fd′\npsuch that X′=A′+A′. We choose A′={(i, x) :i∈I, x∈A′\ni}, where the\nsetsA′\niare defined as follows:\nA′\na=A,\nA′\nb=B,\nA′\nu=U,\nA′\nv=V,\nA′\ns−a=A′\ns−u=A′\nt−b=A′\nt−v={0},\nA′\ni=Fd\np (fori∈I′′).\nWe first verify that A′+A′⊆X′. To this end, we check that A′\ni+A′\nj⊆X′\ni+jfor all pairs i, j∈I.\nThis is clearly true whenever i+j∈I+I′′since X′\ni+j=Fd\np. By Lemma 3.5 (iii), the only other\nrelevant cases are when i+j∈ {a+b, s−a+t−b, s, t}. By Lemma 3.5 (ii) the following cases are\nexhaustive:\nA′\na+A′\nb =A+B =X=X′\na+b,\nA′\ns−a+A′\nt−b={0}+{0}={0}=X′\ns−a+t−b,\nA′\na+A′\ns−a=A+{0}=A⊆U=X′\ns,\nA′\nu+A′\ns−u=U+{0}=U=X′\ns,\nA′\nb+A′\nt−b=B+{0}=B⊆V=X′\nt,\nA′\nv+A′\nt−v=V+{0}=V=X′\nt.\nNext, we verify that X′⊆A′+A′. To this end, we verify that for each k∈I+Ithere exists\nsome pair i, j∈Isuch that X′\nk⊆A′\ni+A′\nj. For each k∈I+I′′this is clear using that A′\ni=Fd\npfor\nalli∈I′′. By Lemma 3.5, these are the remaining cases:\nX′\na+b =X=A+B =A′\na+A′\nb,\nX′\ns =U=U+{0}=A′\nu+A′\ns−u,\nX′\nt =V=V+{0}=A′\nv+A′\nt−v,\nX′\ns−a+t−b={0}={0}+{0}=A′\ns−a+A′\nt−b.\n14Completeness. Next, assume that there is a set A′⊆Fd′\npsuch that X′=A′+A′. Our goal is to\nconstruct sets A⊆UandB⊆VwithX=A+B. For i∈F40\np, let us write A′\ni={x∈Fd\np: (i, x)∈A′},\nand let J={i∈F40\np:A′\ni̸=∅}. As we assume that X′=A′+A′, we must have that I+I=J+J.\nSince Iis primitive by Lemma 3.5 (i), we conclude that J=I+sfor some shift swith 2 s= 0;\nwithout loss of generality we assume that s= 0. Since a+bhas a unique representation in I+I\nby Lemma 3.5 (ii), we have that\nX=X′\na+b=A′\na+A′\nb.\nMoreover, by Lemma 3.5 (ii), ( s−a) + (t−b) also has a unique representation, and therefore\n{0}=X′\ns−a+t−b=A′\ns−a+A′\nt−b.\nIt follows that for some element x∈Fd\npwe have A′\ns−a={x}andA′\nt−b={−x}. We finally have\nthat\nA′\na+x=A′\na+A′\ns−a⊆X′\ns=U,\nA′\nb−x=A′\nb+A′\nt−b⊆X′\nt=V.\nIn summary, the sets A:=A′\na+xandB:=A′\nb−xsatisfy the three conditions that X=A+B\nandA⊆UandB⊆V.\n4 Masking\nIn this section, we implement the “masking” step, which transforms the problem of testing the\nexact sumset condition X=A+Ato a more relaxed version testing whether X⊆A+A⊆Y.\nSpecifically, for the integers, we prove the following reduction:\nLemma 1.5 (Masking for Z).LetX, Y, U ⊆ {0, . . . , n }. There are sets X′, U′⊆ {0, . . . , 217n2}\nthat can be constructed in time poly( n)and satisfying that:\n∃A⊆U:X⊆A+A⊆Y if and only if ∃A′⊆U′:X′=A′+A′.\nIn Section 4.1, we provide a proof of Lemma 1.5, and in the following Section 4.2, we design\nthe appropriate analogue for finite field vector spaces.\n4.1 Masking for Z\nUnfortunately, the proof of Lemma 1.5 turns out to be quite technical. While in the positioning\nstep working with integers had several advantages, in the masking step, we have to deal with several\ndrawbacks. One particular drawback is as follows: In order to “mask” a set A, we want to find\nanother set Msuch that A+Mis predictable without knowing A. Over Fd\npthis easily works\nby choosing M=Fd\np, in which case A+M=Fd\npwithout having any knowledge about A(other\nthan the trivial condition that Abe nonempty). Over the integers, the natural analogue is to pick\nan interval M= [0, N]. However, then A+M= [min( A),max( A) +N], even if we presuppose\nthat A⊆[0, N], which is inconveniently not independent of A. Throughout the proof, this issue\nwill introduce several less important side cases. The first step in dealing with it is the following\nlemma:\nLemma 4.1. LetX, Y, U ⊆[0, n]. We can compute sets X′, Y′, U′⊆[0,32n]in time poly( n)such\nthat:\n15(i)∃A⊆U:X⊆A+A⊆Yif and only if ∃A′⊆U′:X′⊆A′+A′⊆Y′.\n(ii) All elements in X′, Y′, U′are even.\n(iii) min(X′) = min( Y′) = min( U′) = 0 ,max( X′) = max( Y′) = 32 n,max( U′) = 16 n.\nProof. We write 2 X={2x:x∈X}. The construction is simple (emphasizing again that our goal\nis not to optimize the constants but rather to achieve simple proofs):\nX′={0} ∪(2X+ 8n)∪ {32n},\nY′= 2[0 ,3n]∪(2Y+ 8n)∪2[8n,16n],\nU′={0} ∪(2U+ 4n)∪ {16n}.\nFor the soundness, let A⊆Usatisfy that X⊆A+A⊆Y. We choose A′={0}∪(2A+4n)∪{16n}.\nNoting that\nA′+A′={0} ∪(2A+ 4n)∪(2A+ 2A+ 8n)∪ {16n} ∪(2A+ 20n)∪ {32n},\nit is straightforward to verify that A′⊆U′and that X′⊆A′+A′⊆Y′.\nFor the converse direction, suppose that A′⊆U′satisfies that X′⊆A′+A′⊆Y′. Let Abe\nthe part of A′that falls in the interval [4 n,6n] where we divide each number by 2 (here we use\nthat A′contains only even numbers since A′⊆U′). Using again that A′⊆U′we can express A′\nas{0} ∪(A+ 4n)∪ {16n}. It follows easily that X⊆A+A⊆Y.\nProof of Lemma 1.5. By first applying the transformation from Lemma 4.1, we assume through-\nout that X, Y, U ⊆[0,32n] with min( X) = min( Y) = min( U) = 0, max( X) = max( Y) = 32 nand\nmax( U) = 16 n, and that all three sets contain only even numbers. For simplicity, we write N= 16n.\nFurthermore, if X̸⊆Y, then the reduction is trivial, so assume that X⊆Yand let Z=Y\\X.\nIn this proof, we will construct sets X′, U′⊆Zcontaining negative integers; this can later be fixed\nby shifting all sets appropriately into the positive range.\nThe construction of the sets X′andU′is, unfortunately, extremely tedious. We define\nX′=[\n−2≤c≤2\n−8N≤k≤8N(c·64N2+k·4N+X′\nc,k),\nU′=[\n−1≤a≤1\n−4N≤i≤4N(a·64N2+i·4N+U′\na,i),\nwhere the pieces X′\nc,k⊆[0,2N] and U′\na,i⊆[0, N] are defined as follows; we write I= [−4N,4N]\\{0}\nfor simplicity here:\nX′\n2,k= [0,2N] (for k∈I+I),\nX′\n1,k= [0,2N] (for k∈I),\nX′\n1,k=[\ni∈I,z∈Z\ni±z=k[z/2, z/2 +N] (for k̸∈I),\nX′\n0,0=Y,\nX′\n0,k= [0,2N] (for k∈I),\nX′\n−1,0= [0,2N],\nX′\n−1,z=X′\n−1,−z= [z/2, z/2 +N] (for z∈Z),\nX′\n−2,0= [0,2N],\n16and\nU′\n1,i= [0, N] (for i∈I),\nU′\n0,0=U,\nU′\n0,z=U′\n0,−z={z/2} (forz∈Z),\nU′\n−1,0= [0, N].\nMoreover, all sets X′\nℓ,iandU′\nℓ,iwhich are not covered by these cases are defined to be empty.\nBefore checking the soundness and completeness properties, we first check that the size of X′, U′\nis appropriate. We have that X′, U′⊆[−256N2,256N2], and thus by shifting them into the\npositive range, we would obtain sets in [0 ,512N2]. Recalling that N= 16n, the universe bound\n512N2= 217nholds.\nSoundness. Suppose that there is some set A⊆Uwith X⊆A+A⊆Y. We give a set A′⊆U′\nwith X′=A′+A′. As before, we define\nA′=[\n−1≤a≤1\n−4N≤i≤4N(a·64N2+i·4N+A′\na,i)\nwhere A′\na,i⊆[0, n] is defined as follows:\nA′\n1,i= [0, N] (for i∈I),\nA′\n0,0=A,\nA′\n0,z=A′\n0,−z={z/2} (forz∈Z),\nA′\n−1,0= [0, N].\nFrom the construction, it is immediate that A′⊆U′. Observe further that 0 , N∈A(as otherwise\nwe cannot satisfy that {0,2N} ⊆X⊆A+A), and thus A+ [0, N] = [0 ,2N]; this observation will\nbe useful in the following paragraphs.\nNext, we show that A′+A′⊆X′. To this end, we verify that A′\na,i+A′\nb,j⊆X′\na+b,i+jfor all\nchoices a, b, i, j . This is not hard, but it requires a lot of case work. We state the relevant cases\nand omit some others due to symmetries:\nA′\n1,i+A′\n1,j = [0,2N] =X′\n2,i+j (fori, j∈I),\nA′\n1,i+A′\n0,0= [0, N] +A= [0,2N] =X′\n1,i (fori∈I),\nA′\n1,i+A′\n0,z = [0, N] +{z/2}= [z/2, z/2 +N]⊆X′\n1,i+z (fori∈I, z∈Z),\nA′\n1,i+A′\n−1,0= [0,2N] =X′\n0,i (fori∈I, z∈Z),\nA′\n0,0+A′\n0,0=A+A⊆Y=X′\n0,0,\nA′\n0,0+A′\n0,z =A+{z/2} ⊆[0,2N] =X′\n0,z (forz∈Z),\nA′\n0,0+A′\n−1,0=A+ [0, N] = [0 ,2N] =X′\n−1,0,\nA′\n0,z+A′\n0,z′={z/2}+{z/2} ⊆[0,2N] =X′\n0,z+z′ (forz, z′∈Z),\nA′\n0,z+A′\n0,−z={z/2}+{z/2}={z} ⊆Z⊆Y=X′\n0,0 (forz∈Z),\nA′\n0,z+A′\n−1,0={z/2}+ [0, N] = [z/2, z/2 +N] =X′\n−1,z (forz∈Z),\nA′\n−1,0+A′\n−1,0= [0,2N] =X′\n−2,0.\n17Let us finally check that X′⊆A′+A′. That is, our task is to verify that for all pairs c, kit\nholds that\nX′\nc,k⊆[\na+b=c\ni+j=k(A′\na,i+A′\nb,j).\nThis again involves dealing with many cases:\nX′\n2,k= [0,2N] =A′\n1,i+A′\n1,j (fork=i+j∈I+I),\nX′\n1,k= [0,2N] =A+ [0, N] =A′\n0,0+A′\n1,k (fork∈I),\nX′\n1,k=[\ni∈I,z∈Z\ni±z=k[z/2, z/2 +N] =[\ni∈I,z∈Z\ni±z=k(A′\n1,i+A′\n0,z) (for k̸∈I),\nX′\n0,0=Y=X∪Z\n⊆(A+A)∪[\nz∈Z({z/2}+{z/2})\n= (A′\n0,0+A′\n0,0)∪[\nz∈Z(A′\n0,z∪A′\n0,−z),\nX′\n0,k= [0,2N] =A′\n1,k+A′\n−1,0 (fork∈I),\nX′\n−1,0= [0,2N] =A+ [0, N] =A′\n0,0+A′\n−1,0,\nX′\n−1,z= [z/2, z/2 +N] = [0 , N] +{z/2}=A′\n−1,0+A′\n0,z (forz∈Z),\nX′\n−2,0= [0,2N] =A′\n−1,0+A′\n−1,0.\nCompleteness. The completeness proof is simpler in comparison. Suppose that there is a\nsetA′⊆U′with X′=A′+A′; we show that there is some set A⊆Usatisfying that X⊆A+A⊆Y.\nLet, in analogy to before, A′\na,i⊆[0, N] denote the subset of A′that falls into the length- N\nrange starting at a·64N2+i·4N. These are the only nonempty regions in A′(by the condi-\ntion that A′⊆U′), and therefore it holds that\nX′\nc,k=[\na+b=c\ni+j=k(A′\na,i+A′\nb,j).\nOn the one hand, it is clear that A′\n0,0+A′\n0,0⊆X′\n0,0=Y. On the other hand, by the construction,\nit is easy to verify that each element x∈Y\\Zcan only appear in\n[\na+b=0\ni+j=0(A′\na,i+A′\nb,j) = (A′\n0,0+A′\n0,0)∪[\nz∈Z(A′\n0,z+A′\n0,−z)\nifx∈A′\n0,0+A′\n0,0. In particular, this implies that X=Y\\Z⊆A′\n0,0+A′\n0,0. Finally, observe that\ntrivially A′\n0,0⊆U′\n0,0=U, and therefore A′\n0,0satisfies all three relevant conditions.\nRunning Time. The running time due to Lemma 4.1 is negligible, and we can easily compute\nthe sets X′, U′in polynomial time.\n184.2 Masking for Fd\np\nIn comparison to the previous subsection, the masking proof over Fd\npis surprisingly simple.\nLemma 4.2 (Masking for Fd\np).Letpbe a prime and let X, Y, U, V ⊆Fd\np. In time poly( pd)we can\nconstruct sets X′, U′, V′⊆Fd′\np, where d′= 2d+ 3, such that:\n∃A⊆U, B⊆V:X⊆A+B⊆Y if and only if ∃A′⊆U′, B′⊆V′:X′=A′+B′.\nProof. IfX̸⊆Ythen the reduction is trivial, so assume that X⊆Yand let Z=Y\\X. Con-\nsider the vector space Fd+3\np; by embedding Fd\npinto the first dcoordinates, say, we view Zalso\nas a subset of Fd+3\np. We exploit the remaining three dimensions by letting a, b, w ⊥Zdenote\nnonzero pairwise orthogonal vectors; let W⊆Fd\npdenote the subspace orthogonal to w. We de-\nfineX′={(i, x) :i∈Fd+3\np, x∈X′\ni}and similarly U′andV′, where X′\ni, U′\ni, V′\ni⊆Fd\npare the sets\ndefined as follows:\nX′\na+b=Y,\nX′\ni =Fd\np (fori∈W\\ {a+b}),\nX′\ni+w=Fd\np (fori∈W),\nX′\ni−w=Fd\np (fori∈Z∪ {a}, only relevant if p >2)\nand\nU′\na =U,\nU′\nz ={z} (forz∈Z),\nU′\ni+w=Fd\np (fori∈W\\ {a+b}),\nand\nV′\nb =V,\nV′\na+b−z={0} (forz∈Z),\nV′\n−w=Fd\np.\nMoreover, all sets X′\ni, U′\ni, V′\ni, which we have not specified here, are set to be empty.\nSoundness. For the soundness, assume that there is a pair A⊆U, B⊆Vwith X⊆A+B⊆Y.\nWe construct sets A′⊆U′andB′⊆V′with X′=A′+B′. Write A′={(i, x) :i∈I, x∈A′\ni}and\nsimilarly for B′where the sets A′\ni, B′\ni⊆Fd\npare defined as follows:\nA′\na =A,\nA′\nz ={z} (forz∈Z),\nA′\ni+w=Fd\np (fori∈W\\ {a+b}),\nand\nB′\nb =B,\nB′\na+b−z={0} (forz∈Z),\nA′\n−w=Fd\np.\n19Again, all sets A′\ni, B′\nithat we have not specified here are assumed to be empty. From the construc-\ntion, it is immediate that A′⊆U′and that B′⊆V′.\nNext, we show that A′+B′⊆X′. To this end, we verify that A′\ni+B′\nj⊆X′\ni+jfor all i, j∈I.\nThis is trivial whenever X′\ni+j=Fd\npwhich covers almost all cases. The only other relevant cases are\nas follows:\nA′\na+B′\nb =A+B⊆Y=X′\na+b,\nA′\nz+B′\na+b−z={z}+{0} ⊆Z⊆Y=X′\na+b.\nLet us finally check that X′⊆A′+B′. That is, we check that for all k,X′\nk⊆S\ni+j=k(A′\ni+B′\nj).\nThe most interesting case is\nX′\na+b=Y=X∪Z⊆(A+B)∪[\nz∈Z{z}= (A′\na+B′\nb)∪[\nz∈Z(A′\nz+B′\na+b−z).\nThe less interesting cases are\nX′\ni=Fd\np=Fd\np+Fd\np=A′\ni+w+B′\n−w (fori∈W\\ {a+b}),\nX′\ni+w=Fd\np=Fd\np+B=A′\ni+w−b+B′\nb (fori∈W),\nX′\nz−w=Fd\np={z}+Fd\np=A′\nz+B′\n−w (forz∈Z),\nX′\na−w=Fd\np=A+Fd\np=A′\na+B′\n−w.\n(Strictly speaking, here we assumed that A, B̸=∅. This can easily be enforced by a trivial corner\ncase.)\nCompleteness. Suppose that there are sets A′⊆U′, B′⊆V′with X′=A′+B′; we show that\nthere are sets A⊆U, B⊆Vwith X⊆A+B⊆Y. We again write A′\ni={x∈Fd\np: (i, x)∈A′}\nfori∈Fd+3\np, and similarly for B′. From our construction, it is clear that\nX′\nk=[\ni,j∈Fd+3\np\ni+j=k(A′\ni+B′\nj)⊆[\ni,j∈Fd+3\np\ni+j=k(U′\ni+V′\nj).\nIn particular, consider the case k=a+b. By carefully checking all combinations of iandjabove,\nwe in fact have that\nX′\na+b= (A′\na+B′\nb)∪[\nz∈Z((A′\nz+B′\na+b−z)∪(A′\na+b−z+B′\nz)).\nBy the construction of U′andV′, the big union on the right becomes exactly a subset Z′⊆Z.\nTherefore, and using that X′\na+b=Y, we have that Z′∪(A′\na+B′\nb) =Y. In particular, X⊆A′\na+B′\nb,\nand we have thus witnessed sets A=A′\naandB=B′\nbas desired.\n5 Reduction from 3-SAT\nIn this section, we employ the technical lemmas from Sections 3 and 4 to show a polynomial-time\nreduction from 3-SAT to Sumset Recognition. We start with the integer case in Section 5.1 and\nthen deal with finite fields in Section 5.2.\n205.1 Reduction for Z\nGiven a 3-SAT instance, a formula ϕonnvariables and mclauses, the reduction outputs a Sumset\nRecognition instance; a set Xϕ⊆[0,257(n+m)4], such that ϕis satisfiable if an only if there exists\nA⊆Zsuch that Xϕ=A+A. The main technical part in this section is a reduction for a related\nproblem where given ϕ, we output three sets X, Y, U such that ϕis satisfiable if and only if exists\nA⊆Usuch that X⊆A+A⊆Y. In this reduction, we will employ the following Sidon set\nconstruction. Recall that we call a set SSidon if it does not contain nontrivial solutions to the\nequation i+j=k+ℓ, or equivalently, if |S+S|=\0|S|+1\n2\n.\nLemma 5.1 (Sidon Sets over Z).In time poly( n)we can compute a Sidon set S⊆[0,4n2]of size n.\nProof. This result is classic, but we include a quick proof based on Erd˝ os and Tur´ an’s construc-\ntion [27] for the sake of completeness. By Bertrand’s postulate, there is a prime number n≤p <2n,\nand we can find pby, say, Eratosthenes’ sieve in deterministic time O(nlog log n). As Erd˝ os and\nTur´ an proved [27], the set\nS′={(x, x2) :x∈Fp}\nis a Sidon set over F2\np. Indeed, suppose that ( i, i2) + (j, j2) = (k, k2) + (ℓ, ℓ2). Equivalently, we can\nwrite i−k=ℓ−jandi2−k2=ℓ2−j2. Thus, either i−k=ℓ−j= 0 or i+k=ℓ+j. In the latter\ncase, in combination with the initial assumption, we find that i=ℓandj=k. This set S′can be\nlifted to the integers by embedding F2\npinto the integers via ( x, y)7→x·2p+y(viewing 0 ≤x, y < p\nas integers). The resulting set Ssatisfies that S⊆[0,2p(p−1) + 1] ⊆[0,4n2] and can clearly be\nconstructed in time poly( n).\nCorollary 5.2. In time poly( n, m)we can compute integers s1, . . . , s n, t1, . . . , t msuch that:\n(i)0≤s1, . . . , s n≤Nand4N≤t1, . . . , t m≤5N, where N= 16( n+m)2.\n(ii) Whenever |2si−sj−sk|<4, then i=j=k.\n(iii) Whenever |si−sj+tk−tℓ|<4, then i=jandk=ℓ.\nProof. The previous lemma yields a Sidon set {s′\n1, . . . , s′\nn, t′\n1, . . . , t′\nm} ⊆[0,4(n+m)2]; we then\nchoose si:= 4s′\niandti:= 4t′\ni+64( n+m)2. Property (i) is fulfilled by construction. For property (ii),\nnote that |2si−sj−sk|<4 if and only if 2 s′\ni−s′\nj−s′\nk= 0. The Sidon assumption guarantees that\nthis happens if and only if i=j=k. Property (iii) follows by a similar argument.\nLemma 5.3 (Reduction from 3-SAT for Z).There is an algorithm that, given a 3-SAT formula ϕ\nonnvariables and mclauses, outputs sets X, Y, U ⊆[0,160(n+m)2], such that\nϕis satisfiable if and only if ∃A⊆U:X⊆A+A⊆Y.\nThe algorithm runs in time O(n2+m2).\nProof. We denote the variables of ϕbyx1, . . . , x n. Let s1, . . . , s n, t1, . . . , t mdenote the integers as\nconstructed by Corollary 5.2. We then define the three sets as follows. Let X:={t1, . . . , t m}, and\n21let\nCk:=[\nxiappears\npositively in\nthek-th clause.{tk−si−1} ∪[\nxiappears\nnegatively in\nthek-th clause.{tk−si} (fork∈[m]),\nU:=[\ni∈[n](si+{0,1})∪[\nk∈[m]Ck,\nY:=[\ni∈[n](2si+{0,2})∪[\ni,j∈[n]\ni̸=j(si+sj+{0,1,2})\n∪[\ni∈[n]\nk∈[m](si+{0,1}+Ck)∪[\nk,ℓ∈[m](Ck+Cℓ).\nCorollary 5.2 (i) guarantees that 0 ≤s1, . . . , s n≤Nand 4 N≤t1, . . . , t m≤5Nwhere N=\n16(n+m)2. Hence, all sets contain only nonnegative integers of size at most 10 N≤160(n+m)2.\nSoundness. Suppose that ϕis satisfiable and let α∈ {0,1}ndenote a satisfying assignment of ϕ.\nWe show that there is a set A⊆Usatisfying that X⊆A+A⊆Y. We choose\nA=[\ni∈[n]{si+αi} ∪[\nk∈[m]Ck.\nObserve that A⊆U. In addition, it is not too difficult to see that A+A⊆Y, since:\nA+A=[\ni,j∈[n]{si+sj+αi+αj} ∪[\ni∈[n]\nk∈[m](si+αi+Ck)∪[\nk,ℓ∈[m](Ck+Cℓ).\nThe second and third terms are clearly included in the third and fourth terms of Y. For the first\nterm we distinguish two cases: If i=j, then {si+sj+αi+αj} ⊆2si+{0,2}which is included\nin the first term of Y. Otherwise, if i̸=j, then {si+sj+αi+αj} ⊆si+sj+{0,1,2}is clearly\nincluded in the second term of Y.\nLet us finally prove that X⊆A+A. As X={t1, . . . , t m}we need to show, for each k∈[m],\nthattk∈A+A. Since αsatisfies ϕ, it satisfies some literal of some variable xiin the k-th clause.\nConsider the term si+αi+Ck⊆A+A. Assume, on the one hand, that xiappears positively in this\nclause, i.e., αi= 1. Then by the definition of Ckwe have tk=si+ 1 + ( tk−si−1)∈A+A. On the\nother hand, if xiappears negatively in Ck(and thus α0= 0), then tk=si+ 0 + ( tk−si)∈A+A.\nCompleteness. Before we start with the actual completeness proof, let us first assert that our\nconstruction admits the following properties:\n•2si+ 1̸∈Y. Of course 2 si+ 1 does not appear in 2 si+{0,2}, but it requires an argument\nthat 2 s1+ 1 does not spuriously appear in the other terms in Y: Since Y⊆U+U, any other\nexpression would lead to a nontrivial solution of 2 si=sj+sk±3, or 2 si=sj+tk−sℓ±3\nor 2si=tk−sj+tℓ−sh±3. The first equation is ruled out by Corollary 5.2 (ii), and the\nlatter two are ruled out by Corollary 5.2 (i).\n•The only possible representations of tkinU+Uaretk= (si+ 0) + ( tk−si) and tk=\n(si+ 1) + ( tk−si−1) (whenever the variable xiappears in the k-th clause). Indeed, any\n22other representation would take one of the forms tk=si+sj±3,tk=si+ (tℓ−sj)±3\n(fori̸=jork̸=ℓ), or tk= (tℓ−si) + (th−sj)±3. The first and last equations are ruled\nout by Corollary 5.2 (i), and the second one is ruled out by Corollary 5.2 (iii).\nEquipped with these insights, we continue with the completeness proof. So, assume that there\nis a set A⊆Usatisfying that X⊆A+A⊆Y; we construct a satisfying assignment of ϕ. The\nfirst claim implies that it cannot simultaneously happen that si+ 0∈Aand that si+ 1∈A(as\notherwise A+A̸⊆Y). In light of this, we let αi= 1 if and only if si+ 1∈A. To prove that αis\nsatisfying, consider any clause k. Since X⊆A+A, we in particular have that tk∈A+A⊆U+U.\nBy the second claim, tkmust be represented either in the form of tk= (si+ 0) + ( tk−si)\nortk= (si+ 1) + ( tj−si−1). In the former case we have that si+ 0∈A(and thus αi= 0)\nandtk−si∈U(and thus xiappears negatively in the k-th clause). In the latter case we have\nthat si+ 1∈A(and thus αi= 1) and tk−si−1∈U(and thus xiappears positively in the k-th\nclause). In both cases, the clause is satisfied.\nProof of Theorem 1.2. Let us now show a polynomial-time reduction from 3-SAT to the Sumset\nRecognition problem. Since the problem is clearly in NP, this will prove that the problem is NP-\ncomplete. Given a 3-SAT instance; a formula ϕonnvariables and mclauses, apply the algorithm\nfrom Lemma 5.3 to obtain three sets X, Y, U ⊆[0,160(n+m)2]⊆[0,28(n+m)2], such that:\nϕis satisfiable if and only if ∃A⊆U:X⊆A+A⊆Y.\nThen, apply the algorithm from Lemma 1.5 on X, Y, U to obtain two sets U′, X′⊆[0,217·(28(n+\nm)2)2] = [0 ,233(n+m)4], such that:\n∃A⊆U:X⊆A+A⊆Y if and only if ∃A′⊆U′:X′=A′+A′.\nAs a corollary, ϕis satisfiable if and only if ∃A′⊆U′such that X′=A′+A′. Finally, apply the\nalgorithm from Lemma 1.4 on X′, U′to obtain a Sumset Recognition instance Xϕ⊆[0,224·233(n+\nm)4] = [0 ,257(n+m)4], such that:\n∃A′⊆U′:X′=A′+A′if and only if ∃A′′⊆Z:Xϕ=A′′+A′′.\nThus, ϕis satisfiable if and only if ∃A′′⊆Zsuch that A′′+A′′=Xϕ.\nThe running times of the above algorithms are all poly( n, m). Hence, we showed a polynomial-\ntime reduction from 3-SAT to Sumset Recognition.\n5.2 Reduction for Fd\np\nIn this section, we rework the reduction for finite fields. We start with a similar construction of\nSidon sets over Fd\np.\nLemma 5.4 (Sidon Sets over Fd\np).Letpbe a prime, and let d= 2⌈logp(n)⌉. In time poly( n)we\ncan construct a Sidon set S⊆Fd\npof size n.\nProof. We follow a classic construction dating back to Bose and Ray-Chaudhuri [10]; see also [21].\nLetq=pd. By representing the finite field FqasFd\np, it suffices to construct a Sidon set in F2\nq. For\noddp, such a set is for instance S={(x, x2) :x∈Fq}; the proof is identical to the argument in\nLemma 5.1. We take S={(x, x3) :x∈Fq}if instead p= 2 [10]. Polynomial arithmetic can be\nimplemented in time poly( q), and so the construction time of Sis also bounded by poly( n).\n23Lemma 5.5 (Reduction from 3-SAT for Fd\np).There is an algorithm that, given a 3-SAT formula ϕ\nonnvariables and mclauses, outputs sets X, Y, U, V ⊆Fd\np, where d= 2⌈logp(n+m)⌉+ 5, such\nthat\nϕis satisfiable if and only if ∃A⊆U, B⊆V:X⊆A+B⊆Y.\nThe algorithm runs in time poly( n, m).\nProof. Letx1, . . . , x ndenote the variables in ϕ. Further, let a1, . . . , a n, b1, . . . , b n, t1, . . . , t m∈Fd\np,\nwhere d= 2⌈logp(2n+m)⌉+3≤2⌈logp(n+m)⌉+5, denote the elements of a Sidon set of size 2 n+m\nas constructed by Lemma 5.4. We use the three remaining dimensions to obtain pairwise orthogonal\nnonzero vectors v0, v1, wthat are also orthogonal to a1, . . . , a n, b1, . . . , b n, t1, . . . , t m. We then define:\nCk:=[\nxiappears\npositively in\nthek-th clause.{tk−ai−v1} ∪[\nxiappears\nnegatively in\nthek-th clause.{tk−ai−v0},\nU:=[\ni∈[n](ai+{v0, v1}),\nV:=[\ni∈[n](bi− {v0, v1})∪[\nk∈[m](w+Ck),\nX:=[\ni∈[n]{ai+bi} ∪[\nk∈[m]{w+tk},\nY:=[\ni∈[n]{ai+bi} ∪[\ni,j∈[n]\ni̸=j(ai+bj+{v0, v1} − { v0, v1})∪[\ni∈[n]\nk∈[m](ai+{v0, v1}+w+Ck).\nSoundness. Suppose that ϕis satisfiable and let α∈ {0,1}ndenote a satisfying assignment of ϕ.\nWe show that there are sets A⊆UandB⊆Vsatisfying that X⊆A+B⊆Y. To this end, we\npick\nA=[\ni∈[n]{ai+vαi},\nB=[\ni∈[n]{bi−vαi} ∪[\nk∈[m](w+Ck).\nObserve that A⊆UandB⊆V, and that\nA+B=[\ni,j∈[n]{ai+bj+vαi−vαj} ∪[\ni∈[n]\nk∈[m](ai+vαi+w+Ck)⊆Y.\nWe finally show that X⊆A+A. On the one hand, it is clear that ai+bi∈A+Bfor all i∈[n]. On\nthe other hand, focus on an arbitrary clause k∈[m]. Since αis a satisfying assignment, there must\nbe a variable xiwhich satisfies the k-th clause. If the variable appears positively (and thus αi= 1),\nthen w+tk= (ai+v1) + (w+tk−ai−v1)∈A+B. Otherwise, if the variable appears negatively\n(and thus αi= 0), we find w+tk= (ai+v0) + (w+tk−ai−v0)∈A+B.\n24Completeness. For the completeness proof, we again first gather some structural observations.\nSpecifically:\n•ai+bi+v0−v1̸∈Yandai+bi+v1−v0̸∈Y. We check that neither of these elements appears\nspuriously in the second and third terms in Y. For the third term, this is clear as it contains\nthe shift + w, which is orthogonal to ai+bi±v0±v1. And if the second term would contain,\nsay,ai+bi+v0−v1, then we would also obtain a solution to the equation ai+bi=aj+bh\n(where j̸=h). This is ruled out since a1, . . . , a n, b1, . . . , b nstem from a common Sidon set.\nThe same argument shows that ai+bican be represented in exactly two ways in U+V,\nnamely as ai+bi= (ai+v0) + (bi−v0) and ai+bi= (ai+v1) + (b1−v1).\n•The only possible representations of w+tkinU+Varetk= (ai+v0) + (w+tk−ai−v0)\nandtk= (ai+v1) + (w+tk−ai−v1) (whenever the variable xiappears in the k-th clause).\nIndeed, any other representation would necessarily take the form w+tk=ai+bjorw+tk=\nai+ (w+tℓ−aj) (where i̸=jork̸=ℓ). The first equation is ruled out since wis orthogonal\nto all other terms in the equation, and the second out is ruled out since a1, . . . , a n, t1, . . . , t m\nstem from a common Sidon set.\nWe are ready to complete the proof. So assume that there are sets A⊆UandB⊆Vsatisfying\nthat X⊆A+B⊆Y; we construct a satisfying assignment of ϕ. The first claim implies that\neither ai+v0∈Aor that ai+v1∈A. Indeed, if both elements were missing we would violate the\ncondition that ai+bi∈X⊆A+B(which requires at least one of these two ', 'raytos.r.bsinfotech@gmail.com', 'Amir Abboud, Nick Fischer, Ron Safier, Nathan Wallheimer', '', '../pdf_files/671b4c613d817-Recognizing Sumsets is NP-Complete.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(135, '1510283503', '1', 1, 1, 'Counting Locally Optimal Tours in the TSP', '2024-10-25', '2024', 'We show that the problem of counting the number of 2-optimal tours in instances of the Travelling Salesperson Problem (TSP) on complete graphs is #P-complete. In addition, we show that the expected number of 2-optimal tours in random instances of the TSP on complete graphs is O(1.2098n √n!). Based on numerical experiments, we conjecture that the true bound is at most O(√n!), which is approximately the square root of the total number of tours.', 'Data Structures and Algorithms, Computational Complexity, Discrete Mathematics', 'Counting Locally Optimal Tours in the TSP\nBodo Manthey1and Jesse van Rhijn1\n1Department of Applied Mathematics, University of Twente\nOctober 25, 2024\nWe show that the problem of counting the number of 2-optimal tours in instances of the\nTravelling Salesperson Problem (TSP) on complete graphs is #P-complete. In addition, we\nshow that the expected number of 2-optimal tours in random instances of the TSP on complete\ngraphs is O(1.2098n√\nn!). Based on numerical experiments, we conjecture that the true bound\nis at most O(√\nn!), which is approximately the square root of the total number of tours.\n1 Introduction\nThe Travelling Salesperson Problem is among the best-studied problems in computer science. It can be\nstated compactly: given a weighted graph G= (V, E) with edge weights w:E→R, find the Hamiltonian\ncycle (tour) on Gwith the smallest total weight. The TSP is a classic example of a hard optimization\nproblem, being even among Karp’s original 21 NP-hard problems [24].\nOwing to this hardness, practitioners often turn to approximate methods. One extremely successful\nmethod is local search [26]. This is a general optimization framework where one modifies an existing\n(sub-optimal) solution into a better solution.\nThe simplest local search heuristic for the TSP is 2-opt [2]. This heuristic takes as its input a tour T,\nand finds two sets of two edges each, {e1, e2} ⊆ Tand{f1, f2}⊈T, such that exchanging {e1, e2}\nfor{f1, f2}yields again a tour T′, and the total weight of T′is strictly less than the total weight of T.\nThis procedure is repeated with the new tour, and stops once no such edges exist. The resulting tour is\nsaid to be locally optimal with respect to the 2-opt neighborhood.\nA convenient way to view 2-opt (and other local search heuristics) is via the transition graph T. This\ndirected graph contains a node for every tour of G. An arc ( T1, T2) exists in Tif and only if T2can be\nobtained from T1by a 2-opt step and T2has strictly lower cost than T1. The sinks of Tare exactly the\nlocally optimal tours of G. A run of 2-opt can then be characterized by a directed path through Tending\nin a sink.\nMuch research has previously focused on understanding the running time of 2-opt [11, 18, 19, 27, 28]\nand its approximation ratio [8, 17, 18, 21, 25]. On the other hand, little is known about the structure\nofT. In this paper, we are concerned with counting the number of sinks of T, which is equivalent to\ncounting the number of 2-optimal tours in the instance represented by T.\nThere are practical reasons to study the transition graphs of local search heuristics. First, observe that\nthe transition graph of 2-opt for the random TSP instances we consider is a type of random directed\nacyclic graph. A run of 2-opt can be viewed as a path through this random DAG, so that the the length\nof the longest path in Tis an upper bound for the number of iterations 2-opt can perform. This upper\nbound is however rather crude: If we consider a run of 2-opt with a random initialization, then the\nprobability that we start the run on a node of the longest path is likely small. If most paths are much\nshorter, then this can provide a better explanation for the practical running time of 2-opt than only\nstudying the longest path.\nStructural results on the transition graph may in addition have implications for the running time of\nmetaheuristics. In particular, 2-opt is often used as the basis of simulated annealing, a physics-inspired\nmetaheuristic [2, Chapter 8]. It has long been known that the structure of the transition graph strongly\ninfluences the running time of this algorithm. Structural parameters of this graph often enter convergence\nresults and running time estimates [20, 22, 29]. A recent result by Chen et al. [12] especially illustrates\n1arXiv:2410.18650v1  [cs.DS]  24 Oct 2024this point. They showed that the Metropolis process (in essence, simulated annealing at a constant\ntemperature) is unable to find even very large planted cliques in an Erd˝ os-R´ enyi random graph. Their\nanalysis hinges on several structural results on cliques in such random graphs.\nThe result by Chen et al., as well as the preceding result by Jerrum [22], deals with the purely discrete\nproblem of finding cliques. However, simulated annealing is often applied to weighted problems [1], which\nyields significant challenges in understanding the transition graph. We believe that understanding more\nabout the structure of transition graphs is key to proving rigorous results on simulated annealing for\nweighted problems.\nResults\nWe start by showing that the problem of counting 2-optimal tours is #P-complete, even on complete\nweighted graphs. Recall that #Pis the counting analogue to NP, asking not whether a solution exists\nbuthow many solutions exist. A formal definition of #Pis provided in Section 2.\nOur result is in fact slightly stronger. To state it in full, we need the notion of a path cover . A set of\npaths Pin a graph Gis a path cover if every vertex of Gis contained in exactly one path of P. We then\nhave the following.\nTheorem 1.1. Letf2-opt be a function that maps a complete weighted graph on the vertex set Vto the\nnumber of 2-optimal tours on this graph. Using |V|calls to f2-opt, we can compute the number of path\ncovers of size ℓfor each 1≤ℓ≤ |V|in polynomial time, using f2-opt as an oracle.\nThis result yields #P-hardness of #2Opt on complete graphs as a corollary. This counting problem\nasks the question: Given a weighted graph G, how many 2-optimal tours are there on G? Note that\ncounting the number of Hamiltonian cycles is trivial on complete graphs, whereas hardness of counting\n2-optimal tours in the same setting is not immediately obvious.\nTheorem 1.2. #2Opt is#P-complete, even on complete graphs.\nWe note that the result remains true for metric TSP instances on complete graphs, which can be seen\nto hold by adding a sufficiently large number to every edge weight of the original instance.\nWhile counting 2-optimal tours on complete graphs is thus likely intractable in general, we may still\nwonder about the average case. In the case where the edge weights are given by independent uniformly\ndistributed random variables, we obtain the following upper bound on the number of 2-optimal tours.\nTheorem 1.3. LetGbe a complete graph on n= 2k+ 1vertices, with edge weights drawn independently\nfrom U[0,1]for each edge. Then the expected number of 2-optimal tours on Gis bounded from above\nbyO\n1.2098n√\nn!\n.\nIn the process of proving Theorem 1.3 we obtain a link between the number of 2-optimal tours and\nthe probability that all entries of a multivariate normal random vector are positive. This quantity is also\nknown as the positive orthant probability. To estimate this probability we prove the following theorem.\nTheorem 1.4. LetXbe a multivariate normal vector with zero mean and covariance matrix Σ. The\npositive orthant probability P(Rd\n+) =P(X∈Rd\n+)satisfies\nP(Rd\n+)≤exp\n1\n2Pd\ni=1Σ−1\nii\nEh\nX2\niRd\n+i\n2d−1ed/2.\nIn particular, if the diagonal elements of Σ−1are each Σ−1\nii= 1, then\nP(Rd\n+)≤2−d+1e−d/2exp1\n2Eh\n∥X∥2\n2Rd\n+i\n.\nTheorem 1.4 makes no assumptions on the covariance matrix Σ, and thus holds for any set of zero-mean\nmultivariate normal variables. Hence, it may be of independent interest in applications where bounds on\npositive orthant probabilities are necessary.\n22 Preliminaries\n2.1 Notation and Definitions\nWe start with some notational shorthand. Given a symbol a, we write amfor the string consisting of m\ncopies of a. Throughout, log( ·) denotes the logarithm to base 2. We denote the positive orthant of Rd\nbyRd\n+={x∈Rd|xi>0, i∈[d]}. The negative orthant Rd\n−is defined similarly.\nLetG= (V(G), E(G)) be a simple graph. For Ta tour through G, we call the edges of Tthetour-edges\nand the edges of E(G)\\Tthechord-edges . A 2-change on Gthen removes two tour-edges from Tand\nadds two chord-edges to T.\nFor a fixed tour, if two tour-edges are removed then there is only one choice of chord-edges that yields a\nnew tour. Thus, we can characterize a 2-change fully by the tour-edges it removes. If a 2-change removes\nthe tour-edges eandfwe denote this 2-change by ST(e, f), omitting the subscript Twhen the tour is\nclear from the context. We say that two 2-changes on Tarechord-disjoint if they have no chord-edges\nin common.\nGiven a set Sof 2-changes, we define P(S) ={{e, f} |ST(e, f)∈ S} as the set of pairs of tour-edges\nthat participate in the 2-changes in S. For e∈T, we define ke(S) =|{p∈P(S)|e∈p}|, the number\nof 2-changes in Sin which eparticipates. For each of these quantities, we may omit the argument S\nwhenever the set meant is clear from context.\nCounting Complexity\nFor our complexity results, we state the definitions of #Pand#P-completeness taken verbatim from\nArora and Barak [5].\nDefinition 1. A function f:{0,1}∗→Nis in #Pif there exists a polynomial p:N→Nand a\npolynomial-time Turing machine Msuch that for every x∈ {0,1}∗,\nf(x) =n\ny∈ {0,1}p(x)|M(x, y) = 1o.\nFor completeness, we need to recall the complexity class FP, which is the functional analogue to P.\nThis means that FPis the set of functions f:{0,1}∗→ {0,1}∗computable by a polynomial-time\ndeterministic Turing machine. Moreover, we denote by FPfthe set of such functions where the Turing\nmachine additionally has access to an oracle for f.\nDefinition 2. A function fis#P-complete if it belongs to #Pand every g∈#Pis in FPf.\nBy this definition, if we can solve some #P-complete problem in polynomial time, then we can solve\nevery problem in #Pin polynomial time.\n2.2 Multivariate Normal Distribution\nWe require some basic facts about multivariate normal distributions. Let µ∈Rdand let Σ ∈Rd×d\nbe symmetric and positive definite. The multivariate normal distribution N(µ,Σ) is defined by the\nprobability density function\nf(x) =exp\0\n−1\n2(x−µ)TΣ−1(x−µ)\n(2π)d/2√\ndet Σ(1)\nwith support Rd.\nLetX∼ N d(µ,Σ). The positive orthant probability ofXis the probability that Xfalls in the positive\northant Rd\n+. When µ= 0 this quantity is also referred to simply as the orthant probability , without\nspecifiying which orthant, as each orthant is related by flipping the sign of a set of coordinates.\nOrthant probabilities are closely related to the truncated multivariate normal distribution . Let a, b∈Rd\nwith ai< bifor each i∈[d]. By abuse of notation we write [ a, b]d={x∈Rd|ai≤xi≤bi, i∈[d]}. The\nmultivariate normal distribution truncated from below by aand from above by bis given by\nf(x;a, b) =\n\n1\nP(X∈[a,b]d)·exp(−1\n2(x−µ)TΣ−1(x−µ))\n(2π)d/2√\ndet Σ,ifx∈[a, b]d,\n0, otherwise .(2)\n3A special case of the truncated normal distribution is the half-normal distribution , which is obtained by\nsetting ai= 0 and bi=∞for all i, and taking µ= 0 and Σ = diag( σ2\n1, . . . , σ2\nd).\nThe moments of the truncated multivariate normal distribution are significantly harder to compute than\nthose for the non-truncated distribution. Nevertheless, there are some elegant results in the literature.\nWe need the following result due to Amemiya [4].\nTheorem 2.1 ([4, Theorem 1]) .LetXbe distributed according to a d-dimensional truncated multivariate\nnormal distribution with zero mean and covariance matrix Σ, with each variable truncated only from below\nat zero. Then for each i∈[d],\ndX\nj=1Σ−1\nijE[XiXj] = 1.\nThere are also explicit formulae for the second-order moments of this distribution. We use a formula\nby Manjunath and Wilhelm [6], adapted to our purposes.\nTheorem 2.2 ([6, adapted from Equation (16)]) .LetXbe distributed according to a d-dimensional\ntruncated multivariate normal distribution with zero mean and covariance matrix with entries σij, with\neach variable truncated only from below at zero. Then for each i∈[d],\nE[X2\ni] =σii+dX\nk=1X\nq̸=kσik\nσiq−σkqσik\nσkk\nFkq(0,0),\nwhere Fijdenotes the joint marginal distribution of (Xi, Xj).\n3 Complexity of Counting 2-Optimal Tours\nWe now proceed to show hardness of counting 2-optimal tours on complete graphs. We start by recalling\nthe notion of a path cover . Given a simple graph G= (V, E), a path cover PofGis a collection of\nvertex-disjoint paths such that every v∈Vbelongs to exactly one path of P. The sizeofPis the\nnumber of paths in P. Note that a path cover of size 1 is equivalent to a Hamiltonian path, and that a\npath cover may contain paths that consist of a single vertex.\nFrom an instance G= (V, E) of#HamPath we construct a family of instances Gm= (V∪S, E∪F)\nof#2Opt form≥ |V|+ 1. First, we add a new set Sof vertices to G′, where |S|=m≥ |V|+ 1. To\nensure that the reduction is polynomial-time computable, we also require m≤2|V|; the reason for this\nchoice will be apparent shortly. The edges of Gmare the edges of G, which are assigned a weight of 0\nplus the set of edges F, which contains:\n•all missing edges between the vertices of V, with weight M, which we call non-edges;\n•all edges between the vertices of S, with weight N, which we call S-edges;\n•all edges between the vertices of Vand the vertices of S, with weight L, which we call ( V, S)-edges.\nThe relationship between the edge weights is as follows: we set M≫N= 2L. The precise values of\nthese numbers are not important. See Figure 1 for a schematic depiction of the reduction.\nBy this construction, Gmis a complete graph on |V|+mvertices. We claim that by computing the\nnumber f2-opt(Gm) of 2-optimal tours on Gmform∈ {|V|+ 1, . . . , 2|V|}we can compute the number of\npath covers of Gof size 1 ≤ℓ≤ |V|. To that end, we first characterize the 2-optimal tours on Gm.\nLemma 3.1. A tour Tthrough Gmis 2-optimal if and only if it contains no non-edges.\nProof. To begin, we note that since |S|>|V|, any tour must contain at least one S-edge. Now suppose T\ncontains a non-edge uv /∈E, and let abbe an S-edge in T. Assume these vertices are traversed in the\nwritten order on T. Then we replace uvandabbyuaandvb, a 2-change which decreases the tour length\nbyM+N−2L >0. Hence, Tis not 2-optimal, proving one direction.\nFor the other direction, suppose Tcontains no non-edges. Since Mis much larger than NorL, an\nimproving 2-change cannot add any non-edges to the tour. Any 2-changes on Tmust then involve only\nedges of G,S-edges and ( V, S)-edges. We go case by case, considering the possible types of the edges\nremoved by any 2-change on T.\n4VS\n0M L\nL\nL NN\nN\n(a) The reduction we use to prove #P-hardness of\n#2Opt . The set Vrepresents the vertices of the\noriginal graph, and Sis the set of mvertices added\nin the reduction. Each depicted edge is labelled with\nits weight. Note that in Gm, the non-edges of Gare\nadded as well (represented here by the dashed edge).(b) A 2-optimal tour through Gmconsist-\ning of two segments. Solid black curves\nrepresent paths through V, solid gray\nlines are paths through S, and dotted\nlines are ( V, S)-edges.\nFigure 1: Schematic depiction of the reduction we use to prove #P-hardness of #2Opt , and of a 2-\noptimal tour in the image instance.\nTwoS-edges. Since the vertices involved are all vertices of Sthe added edges are also S-edges, and\nhence the 2-change does not change the length of the tour at all and is therefore not feasible.\nTwo edges of G.Since these edges have zero weight the tour length cannot decrease, and the 2-change\nis not feasible.\nTwo(V, S)-edges. There are two possibilities for the added edges. In one case we obtain one S-edge and\none edge of G, for an improvement of 2 L−N= 0. In the other case we obtain again two ( V, S)-edges,\nagain for no improvement.\nOneS-edge aband one edge uvofG.The added edges are auandbv, both of which are ( V, S)-edges\nand thus of weight L. The tour is thus shortened by N−2L= 0, and the 2-change yields no\nimprovement.\nOne(V, S)-edge auand one edge vwofG.The added edges are avanduw. The added edges are\nagain a ( V, S)-edge and an edge of G, yielding no improvement.\nOne(V, S)-edge auand one S-edge bc.The added edges consist of one ( V, S)-edge and one S-edge,\nand there is no change in tour length.\nThese cases cover all possibilities, and hence a tour that contains no non-edges is 2-optimal, concluding\nthe proof.\nLetTbe a 2-optimal tour through Gm. If we remove from Tall edges incident to S, then we obtain a\npath cover of G. We call the size of the resulting path cover the number of segments ofT. On the other\nhand, from any path cover of G, we can construct many 2-optimal tours by connecting the paths in the\ncover using vertices of S.\nMore formally, we say that a path cover Pcorresponds toTif we obtain Pby removing the edges\nofTincident to S. Note that two distinct path covers of Gcorrespond to two disjoint sets of 2-optimal\ntours through Gm, and every 2-optimal tour corresponds to exactly one path cover. The following lemma\ncounts the number of 2-optimal tours that correspond to a single path cover of size ℓ.\nLemma 3.2. A path cover of size ℓcorresponds to exactly2ℓ−1·m!·(m−1)!\n(m−ℓ)!2-optimal tours in Gmwithℓ\nsegments.\nProof. By Lemma 3.1, the 2-optimal tours are exactly those tours which contain no non-edges. Given a\npath cover Pof size ℓ, we can then construct a 2-optimal tour in Gmas follows.\nAny tour must visit all vertices in Sin some order. Hence, we first fix a tour TSthrough S; there\nare1\n2(m−1)! such choices. Next, we break ℓedges of TS; there are\0m\nℓ\nchoices of which edges to break.\n5We must now insert the ℓpaths of Pin place of these broken edges, reconnecting the endpoints of\neach path to the endpoints of the broken edge it replaces. Note that whenever we perform this operation,\nthere are two possible ways to connect the path. Moreover, there are ℓ! ways to match an endpoint to a\nbroken edge, for a total of 2ℓ·ℓ! ways to insert the paths.\nPutting the pieces together, we thus have\n(m−1)!\n2·m\nℓ\n·2ℓ·ℓ! =2ℓ−1·m!·(m−1)!\n(m−ℓ)!\nways to construct a 2-optimal tour through Gm.\nLetc(ℓ, m) =2ℓ−1·m!·(m−1)!\n(m−ℓ)!, and let C∈Z|V|×|V|be a matrix with entries Cij=c(i, j+|V|). Recall\nthatℓruns from 1 to |V|andmruns from |V|+ 1 to 2 |V|.\nLemma 3.3. The matrix Cdefined above has full rank.\nProof. To start, we write out the entries of Cexplicitly. Letting n=|V|,\nCij=2i−1·(n+j)!·(n+j−1)!\n(n+j−i)!.\nScaling any row or column of a matrix uniformly does not change its rank. Hence, we multiply column j\nby1\n(n+j)!·(n+j−1)!, and subsequently multiply row iby 1/2i−1. Finally, interchanging any two rows also\ndoes not change the rank of the matrix, and hence we also mirror the rows of the matrix. The resulting\nmatrix C′has entries\nC′\nij=1\n(i+j−1)!.\nTo show that this matrix has full rank, we first recall that a square matrix has full rank if and only\nif its determinant is nonzero. While we could in principle compute the determinant exactly, this is\ntedious and not necessary for our purposes. Hence, we use a concise argument from analysis to only\nshow det C′̸= 0 [31], reproduced here for the sake of completeness. The proof uses the notion of\ntheWronskian W(x) of a set of functions fj(x), which is the determinant of the matrix with ( i, j)-th\nelement f(i)\nj(x). If the functions are analytic, then W(x) vanishes identically if and only if the functions\nare linearly dependent [7].\nWe observe that the determinant of C′is, up to a sign, the Wronskian of the functions fj(x) =\nxn+j−1\n(n+j−1)!evaluated at x= 1. Since these functions are polynomials of different degrees, they are linearly\nindependent and hence from analyticity of the polynomials it follows that the Wronskian does not vanish\nidentically. By factoring out all the powers of xfrom the rows and columns, we see that the Wronskian\nis a power of xmultiplied by its value at x= 1, which is det C′up to a sign. As the Wronskian does not\nvanish identically, we must have det C′̸= 0.\nNow we proceed to our main algorithmic result, from which #P-completeness of #2Opt follows as a\ncorollary.\nTheorem 1.1. Letf2-opt be a function that maps a complete weighted graph on the vertex set Vto the\nnumber of 2-optimal tours on this graph. Using |V|calls to f2-opt, we can compute the number of path\ncovers of size ℓfor each 1≤ℓ≤ |V|in polynomial time, using f2-opt as an oracle.\nProof. For a graph G, let Gmbe the complete weighted graph resulting from the reduction described\nabove. Let aℓ(G) be the number of path covers of size ℓ, and let bℓ(Gm) be the number of 2-optimal\ntours on Gmconsisting of ℓsegments. From Lemma 3.2, we have\nbℓ(Gm) =c(ℓ, m)aℓ(G).\nWe have f2-opt(Gm) =P|V|\nℓ=1bℓ(Gm) =P|V|\nℓ=1c(ℓ, m)aℓ(G).\nWe aim to compute the numbers aℓ(G) for each ℓ∈[|V|]. Let a= (aℓ(G))ℓ∈[|V|], and let b=\n(f2-opt(Gm))2|V|\nm=|V|+1. Then the above yields the matrix equation b=CTa.\nBy Lemma 3.3, the matrix Chas full rank, and is hence invertible. While Cis rather ill-conditioned,\nthe elements of Ccan be encoded using a number of bits polynomial in |V|+|E|. Thus, after making |V|\ncalls to f2-opt to compute the vector b, we can compute ain polynomial time. The entries aℓofaare, by\nconstruction, exactly the number of path covers of size ℓofG.\n6Theorem 1.2. #2Opt is#P-complete, even on complete graphs.\nProof. Membership in #Pis obvious, since the problem of verifying 2-optimality of a tour is in P. For\nhardness, we rely on the #P-hardness of #HamPath , which was shown by Valiant [30]. Note that the\nnumber of Hamiltonian paths through a graph Gis exactly the number of path covers of size ℓ= 1. By\nTheorem 1.1, given oracle access to f2-opt, we can solve #HamPath – and thus every problem in #P–\nin polynomial time, and hence #2Opt is#P-complete when restricted to complete graphs.\n4 Counting 2-Optima in Random Instances\nWhile counting 2-optimal tours is in general hard on complete graphs, we can still provide some results\nfor special cases. In this section, we restrict our attention to complete graphs on n= 2k+ 1 vertices\nfor some integer k. The weights of the edges of our graphs are drawn independently from the uniform\ndistribution on [0 ,1].\nThe strategy we use is to bound the probability that a given tour is 2-optimal. Since we assume\nthe input graph is complete, this probability is the same for all tours. It then suffices to multiply this\nprobability by the total number of tours, which is1\n2(n−1)!.\nTo bound the probability of a tour Tbeing 2-optimal we find a large set Sof mutually chord-disjoint\n2-changes on T. We then apply a general result that links the probability of 2-optimality of Tto how often\neach edge of Tis used in S(Lemma 4.1). Details of the construction of this set are given in Section 4.2.\n4.1 Orthant Probabilities and 2-Optimality\nLetSbe a set of chord-disjoint 2-changes on a tour Ton the complete graph on nvertices, and define\nforx∈RE\ngS(x) = exp\n−X\n{e,f}∈P(S)xexfp\nke(S)kf(S)\n.\nNow let X= (Xe)e∈T,ke(S)>0be a sequence of independent half-normal distributed random variables\nwith unit variance. We define the function\nG(S) =E[gS(X)].\nObserve that Gis solely a function of S.\nLemma 4.1. LetGbe a complete graph on nvertices, with each edge of Gindependently assigned a\nweight drawn from U[0,1]. Let Tbe any tour through G. LetSbe a set of chord-disjoint 2-changes on T.\nThen\nP(Tis 2-optimal )≤ G(S)Y\ne∈T\nke(S)>0rπ\n2ke(S).\nBefore moving to a proof, we need a technical lemma.\nLemma 4.2. For1≤x≤2, it holds that1\n2(2−x)2≤e−x2/2.\nProof. First, observe that the inequality holds for x= 1, as1\n2<1/√e≈0.6. Next, note that e−x2/2is\nstrictly convex on (1 ,∞). Thus, this function lies entirely above its tangent line at x= 1 for all x >1.\nThe tangent line is given by x7→2e−1/2−e−1/2x. It then suffices to show that1\n2(2−x)2≤2e−1/2−e−1/2x\nforx∈(1,2]. Indeed,\n1\n2(2−x)2≤2e−1/2−e−1/2x⇐⇒ 2\n1−1√e\n−\n2−1√e\nx+1\n2x2≤0,\nwhich holds for x∈[2−2/√e,2]⊃(1,2].\nProof of Lemma 4.1. LetSbe a 2-change on Tand write ∆( S) for the improvement in tour length due\ntoS. Then Tis 2-optimal if and only if for all possible 2-changes SonTwe have ∆( S)≤0, and so\nP(Tis 2-optimal) ≤P ^\nS∈S∆(S)≤0!\n.\n7If we condition on the values of the weights on the edges of T, then, since the 2-changes in Sare all\nchord-disjoint, the events {∆(S)≤0}S∈Sare independent subject to this conditioning. Thus,\nP(Tis 2-optimal |w(e) =se, e∈T)≤Y\nS∈SP(∆(S)≤0|w(e) =se, e∈T).\nConsider a 2-change Sthat involves the tour-edges eiandej. Then\nP(∆(S)≤0|w(ei) =si, i∈[n]) =P(X+Y≥si+sj),\nwhere X, Y∼U[0,1]. We can directly compute this latter probability, yielding\nP(X+Y≥si+sj) =Z2\nsi+sjfX+Y(x) dx,\nwhere the integrand is the density of X+Y, given by\nfX+Y(x) =\n\nx, if 0≤x≤1,\n2−x,if 1< x≤2,\n0, otherwise .\nIntegrating this density, we obtain\nP(X+Y≥si+sj) =\n\n1, ifsi+sj≤0,\n1−1\n2(si+sj)2,ifsi+sj≤1,\n1\n2(2−(si+sj))2,if 1< si+sj≤2,\n0, ifsi+sj>2.\nOn [0 ,2], this function is bounded from above by\ne−(si+sj)2\n2=e−s2\ni/2e−s2\nj/2e−sisj.\nFor 0 ≤si+sj≤1, this follows from the standard inequality 1 + x≤ex, while for 1 < si+sj≤2 we\nuse Lemma 4.2.\nUsing this upper bound, we can write\nP(Tis 2-optimal |w(e) =se, e∈T)≤Y\n{e,f}∈P(S)e−s2\ne/2e−s2\nf/2e−sesf.\nNote that for a given edge e∈T, the factor factor e−s2\ne/2appears ketimes. Hence,\nP(Tis 2-optimal |w(e) =se, e∈T)≤Y\ne∈Te−kes2\ne/2·Y\n{e,f}∈P(S)e−sesf.\nWe now get rid of the conditioning,\nP(Tis 2-optimal) ≤Z1\n0···Z1\n0exp\n−1\n2X\ne∈T\nke>0kes2\ne\nexp\n−X\n{e,f}∈P(S)sesf\nY\ne∈T\nke>0dse.\nWe perform a change of variables: let xe=√kese. Next, we let the upper limit of each integral go to\ninfinity; it is easily verified that this leads to a negligible loss in the upper bound. We find\nP(Tis 2-optimal) ≤Y\ne∈T\nke>01√keZ\nRd\n+exp\n−1\n2X\ne∈T\nke>0x2\ne\nexp\n−X\n{e,f}∈P(S)xexfp\nkekf\ndx,\nwhere d x=Q\ne∈T\nke>0dxe. We recognize in this expression the function gS, as well as the un-normalized\nprobability density function of the half-normal distribution. Adding in the appropriate normalization\nfactor ofp\n2/πfor each variable then yields the claim.\n8Bounding P(Tis 2-optimal) now involves two steps. First, we must construct a set Sof chord-disjoint\n2-changes such that each edge of Tis used in many 2-changes in S. Second, given this set, we must\nbound G(S).\nWe remark now that G(S) is trivially bounded from above by 1. However, this leaves a factor of\nabout ( π/2)n/2. Although this factor is small compared toQ\ne∈T, ke>01√\nke(S)for the set Swe construct,\nleaving it in is somewhat unsatisfactory. We thus make an attempt to prove a stronger bound for G.\nComputing G(S) directly is unfeasible. It helps to recast it in terms of a positive orthant probability.\nLemma 4.3. For a set Sof chord-disjoint 2-changes on a tour T, letkdenote the number of tour-edges\nwith ke(S)>0. Label these edges of Tarbitrarily from 1tok. For any I⊆[k], the function G(S)is\nbounded from above by 2|I|·√\ndet Σ·P\0V\ni∈IZi>0\n, where (Zi)i∈Iis distributed according to a multivariate\nnormal distribution with mean 0 and inverse covariance matrix Σ−1∈R|I|×|I|with entries indexed by I,\nΣ−1\nij=(\n1, ifi=j,\nsij,otherwise ,\nwhere sij≤1/p\nkikj.\nProof. Since gS(x)≤1 and gSis decreasing in each variable, we can bound gSfrom above uniformly\nby setting the coefficients of any subset of the variables to zero. Setting these to zero for all variables\noutside Ithen leaves\nG(S)≤2\nπ|I|/2Z\nR|I|\n+exp \n−1\n2X\ni∈Ix2\ni!\nexp\n−X\ni∈PI(S)xixjp\nkikj\nY\ni∈Idxi,\nwhere PI(S) is the same as P(S), except we keep only pairs with both elements in I.\nObserve that e−xixj/√\nkikj≤e−sijxixj, allowing us to replace the coefficients of these products. We\nnow only need to insert the appropriate normalization factor for a multivariate normal distribution.\nComparing the resulting expression with Equation (1) completes the proof.\nStill, computing the positive orthant probability directly is rather difficult. Explicit formulas are\nknown for low-dimensional cases, as well as general recursive formulas [3, 13, 14], but none of these are\nparticularly helpful in bounding G(S). As we only need a nontrivial upper bound, some simplifications\nare possible. In Theorem 1.4 (restated below), we show that it suffices to bound the expected squared\nnorm of a multivariate normal vector.\nIn the proof of Theorem 1.4, we need another technical lemma.\nLemma 4.4. LetSbe a random string uniformly chosen from {1,−1}d\\ {1d,−1d}ford≥2. Then we\nhaveP(Si+Sj= 0)≥1\n2for any distinct i, j∈[d].\nProof. The case d= 2 yields P(S1+S2= 0) = 1 ≥1\n2; hence, we assume d >2 in the remainder. Note\nnext that by symmetry, it suffices to consider i= 1, j= 2. The event S1+S2= 0 occurs if and only\nif (S1, S2) is either (1 ,−1) or ( −1,1).\nWe use the principle of deferred decisions. Suppose that the remaining d−2 variables have been\nfixed. If the string formed by these remaining variables is equal to neither 1d−2nor−1d−2, then the\noutcome of drawing ( S1, S2) is unconstrained. There are four outcomes and by symmetry each outcome\nhas equal probability, yielding the claim. If the remaining string is 1d−2, then there are only three possible\noutcomes for ( S1, S2), each with equal probability. Two of these outcomes satisfy S1+S2= 0; hence in\nthis case P(S1+S2= 0) =2\n3≥1\n2. The case where the remaining string is −1d−2is identical.\nTheorem 1.4. LetXbe a multivariate normal vector with zero mean and covariance matrix Σ. The\npositive orthant probability P(Rd\n+) =P(X∈Rd\n+)satisfies\nP(Rd\n+)≤exp\n1\n2Pd\ni=1Σ−1\nii\nEh\nX2\niRd\n+i\n2d−1ed/2.\nIn particular, if the diagonal elements of Σ−1are each Σ−1\nii= 1, then\nP(Rd\n+)≤2−d+1e−d/2exp1\n2Eh\n∥X∥2\n2Rd\n+i\n.\n9Proof. We prove the first claim, as the second claim follows trivially. For s∈ {− 1,1}d, letRd\nsbe the\northant corresponding to s, given by the points x∈Rdsatisfying\nsixi>0, i∈[d].\nWith this notation, the positive and negative orthants are given by Rd\n±=Rd\n±1d.\nSince Rd=S\ns∈{±1}dRd\nsand the orthants are mutually disjoint,P\ns∈{±1}dP(Rs) = 1. By symme-\ntry,P(Rd\n+) =P(Rd\n−), and so\nP(Rd\n+) =1\n2−1\n2X\ns∈{±1}d\ns̸=±1dP(Rd\ns). (3)\nGiven s∈ {± 1}d, define the linear transformation Rs(x) = (sixi)i∈[d]. Any x∈Rd\nscan then be written\nasx=Rs(x′) for some x′∈Rd\n+. Let Σ−1\nsdenote the matrix with the same entries as Σ−1, but with\nzeroes on the diagonal and zeroes for any entries ( i, j) with si+sj̸= 0. Now note that for x∈Rd\ns,\n1\n2xTΣ−1x=1\n2dX\ni=1dX\nj=1Σ−1\nijxixj=1\n2dX\ni=1dX\nj=1Σ−1\nijx′\nix′\nj−dX\ni=1dX\nj=1Σ−1\ns,ijx′\nix′\nj,\nsince only the terms satisfying si+sj= 0 change sign under Rs. Thus, we have\nP(Rd\ns) =1\n(2π)d/2√\ndet ΣZ\nRd\n+e−1\n2xTΣ−1xexp\ndX\ni=1dX\nj=1Σ−1\ns,ijxixj\ndx\n=E\nexp\ndX\ni=1dX\nj=1Σ−1\ns,ijXiXj\nRd\n+\nP(Rd\n+).\nInserting this into Equation (3) and rearranging yields\nP(Rd\n+) =\n2 +X\ns∈{1,−1}d\ns̸=±1dE\nexp\ndX\ni=1dX\nj=1Σ−1\nijXiXj\nRd\n+\n\n−1\n.\nSince exp( ·) is a convex function, we bound the denominator from below by moving the expectation\noperator inside the exp( ·) using Jensen’s inequality. To shorten our notation, we replace the variables Xi\nbyZidistributed according to a multivariate normal distribution truncated from below at zero. We\nabbreviate the expectation with respect to ZbyEZ[·]. Then (discarding the 2 in the denominator above)\nP(Rd\n+)≤\nX\ns∈{±1}d\ns̸=±1dexp\nEZ\ndX\ni=1dX\nj=1Σ−1\ns,ijZiZj\n\n\n−1\n.\nLetSbe a random string drawn uniformly from {±1}d\\{±1d}. Observe that the sum in brackets above\nis the same as\n\0\n2d−2\nES\nexp\nEZ\ndX\ni=1dX\nj=1Σ−1\nS,ijZiZj\n\n\n.\nAnother application of Jensen’s inequality moves the ES[·] into the exp( ·). To simplify the expression yet\nfurther, we bound 2d−2≥2d−1ford≥2.\nLetYij(S) be an indicator random variable taking a value of 1 if Σ−1\ns,ij>0 and 0 otherwise. Then Σ−1\nS,ij=\nYij(S)Σ−1\nij. Note that Yij(S) = 1 if and only if Si+Sj= 0. We then use Lemma 4.4 to obtain ES[Yij(S)] =\n10P(Yij(S) = 1) ≥1\n2. Using Yij(S), we further rewrite our bound to\nES\nEZ\ndX\ni=1dX\nj=1Σ−1\ns,ijZiZj\n\n=dX\ni=1dX\nj=1\nj̸=iES\nEZ\nYij(S)Σ−1\nijZiZj\n=dX\ni=1dX\nj=1\nj̸=iES[Yij(S)]\nEZ\nΣ−1\nijZiZj\n≥1\n2dX\ni=1dX\nj=1\nj̸=iΣ−1\nijEZ[ZiZj].\nThe second equality follows from the independence of {Zi}d\ni=1andYij(S).\nFor the final step we use Theorem 2.1, from which we conclude\n1\n2dX\ni=1dX\nj=1\nj̸=iΣ−1\nijEZ[ZiZj] =1\n2dX\ni=1dX\nj=1Σ−1\nijEZ[ZjZj]−1\n2dX\ni=1Σ−1\niiEZ[Z2\ni]\n=d\n2−1\n2dX\ni=1Σ−1\niiEZ[Z2\ni].\nPutting the pieces together now yields the claim.\n4.2 Finding Chord-Disjoint 2-Changes\nTo proceed, we need to construct an appropriate set Sof chord-disjoint 2-changes. We provide an explicit\nconstruction of such a set. In doing so, we need the following four lemmas to help us characterize when\na pair of 2-changes is chord-disjoint.\nIt is convenient for the remainder of the section to assign an orientation to T. Pick an arbitrary vertex\nofT, and walk along Tin an arbitrary direction. We order the edges of Taccording to the order we\nencounter them in, labelling the first edge e1, the second e2, and so on. Moreover, we consider these\nedges directed : Ifeis incident to uandvanduis encountered before v, then we write e=uv.\nLemma 4.5. If two 2-changes share exactly one tour-edge, then they are chord-disjoint.\nProof. LetS1=S(e, f1) and S2=S(e, f2) be two 2-changes sharing a single tour-edge e=u1u2.\nLetf1=v1v2andf2=v3v4. Since f1̸=f2, these edges can share at most one endpoint. Moreover, by\nthe orientation of T, we can only have v2=v3orv1=v4\nThe chord-edges involved in S1areu1v1andu2v2, while the chord-edges involved in S2areu1v3\nandu2v4. Thus, S1andS2only share a chord-edge if v1=v3orv2=v4, which is not possible.\nLemma 4.6. If two 2-changes have at most one endpoint in common, then they are chord-disjoint.\nProof. LetS1andS2be two 2-changes. Note that by assumption, S1andS2cannot share any tour-edges,\nsince then they would have two endpoints in common. If the 2-changes have no endpoints in common,\nthen the lemma is obviously true.\nAssume then that the 2-changes have one endpoint in common. Let e1andf1be removed by S1, and e1\nandf2be removed by S2. Without loss of generality, assume e1ande2have an endpoint in common.\nWe write e1=v1v2ande2=v2v3. Let f1=u1u2andf2=u3u4. Note that all of these vertices with\ndifferent labels are distinct.\nThe chord-edges added by S1are then v1u1andv2u2, while those added by S2arev2u3andv3u4.\nObserve that these are four distinct edges, concluding the proof.\nLemma 4.7. LetT1andT2be two successive sub-paths of a tour T, both containing an even number of\nedges. Any two 2-changes which are each formed by removing one edge in T1and one edge in an even\nposition along T2are chord-disjoint.\n11T1T2T3\nT4\nT5\nT6\nT7T8\nFigure 2: Colors of the edges in the tour Tat stage t= 3, for n= 24+ 1. The dotted lines are drawn to\nshow the boundaries of each segment Timore clearly. The segments of the tour are numbered\nstarting at the right and proceeding counterclockwise. The 2-changes we consider in the proof\nof Lemma 4.9 are then the 2-changes formed from the red edges in Ti(drawn black) and the\nblue edges in Ti+1(drawn gray) that appear in even positions along T, for iodd. Note that\nthe last edge along Tis drawn dashed to indicate that it is not used in the construction of S.\nProof. Lete1, e2∈T1andf1, f2∈T2. Consider two distinct 2-changes S1=S(e1, f1) and S2=S(e2, f2).\nNote that if e1̸=e2andf1̸=f2, then the edges involved in S1share at most one endpoint with the\nedges involved in S2(namely a common endpoint between two edges in T1), and the conclusion follows\nfrom Lemma 4.6. Moreover, if e1=e2andf1=f2, then S1=S2, so we can ignore this case.\nIt remains to consider the case that S1andS2share exactly one tour-edge. The conclusion then follows\nfrom Lemma 4.5.\nLemma 4.8. LetS1=ST(e1, f1)andS2=ST(e2, f2)be two 2-changes with the property that three edges\nof{e1, e2, f1, f2}form a path disjoint from the remaining edge. Then S1andS2are chord-disjoint.\nProof. Observe that two edges on the path Pmust form a 2-change Stogether. The remaining edge of the\npath forms a 2-change S′with some edge e′vertex-disjoint from the path. It follows that these 2-changes\nare chord-disjoint, since the chord-edges of S′both contain vertices not on Pwhile the chord-edges of S\nonly contain vertices of P.\nNext, we construct a set Sof 2-changes such that any two 2-changes in Sare chord-disjoint, and\nmost of the edges of Tparticipate in many 2-changes in S. The construction we provide here works for\ncomplete graphs with n= 2k+ 1 vertices for some integer k.\nThe construction of Sproceeds as follows. Recall that we ordered the edges of Tas (e1, e2, . . . , e n).\nWe define the following process on T, occurring in stages. At stage twe divide the tour into 2tequal\nsegments {T1, . . . , T 2t}, starting at e1. In each stage, we color all the edges in each odd segment red and\nthe edges in each even segment blue. The only exception to this rule is the last edge en, which we color\nblack; this edge is not used to form any 2-changes. See Figure 2 for an illustration at stage t= 3.\nAt each stage we consider the 2-changes formed by the red edges in each odd segment Titogether with\ntheeven blue edges in its successor segment Ti+1. We say that these are the 2-changes added in stage t,\nand denote the set of these 2-changes by St. We continue this process for log( n−1)−1 stages. Note\nthat in the final stage, each segment contains two colored edges.\nLemma 4.9. The 2-changes in S=Slogn−1\nt=1Stare chord-disjoint.\nProof. For any two 2-changes in St, chord-disjointness follows from Lemma 4.7. It thus remains to show\nthis for some S1∈ St1andS2∈ St2. Assume w.l.o.g. that t1< t2. In the following, we write S1=\nST(e1, f1) and S2=ST(e2, f2).\nWe consider the number of shared vertices between S1andS2. Since the case of two shared vertices is\nthe hardest to analyze, we consider it last.\nBy Lemma 4.6, if S1andS2share at most one vertex, then the 2-changes are chord-disjoint. If S1\nandS2share three vertices, then they have exactly one edge in common. By Lemma 4.5, they are then\nchord-disjoint.\n12Next, if the two 2-changes have four vertices in common, then either the edges of S1and of S2form a\ncycle, or S1=S2. The former case is only possible if n= 4, but we assume that nis odd throughout.\nThus, assume S1=S2. By construction, S1andS2both remove one red and one even blue edge from\nsuccessive segments. Observe that at any stage t≥2, ifeandfparticipate in the same 2-change, then\nby construction eandfare both red in every stage t′≤t. Thus both edges removed in S2are red in\nstage t1. This is impossible, as S1removed the same pair of edges as S2in stage t1, and every 2-change\nofSt1removes one red and one blue edge.\nIfS1andS2have three vertices in common, then the edges must form a path. This path must\nbee1e2f1f2up to interchanging the indices, since the tour-edges of a 2-change cannot share any vertices.\nBy our chosen orientation e1must be red in stage t1ande2must be red in stage t2. Then f1andf2\nare both blue in these respective stages. But blue edges are only used in a 2-change when they are even,\nandf1andf2cannot both be even: a contradiction.\nLastly, assume that S1andS2share two vertices. If these vertices are both incident to the same edge\nin both 2-changes, then S1andS2share exactly one edge, and so once again by Lemma 4.5 S1andS2are\nchord-disjoint. Thus, there are two cases: either e1ande2share an endpoint, as do f1andf2; or three\nedges among {e1, f1, e2, f2}lie on a path disjoint from the last edge. The second case follows directly\nfrom Lemma 4.8.\nIn the first case, assume w.l.o.g. that e1comes before e2inTand that e1is red in stage t1. Then f1is\nblue in stage t1, and thus f1is an even edge. Since e2directly follows e1and we assume f1andf2share\na vertex, we also know that e2is red in stage t2andf2is blue in stage t2. But in constructing Sblue\nedges are only used in 2-changes when they occur in even positions along T, and f1andf2cannot both\nbe even; a contradiction. Note that this part of the analysis does not use the fact that t1< t2, and thus\nif we interchange the indices, the same reasoning goes through. Hence, this case can be excluded.\nThis concludes the case analysis. We have thus shown that two 2-changes from two different stages\nmust be chord-disjoint, and therefore Sconsists only of chord-disjoint 2-changes.\nWe now determine how often each edge of Tis used in S.\nLemma 4.10. ForSas constructed above, we have {ke(S)}e∈T={0,1,2, . . . , n −3}. Moreover, there\nare two edges with ke(S) = 0 and two edges with ke(S) =n−1\n2.\nProof. We maintain the same order on the edges of Tas used in the construction of S. Using this order,\nwe call an edge even if it appears in an even position in this order, and odd otherwise. Note that the last\nedge enis not considered in the construction of S, and so ken= 0. For the remainder of the proof, we\nconsider Twith enremoved.\nFor convenience, denote by kt\nethe number of 2-changes that eparticipates in at stage t, so that ke=Plogn−1\nt=1kt\ne. We observe the following property of S.\nFact. Consider stage tin the construction of S. If an edge eis red in stage t, then kt\ne=n/2t+1. Ifeis\nblue, then kt\ne=n/2tifeis even, and kt\ne= 0otherwise.\nFor any edge of T, we can count the number of 2-changes of Sit participates in as follows. Construct a\nrooted directed binary tree H, where the nodes of Hare sub-paths of T. The root of HisTitself, while\nthe children of any node PofHare the first and the second halves of the edges in Punder the ordering\nof the edges of T, labelled P1andP2respectively. Thus, the children of TareP1={e1, . . . , e (n−1)/2}\nandP2={e(n−1)/2+1, . . . , e n−1}. We moreover label the arcs of H. IfP1andP2are the children of a\nnode Pas described above, then the arc a1= (P, P 1) gets a label L(a1) = 1, while a2= (P, P 2) gets a\nlabel L(a2) = 0.\nWe construct Hin this way from the root, continuing until Hhas depth log( n−1)−1. (We define\nthe depth of a node vin a rooted directed tree as the number of arcs in the directed path from the root\ntov. The depth of the tree itself is the largest depth among all nodes of the tree.) Then the nodes at\ndepth tofHare the parts into which Tis partitioned at stage t. Note that the leaves of Heach contain\ntwo successive edges of T.\nLeta= (P, Q) be an arc in HwithL(a) = 1. From the construction of S, it follows that any edge e∈Q\nis colored red in the stage corresponding to the depth of Q. Conversely, if L(a) = 0, then Qis colored\nblue in this stage.\nFor each leaf PofH, we then consider the path P(v) = Ta1P1a2. . . a log(n−1)−1Qfrom the root\nto this leaf. Following this path, we collect the labels of the arcs along this path into a string x(Q),\nsox(Q) =L(a1)L(a2). . . L(alog(n−1)−1). For e∈Q, we set xe=x(Q).\n13Given xefor some edge e∈T, we know that eis red in stage tif and only if xe(t) = 1. We thus know\nexactly in which stages eis colored red, and in which it is colored blue. Using this information together\nwith the fact above, we can derive formulae for kefor any e∈T. There are two distinct cases.\nCase 1: eodd. Since eis odd, it only participates in any 2-change when it is colored red. Thus, stage t\ncontributes xe(t)·(n−1)/2t+12-changes, and so we count\nke= (n−1)log(n−1)−1X\nt=1xe(t)·1\n2t+1=log(n−1)−1X\nt=1xe(t)·2log(n−1)−1−t\n=log(n−1)−2X\nj=0xe(log(n−1)−1−j)·2j.\nNote that for a given bit string xe, this is simply the decimal expansion of the binary number\nrepresented by xe.\nSince every bit string of length log( n−1)−1 is present for some odd edge (there are 2log(n−1)−1\nleaves in Hand each leaf corresponds to a distinct string), we find that {ke|odde∈T}=\n{0,1, . . . , (n−1)/2−1}.\nCase 2: eeven. An even edge contributes ( n−1)/2t+12-changes at stage tif it is red, and ( n−1)/2t\n2-changes if it is blue. Thus, the contribution at this stage is ( n−1)/2t−xe(t)·(n−1)/2t+1, and\nso we have\nke= (n−1)\nlog(n−1)−1X\nt=12−t−log(n−1)−1X\nt=2xe(t)·1\n2t+1\n\n=n−3−n−1\n2·log(n−1)−1X\nt=1xe(t)·1\n2t\n=n−3−log(n−1)−2X\nj=0xe(log(n−1)−1−j)·2j.\nAs in the previous case, we recognize here the decimal expansion of xein the second term.\nThus, {ke|even e∈T}={(n−1)/2−1,(n−1)/2, . . . , n −2, n−3}.\n4.3 Putting the Pieces Together\nWe return to the positive orthant probability by constructing an inverse covariance matrix Σ−1corre-\nsponding to Saccording to Lemma 4.3. In the following, we sort the edges of Tby decreasing value\nofke(S).\nObserve that the first d= (n−3)/2 edges of Tin this order each form 2-changes with one another\ninS. Note that dis an integer, as n= 2k+1 is odd. The entries of Σ−1corresponding to these 2-changes\nare Σ−1\nij= 1/p\nkikj≥1\nn−3. Thus, the inverse covariance matrix Σ−1constructed from Sis upper-left\ntriangular, except with ones on the diagonal. We can then write it in block form,\nΣ−1=˜Σ−1A\nATI\n,\nwhere the diagonal entries of ˜Σ−1∈Rd×dare each 1, and the off-diagonal entries each satisfy ˜Σ−1\nij=≥\n1\nn−3=1\n2d. We consider the matrix ˆΣ−1, which is identical to ˜Σ−1, but with the off-diagonal entries\nreplaced by1\n2d.\nComparing ˆΣ−1to Lemma 4.3, we proceed to bound the positive orthant probability associated\nwith ˆΣ−1. A trivial bound for this probability is 2−d. Lemma 4.11 therefore represents a non-trivial, if\nmodest, improvement.\nLemma 4.11. LetXbe distributed according to Nd(0,ˆΣ), where ˆΣ−1∈Rd×dhas unit diagonal entries\nand off-diagonal entries1\n2d. The positive orthant probability of Xis bounded from above by O\n2−de−2d\n9π\n.\n14Proof. It suffices to bound E[∥X∥2|Rd\n+] and use Theorem 1.4. By symmetry of ˆΣ−1the marginal densities\nof the entries of Xare all identical. Hence,\nE[∥X∥2|Rd\n+] =d·E[X2\n1|Rd\n+].\nTo compute this expected value we use Theorem 2.2, which yields\nE[X2\ni|Rd\n+] =σii+dX\nk=1X\nq̸=kσik\nσiq−σkqσik\nσkk\nFkq(0,0),\nwhere σijdenotes the i, j-entry of ˆΣ, and Fkq(x, y) is the joint marginal distribution of ( Xk, Xq) condi-\ntional on X∈Rd\n+.\nThe marginal distributions are given by a rather compact expression, since we only evaluate them at\nthe origin. Using the conditional density of Xas given in Equation (2),\nFkq(0,0) =1\n(2π)d/2p\ndetˆΣ·1\nP(Rd\n+)·Z\nRd−2\n+exp\n−1\n2xTˆΣ−1\n(kq)x\ndx,\nwhere ˆΣ−1\n(kq)is simply ˆΣ−1with the kthandqthrows and columns removed.\nThis expression can be simplified further as follows. For arbitrary m∈N, let Σ−1\nmbe the m×mmatrix\nwith unit diagonal and off-diagonal entries1\n2d. Then ˆΣ−1= Σ−1\ndand Σ−1\n(kq)= Σ−1\nd−2. Hence, inserting the\nexpression for P(Rd\n+) and cancelling like terms, we obtain\nFkq(0,0) =R\nRd−2\n+exp\0\n−1\n2xTΣ−1\nd−2x\ndx\nR\nRd\n+exp\0\n−1\n2xTΣ−1\ndx≥R\nRd−2\n+exp\0\n−1\n2xTΣ−1\nd−2x\ndx\nR\nRd−2\n+exp\0\n−1\n2xTΣ−1\nd−2xR∞\n0e−1\n2x2dx2\n=2\nπ.\nNext, we need to compute the entries of ˆΣ and the determinant det Σ−1\nd. Note that Σ−1\nd=D+1\n2deeT,\nwhere D=\0\n1−1\n2d\nIandeis the all-1 column vector. It can then be straightforwardly verified from the\nSherman-Morrison formula that\ndet Σ−1\nd=3d−1\n2d−12d−1\n2dd\nand σij=2d\n2d−1·(\n1−1\n3d−1,ifi=j,\n−1\n3d−1, otherwise .\nWe omit the details of the calculations as they are routine.\nLetgkq=σ1k\nσ1q−σkqσ1k\nσkk\n. We now computePd\nk=1P\nk̸=qgkq. There are three values that gkqtakes:\nCase 1: k̸= 1,q̸= 1.Then gkq=\n2d\n2d−12\n1\n3d−12\n1 +1\n3d−2\n.\nCase 2: k= 1.Then gkq=σ1q−σ1qσ11/σ11= 0.\nCase 3: q= 1.Then gkq=−\n2d\n2d−12\n·1\n3d−1·\n1−1\n3d−1−1\n3d−2\n. Simplifying slightly, we have gkq≤\n−\n2d\n2d−12\n·1\n3d−1·\n1−2\n3d−2\n.\nIn computing the sum over kandqwe find ( d−1)(d−2) terms corresponding to case Case 1, d−1 terms\ncorresponding to Case 2, and d−1 terms corresponding to Case 3. Thus, we have\ndX\nk=1X\nq̸=kgkq≤(d−1)(d−2)·2d\n2d−12\n·1\n3d−12\n1 +1\n3d−2\n−(d−1)·2d\n2d−12\n·1\n3d−1·\n1−2\n3d−2\n.\nRearranging, simplifying, and grouping negligible terms, we find\ndX\nk=1X\nq̸=kgkq≤ −2\n9+O1\nd2\n.\n15Plugging all of the above into the formula for E[X2\n1|Rd\n+] results in\nE[X2\n1|Rd\n+]≤σ11−2\nπ2\n9−O1\nd2\n= 1−4\n9π+O1\nd\n.\nUsing Theorem 1.4, we then finally obtain\nP(Rd\n+)≤2−d+1e−d/2e1\n2(O(1)+d−4d\n9π)=O\n2−de−2d\n9π\nas claimed.\nThe following is now an immediate consequence of Lemmas 4.3 and 4.11, recalling that d= (n−3)/2.\nLemma 4.12. ForSas constructed above, G(S) =O\0\ne−n\n9π\n.\nProof. By Lemma 4.3, we need to multiply the bound from Lemma 4.11 by a factor 2dp\ndetˆΣ. It is\neasily seen from the proof of the latter lemma that this determinant is O(1).\nFinally, we combine all of the above for the last crucial lemma, from which our main result follows\ndirectly.\nLemma 4.13. LetGbe a complete graph on n= 2k+ 1≥5vertices, with edge weights drawn indepen-\ndently from U[0,1]for each edge. Let Tbe any tour through G. The probability that Tis 2-optimal is\nbounded from above by\nO \ncn\np\n(n−2)!!\n,\nwhere c=pπ\n2·e−1\n9π<1.2098.\nProof. LetSbe a set of 2-changes on Gconstructed as described above, and let kebe the number of\n2-changes in Sin which e∈Tparticipates. From Lemma 4.10 we have\nY\ne∈T\nke>01\nke=1\nn−1\n2−1·1\n(n−3)!=O1\n(n−2)!\n.\nUsing this result in Lemma 4.1 together with Lemma 4.12 yields the claim.\nThis leads to our last result (Theorem 1.3), using the fact that the number of tours on a complete\ngraph is1\n2(n−1)!.\n4.4 Numerical Experiment\nIt seems unlikely that the bound in Theorem 1.3 is tight. A simple numerical estimate of G(S) already\nshows that it could be improved to O(1.0223n√\nn!), but even this may be a coarse approximation; after\nall, in constructing S, we discard many 2-changes.\nTo estimate the number of 2-optimal tours numerically, one could take a na¨ ıve approach: simply fix a\ntourT, generate edge weights from U[0,1], and check 2-optimality of Twith these weights. By repeating\nthis experiment we can estimate P(Tis 2-optimal). However, since this probability is super-exponentially\nsmall (Lemma 4.13), this is rather inefficient.\nWe can do better by taking a different view of the problem. Fix again an arbitrary tour T. We write\nthe edge weights as a vector w∈[0,1]E. Given T, we can determine all n(n−3)/2 possible 2-changes\nonT. Local optimality of Tmeans that all these 2-changes yield a negative improvement. Thus, for a\n2-change that removes edges e1ande2and adds f1andf2, this yields an inequality\nwe1+we2−wf1−wf2≤0. (4)\nEach possible 2-change on Tyields such a constraint. Together with the constraints 0 ≤we≤1 for each\nedge, this yields a convex polytope Pembedded in Rm. Since the edge weights are i.i.d uniform random\nvariables,\nP(Tis 2-optimal) = vol( P),\nthe|E|-dimensional volume of P.\n165 10 15 20 25 30 35 40\nnumber of vertices1029\n1025\n1021\n1017\n1013\n109\n105\n101\nest. volume\n1/n!\nFigure 3: Estimated volume of the 2-opt polytope Pn, for different values of n, as computed by Volesti.\nFor comparison, the function n7→1/√\nn! is also plotted.\nWe remark now that our approach through Lemma 4.1 is equivalent to bounding the volume of a\npolytope that contains P, by discarding some of the inequalities (Equation (4)). It may be possible to\nuse methods from convex geometry to compute better estimates of vol( P); we leave this discussion to\nSection 5.\nComputing the volume of an arbitrary polytope is itself not an easy task: this problem is #P-hard\nin general, as shown by Dyer and Frieze [15]. In the same work however, they show that volume ap-\nproximation can be done efficiently by randomized algorithms. We use the open-source software package\nVolesti [10, 16] to numerically approximate the volume of P.\nFor a range of different n, we compute the inequalities that define P, and output them in a format\nreadable for Volesti. We use the ‘Cooling Balls’ algorithm of Volesti, with an error parameter of 0.001\n(see the specification of Volesti [10] approximated vol( P) up to n= 40. The results of these computations\nare shown in Figure 3.\n5 Discussion\nThe result we present in Theorem 1.2 is to our knowledge the first hardness result for counting locally\noptimal solutions for a natural local search problem. We note that it is easy to show that counting the\nlocal optima is #P-hard for some local search problem. For instance, Johnson et al. [23] provided a local\nsearch problem whose locally optimal solutions are exactly the satisfying assignments of an instance of\nBoolean Satisfiability (plus one extra solution). However, their construction is rather artificial, whereas\n2-opt is a heuristic often used in practice.\nTheorem 1.3 is to our knowledge the first non-trivial bound on the number of locally optimal solutions\nfor a local search problem. It must be noted that we only proved Theorem 1.3 for specific values of n,\nnamely n= 2k+ 1 for k∈N. This restriction simplifies mainly the construction of S, our set of chord-\ndisjoint 2-changes. We believe that the results can be extended at the cost of some complexity in the\nproofs. For the sake of simplicity, we chose not to do so.\nThe bound in Theorem 1.3 shows that in expectation, the number of 2-optimal tours in a random TSP\ninstance is approximately the square root of the total number of tours. While still a rather large number,\nit is nonetheless a super-exponentially small fraction of the total number of tours.\nLimitations. A natural question concerns the tightness of the bound in Theorem 1.3. We have not suc-\nceeded in constructing a lower bound for the number of 2-optimal tours. Presumably such a construction\nwould be rather involved, since there is little structure in this random instance model. Nonetheless, we\ncan still argue that Theorem 1.3 can be improved significantly from two directions: bounding G(S) and\nconstructing S.\nLemma 4.12 is far from optimal. A simple numerical experiment to estimate G(S) yields G(S) =\n17O(1.226−n). This results in a bound of O(1.0223n√\nn!) in Theorem 1.3. We also note that, even though\nour set Sachieves essentially the largest number of chord-disjoint 2-changes possible on any tour, it may\nnot be an optimal choice: different choices may lead to better sequences of values for ke.\nUsing the trivial bound of G(S)≤1 instead of Lemma 4.12 in Lemma 4.13, we would obtain in\nTheorem 1.3 a bound of approximately O(1.2534n√\nn!). The difference with our bound is thus less than\na factor of 1 .04n, which is a rather minute improvement for the amount of trouble we went through\nto obtain it. We therefore regard the calculations leading to Lemma 4.12 more as a proof-of-concept\nthat significant improvements are still possible to obtain rigorously, and as a demonstration of the effort\nrequired to achieve anything non-trivial.\nAnother possible direction for improving the bound in Theorem 1.3 lies in polyhedron volume estima-\ntion. In Section 4.4, we defined a polytope Psuch that the volume of Pis the probability that a tour\nonnvertices is 2-optimal. While computing the volume of a polytope is #P-hard in general [15], it may\nbe possible to obtain an asymptotic formula for our specific case, as was done by Canfield and McKay\nfor the well-studied Birkhoff polytope [9].\nA conjecture. In light of these observations, and the estimate resulting from the numerical experiments,\nwe conjecture the following.\nConjecture. LetGbe a complete graph on nvertices, with edge weights drawn independently from U[0,1]\nfor each edge. Then the expected number of 2-optimal tours on Gis bounded from above by O(√\nn!).\nThe numerical data suggests that the expected number of tours may even be cn√\nn! for some c <1 (as\nopposed to c >1 as in Theorem 1.3), although we could not perform the numerical experiments for large\nenough nto state this with confidence.\nReferences\n[1] E. Aarts and J. Korst. Simulated Annealing and Boltzmann Machines: A Stochastic Approach to\nCombinatorial Optimization and Neural Computing . John Wiley & Sons, Inc., USA, 1989.\n[2] E. Aarts and J. K. Lenstra, editors. Local Search in Combinatorial Optimization . Princeton Univer-\nsity Press, 2003.\n[3] I. G. Abrahamson. Orthant Probabilities for the Quadrivariate Normal Distribution. The Annals of\nMathematical Statistics , 35(4):1685–1703, Dec. 1964.\n[4] T. Amemiya. Multivariate Regression and Simultaneous Equation Models when the Dependent\nVariables Are Truncated Normal. Econometrica , 42(6):999–1012, 1974.\n[5] S. Arora and B. Barak. Computational Complexity: A Modern Approach . Cambridge University\nPress, Cambridge, 2009.\n[6] M. B. G. and S. Wilhelm. Moments Calculation for the Double Truncated Multivariate Normal\nDensity, Sept. 2009.\n[7] M. Bˆ ocher. Certain cases in which the vanishing of the Wronskian is a sufficient condition for linear\ndependence. Transactions of the American Mathematical Society , 2(2):139–149, 1901.\n[8] U. A. Brodowsky and S. Hougardy. The Approximation Ratio of the 2-Opt Heuristic for the Euclidean\nTraveling Salesman Problem. In DROPS-IDN/v2/Document/10.4230/LIPIcs.STACS.2021.18 .\nSchloss Dagstuhl – Leibniz-Zentrum f¨ ur Informatik, 2021.\n[9] E. R. Canfield and B. D. McKay. The asymptotic volume of the Birkhoff polytope. Online Journal\nof Analytic Combinatorics , 2009.\n[10] A. Chalkis and V. Fisikopoulos. Volesti: Volume Approximation and Sampling for Convex Polytopes\nin R. The R Journal , 13(2):642–660, 2021.\n[11] B. Chandra, H. Karloff, and C. Tovey. New Results on the Old k-opt Algorithm for the Traveling\nSalesman Problem. SIAM Journal on Computing , 28(6):1998–2029, Jan. 1999.\n18[12] Z. Chen, E. Mossel, and I. Zadik. Almost-Linear Planted Cliques Elude the Metropolis Process. In\nProceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) , Proceed-\nings, pages 4504–4539. Society for Industrial and Applied Mathematics, Jan. 2023.\n[13] M. C. Cheng. The Orthant Probabilities of Four Gaussian Variates. The Annals of Mathematical\nStatistics , 40(1):152–161, 1969.\n[14] F. N. David. A note on the evaluation of the multivariate normal integral. Biometrika , 40(3-4):458–\n459, Dec. 1953.\n[15] M. E. Dyer and A. M. Frieze. On the Complexity of Computing the Volume of a Polyhedron. SIAM\nJournal on Computing , 17(5):967–974, Oct. 1988.\n[16] I. Z. Emiris and V. Fisikopoulos. Practical Polytope Volume Approximation. ACM Trans. Math.\nSoftw. , 44(4):38:1–38:21, June 2018.\n[17] C. Engels and B. Manthey. Average-case approximation ratio of the 2-opt algorithm for the TSP.\nOperations Research Letters , 37(2):83–84, Mar. 2009.\n[18] M. Englert, H. R¨ oglin, and B. V¨ ocking. Worst Case and Probabilistic Analysis of the 2-\nOpt Algorithm for the TSP. Algorithmica , 68(1):190–264, Jan. 2014. Corrected version:\nhttps://arxiv.org/abs/2302.06889.\n[19] M. Englert, H. R¨ oglin, and B. V¨ ocking. Smoothed Analysis of the 2-Opt Algorithm for the General\nTSP. ACM Transactions on Algorithms , 13(1):10:1–10:15, Sept. 2016.\n[20] B. Hajek. Cooling Schedules for Optimal Annealing. Mathematics of Operations Research , 13(2):311–\n329, 1988.\n[21] S. Hougardy, F. Zaiser, and X. Zhong. The approximation ratio of the 2-Opt Heuristic for the metric\nTraveling Salesman Problem. Operations Research Letters , 48(4):401–404, July 2020.\n[22] M. Jerrum. Large Cliques Elude the Metropolis Process. Random Structures & Algorithms , 3(4):347–\n359, 1992.\n[23] D. S. Johnson, C. H. Papadimitriou, and M. Yannakakis. How easy is local search? Journal of\nComputer and System Sciences , 37(1):79–100, Aug. 1988.\n[24] R. M. Karp. Reducibility among Combinatorial Problems. In R. E. Miller, J. W. Thatcher, and\nJ. D. Bohlinger, editors, Complexity of Computer Computations: Proceedings of a Symposium on the\nComplexity of Computer Computations , The IBM Research Symposia Series, pages 85–103. Springer\nUS, Boston, MA, 1972.\n[25] M. K¨ unnemann, B. Manthey, and R. Veenstra. Smoothed Analysis of the 2-Opt Heuristic for the\nTSP under Gaussian Noise, Aug. 2023. Comment: Combination of an ISAAC 2013 paper by Bodo\nManthey and Rianne Veenstra and an ICALP 2015 paper by Marvin K \\”unnemann and Bodo\nManthey. The results of the ISAAC 2013 paper have been improved.\n[26] S. Lin and B. W. Kernighan. An Effective Heuristic Algorithm for the Traveling-Salesman Problem.\nOperations Research , 21(2):498–516, Apr. 1973.\n[27] B. Manthey and J. van Rhijn. Improved Smoothed Analysis of 2-Opt for the Euclidean TSP. In\nDROPS-IDN/v2/Document/10.4230/LIPIcs.ISAAC.2023.52 . Schloss Dagstuhl – Leibniz-Zentrum\nf¨ ur Informatik, 2023.\n[28] B. Manthey and R. Veenstra. Smoothed Analysis of the 2-Opt Heuristic for the TSP: Polynomial\nBounds for Gaussian Noise. In L. Cai, S.-W. Cheng, and T.-W. Lam, editors, Algorithms and\nComputation , Lecture Notes in Computer Science, pages 579–589, Berlin, Heidelberg, 2013. Springer.\nFull, improved version: https://arxiv.org/abs/2308.00306.\n[29] A. Nolte and R. Schrader. A Note on the Finite Time Behavior of Simulated Annealing. Mathematics\nof Operations Research , 25(3):476–484, 2000.\n[30] L. G. Valiant. The Complexity of Enumeration and Reliability Problems. SIAM Journal on Com-\nputing , 8(3):410–421, Aug. 1979.\n[31] Q. Yuan. Answer to ”Determinant of a matrix involving factorials”, Nov. 2022.\n19', 'raytos.r.bsinfotech@gmail.com', 'Bodo Manthey, Jesse van Rhijn', '', '../pdf_files/671b4ccd4f4cd-Counting Locally Optimal Tours in the TSP.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(136, '9936450399', '1', 1, 1, 'Learning k-body Hamiltonians via compressed sensing', '2024-10-25', '2024', 'We study the problem of learning a k-body Hamiltonian with M unknown Pauli terms that are not necessarily geometrically local. We propose a protocol that learns the Hamiltonian to precision ϵ with total evolution time O(M1/2+1/p/ϵ) up to logarithmic factors, where the error is quantified by the ℓp-distance between Pauli coefficients. Our learning protocol uses only single-qubit control operations and a GHZ state initial state, is non-adaptive, is robust against SPAM errors, and performs well even if M and k are not precisely known in advance or if the Hamiltonian is not exactly M-sparse. Methods from the classical theory of compressed sensing are used for efficiently identifying the M terms in the Hamiltonian from among all possible k-body Pauli operators. We also provide a lower bound on the total evolution time needed in this learning task, and we discuss the operational interpretations of the ℓ1 and ℓ2 error metrics. In contrast to previous works, our learning protocol requires neither geometric locality nor any other relaxed locality conditions.', 'Quantum Physics, Data Structures and Algorithms, Machine Learning', 'Learning k-body Hamiltonians via compressed sensing\nMuzhou Ma1,6, Steven T. Flammia2,3, John Preskill1,7, and Yu Tong1,4,5\n1Institute for Quantum Information and Matter, California Institute of Technology,\nCA 91125, USA\n2Department of Computer Science, Virginia Tech, Alexandria, VA 22314, USA\n3Phasecraft Inc., Washington DC 20001, USA\n4Department of Mathematics, Duke University, Durham, NC 27708, USA\n5Department of Electrical and Computer Engineering, Duke University, Durham, NC\n27708, USA\n6Department of Electronic Engineering, Tsinghua University, Beijing, China\n7AWS Center for Quantum Computing, Pasadena, CA 91125, USA\nOctober 23, 2024\nAbstract\nWe study the problem of learning a k-body Hamiltonian with Munknown Pauli terms that\nare not necessarily geometrically local. We propose a protocol that learns the Hamiltonian\nto precision ϵwith total evolution time O(M1/2+1/p/ϵ)up to logarithmic factors, where the\nerror is quantified by the ℓp-distance between Pauli coefficients. Our learning protocol uses only\nsingle-qubit control operations and a GHZ state initial state, is non-adaptive, is robust against\nSPAM errors, and performs well even if Mandkare not precisely known in advance or if the\nHamiltonian is not exactly M-sparse. Methods from the classical theory of compressed sensing\nare used for efficiently identifying the Mterms in the Hamiltonian from among all possible\nk-body Pauli operators. We also provide a lower bound on the total evolution time needed in\nthis learning task, and we discuss the operational interpretations of the ℓ1andℓ2error metrics.\nIn contrast to previous works, our learning protocol requires neither geometric locality nor any\nother relaxed locality conditions.\n1arXiv:2410.18928v1  [quant-ph]  24 Oct 2024Contents\n1 Introduction 3\n2 Background 6\n2.1 Hamiltonian reshaping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.2 Compressed sensing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.3 Robust frequency estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3 The Hamiltonian learning protocol 10\n3.1 Completely commuting Hamiltonians . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.2 The experimental setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.3 Learning a completely commuting Hamiltonian . . . . . . . . . . . . . . . . . . . . . 15\n3.4 Randomized basis selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.5 Robustness to modeling errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.6 Computational complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.6.1 Reformulation to an SDP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.6.2 Self-contained analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n4 Lower bounds 23\n4.1 Model of quantum experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.2 Lower bound of the total evolution time in Hamiltonian learning . . . . . . . . . . . 24\n5 Operational interpretation of error metrics 28\n5.1 Operational interpretation of the ℓ1-norm . . . . . . . . . . . . . . . . . . . . . . . . 28\n5.2 Operational interpretation of the ℓ2-norm . . . . . . . . . . . . . . . . . . . . . . . . 29\n6 Discussion 30\nA The Hamiltonian reshaping error bound 31\nB Technical lemmas for compressed sensing 33\nC Technical lemmas for the lower bound 35\nD The robust frequency estimation protocol 36\n21 Introduction\nHamiltonian learning is a fundamental problem in quantum physics, crucial for understanding and\ncontrolling quantum systems. Accurate models of Hamiltonians are needed for tasks ranging from\nquantum simulation to quantum error correction, where precise knowledge of interactions allows\nfor better optimization and control. It is also a fundamental problem in computer science, where\nthe classically analogous task of learning undirected graphical models is central in many models of\nmachine learning.\nLearning Hamiltonians, particularly in large systems with many-body interactions, is complicated\nby the fact that dynamical access to the Hamiltonian naturally leads to entangled quantum states.\nInferring a general unknown Hamiltonian from measurements in the computational basis is therefore\nnontrivial. Similarly, access via Gibbs states introduces challenges in state preparation and post-\nprocessing of measurement results. Prior work, which we review below, has nonetheless shown that an\nunknown Hamiltonian can be learned in polynomial time from its dynamics [1 –6] or from samples of\na Gibbs state when the bipartite graph connecting qubits to interactions has bounded degree [1,7,8].\nThe classical theory of compressed sensing [9 –16] is a promising avenue for improving Hamiltonian\nlearning and extending it to the setting where the interactions are sparse, or approximately sparse,\nin a known basis. It also has many applications in other types of learning tasks involving quantum\nstates or processes [17 –23]. Classically, compressed sensing efficiently solves the following problem:\ngiven a linear measurement matrix A:Cn→Cmand an unknown vector x∈Cnwhich is promised\nto be s-sparse in a given basis, reconstruct xfrom y=Axwhen m=O(slogn). At first glance this\nseems impossible for at least two reasons. First, the well-known Nyquist theorem states that learning\na signal with bandwidth nrequires measuring Ω(n)frequencies. This however does not take into\naccount the sparsity of the underlying signal. But second, naively taking the sparsity into account\nquickly runs into fundamental computational bottlenecks, as finding the sparsest vector consistent\nwith affine constraints is NP-hard [24].\nUnder surprisingly mild conditions on the measurement matrix A, compressed sensing overcomes\nthese two obstacles. Moreover, the compressed-sensing estimate of the signal is robust to measurement\nnoise due to sampling, robust to the signal being only “near” to a sparse signal, and is even efficient\nto compute via a reduction to an easy convex optimization problem. It is therefore natural to hope\nthat compressed sensing can offer a powerful approach to reconstructing sparse Hamiltonians.\nMainresults. Weconsidertheclassof n-qubit k-bodyHamiltonians, whereallcouplingsarewritten\nin the Pauli basis and involve Paulis of weight at most kwithk=O(1). Let M≤Pk\nl=03l\0n\nl\n=O(nk)\nbe the total number of nonzero couplings in the Hamiltonian. Write H=PM\na=1µaPafor the explicit\nunknown Hamiltonian, where the coefficients µaare assumed to be normalized to lie in the interval\n[−1,1]. Our goal is to output the unknown Paulis Paand estimates bµaof the coefficients that are\naccurate in ℓperror, defined as\r\rbµ−µ\r\r\np=\0PM\na=1|bµa−µa|p1/pfor suitable p.\nIn what follows, we use eO(f)to represent O(fpolylog (n, M, 1/δ,1/ϵ,2k))where δis the failure\nprobability and ϵis the precision that we want to achieve. Although k=O(1)throughout, we keep\nfactors 2O(k)explicit to help inform the reader on some kdependence.\nTheorem (Informal version of Theorem 6) .There exists a learning protocol that uses N=eO(M)\nindependent non-adaptive experiments to learn, with probability at least 1−δ, an estimate bµof all\ncoefficients with weight ≤kthat has ℓperror ( 1≤p≤2) at most ϵ, and uses a total evolution time\nT=eOM1/p+1/2\nϵ\n.\n3The protocol is robust to a constant amount of state preparation and measurement (SPAM) noise.\nIn the above, by total evolution time , we mean the total time needed to evolve with the unknown\nHamiltonian in all experiments. Our method is also robust to modeling errors (i.e., the Hamiltonian\nmay not be exactly k-local or have more than Mterms), as discussed in Section 3.5. The operational\ninterpretations of the ℓperror metric for p= 1and2are discussed in Section 5 and correspond to\nnotions of worst- and average-case error, respectively. It is notable that our algorithm nearly achieves\nHeisenberg-limited scaling, O(1/ϵ), in the total evolution time. Also importantly, the classical\ncomputation required by our algorithm is polynomial. In fact, our estimator reduces to a convex\noptimization of the form\nminimize\nx∥x∥1subject to ∥Ax−y∥2≤α. (1)\nIn Theorem 8, we give an explicit bound on the computational resources required to obtain an\n(approximately) optimal solution to Eq. (1). As our analysis of this optimization is self-contained\n(it does not rely on reducing Eq. 1 to a semidefinite program) and appears to be new, it may be of\ninterest to a wider community.\nWe also prove a lower bound for the total evolution time for the case of ℓ1error.\nTheorem (Informal version of Theorem 9) .Suppose a learning algorithm estimates bµfor the\nunknown Hamiltonian H=PM\na=1µaPawith∥bµ−µ∥1≤ϵin expectation value over experimental\noutcomes. Then\nT= ΩM\nϵlog(1/γ)\n. (2)\nHere γis the amount of measurement error (see (66)).\nInterestingly, our lower bound holds for learning n-qubit Hamiltonians with the Mtermsfixed\nand having knownsupport. This naturally implies a lower bound for learning n-qubit M-term\nHamiltonians without prior knowledge of which Mterms are in the Hamiltonian. This suggests that\nparameter estimation, rather than support identification, may be the primary obstacle to improving\nthe time complexity for Hamiltonian learning.\nTechniques. The lack of locality presents a considerable challenge to the Hamiltonian learning\nproblem, as it prevents us from decoupling the learning problem into small problems that can be\nefficiently solved. We are therefore compelled to deal with the entire quantum system as a whole,\nand new techniques are needed to circumvent the exponential cost that usually comes from such\nproblems. Compressed sensing utilizes sparsity to greatly reduce the complexity of reconstructing\na high-dimensional vector, but prior to this work, it was far from clear how it can be applied to\nHamiltonian learning. Although the Hamiltonian coefficients can be collected into a sparse vector,\na generic observable does not depend on these coefficients linearly. The non-commutativity of the\nterms presents additional difficulties.\nOne key observation that led to this work is that we can apply compressed sensing to learn a\ncompletely commuting Hamiltonian, i.e., a Hamiltonian whose Pauli terms commute on each qubit .\nFor such a Hamiltonian, the eigenvalue differences depend linearly on the coefficients, and we can\nestimate these differences efficiently as the eigenstates are all product states.\nWe then extend this method to general k-body Hamiltonians with Mterms using Hamiltonian\nreshaping. Hamiltonian reshaping was used to decouple the dynamics and choose local bases in [5],\nbut here we use it to obtain an effective Hamiltonian that is diagonal in a global basis set of our\nchoosing. This effective Hamiltonian can then be learned using compressed sensing. However, this\n4procedure will only allow us to learn the terms that are diagonal in the given basis, and multiple\nchoices of bases are needed to cover all terms in the Hamiltonian. We then choose the basis randomly,\nand this allows us to cover all k-body terms with mild overhead. This idea comes from randomized\nmeasurement [25 –27], but to the best of our knowledge this is the first time it has been applied to a\ndynamical setting.\nPrior work. Hamiltonian learning has been the focus of many previous works [1,2,4 –6,17,25,28 –46].\nMost early works focused on achieving the Heisenberg-limited scaling, i.e., estimating parameters of\nthe Hamiltonian to precision ϵwithO(1/ϵ)cost [47], for small quantum systems, or scalability for\nlarge quantum systems but without achieving the Heisenberg-limited scaling. Recently, [5] proposed\na method to learn an n-qubit many-body Hamiltonian with total evolution time O(log(n)/ϵ), where ϵ\nis the ℓ∞-error on the coefficients, when the Hamiltonian is low-intersection, i.e., the number of Pauli\nterms acting on a qubit is a constant that is independent of the system size, and the terms in the\nHamiltonian are known. This condition can be seen as a slight relaxation of geometric locality. The\nmain technique used in [5] is Hamiltonian reshaping, which inserts random Pauli operators during\nthe experiment to obtain an effective Hamiltonian that is easy to learn and preserves some of the\ncoefficients. Later works obtained similar results for other control models [40] and in bosonic and\nfermionic scenarios [41 –43]. These works all assume that the Hamiltonian terms are known and we\nonly need to learn the coefficients.\nThe first work to consider achieving the Heisenberg-limited scaling for Hamiltonians with unknown\nterms is [45], the authors of which use a bootstrapping approach (as was also done in [40]) to gradually\nrefine the estimation of the Hamiltonian. A rough estimate of the Hamiltonian is used in the time\nevolution to partially cancel out the actual Hamiltonian, so that a finer estimate of the residue can be\nobtained. This approach necessitates implementing multi-qubit operations during the time evolution\nwhich are adapted based on previous measurement results. Moreover, although [45] went beyond the\nlow-intersection assumption, its results are still limited by certain relaxed locality assumptions. Most\nimportantly, they assume that the total interaction strength on a qubit is bounded independently of\nthe system size [45, Eq. (1)], and the number of terms with coefficient larger than ϵ(the final ℓ∞\nerror tolerance), which they call effective sparsity [45, Eq. (2)], also goes into the cost of the protocol.\nGHZ states and compressed sensing have been used previously to learn dephasing noise with\nlong-range correlation and sparsity [17], but the dissipative nature of the noise makes it impossible\nto achieve the Heisenberg limit. Compared to the setup in [17], we also need to deal with the\nnon-commutativity of the Hamiltonian terms.\nOur learning protocol takes several important steps beyond this prior work. First, it only\napplies single-qubit operations during time evolution, which is an enormous advantage for near-term\nimplementation of algorithms that may have practical importance like Hamiltonian learning. Second,\nwe do not require any locality assumptions beyond there being Mterms of bounded strength, each\nof which is k-body. Lastly, our algorithm is completely non-adaptive.\nOur result is the first to learn generic k-body Hamiltonians with a natural cost function on the\nnotion of sparsity. This is an important extension beyond state of the art: many problems arising\nin physics have k-body interactions that are not geometrically local, arising for example from a\nCoulomb potential, as in quantum chemistry or other systems where long-range interactions cannot\nbe neglected. The Sachdev–Ye model [48] (precursor to the Sachdev–Ye–Kitaev (SYK) model) is\nanother example where our results apply and where previous work does not; a fermionic extension of\nour results may apply to the fermionic SYK model. Because these models exhibit complex dynamics\nsuch as fast scrambling dynamics or quantum spin liquid phases, one might have the intuition that\nlearning these Hamiltonians is difficult. Our work provides evidence that they can be learned despite\nthese complexities.\n5Organization. This paper is organized as follows. In Section 2, we provide the background on key\ntechniques, including Hamiltonian reshaping, compressed sensing, and robust frequency estimation,\nwhich are used in the learning protocol proposed later. Section 3 introduces the main Hamiltonian\nlearning protocol and the experimental setup, including how we reshape the unknown Hamiltonian\ninto completely commuting Hamiltonians and proving the total evolution time complexity of quantum\nexperiments and the computational complexity of classical post processing for the learning protocol.\nIn Section 4, we establish theoretical lower bounds for the total evolution time required for learning\narbitrary sparse Hamiltonians based on a characterization of generic quantum experiments and\nAssouad’s lemma. Finally in Section 5, we analyze the operational interpretation of the error metrics\nused in the learning protocol, clarifying how these metrics relate to the ability of predicting observable\nexpectation values.\nNotations. In this work we use ∥x∥pto denote the ℓp-norm of vector x. For a bit string b, we\nuse|b|to denote its Hamming weight. The Pauli matrices are denoted by σx, σy, σz. We use the\nfollowing notation to denote the Pauli eigenstates:\n|1, z⟩=|0⟩,|−1, z⟩=|1⟩,|1, x⟩=|+⟩,|−1, x⟩=|−⟩,\n|1, y⟩=1√\n2(|0⟩+i|1⟩),|−1, y⟩=1√\n2(|0⟩ −i|1⟩).(3)\nWe denote the set of all n-qubit Pauli matrices by Pn:\nPn=(nO\ni=1Pi:Pi=I, σx, σy,orσz)\n. (4)\nFor each P=Nn\ni=1Pi∈Pn, we define its weight by\nwt(P) =|{i:Pi̸=I}|. (5)\nWe denote the set of Pauli operators that are at most k-body by\nP(k)\nn={P∈Pn: wt(P)≤k}. (6)\n2 Background\n2.1 Hamiltonian reshaping\nThe basic idea behind [5] is that we can reshape the Hamiltonian during time evolution into a new\nHamiltonian that is easy to learn and also contains useful information about the original Hamiltonian.\nIn this section we will provide a brief introduction to this technique.\nHamiltonian reshaping is done by doing random unitary transformations to the time evolution\noperator corresponding to the unknown Hamiltonian and obtaining the effective Hamiltonian Heff. At\neach time step we apply a unitary transformation that is randomly sampled from an ensemble, which\nwe will describe later in this section. As a result the system evolves under a random Hamiltonian\ntransformed under the unitary operation. We assume that these unitary transformations are applied\ninstantaneously. The same analysis as the one underlying the randomized Hamiltonian simulation\nalgorithm known as qDRIFT [49 –51] then tells us that the effective Hamiltonian Heffis the ensemble\naverage of therandom Hamiltonians. This approachis similar inspirit to dynamicaldecoupling[52,53],\nwhich applies unitary operations in a deterministic manner. However, the randomness in our protocol\n6is helpful as it allows us to efficiently apply random unitaries from a potentially exponentially large\nset.\nIn this work we will need to use the Hamiltonian reshaping technique to obtain an effective\nHamiltonian that is diagonal with respect to a given single-qubit Pauli eigenbasis. More precisely,\ngiven a vector β= (β1, β2,···, βn), where βi∈ {x, y, z}, we want the effective Hamiltonian to only\ncontain Pauli terms that are either Iorσβion the ith qubit. To achieve this, we apply, with an\ninterval of τ, Pauli operators randomly drawn from the set\nKβ=\n\nnO\nj=1Qj:Qj=Iorσβj\n\n. (7)\nHere we can see that |Kβ|= 2n.Kβhere is an abelian subgroup of the Pauli group on nqubits. Also,\nτneeds to be sufficiently small as will be analyzed in Theorem 1. More precisely, the evolution of\nthe quantum system is described by\nQre−iHτQr···Q2e−iHτQ2Q1e−iHτQ1, (8)\nwhere Qk,k= 1,2,···, r, is uniformly randomly drawn from the set Kβ. In one time step of length\nτ, the quantum state evolves as\nρ7→1\n2nX\nQ∈KβQe−iHτQρQeiHτQ=ρ−1\n2nX\nQ∈Kβiτ[QHQ, ρ ] +O(τ2)\n=ρ−iτ[Heff, ρ] +O(τ2) =e−iHeffτρeiHeffτ+O(τ2),(9)\nwhere Heff, the effective Hamiltonian, is\nHeff=1\n2nX\nP∈KβQHQ. (10)\nIn Appendix A we will provide a bound on how far the actual dynamics deviate from the dynamics\ninduced by the effective Hamiltonian.\nThe above can be seen as a linear transformation of the Hamiltonian H. It is therefore reasonable\nto consider what is the effect of the above transformation on each Pauli term in the Hamiltonian.\nFor a Pauli term Pa, we note that there are two possible outcomes:\nLemma 1. LetPbe a Pauli operator and let Kβbe as defined in (7). Then\n1\n2nX\nQ∈KβQPQ =(\nP,ifP∈C(Kβ),\n0,ifP /∈C(Kβ),(11)\nwhere C(Kβ)denotes the centralizer of the subgroup Kβ.\nProof.IfP∈C(Kβ), then QPQ =Pfor all Q∈ Kβ, and averaging over all Qtherefore yields P.\nIfP /∈ Kβ, then there exists Q0∈ Kβsuch that PQ0=−Q0P(because two Pauli matrices either\ncommute or anti-commute). Consider the mapping ϕ:Kβ→ K βdefined by ϕ(Q) =Q0Q. This is\na bijection from Kβto itself, and it can be readily checked that if Qcommutes with P, then ϕ(Q)\nanti-commutes with P; ifQanti-commutes with P, then ϕ(Q)commutes with P. Consequently\nQPQ =Pfor half of all Q∈ KβandQPQ =−Pfor the other half. Thus taking the average yields\n0.\n7The above lemma allows us to select which Pauli terms we want to preserve in the Hamiltonian\nand which ones we want to discard. Because C(Kβ) =Kβ, we have\nHeff=X\na:Pa∈KβµaPa. (12)\nNote that because Kβis abelian, Heffconsists of commuting Pauli terms, making it easier to learn\nthe coefficients, as will be discussed in Section 3.3. Also the coefficients µaofPathat are in Kβare\npreserved in this effective Hamiltonian. We therefore need to choose a set of βso that each Pauli\nterm of His contained in at least one of the Heffcorresponding to a β. We will discuss the way to\ndo this in Section 3.4.\nWhile Lemma 1 concerns the uniform average over all 2nelements of a set of commuting Pauli\noperators, in our learning protocol we will randomly sample from this set. To assess the protocol’s\naccuracy, we will use the following theorem.\nTheorem 1. Letβbe a length- nstring of x, y, z, and let Kβbe as defined in (7). Let Ube the\nrandom unitary defined in (8). Let V=e−iHefftforHeffgiven in (12), and t=rτ. We define the\nquantum channels UandVbe\nU(ρ) =E[UρU†],V(ρ) =V ρV†.\nThen\n∥U − V∥ ⋄≤4M2t2\nr.\nHere the norm is the diamond norm (or completely-bounded norm), given in terms of the Schatten\nL1norm by ∥U∥⋄:= max X:∥X∥1≤1\r\r\0\nU ⊗ 1n\n(X)\r\r\n1. The proof can be found in Appendix A, where\nwe analyze how the error in each segment of time-evolution contributes to the total diamond distance\nbetween the quantum channels UandV. The error in each segment is analyzed using a Taylor\nexpansion.\n2.2 Compressed sensing\nThe task of learning a sparse coefficient vector is studied in the field of compressed sensing, which\nis related to learning the M-sparse coefficient vector in the Hamiltonian learning scenario. Com-\npressed sensing provides a powerful tool to reconstruct a sparse high-dimensional vector from few\nmeasurements. This is relevant to the problem we are studying: the Hamiltonian coefficients form an\nM-sparse vector, but this vector is at the same time high-dimensional, as any of the O(nk)k-local\nPauli terms can be present.\nThe basic setup of compressed sensing is as follows: we want to reconstruct a vector x∈CD\nbased on observations y∈CΓof the form\ny=Ax+e, (13)\nwhere Ais aΓ×Dmatrix and e∈CΓrepresents (typically small) noise in the observation. When\nΓ< D, we will not be able to uniquely determine xin general. However, below we will use A\nthat has the restricted isometry property (RIP), which will be discussed in detail in Appendix B.\nThe restricted isometry property of Aguarantees that the ℓ2-norm of any sparse vector xwill\nbe approximately preserved after applying A. This intuitively implies that we can have enough\ninformation to reconstruct xgiven access to Ax. A matrix satisfying the RIP is nearly an isometry\n8when acting on sufficiently sparse vectors, and thus the vector we want to reconstruct is not distorted\nbeyond recognition when transformed through this matrix.\nWe further assume that xisM-sparse and solve the following ℓ1-minimization problem,\nminimize\nz∈CD∥z∥1subject to ∥Az−y∥2≤η√\nΓ, (14)\nwith Γbeing sufficiently large but potentially small compared to D. The solution x♯∈CDis\nguaranteed to be close to the actual vector xif each entry of the error vector eis at most ηin\nabsolute value. The optimization problem (14) can be solved efficiently as we show in Section 3.6.\nIn this work, we will focus on what we call a weight- kHadamard matrix , which we define as\nfollows:\nDefinition 1 (Weight- kHadamard matrix H(k)).LetHbe the Hadamard matrix of size 2n×2n,\ni.e.,\nH=1 1\n1−1⊗n\n.\nFor each i= 1,2,···,2n, we let bibe the n-bit string representing the integer i−1. Then the weight- k\nHadamard matrix, denoted as H(k), is the sub-matrix of Hconsisting of every ith column of Hwhere\n|bi| ≤k. Here |bi|is the Hamming weight of the bit string bi.\nOne can readily see that H(k)is of size 2n×Dwhere D=Pk\nl=0\0n\nl\n. Below we will use this\nmatrix for our compressed sensing task. Before we state the result we will first introduce a notation:\nwe define for a vector xand integers s, p≥0,\nσs(x)p= min\ny:∥y∥0≤s∥x−y∥p. (15)\nIn other words σs(x)pis the smallest error in the p-norm one can achieve when approximating x\nwith an s-sparse vector.\nTheorem 2 (Compressed sensing with the weight- kHadamard matrix) .LetD=Pk\nl=0\0n\nl\n. Let\nA∈CΓ×Dbe a matrix whose rows are independently randomly sampled from the rows of H(k)with\nreplacement. Let δCS∈(0,1)and let M > 0be an integer. If\nΓ≥CMmax{ln2(M) ln(Mln(D)) ln(D),ln(1/δCS)}, (16)\nthen, with probability at least 1−δCS, the following statement holds for every x∈CD. Let noisy\nsamples y=Ax+ebe given with ∥e∥2≤η√\nΓ, and let x♯be the solution of the ℓ1-minimization\nproblem (14). Then\n\r\rx−x♯\r\r\np≤C1\nM1−1/pσM(x)1+C2M1/p−1/2η,1≤p≤2. (17)\nσM(x)1is defined as in (15). All constants C, C 1, C2>0are universal.\nThe proof of this theorem is provided in Appendix B. From the above theorem we can see that, if\nxis itself M-sparse, then σM(x)1= 0, and the ℓ1-minimization allows us to estimate xto within\nC2M1/p−1/2ηerror in the ℓp-norm.\n92.3 Robust frequency estimation\nTaking advantage of the Hamiltonian reshaping procedure, we will be able to identify eigenvectors\nof the effective Hamiltonian, and as a part of the protocol we want to estimate the corresponding\neigenvalue. The estimation needs to be performed in a noise-robust way in order to achieve Heisenberg-\nlimited scaling and SPAM robustness. The robust frequency estimation protocol that we introduce\nin this section helps us achieve this goal. This protocol follows the same idea as the robust phase\nestimation protocol [54], but is modified to obtain a good confidence interval rather than minimizing\nthe mean-squared error.\nFrom the phase estimation experiments to be introduced in Section 3.2, we will generate signals\nfluctuating around cos(θt)andsin(θt)where θcorresponds to the eigenvalue we want to estimate.\nThe goal is therefore to reconstruct θbased on noisy estimates of cos(θt)andsin(θt). Through\nthe robust frequency estimation protocol, we can accomplish this task with the cost stated in the\nfollowing theorem:\nTheorem 3 (Robust frequency estimation) .Letθ∈[−A, A]. Let X(t)andY(t)be independent\nrandom variables satisfying\n|X(t)−cos(θt)|<1/√\n2,with probability at least 2/3,\n|Y(t)−sin(θt)|<1/√\n2,with probability at least 2/3.(18)\nThen with Kindependent non-adaptive1samples X(t1), X(t2),···, X(tK)andY(t1), Y(t2),···, Y(tK),\ntj≥0, for\nK=O(log(A/ϵ)(log(1 /q) + log log( A/ϵ))), (19)\nT=KX\nj=1tj=O((1/ϵ)(log(1 /q) + log log( A/ϵ))),max\njtj=O(1/ϵ), (20)\nwe can obtain a random variable ˆθsuch that\nPrh\n|ˆθ−θ|> ϵi\n≤q. (21)\nFor a detailed proof see Appendix D. The main idea is to reduce the estimation problem into\na sequence of decision problems with binary outputs in a way similar to bisection. Solving each of\nthese decision problems updates our knowledge of θ, and in the process we obtain a smaller and\nsmaller interval containing the exact value. We stop the process when the interval is small enough to\nprovide sufficient accuracy.\n3 The Hamiltonian learning protocol\nThe Hamiltonians we will focus on in this work are defined as follows\nDefinition 2 (k-body Hamiltonians with Mterms).Ak-body Hamiltonians with Mterms takes the\nform\nH=X\nP∈PnµPP, (22)\nwhere Pnis the set of all Pauli matrices defined in (4),−1≤µP≤1, and µP̸= 0only for MPauli\nterms Pawith wt(Pa)≤k.\n1By “non-adaptive” we mean that the choice of each tjdoes not depend on the value of X(tj′)orY(t′\nj)for any j′.\n103.1 Completely commuting Hamiltonians\nThe Hamiltonian reshaping procedure discussed in Section 2.1 provides an effective Hamiltonian\nconsisting of completely commuting Pauli terms, by which we mean that the Pauli terms commute\nwith each other when acting on any one of the qubits. One can readily verify that the Pauli terms in\nKβ(7)satisfy this requirement. We call these Hamiltonians completely commuting Hamiltonians .\nEquivalently, we can assign an σx,σy, orσzbasis to each qubit, thus forming a basis for the entire\nHilbert space, and then require the Hamiltonian to be diagonal in this basis.\nThe effective Hamiltonian from Hamiltonian reshaping takes the form\nHeff=X\nP∈KβµPP, (23)\nas shown in (12). The set Kβof completely commuting Pauli terms is specified by the basis given\nthrough β= (β1, β2,···, βn), as defined in (7). Based on the above, we can rewrite Heffin another\nway:\nHeff=X\nc∈{0,1}nµcPc, (24)\nwhere\nPc=O\ni(σβi)ci, c i∈ {0,1}, (25)\nthe coefficient µc=µPifPc=P, and µc= 0otherwise. We then collect all coefficients µcinto a\n2n-dimensional vector µβ. Note that this vector contains at most Mnon-zero entries.\nThe effective Hamiltonian Heffhas the nice property that its eigenvalues and eigenstates can be\nwritten down explicitly. For an n-bit string b= (b0, b1,···, bn)we define\n|b⟩β=nO\ni=1(−1)bi, βi\n. (26)\nThe Pauli eigenstates |±1, β⟩are defined as in (3). Then the above |b⟩βis an eigenstate of Heff. We\ncan write down its corresponding eigenvalue, which is\nλb=X\nc∈{0,1}nµc(−1)c·b, (27)\nwhere c·b=c1b1+c2b2+···+cnbn(mod 2). Collecting all eigenvalues λbinto a 2n-dimensional\nvector λ, we can then write down the relation between the eigenvalues and coefficients in a more\ncompact form:\nλ=Hµβ, (28)\nwhere His the 2n×2nHadamard matrix defined in Definition 1. Therefore we can reconstruct the\ncoefficients of the Hamiltonian by\nµβ=H−1λ=1\n2nHλ. (29)\nThis approach has the drawback that we will need to estimate all 2nof the eigenvalues. While\ntechniques such as \"bins and peelings\" for Walsh-Hadamard transforms with sparsity in the transform\ndomain [55,56] could theoretically reduce the computational cost, as used in [3,23], they cannot\nbe used to achieve the Heisenberg-limited scaling and typically assume that the sparse support is\nrandomly distributed across the entire vector space, rather than localized to the subspace with weight\nat most k. We therefore need to consider an alternative approach in Section 3.3.\n113.2 The experimental setup\nFigure 1: Illustration of the Hamiltonian learning experiments. Quantum processes are\nillustrated in blue blocks, and classical processes are illustrated in orange blocks. State preparation\nand measurement (SPAM) errors are taken into account in the experiments.\nAs illustrated in Fig 1, in an experiment we will start from an initial state\n|ϕ0⟩=1√\n2(|0⟩β+|b⟩β) =1√\n2 nO\ni=1|1, βi⟩+nO\ni=1(−1)bi, βi!\n, (30)\nwhere |b⟩βis defined in (26), and the bit string b̸= 0. This state can be prepared from a |b|-qubit\nGHZ state by applying σxon some of the qubits. The GHZ state can be prepared in constant depth\nusing measurements and feedback [57,58]. Because bis uniformly sampled from all bit-strings of\nlength n, the average size of the GHZ state that needs to be prepared is n/2. We then let the system\nevolve while applying random Pauli operators with interval τfor time tto perform Hamiltonian\nreshaping as discussed in (8). Because |0⟩βand|b⟩βare both eigenstates of the effective Hamiltonian\nHeffcorresponding to eigenvalues λ0andλb(defined in (27)), as discussed in Section 3.1, at time t\nwe will approximately obtain the state\n|ϕt⟩=1√\n2(e−iλ0t|0⟩β+e−iλbt|b⟩β). (31)\nIn the end, we then measure the observable Xb\nβ=Nn\ni=1Qi, where each Qiis chosen to be a Pauli\noperator such that\nQi|1, βi⟩=(−1)bi, βi\n, Q i(−1)bi, βi\n=|1, βi⟩. (32)\n12Such Qioperators can be constructed as follows: in the case of bi= 1, ifβi=zthen Qi=σx, and if\nβi=yorxthen Qi=σz; in the case of bi= 0then Qi=I. This observable therefore satisfies\nXb\nβ|0⟩β=|bβ⟩, Xb\nβ|bβ⟩=|0β⟩.\nThe expectation value will be\n⟨ϕt|Xb\nβ|ϕt⟩= cos(( λb−λ0)t). (33)\nNote that in order to measure Xb\nβwe only need to measure each individual Qito obtain a ±1outcome\nand then multiply them together.\nSimilarly, we can measure the observable Yb\nβ=Nn\ni=1Qi, where the Qioperators are chosen\nslightly differently. For the first ifor which bi= 1, we choose Qiso that\nQi|1, βi⟩=i(−1)bi, βi\n, Q i(−1)bi, βi\n=−i|1, βi⟩. (34)\nNote that we can choose Qi=σyifβi=z,Qi=σxifβi=y, and Qi=−σyifβi=xto satisfy this\nrequirement. For all other iwe choose Qito satisfy (32). The resulting operator Yb\nβsatisfies\nYb\nβ|0⟩β=i|bβ⟩, Yb\nβ|bβ⟩=−i|0β⟩.\nTherefore the expectation value is\n⟨ϕt|Yb\nβ|ϕt⟩=−sin((λb−λ0)t). (35)\nWe summarize the above experiment in the following definition\nDefinition 3 (Phase estimation experiment) .We call the procedure below a (β, b, t, τ )-phase estima-\ntion experiment:\n1. Prepare the initial state1√\n2(|0⟩β+|b⟩β)as in(30).\n2.Let the system evolve for time twhile applying random Pauli operators from Kβ(defined in\n(7)) with interval τ.\n3.Measure the observables Xb\nβorYb\nβ(by measuring every qubit in either σx,σy, orσzbasis) as\ndefined above to obtain a ±1outcome.\nThe goal of the above experiment is to estimate λb−λ0, for which we also need to use the robust\nfrequency estimation protocol introduced in Section 2.3. Below we will discuss how this is done, and\nanalyze the effect of the Hamiltonian reshaping error and the state preparation and measurement\n(SPAM) error.\nWe model the SPAM error as follows:\nDefinition 4. The preparation of the initial state involves an error channel Eprepapplied after the\nideal state preparation channel, and the measurement involves an error channel Emeasapplied before\nthe ideal measurement channel. We assume that\n∥Eprep− I∥⋄+∥Emeas− I∥⋄≤ϵSPAM .\nThrough a (β, b, t, τ )-phase estimation experiment, if we measure Xb\nβin the end, we will obtain a\nrandom variable sx(t)∈ {± 1}. If we had the exact state |ϕt⟩as defined in (31), then we would have\n13E[sx(t)] =cos((λb−λ0)t). However, due to the Hamiltonian reshaping error and the SPAM error,\nwe have\n|E[sx(t)]−cos((λb−λ0)t)| ≤4M2t2\nr+ϵSPAM . (36)\nNotice that the first term on the right-hand side comes from the Hamiltonian reshaping error,\nwhere we set t=rτas in Theorem 1. Moreover the variance of sx(t)is at most 1because it can only\ntake values ±1. We assume that ϵSPAM≤1/(3√\n2), and choose rto be r=O(M2t2)so that\n4M2t2\nr<1\n3√\n2.\nNote that τandrare related through τ=t/r. Then we have\n|E[sx(t)]−cos((λb−λ0)t)|<2\n3√\n2.\nWe then take 54independent samples of sx(t)and average them, denoting the sample average by\nX(t). By Chebyshev’s inequality, this ensures\nPrh\n|X(t)−E[sx(t)]| ≥1/(3√\n2)i\n= Prh\n|X(t)−E[X(t)]| ≥1/(3√\n2)i\n≤1\n54×1/(3√\n2)2=1\n3.\nTherefore combining the above with (36) we have\nPrh\n|X(t)−cos((λt−λ0)t)| ≥1/√\n2i\n≤1/3.\nThis guarantees estimating cos((λt−λ0))tto a constant 1/√\n2accuracy with at least 2/3probability,\nwhich gives us the X(t)required in the robust frequency estimation protocol in Theorem 3. The\nY(t)in Theorem 3 can be similarly obtained. We also note that because |λb−λ0| ≤2M, we can set\nA= 2Min Theorem 3. Therefore we can state the following for the phase estimation experiment\n(using the notation of Kβas defined in (7)andP(k)\nnfor the set of Pauli operators on at most kqubits\nas defined in (6)):\nTheorem 4. We assume that the quantum system is evolving under a k-body Hamiltonian with M\nterms (Definition 2). With Nexpindependent non-adaptive (β, bj, tj, τj)-phase estimation experiments\n(Definition 3), j= 1,2,···, Nexp, with the SPAM error (Definition 4) satisfying ϵSPAM≤1/(3√\n2),\nwe can obtain an estimate ˆθsuch that\nPrh\n|ˆθ−(λb−λ0)| ≥ηi\n≤q,\nwhere λ0andλb(defined in (27)) are eigenvalues of the effective Hamiltonian Heffdefined in (24).\nIn the above Nexp,{tj}, and{τj}satisfy\nNexp=O(log(M/η)(log(1 /q) + log log( M/η))),\nT=NexpX\nj=1tj=O1\nη(log(1 /q) + log log( M/η))\n,max\njtj=O(1/η), (37)\nandτj= Ω(1 /(M2tj)).D=Pk\nl=0\0n\nl\n= Θ( nk).\n143.3 Learning a completely commuting Hamiltonian\nIn the last section we have shown how to estimate eigenvalue differences λb−λ0through phase\nestimation experiments. Up to fixing a global phase, we have the eigenvalues λb(we will discuss the\nglobal phase issue in more detail later in this section). These eigenvalues can be used to recover the\nHamiltonian coefficients though an inverse Hadamard transform as described in (29), but a naive\napproach would not be efficient as there are 2ndifferent eigenvalues to estimate. Note that we have\nnot yet used the information that the coefficient vector µβcontains at most Mnon-zero entries, and\ncompressed sensing is a tool that utilizes exactly this information.\nBefore we apply compressed sensing, we first note that all the nonzero entries of µβof the\nunknown k-body Hamiltonian must (by assumption) correspond to k-body Pauli terms, which already\nhelps us reduce the size of the linear system. Let µ(k)\nβbe the D-dimensional vector consisting of the\nentries of µthat correspond to k-body Pauli terms, where D=Pk\nl=0\0n\nl\n. Then we can write (28)as\nλ=H(k)µ(k)\nβ,\nwhere H(k)is the 2n×Dweight- kHadamard matrix defined in Definition 1.\nAs is commonly done in compressed sensing, we generate Γindependent samples of the rows of\nH(k), use those rows to form a matrix A, and use the corresponding entries of λto form a vector y.\nThen we solve the ℓ1-minimization problem in (14), where ηis the estimation error upper bound\nfor each entry of y. When Γsatisfies(16), then by Theorem 2 the solution of the ℓ1-minimization\nproblem (14)is guaranteed to be close to the actual coefficients. More precisely, denoting the solution\nbyˆµ(k)\nβ, we have ∥ˆµ(k)\nβ−µ(k)\nβ∥p≤C2M1/p−1/2ηfor1≤p≤2.\nIn the above we assumed that we can estimate eigenvalues λbfor any b∈ {0,1}nto precision η.\nThis is impossible given the ambiguity coming from the global phase. However, we will explain why\nthis does not affect our ability to learn the Hamiltonian. Note that the phase estimation experiment\nallows us to estimate λb−λ0. We can therefore fix the global phase by first assuming λ0= 0to\nobtain λb. This can be done by shifting the effective Hamiltonian, so that we are in fact estimating\nthe eigenvalues of\n˜Heff=\n−X\nc̸=0µc\nI+X\nc̸=0µcPc.\nTherefore the above procedure guarantees that we can learn all the coefficients µcaccurately. Note\nthat these µccorrespond to all Pauli terms that are k-body and are in Kβ. Therefore we have\nobtained a set of estimates ˆµPfor all P∈ Kβandwt(P)≤kthat satisfies\n\nX\nP∈Kβ:1≤wt(P)≤k|ˆµP−µP|p\n1/p\n≤CM1/p−1/2η, (38)\nfor1≤p≤2and a universal constant C.\nMultiplying the overhead of compressed sensing as described in (16)by the number of samples\nNexpand total evolution time Tdescribed in Theorem 4, we arrive at the following theorem (using\nthe notation of Kβas defined in (7)andP(k)\nnfor the set of Pauli operators on at most kqubits as\ndefined in (6)):\nTheorem 5 (Learning the coefficients of terms in Kβ).We assume that the quantum system is\nevolving under a k-body Hamiltonian with Mterms (Definition 2). With Nexpindependent non-\nadaptive (β, bj, tj, τj)-phase estimation experiments (Definition 3), j= 1,2,···, Nexp, with the SPAM\n15error (Definition 4) satisfying ϵSPAM≤1/(3√\n2), we can obtain estimates ˆµPfor every P∈ Kβ∩P(k)\nn,\nsuch that (38)holds with probability at least 1−δCS−Γq. In the above Nexp,{tj}, and{τj}satisfy\nNexp=O(Γ log( M/η)(log(1 /q) + log log( M/η))),\nT=NexpX\nj=1tj=OΓ\nη(log(1 /q) + log log( M/η))\n,max\njtj=O(1/η), (39)\nΓ =O\0\nM(ln2(M) ln(Mln(D)) ln(D) + ln(1 /δCS))\n, (40)\nandτj= Ω(1 /(M2tj)).D=Pk\nl=0\0n\nl\n= Θ( nk).\nThe success probability in the theorem comes from considering all possible ways the protocol may\nfail and then taking the union bound: it may fail because the sub-sampled matrix in compressed\nsensing does not have the RIP property, which contributes a failure probability of δCS, and it may\nfail because any one of the eigenvalue estimations is not accurate enough, which contributes a failure\nprobability of Γq. Note that the failure probability can be made small with little overhead, as the\ndependence on 1/qand1/δCSare both logarithmic.\n3.4 Randomized basis selection\nIn the previous section we have discussed how to learn all the coefficients corresponding to Hamiltonian\nterms contained in the set Kβ(defined in (7)). In this section, we will focus on the way to choose a\nset of Kβso that all the terms in the Hamiltonians are covered with large probability. We will show\nthat uniformly randomly choosing Kβis a good strategy.\nTo see this, we observe that by uniformly randomly sampling a β∈ {x, y, z}n, for a fixed Pauli\noperator P∈Pn,\nPr[P∈ Kβ] = 3−wt(P)≥3−k.\nTherefore, each time we learn a randomly sample β, there is at least 3−kprobability that we will learn\nthe coefficient µPforwt(P)≤k. If we generate Lindependent samples of β, then the probability of\na term Pbeing not covered in any of the Linstances is at most (1−3−k)L. By the union bound, to\nensure that all the Mterms are included in at least one of the Linstances with probability at least\n1−δbasis, we need\nM(1−3−k)L≤Mexp\0\n3−kL)≤δbasis. (41)\nIt is thus sufficient to choose L= 3klog(M/δ basis). Taking this overhead Linto account, we then\narrive at our main result (using the notation of Kβas defined in (7)andP(k)\nnfor the set of Pauli\noperators on at most kqubits as defined in (6)):\nTheorem 6 (Learning a k-body Hamiltonian containing Mterms).We assume that the quantum\nsystem is evolving under a k-body Hamiltonian with Mterms (Definition 2). With Nexpindependent\nnon-adaptive (β, bj, tj, τ)-phase estimation experiments (Definition 3), j= 1,2,···, Nexp, with the\nSPAM error (Definition 4) satisfying ϵSPAM ≤1/(3√\n2), we can obtain estimates ˆµPfor every\nP∈P(k)\nnsuch that, with probability at least 1−δ\n\nX\nP∈P(k)\nn\\{I}|ˆµP−µP|p\n1/p\n≤ϵ, (42)\n16for1≤p≤2. In the above Nexp,{tj}, and τsatisfy\nNexp=eO(3kM),\nT=X\njtj=eO9kM1/p+1/2\nϵ\n,\nandτ= Ω(3−kϵ/(M1/p+3/2log(M/δ))).\nIn the above, we choose τto be the same for all experiments for simplicity. One can also choose\nτdifferently for each experiment to reduce the total number of Pauli operators that are needed, as is\ndone in the remark below. We are primarily concerned with the cases with p= 1andp= 2, which\nhave specific operational interpretations that we will discuss in Section 5, but our result holds for all\n1≤p≤2.\nRemark 7. In the above we have used the ˜O-notation to hide polylogarithmic factors. Here we provide\na more precise statement. We constructed a protocol that with probability at least 1−LδCS−LΓq−δbasis,\ncan obtain estimates ˆµPforP∈P(k)\nnsuch that\n\nX\nP∈P(k)\nn\\{I}|ˆµP−µP|p\n1/p\n≤CLM1/p−1/2η,\nfor1≤p≤2and a positive universal constant C. This protocol uses\nNexp=O(LΓ log( M/η)(log(1 /q) + log log( M/η))),\nexperiments and\nT=NexpX\nj=1tj=OLΓ\nη(log(1 /q) + log log( M/η))\n,max\njtj=O(1/η), (43)\ntotal evolution time. In the above {tj},{τj},Γ, and Lsatisfy\nΓ =O\0\nM(ln2(M) ln(Mln(D)) ln(D) + ln(1 /δCS))\n, (44)\nL=O\0\n3klog(M/δ basis)\n, (45)\nandτj= Ω(1 /(M2tj)).D=Pk\nl=0\0n\nl\n= Θ( nk).\n3.5 Robustness to modeling errors\nIn Theorem 2 we have shown that the Hamiltonian learning protocol is robust against SPAM error.\nIn this section we will discuss the robustness against modeling errors. More precisely, we will ask two\nquestions: (1) What if the Hamiltonian contains more than Mterms? (2) What if the terms in the\nHamiltonian are not exactly k-body? We will show that our learning protocol can still work if these\ntwo types of modeling errors occur.\nThe robustness against the first type of modeling error, i.e., that the Hamiltonian contains more\nthan Mterms, but all terms are still k-body, is a direct consequence of Theorem 2, in which an\nadditional error term σM(x)1(defined in (15)) is included to account for the error of approximating\n17a potentially non-sparse vector with an M-sparse one. In the context of Theorem 2, this means an\nextra term is included in the estimation error for the coefficients, which gives us\n\nX\nP∈P(k)\nn\\{I}|ˆµP−µP|p\n1/p\n≤C3kσM(µ)1log(M/δ)\nM1−1/p+ϵ, (46)\nfor some universal constant C, where ϵis the error bound without modeling errors as defined in (42),\nandµis the vector consisting of µPfor all P∈Pn\\ {I}. Here we have used the fact that the best\nM-sparse approximation error for terms in Kβmust be smaller than or equal to that for the whole\ncoefficient vector. From the above we can see that if the Hamiltonian can be well-approximated by\none with M k-body terms, then we can still obtain an accurate estimate for its leading coefficients.\nFor the second type of modeling error, we will first focus on the procedure of learning terms in Kβ\ndescribed in Section 3.3. The coefficients for all terms in Kβare collected into a vector µβ. Those\nthat are also k-body are collected into µ(k)\nβ, while the rest form a vector ¯µ(k)\nβ. Here µβcontains\nD=Pk\nl=0\0n\nl\nentries.\nWe denote by eAthe submatrix of the original Wash-Hadamard matrix Hconsisting of the Γrows\ncorresponding to the randomly sampled rows of Ain Theorem 2. We can write eAaseA= [A B],\nwhere A∈RΓ×Dis the submatrix corespond to rows of the weight- kHadamard matrix as defined in\nDefinition 1, and B∈RΓ×(2n−D). Then the eigenvalue estimates yand the coefficients are related\nthrough\ny=eAµβ+e=Aµ(k)\nβ+B¯µ(k)\nβ+e, (47)\nwhere eis the vector consisting of errors on each eigenvalue estimate, and using the phase estimation\nexperiments described in Section 3.2 we can ensure that each entry of eis at most ηin absolute\nvalue, thus ensuring ∥e∥ ≤√\nΓη. We therefore have\n∥y−Aµ(k)\nβ∥2≤ ∥B¯µ(k)\nβ∥2+√\nΓη. (48)\nSince each entry of Bis±1, we can prove that ∥Bw∥2≤√\nΓ∥w∥1for any (2n−D)-dimensional\nvector w, and therefore\n∥y−Aµ(k)\nβ∥2≤√\nΓ(η+∥¯µ(k)\nβ∥1). (49)\nThis motivates us to solve a modified ℓ1-minimization problem\nminimize\nz∈CD∥z∥1subject to ∥y−Az∥2≤√\nΓeη, (50)\nwhere eηis any number such that eη≥η+∥¯µ(k)\nβ∥1. Solving this ℓ1-minimization problem yields a\nsolution, which we denote by ˆµ(k)\nβ. By Theorem 2 we have\n∥ˆµ(k)\nβ−ˆµβ∥p≤C1\nM1−1/pσM(µ(k)\nβ)1+C2M1/p−1/2eη. (51)\nWe let ϵ(k)be a known upper bound of ∥¯µ(k)\nβ∥1, and considering all 3klog(M/δ)randomly sampled\nindices β, we can therefore produce estimates ˆµPfor all k-body coefficients satisfying\n\nX\nP∈P(k)\nn\\{I}|ˆµP−µP|p\n1/p\n≤ϵ+C13kσM(µ)1log(M/δ)\nM1−1/p+C23kϵ(k)\nM1/2−1/p, (52)\nfor universal constants C1, C2>0, with the same total evolution time as given in Theorem 6. Note\nthat this error bound include both types of modeling errors.\n183.6 Computational complexity\nIn this section we will show that the classical post-processing takes time that is polynomial in n\nandlog(1/ϵ1)where nis the number of qubits and ϵ1is the allowed ℓ1-error on the coefficients. The\nclassical post-processing comprises solving poly(n,log(1/ϵ1))ℓ1-minimization problems as described\nin (14), which we restate here:\nminimize\nz∈CD∥z∥1subject to ∥Az−y∥2≤η√\nΓ.\nHereAis aΓ×Dsubmatrix of the Hadamard matrix. An important feature that we will use later\nis that all entries of Aare at most 1in absolute value (in fact they are all ±1). Moreover, the\nadmissible set of this optimization problem is non-empty, since the exact coefficient vector xthat\nwe want to recover satisfies ∥Ax−y∥2≤√\nΓη, and xisM-sparse whose entries are bounded by 1\nin absolute value. We only need to show that approximately solving each of these ℓ1-minimization\nproblems takes time poly( n,log(1/ϵ1)).\nWe will first demonstrate how this problem can be reformulated as a semidefinite programming\n(SDP) problem to build intuition. Because certain SDPs are pathological (for example, the optimal\nsolution is exponentially large), this does not immediately imply that the solution is efficient. We\ntherefore provide a self-contained analysis of the computational complexity by examining its dual (56),\nand we rigorously prove that the classical computation requires weak polynomial time.\n3.6.1 Reformulation to an SDP\nWe first make the substitution\nz=z+−z−,v=A(z+−z−)−y,\nwhere z±= (z±\n1, z±\n2,···, z±\nD), and they are related to the zin(14)viaz=z+−z−andz+\ni=\nmax{zi,0},z−\ni=−min{0, zi}. Then (14) can be written as:\nminimize z++z−\nsubject to: ∥v∥2≤η√\nΓ,z+≥0,z−≥0.(53)\nIntroduce the block matrix\nW=\nη2Γv∗\nv 1\n, (54)\nwhere the first entry is a scalar, and the lower right block is an identity matrix. Then W≥0is\nequivalent to ∥v∥2≤η√\nΓby a standard inequality on such block matrices.\nThe optimization becomes\nminimize z++z−\nsubject to: z+≥0,z−≥0,\nv=A(z+−z−)−y,\nW≥0,W=η2Γv∗\nv 1\n,(55)\nwhere the objective is linear and all the constraints are positive semi-definite constraints, meaning\nthat this is an SDP.\nIn practice, semidefinite programs can be solved efficiently. However, to rigorously prove that (14)\nis solvable in polynomial time, a more careful analysis of the optimization error and the properties of\nthe constraints, as in the following section, is required within the context of the Hamiltonian learning\nscenario we are considering.\n193.6.2 Self-contained analysis\nFor the ℓ1-minimization problem in (14), we consider a related problem in the following form\nminimize ∥Az−y∥2subject to ∥z∥1≤ξ. (56)\nThis is equivalent to a convex quadratic program,\nminimize1\n2∥A(z+−z−)−y∥2\n2,\nsubject toX\ni(z+\ni+z−\ni)≤ξ,z+≥0,z−≥0,(57)\nwhere z±= (z±\n1, z±\n2,···, z±\nD), and they are related to the zin(56)viaz=z+−z−as before. This\nconvex quadratic program can be solved in time poly(Γ, D,log(1/ϵ′))so that the ∥Az−y∥2obtained\nisϵ′away from the optimal value [59].\nWe will first study the properties of the optimization problem (56)and discuss how it helps us\nsolve the original ℓ1minimization problem (14). We denote by z(ξ)the solution to (56)(which may\nnot be unique, but any one of the solutions can be used) and by f(ξ)the corresponding value of the\nobjective function, i.e.\nf(ξ) =∥Az(ξ)−y∥2.\nWe note that when ξis large enough, the constraint in (56)will have no effect, and the optimization\nproblem is solved by any zthat minimizes ∥Az−y∥2, which is equivalent to A†Az=A†y. The\nsmallest value for ξfor which this happens is\nξ0= min {∥z∥1:A†Az=A†y}. (58)\nLemma 2. LetA+be the Moore–Penrose pseudoinverse of A.\n(i) If ξ≥ξ0, then f(ξ) =p\ny†y−y†AA+y.\n(ii) If 0≤ξ≤ξ0, then ∥z(ξ)∥1=ξandf(ξ)is a strictly decreasing function of ξ.\n(iii) fis Lipschitz continuous with Lipschitz constant√\nΓ. More precisely, for any 0≤ξ1≤ξ2, we\nhave\nf(ξ2)≤f(ξ1)≤f(ξ2) +√\nΓ(ξ2−ξ1).\nProof.For (i), we note that the constraint in (56)no longer has any effect and we are solving an\nunconstrained quadratic optimization problem. Solving this unconstrained quadratic optimization\nproblem readily yields the expression for f(ξ), which does not depend on ξ.\nFor (ii), if ∥z(ξ)∥1< ξ, then there exists an open neighborhood Uofz(ξ)such that U⊂ {z:\n∥z∥1≤ξ}. Because z(ξ)minimizes ∥Az−y∥2within the open neighborhood U, the gradient of this\nobjective function must be 0atz(ξ). This implies A†Az(ξ) =A†y. By(58), we have ∥z(ξ)∥1≥ξ0.\nTherefore ξ0≤ ∥z(ξ)∥1< ξ, which contradicts ξ≤ξ0. This proves ∥z(ξ)∥1=ξ.\nNext we will prove that f(ξ)is strictly decreasing for 0≤ξ≤ξ0. If for ξ1, ξ2∈[0, ξ0]we have\nξ1< ξ2andf(ξ1)≤f(ξ2), then ∥Az(ξ1)−y∥2≤ ∥Az(ξ2)−y∥2, which implies that z(ξ1)is a\nsolution to the optimization problem (56)with ξ=ξ2. Note that z(ξ1)is in the interior of the\nadmissible set of the this optimization problem, and therefore the gradient argument in the preceding\nparagraph applies, giving us A†Az(ξ1) =A†y, which results in the same contradiction. This proves\nthatf(ξ1)> f(ξ2).\n20For (iii), we only need to prove that f(ξ1)≤f(ξ2) +√\nΓ(ξ2−ξ1)forξ1≤ξ2≤ξ0. We define\nz′= (ξ1/ξ2)z(ξ2). Then by (ii) we have ∥z′−z2∥1= (1−ξ1/ξ2)∥z(ξ2)∥1=ξ2−ξ1. Also, ∥z′∥=ξ1\nandz′is therefore in the admissible set of (56) with ξ=ξ1. Consequently\nf(ξ1)≤ ∥Az′−y∥2≤ ∥Az(ξ2)−y∥2+∥Az(ξ2)−Az′∥2=f(ξ2) +∥A(z(ξ2)−z′)∥2.(59)\nNote that ∥A(z(ξ2)−z′)∥2≤ ∥A∥1→2∥z(ξ2)−z′∥1≤ ∥A∥1→2(ξ2−ξ1), where\n∥A∥1→2:= max\n∥z∥1≤1∥Az∥2.\nBecause all entries of Aare±1, we therefore have ∥A∥1→2≤√\nΓ. Hence ∥A(z(ξ2)−z′)∥2≤√\nΓ(ξ2−ξ1). This combined with (59) then results in the desired inequality.\nWe then show that the above properties of f(ξ)allow us to solve (14)by finding the right ξ. We\nconsider the following cases for (14): In the first case,√\nΓη <p\ny†y−y†AA+y=f(ξ0). In this\nscenario, the admissible set is empty, but we do not need to worry about this scenario because in our\nsetup the exact coefficient vector is always in the admissible set. In the second case,√\nΓη=f(ξ0).\nThe inequality constraint is then equivalent to A†Az=A†y, an equality constraint. Therefore (14)\ncan be reduced to a linear program and solved in weak polynomial time. Therefore, the only case we\nneed to examine closely is the third case, where√\nΓη > f (ξ0).\nLemma 3. We assume√\nΓη >p\ny†y−y†AA+y. If there exists xsuch that ∥Ax−y∥2≤√\nΓη,\nand∥y∥2>√\nΓη, then there exists a unique ξ∗∈[0,min{∥x∥1, ξ0}]such that f(ξ∗) =√\nΓη, and z(ξ∗)\nis a solution of (14).\nProof.Because f(∥x∥1)≤ ∥Ax−y∥2≤√\nΓη, and f(0) =∥y∥2, we have\nmax{f(∥x∥1), f(ξ0)} ≤√\nΓη < f (0),\nwhere we have used Lemma 2 (i) which states that f(ξ0) =p\ny†y−y†AA+y. Because fis\ncontinuous and strictly decreasing in [0, ξ0], we therefore have a unique ξ∗such that f(ξ∗) =√\nΓη,\nand\n0< ξ∗≤min{∥x∥1, ξ0}.\nWe then show that solving the optimization problem (56)with the ξ∗in Lemma 3 yields the\nsolution to the ℓ1-minimization problem (14).\nLemma 4. With the same assumptions as Lemma 3, z(ξ∗)solves the ℓ1-minimization problem (14).\nProof.First note that because f(ξ∗) =√\nΓη,z(ξ∗)is in the admissible set of (14). If there exists z′\nin the admissible set of (14) such that\n∥z′∥1<∥z(ξ∗)∥=ξ∗, (60)\nwhere we have used 0< ξ∗≤ξ0and Lemma 2 (ii) to show ∥z(ξ∗)∥=ξ∗, then\nf(∥z′∥1)≤ ∥Az′−y∥ ≤√\nΓη=f(ξ∗),\nimplying ∥z′∥1≥ξ∗by Lemma 2 (ii), which contradicts (60).\n21Algorithm 1 Solving the ℓ1-minimization problem (14).\nInput: A∈CΓ×D,y∈CΓ, M∈N+, η > 0, error tolerance ν >0.\nξL←0,ξR←M;\nwhile ξR−ξL>2νdo\nSolve the convex quadratic program (57)with ξ= (ξL+ξR)/2to obtain the minimum f(ξ)2/2;\niff(ξ)>√\nΓηthen\nξL←(ξL+ξR)/2;\nelse\nξR←(ξL+ξR)/2;\nend if\nend while\n˜ξ= (ξL+ξR)/2;\nSolve the convex quadratic program (57) with ξ=˜ξto obtain the solution ˜x♯;\nOutput: ˜x♯.\nTherefore solving the ℓ1-minimization problem (14)reduces to finding ξ∗, which can be done\nthrough a bisection procedure as described in Algorithm 3.6.2. Each bisection step involves solving\n(56)for a certain ξ, which is equivalent to the convex quadratic program (57). In the bisection\nprocess, we start from an interval [0, M], in each iteration compute f(ξ)where ξis the mid-point\nof the interval, thereby deciding whether ξ∗is in the right half of the interval or the left half. This\nallows us to get a new interval with half the size but still contains ξ∗, thereby proceeding to the next\niteration. When the interval size is 2νwe can take the mid-point ˜ξ∗as the estimate for ξ∗, which\nensures\n|˜ξ∗−ξ∗| ≤ν.\nThe total number of iterations needed is at most ⌈log2(M/ν)⌉.\nHowever, our ultimate goal is to recover the original coefficient vector x, and we need to know\nhow small νneeds to be in order for the approximate solution ˜x♯(obtained by solving (57)with\nξ=˜ξ∗) to be close to x. Next we will provide an answer to this question.\nNote that solving (57)with ξ=˜ξ∗is equivalent to solving the ℓ1-minimization problem (14)but\nwith ηreplaced with some eη. This eηcan be identified by f(˜ξ∗) =√\nΓeη. Therefore by the Lipschitz\ncontinuity of f(Lemma 2 (iii)) we have\n|√\nΓeη−√\nΓη|=|f(˜ξ∗)−f(ξ∗)| ≤√\nΓ|˜ξ∗−ξ∗|,\nwhich leads to\n|eη−η| ≤ |˜ξ∗−ξ∗| ≤ν.\nFrom the above we can see that in the end we obtain an approximate solution ˜x♯that corresponds to\nthe exact solution of (14)but with ηreplaced with some eηsatisfying eη≤η+ν. We can therefore\nuse Theorem 2 to obtain the following guarantee about the closeness to x:\nTheorem 8 (Compressed sensing with approximate solution) .LetD=Pk\nl=0\0n\nl\n. Let A∈CΓ×Dbe\na matrix whose rows are independently randomly sampled from the rows of H(k)with replacement.\nLetδCS∈(0,1)and let M > 0be an integer. If\nΓ≥CMmax{ln2(M) ln(Mln(D)) ln(D),ln(1/δCS)}, (61)\nthen, with probability at least 1−δCS, the following statement holds for every M-spase x∈CD\nwhose entries are bounded by 1in absolute value. Let noisy samples y=Ax+ebe given with\n22∥e∥2≤η√\nΓ, and let ˜x♯be the approximate solution of the ℓ1-minimization problem (14)produced by\nAlgorithm 3.6.2 with the error tolerance on ξ∗chosen to be ν >0. Then\n\r\rx−˜x♯\r\r\np≤C1M1/p−1/2(η+ν),1≤p≤2. (62)\nBoth constants C, C 1are universal. The approximate solution ˜x♯is obtained through Algorithm 3.6.2\nwhich runs in time poly( n,Γ,log(1/ν)).\n4 Lower bounds\nIn this section we provide a lower bound for the Hamiltonian learning task we consider. Specifically\nwe consider the dependence on the accuracy ϵand the number of Pauli terms M. The adaptive\nexperiments are modeled as in [60], where all experiments form a tree such that the outcome of the\nexperiment at a vertex determines which child leaf to move to, thus determining the next experiment\nto perform. Our main tool for the total evolution time lower bound is Assouad’s lemma [61], which\nprovides a lower bound on the achievable ℓ1-error given two prerequisites: (1) an estimate of how\nhard it is to distinguish two output probability distributions if they come from two Hamiltonians\nthat differ slightly, and (2) a lower bound on the penalty in ℓ1-error if such a pair of Hamiltonians\nare not correctly distinguished. The second prerequisite is easy to fulfill, as discussed in the proof\nof Theorem 9. For the first prerequisite, we will follow [5] to capture the difficulty of correctly\ndistinguishing the output probability distributions by induction on the tree of adaptive experiments.\nIn the following, we first characterize the model of quantum learning experiments following [60].\nDetails of the proofs are in Appendix C.\n4.1 Model of quantum experiments\nWe consider the scenario of learning the unknown Hamiltonian Hfrom dynamics. Consider the time\nevolution operator of Hparameterized by time t:\nU(t) =e−iHt, (63)\nA learning agent can have access to U(t)by quantum experiments without knowing H. The learning\nalgorithm includes the scenario where each quantum experiment is chosen adaptively based on past\nmeasurement outcomes. Following [60], we first define a single experiment:\nDefinition 5 (An ideal experiment) .Given a n-qubit unitary U(t) =e−iHtparameterized by time t,\nwithHbeing the unknown Hamiltonian. A single ideal experiment E(0)is specified by:\n1. an arbitrary n′-qubit initial state |ψ0⟩ ∈C2n′\nwith an integer n′≥n,\n2. an arbitrary POVM F={Mi}ion an n′-qubit system,\n3. an n′-qubit unitary of the following form,\nUexp=UK+1(U(tK)⊗I)UK. . . U 3(U(t2)⊗I)U2(U(t1)⊗I)U1, (64)\nfor some arbitrary integer K, arbitrary evolution times t1, . . . , t K∈R, and arbitrary n′-qubit\nunitaries U1, . . . , U K, UK+1. Here Iis the identity unitary on n′−nqubits subsystem.\n23A single run of E(0)returns an outcome from performing the POVM F={Mi}ion the state U|ψ0⟩.\nThe evolution time of the experiment is defined as\nt\nE(0)\n:=KX\nk=1tk. (65)\nNext, we will take noise into account. A small SPAM error is unavoidable in any quantum\nexperiment, and being robust against it is an important consideration in useful algorithms for\ncharacterizing and benchmarking quantum systems [27,54,60,62 –65]. We model the SPAM error by\na global depolarizing channel\nD:ρ7→ D(ρ) = (1 −γ)ρ+γtr(ρ)\n2n′I, (66)\nwhich is applied to the system right before the POVM F. This is equivalent to changing the POVM\nto\nF(γ)=n\n(1−γ)Mi+γtr (Mi)\nI/2n′o\ni. (67)\nThe noise strength is measured by the constant γ, which can take any value in (0,1).\nIn proving the lower bound, we are allowed to only consider SPAM error in the form of the global\ndepolarizing noise applied in the way described above, because any algorithm that is robust to SPAM\nerror in general must be robust to this type of SPAM error in particular. We will then define a single\nexperiment with measurement noise as follows:\nDefinition 6 (An experiment with measurement noise) .A single experiment E(γ)with measurement\nnoise γ∈(0,1)is identical to a single ideal experiment E0except for the POVM, which is F(γ)given\nin(67)instead of F={Mi}i.\nNote that a lower bound for learning with measurement noise naturally also holds for learning with\nboth state-preparation and measurement errors, since the latter is a more difficult task. Therefore\nfor simplicity we only consider measurement noise in this section.\nWith the definition of a single experiment with measurement noise, we can now formally define a\nlearning algorithm with total evolution time Tas follows, where we again adopt the definition in [5].\nDefinition 7 (Learning algorithm with bounded total evolution time) .Consider T >0,0.5> γ > 0.\nA learning algorithm with total evolution time Tand measurement noise γcan obtain measurement\noutcomes from an arbitrary number of experiments E(γ)\n1, E(γ)\n2, . . .as long as\nX\nit\nE(γ)\ni\n≤T (68)\nThe parameters specifying each experiment E(γ)\nican depend on the measurement outcomes from\nprevious experiments E(γ)\n1, . . . , E(γ)\ni−1.\n4.2 Lower bound of the total evolution time in Hamiltonian learning\nWith the definition of the learning algorithm and the possible sets of experiments, we now present a\nfundamental lower bound on the total evolution time for any learning algorithm that tries to learn an\nunknown n-qubit Hamiltonian consisting of MPauli terms from real-time evolution. The theorem is\nstated as follows:\n24Theorem9. Given integers nandM, real numbers ϵ, δ∈(0,1), and a set {P1, P2, . . . , P M} ∈Pn\\{I}\nrepresenting the M n-qubit Pauli terms in the Hamiltonian, we consider any learning algorithm with\na total evolution time Tand a constant measurement noise γ∈(0,0.5)as defined in Definition 7.\nSuppose that such a learning algorithm satisfies that for an n-qubit Hamiltonian H=PM\na=1µaPa\nwith any unknown parameters |µa| ≤1, after multiple rounds of noisy experiments, the algorithm\ncan estimate any µ=(µ1, . . . , µ M)toϵ1-error in the ℓ1-norm in expectation value averaged over\nexperimental outcomes. Then,\nT≥M\nϵ1elog(1/γ). (69)\nNotice that the lower bound in Theorem 9 is for learning n-qubit Hamiltonians with fixed M\nterms. It naturally implies a lower bound for learning n-qubit M-term Hamiltonians without prior\nknowledge of which Mterms are in the Hamiltonian. Moreover, by restricting the terms in the\nHamiltonian to be k-body, this lower bound also holds for the k-body, M-term, n-qubit Hamiltonian\nlearning problem we discussed in the previous sections.\nWe begin by considering how well a single noisy experiment can distinguish two Hamiltonians.\nLemma 5 (TV for one experiment, Lemma 30 [5]) .Consider a noisy experiment as defined in\nDefinition 6. Let p(i)andp′(i)be the probability of obtaining the measurement outcome iby performing\nthe POVM F(γ)when the unknown Hamiltonian is HandH′respectively. Then\nTV (p, p′)≤(1−γ) min\n∥H−H′∥ ·t\nE(γ)\n,1\n, (70)\nwhere t\0\nE(γ)\n=PK\nk=1|tk|is the total evolution time in this single experiment E(γ). Here TV\ndenotes the total variation distance between probability distributions.\nProof.We define\n|ψ⟩=UK+1(U(tK)⊗I)UK. . . U 3(U(t2)⊗I)U2(U(t1)⊗I)U1|ψ0⟩,\n|ψ′⟩=UK+1(U′(tK)⊗I)UK. . . U 3(U′(t2)⊗I)U2(U′(t1)⊗I)U1|ψ0⟩(71)\nBy the triangle inequality and telescoping', 'raytos.r.bsinfotech@gmail.com', 'Muzhou Ma, Steven T. Flammia, John Preskill, Yu Tong', '', '../pdf_files/671b4d1d60579-Learning k-body Hamiltonians via compressed sensing.pdf', '2024-10-26', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(137, '7087459819', '1', 1, 1, 'How to Design a Quantum Streaming Algorithm Without Knowing Anything About Quantum Computing', '2024-10-25', '2024', 'A series of work [GKK+08, Kal22, KPV24] has shown that asymptotic advantages in space complexity are possible for quantum algorithms over their classical counterparts in the streaming model. We give a simple quantum sketch that encompasses all these results, allowing them to be derived from entirely classical algorithms using our quantum sketch as a black box. The quantum sketch and its proof of correctness are designed to be accessible to a reader with no background in quantum computation, relying on only a small number of self-contained quantum postulates', 'Quantum Physics, Data Structures and Algorithms ', 'arXiv:2410.18922v1  [quant-ph]  24 Oct 2024How to Design a Quantum Streaming Algorithm Without Knowing\nAnything About Quantum Computing\nJohn Kallaugher\nSandia National Laboratories\njmkall@sandia.govOjas Parekh\nSandia National Laboratories\nodparek@sandia.govNadezhda Voronova\nBoston University\nvoronova@bu.edu\nAbstract\nA series of work [GKK+08, Kal22, KPV24] has shown that asymptotic advantages in space\ncomplexity arepossible forquantum algorithmsovertheir classicalco unterpartsin the streaming\nmodel. We give a simple quantum sketch that encompasses all t hese results, allowing them to\nbe derived from entirely classical algorithms using our qua ntum sketch as a black box. The\nquantum sketch and its proof of correctness are designed to b e accessible to a reader with no\nbackground in quantum computation, relying on only a small n umber of self-contained quantum\npostulates.Contents\n1 Introduction 1\n1.1 A Quantum Sketch for Pair Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Streaming Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2 Quantum Pair Sketch 6\n3 Implementing the Pair Sketch 8\n3.1 Quantum Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n3.2 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n4 Boolean Hidden Matching in the Stream 15\n4.1 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n4.2 Correctness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n5 Triangle Counting 19\n5.1 Triangle Weights . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n5.2 Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n5.3 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n6 Maximum Directed Cut 24\n6.1 Counting Heavy Edges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n6.1.1 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n6.1.2 Correctness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n6.2 Pseudosnapshot Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n6.3 Pseudosnapshot Estimation Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n6.4 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n6.4.1 Sketch Invariant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n6.4.2 Query Outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n6.4.3 Space Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nA Omitted Proofs from Section 6.1 431 Introduction\nSettings in which data is generated much faster than it can be stored are increasingly commonplace\nin many applications, such as those arising in processing an d analyzing internet traffic. In the\ndata stream model, which captures such settings, random acc ess to the input is prohibited, and\ninput data elements arrive sequentially. A streaming algor ithm in this model must process each\ndata element as it arrives using as little space as possible, ideally polylogarithmic in the size of\nthe entire input. While streaming algorithms were conceive d to compute statistics of numerical\ndata streams [Mor78, FN85, AMS96], they have since been appl ied more broadly—notably for\nestimating graph parameters [BKS02, McG14]. Streaming gra ph algorithms are well poised to\naddress applications stemming from massive graphs, such as those derived from social or sensor\nnetwork activity.\nQuantum computing leverages quantum mechanics to process i nformation and offers the hope\nof exponential resource advantages over classical computi ng. Certain problems, such as factoring\nintegers, can be solved exponentially faster with quantum a lgorithms than with the best-known\nclassical algorithms [Sho99]. Yet provable exponential qu antum advantages against best-possible\nclassical algorithms remain scarce. Provable exponential advantages are achievable in restricted\ncomputational models such as the data stream model [LG06, GK K+08], where such advantages\nare with respect to space (the number of classical or quantum bits required) rather than execution\ntime.\nSpace is an especially critical resource for quantum comput ing, as developing error-tolerant and\nscalable quantum bits (qubits) is a major challenge. It is un clear whether noisy intermediate-scale\nquantum (NISQ) computers or early fault-tolerant quantum c omputers, with relatively limited\nquantities of logical qubits, will be able to realize quantu m advantages. Space-efficient quantum\nalgorithms, including quantum streaming algorithms, offe r an alternative opportunity for such ad-\nvantages. Even early quantum computers with limited quantu m memory may be able to process\nlarger data sets than possible classically, and problems ad mitting exponential quantum space ad-\nvantages are promising candidates.\nThe Quantum Streaming Model In the streaming model, the input to a problem is received\nas a “stream” (σi)m\ni=1, one element at a time, in an arbitrary order. For each possib le value of\n{σi:i∈[m]}there is a set of valid answers to output. The task of a streami ng algorithm is to\noutput one of these valid answers after processing the strea m. Note that the answer is not allowed\nto depend on the orderof the stream, and a “promise” on the input can be enforced by a llowing all\npossible answers for inputs violating the promise. For inst ance, in a graph streaming problem, the\nstream elements σimight be edges of the graph, and the desired output might be to approximate\nsome parameter of the graph to a desired accuracy. Typically in this model we are interested in\nthespacecomplexity of the algorithm: how many bits (or qubits) of sto rage are needed to solve\nthe problem, although other parameters, such as update time , may also be considered.\nIn thequantum streaming model, the input stream takes the same (classical ) form, but it\nis processed by an algorithm with access to quantum resource s. Formally, we may think of the\nalgorithm as having an array of qubits and a classical algori thm that, for every update processed,\nchooses aquantum circuitbuilt fromsomefinitesetofgates andmeasurement operators, toapply to\nthequbits. Thealgorithm isallowed toperformbothpre-pro cessing andpost-processing operations.\nIts space complexity, then, is the sum of the number of qubits used and the number of bits required\nbytheclassical algorithm. Notethatweallowmeasurements atintermediate points whileprocessing\nthe stream: it is not in general possible to defer measuremen ts to the end of the algorithm because\nwhichmeasurements areperformedmaydependontheupdates seen, w hichwouldrequireadditional\n1space to remember.\nSketching A closely related concept is the idea of a “sketch” of a datase t [Cor17]. This is a\nsuccinct representation of a dataset (smaller than the data set itself; for our purposes we will want\nittouseatmost o(n)bitsorqubitsforan n-bitinput)thatsupportsarestrictedsetofqueries. Basic\nresults in classical and quantum information imply that the se queries cannot be expressive enough\nto allow reconstructing the entire dataset, and we will also allow them to be randomized , obeying\nonly some probabilistic guarantee of correctness. We will o ften refer to a sketch as “containing” an\nelement or having an “element” added to it, to denote that ele ment being in the dataset sketched,\nbut it is important to note that this does not put sketches in o ne-to-one correspondence with sets\nof elements—two identical sketches may contain different e lements in this sense.\nA minimal requirement for a sketch to be useful for streaming is that it can be updated:\nwhenever a new element is seen in the stream, it must be possib le to update the sketch to contain\nthat element. Oftenother update operations, such as theabi lity tomergesketches, areconsidered—\nin our case, we will consider sketches that support permutin g the underlying dataset (that is, given\na permutation π, there is an update operation for the sketch that is equivale nt to applying πto\nevery element previously added, beforeit was added to the sketch).\nIn the quantum setting, the no-cloning theorem [Wil17, p. 79 ] means that it is not, in general,\npossible to copy a quantum sketch. This in turn makes it possi ble for the queries supported by the\nsketch to be meaningfully destructive , irreversibly changing the sketch.\nOther Quantum Streaming Models We only consider the standard one-pass streaming model\nin this work. When multiple passes are allowed (that is, the i nput stream is given to the algorithm\nmultiple times), quantum advantages are known that are not e ncompassed by our sketch, provided\nthe number of passes is more than constant [LG06, Mon16, HM19 ].\nItis known [AD11] that quantum automata with only asingle qu bit can solve the “coin problem”\nof differentiating a coin that is heads with probability pfrom one that is heads with probability\np+ε, while a classical automaton would need Ω((p(1−p)/ε)states [HC70]. However, such quan-\ntum automata cannot be implemented as constant-space quant um streaming algorithms under our\ndefinition, as they depend on the ability to perform noisele ss rotations that depend on ε, and so\naccounting for noise (or the error introduced by constructi ng such rotations from a finite set of\ngates) would blow up the space.\nRelated Work A provable exponential quantum space advantage for a stream ing graph problem\nwas first1established by Gavinsky, Kempe, Kerenidis, Raz, and de Wolf [GKK+08], who considered\na streaming variant of the Boolean Hidden Matching (BHM) pro blem. While BHM can be seen\nas a graph problem, it is not known to have algorithmic applic ations, although it is a powerful\ntool for proving lower bounds . The question of a quantum streaming advantage for a “natura l” and\npreviously classically studied problem, as articulated by Jain and Nayak [JN14], remained open.\nKallaugher discovered the first such advantage, for counti ng triangles in graph streams [Kal22],\nwhich is well studied and motivated by applications [BKS02, BOV13, JK21]. However, this ad-\nvantage is polynomial in the input size, and Kallaugher, Par ekh, and Voronova [KPV24] gave the\nfirst natural exponential quantum streaming advantage, fo r approximating the value of the Max\nDirected Cut problem in a directed graph stream. This also re presents the first known quantum\nadvantage for approximating a graph problem, albeit in the s treaming model. The details of the\n1A similar separation was proved in [LG06], although the prob lem considered is not formally a streaming problem\nin the sense we use in this paper, as it comes with a guarantee o n theorderin which the updates will be received.\n2graph problem considered arecritical, since Kallaugher an dParekh[KP22]showed that noquantum\nstreaming advantage is possible for the very similar Max Cut problem in undirected graphs.\nOur Contributions One of our main goals is to provide experts in designing class ical algorithms\na simple entry point for designing novel and cutting-edge qu antum algorithms offering quantum\nadvantages over classical counterparts. We observe that qu antum streaming algorithms provide a\nunique opportunity toward this end. Learning more traditio nal quantum algorithms such as Shor’s\nalgorithm [Sho99] requires an understanding of quantum cir cuits and more basic kernels such as\nthe Quantum Fourier Transform. The details of such algorith ms can be daunting and a potential\ndeterrent fornewcomers toquantum computing. Incontrast, weshow that asimple quantum sketch\ncoupled with more sophisticated but purely classical techn iques captures state-of-the-art quantum\nstreaming algorithms that represent recent breakthrough r esults. While conventional wisdom might\nsuggest that novel quantum techniques are necessary for breakthroughs in quantum algo rithms, we\nobserve through the present work that the novelty lies on the classical side for recent quantum\nstreaming algorithms. More broadly we believe that effecti vely enlisting and engaging classical\nalgorithms researchers is critical in advancing quantum al gorithms, and we intend for this work to\nprovide such a path.\nWe show that the quantum streaming advantages for the Boolea n Hidden Matching [GKK+08],\nTriangle Counting [Kal22], and Max Directed Cut [KPV24] pro blems may be cast as classical\nalgorithms employing a simple-to-understand quantum sket ch as a black box. The sketch and\naccompanying proofs of correctness rely only on a few basic a nd self-contained quantum postulates.\nAs such, they are accessible to readers with no background in quantum computing and can serve\nas an alternative to other first examples in quantum informa tion such as quantum teleportation\nor superdense coding [NC10]. Isolating and abstracting the quantum components of the above\nquantum streaming advantages also better illustrates how a nd why quantum streaming advantage\narises, especially to those unversed in quantum algorithms .\nHow to Read This Paper In the remainder of this section, we will give a high level des cription\nof the sketch and its application to streaming algorithms. F or an exact description of the operations\nprovided by the sketch, see Section 2. In Section 3 we prove th at the sketch can be implemented.\nThis is the only part of the paper that uses any quantum inform ation, and can be skipped by\nthe reader who is happy to have the sketch as a “black box”. How ever, the quantum information\npostulates used are all stated in the section, and so it shoul d not require any additional quantum\nbackground.\nIn Sections 4, 5, 6, we give explicit constructions of the kno wn one-pass quantum streaming\nalgorithms as algorithms that are classical other than thei r use of the sketch as a subroutine.\nThese are in increasing order of complexity. For Sections 5, 6, the “quantum part” of the original\nalgorithms can in each case be characterized by a single lemm a, so we prove the “black box” variant\nof that lemma rather than reproducing all the content of the o riginal paper. Section 6 also contains,\nby way of presenting a simpler version of the problem solved, a solution to a “counting heavy edges”\nproblem that may be of independent interest as a streaming pr imitive.\n1.1 A Quantum Sketch for Pair Sampling\nThe core of our paper is a quantum sketch QTfor a setT(contained in a poly(|T|)-sized universe of\npossible elements U) that solves a “pair sampling” problem in the stream. Given a stream of query\npairs(u,v)∈P⊆U2, wewant to estimate the number of pairs from Pthat arecontained in T(that\nis,|{(u,v)∈P:u∈T∧v∈T}|), and, assumingwedeterminethatthisnumberisnon-zero, w ewant\n3to, by the end of the stream, randomly sample one of those pair s in{(u,v)∈P:u∈T∧v∈T}.\nNote that we do not know Pat the time we form the sketch QT.\nOne classical approach to this problem would be to form QTby randomly subsampling T. It is\neasy to see that this would require sampling at least Ω/parenleftig/radicalbig\n|T|/parenrightig\nelements: if kelements are sampled,\nany given pair is lost with probability 1−k2/|T|2, and so if k= o/parenleftig/radicalbig\n|T|/parenrightig\n, we can expect to\nloseeverypair fromPcontained in T, even if the greatest possible number of such pairs ( |T|/2)\nis present. A reduction to the Boolean Hidden Matching probl em [GKK+08] proves that this is\noptimal up to a log factor: anyclassical algorithm needs Ω/parenleftig/radicalbig\n|T|/parenrightig\nbits of storage to solve the\nsampling part orthe counting part of the problem, even if we only want, say, a ±|T|/10bound on\nthe additive error.\nOur quantum sketch solves this problem with only O(logn)qubits, assuming the universe U\nhas sizepoly(n). This comes with two important caveats:\n•It only works as described when the pairs in Paredisjoint. However, it will not fail arbitrarily\nwhen this does not happen. Rather, every time a pair query (u,v)is made, both uandv\nare removed from the sketch, with the effect that e.g. a subse quent query to (u,w)will be\ntreated as if uwere not in T. Working around this limitation is a core challenge in writi ng\nalgorithms that make use of the sketch, as in e.g. graph probl ems where the pairs we want\nto query are edges, there will sometimes be high-degree vert ices that cause a large amount of\noverlap among the pairs to be queried.\n•When the sketch returns a sample (which is supposed to be a pai r fromPcontained in T),\nit may sometimes instead return an element (u,v)fromPsuch that only oneofuandvis a\nmember ofT. However, we will have two guarantees that mitigate this dra wback. Firstly, the\nprobability of returning a valid pair will be proportional t o the fraction of Tthat is covered\nby pairs from P, i.e. to|{(u,v)∈P:u∈T∧v∈T}|\n|T|. Secondly, the sample will come with a ±sign.\nIf the sample is valid, this will always be +, while if it is spurious it will be +or−with\nequal probability. We can therefore use the −responses to “cancel out” the effect of spurious\nsamples, depending of course on the application in question .\nIn order to be useful for streaming algorithms, we must be abl e to update this sketch as well as\nquery it in the stream. We will have a somewhat more powerful u pdate rule than simply being\nable to add elements to the sketch: at any point, we can execut e an arbitrary permutation π(on\nthe universe U), replacing the sketched set Twithπ(T). In particular, we can add elements to the\nsketch by initializing it on a set of “dummy elements” and the n using this operation to replace a\ndummy element whenever we want a new element added to the sket ch (although note that means\nwe must start by initializing the sketch with a set as large as the set of all elements we will add to\nthe sketch).\nA formal description of the operations supported by the sket ch can be found in Section 2. Note\nthat we formalize the query process by saying that a query to a pair(u,v)contained in Treturns\nYeswith probability proportional to 1/|T|(destroying the set as this happens), and otherwise\ncausesuandvto be removed from T, which will suffice both for the estimation and sampling par t\nof the task described. In fact, it is somewhat more powerful, as the fact that we don’t have to wait\nuntil the end of the stream to receive our sampled pair will be necessary for the Max Directed Cut\nalgorithm in Section 6.\n41.2 Streaming Applications\nWe give three applications of the sketch, corresponding to t he three known examples of one-pass\nquantum advantage in the streaming model.\nBoolean Hidden Matching The first demonstration of quantum space advantage in strea ming\nwas in [GKK+08], for a streaming version of the Boolean Hidden Matching p roblem (also described\nin this paper). Boolean Hidden Matching is a one-way communi cation problem in which Alice has\na stringx∈ {0,1}nrepresenting set of vertices [n]labeled by bits, and Bob has a partial matching\nMon[n](that is, a set of disjoint edges with vertex set [n]), along with an edge label for each edge\nin the matching, given by z∈ {0,1}M. There is a secret bit b∈ {0,1}such thatxu⊕xv⊕zuv=b\nfor every edge uv∈M, and their task is to determine b, using as little communication as possible\nand with only one-way communication (Alice to Bob). The auth ors of [GKK+08] showed that this\nproblem can be solved with O(logn)qubits of communication, but requires Ω(√n)bits if only\nclassical communication is allowed.\nIn the streaming version, the stream consists of edges from Mwith their labels, and individual\nbits ofx(in the form (i,xi)), in any order and interspersed in any way. They gave a O(logn)-qubit\nstreaming algorithm for this problem, based on the same prin ciples as the communication protocol.\nWe show that this streaming problem can be solved with O(logn)space by an algorithm that\nis entirely classical other than its use of our sketch. This i s the most “pure” use of the sketch, as\nthe edges in Mcorrespond exactly to the pairs we want to sample, as the prob lem can be solved\nwith knowledge of any xu,xvandzuv(indeed, the sketch was inspired by the quantum protocol for\nthis problem). The main complications come in the fact that a n edgeuvmay arrive before one or\nboth ofxuandxv. This algorithm is described in Section 4.\nTriangle Counting After [GKK+08] established that exponential quantum streaming advant age\nwaspossible, thefirstworktoshow advantage fora naturalone-pass streamingproblem was[Kal22],\nwhich gave it for the triangle counting problem. This is a graph streaming problem, in which an\nm-edge graph Gis received one edge at a time, and the objective is to approxi mate the number of\ntriangles inG—the number of triples u,v,wsuch thatuv,vw,wu are all edges in the graph. It is\nknown [BKS02] that small-space algorithms for this problem are impossible when Gcontains very\nfew triangles, or when [BOV13] too many of these triangles sh are the same edge. In this discussion,\nfor simplicity we will assume Gcontains Θ(m)triangles, no more than O(1)of which intersect at\nany given edge.\nIn this setting, by [KP17], no classical algorithm can do bet ter than Ω(√m)space, with the\n“hard instance” being when every triangle in the graph inter sects at a single vertex. In particular,\nthis occurs when the stream is a star ( Θ(m)edges all incident to one vertex) followed by edges that\nmay or may not complete triangles with the edges of that star. Conversely, the quantum algorithm\nof [Kal22] achieves /tildewideO/parenleftbig\nm1/3/parenrightbig\nspace.\nWe show how to implement that algorithm as a classical algori thm with access to the quantum\nsketch as a subroutine. Here the set sketched contains the or dered pairs (u,v)and(v,u)for each\nedgeuvseen in the stream. Then, the “pairs” to be queried whenever w e see an edge uvare\n((w,u),(w,v))for eachwin the set of possible vertices for the graph. Therefore, the number of\n“yes” answers is the number of triangles completed by uv. The complication in the algorithm comes\nfrom the fact that while the pairs queried for any individual uvare disjoint, there is an overlap\nbetween those queried for any incident edges uv,vt.\nAs in the original algorithm of [Kal22], the solution uses th e fact that the worst case for the\nquantum-sketch-based strategy (i.e. for every triangle, i ts third edge to arrive in the stream is\n5incident tomanyotheredges)isincompatible withtheworst caseforclassicalalgorithms. Therefore,\nby interpolating between an entirely classical estimator a nd an estimator based on the quantum\nsketch, an algorithm improving over the best classical algo rithm is achieved. However, the cost of\nthis interpolation is that only a polynomial advantage ( O/parenleftbig\nm1/3/parenrightbig\nv.Ω(√m)) is achieved, despite\nexponential advantage being possible on those instances th at are hardest for classical algorithms.\nWe describe the algorithm in Section 5.\nMaximum Directed Cut Finally, [KPV24] gave exponential quantum streaming advan tage for\na different natural graph problem: the maximum directed cut problem in (directed) graph streams.\nThe maximum directed cut value of a digraph (V,E)is defined as the maximum over all x∈ {0,1}V\nof|{− →uv∈E:xu= 0∧xv= 1}|. Thatis, itisthemaximum, over all partitions of Vintoa“head” and\n“tail” set, number of edges that can be made to go from the head set to the tail set. The objective\nof the streaming problem is to approximate this number with t he best possible approximation ratio\nα: to return a number in [α·Opt,Opt], where Opt is the true optimal cut value.\nIn [CGV20], it was shown that any approximation ratio than4\n9requires Ω(√n)classical space,\nwhile [SSSV23, Sin23] showed that 0.4844is achievable in /tildewideO(√n)space by estimating a “first-order\nsnapshot”. This is given by grouping the vertices of the grap h into a constant number of classes Ci\nbased on their biases (the bias of a vertex visbv=dout\nv−din\nv\ndv, wheredout\nvis the number of edges− →vu\nin the graph, din\nvis the number of edges− →uv, anddv=dout\nv+din\nv), and counting, for every pair of\nclassesCi,Cj, the number of edges− →uvwithu∈Ciandv∈Cj.\nThis problem has a natural “pair sampling” structure: for ea ch pair of classes we want to sketch\nthe vertices in Ciand those in Cj, and then, for each edge− →uv, query the sketch to ask if uis in\nCiandvis inCj. There are two major obstacles to achieving this. One is the i ssue we saw in the\ntriangle counting case: the queries we want to make will not b e disjoint. The other is that we need\nto dynamically update the “bias class” of each vertex as the s tream is processed, as these classes\ndepend on the edges that have been seen incident to the vertex .\nIt turns out that the same solution applies to both of these is sues: each vertex is represented by\na “stack” of elements in the sketch (in fact, several stacks) (v,i)i=1,...which is incremented whenever\nan edge is seen incident to that sketch. Then, the presence of an element (v,d)corresponds to the\nvertex having degree at least d, and so querying e.g. ((u,d),(v,d))tests whether vertices uandv\nboth have degree ≥din the stream seen so far. This avoids the problem of pairs ove rlapping, as\nwhile this query removes (u,d)and(v,d)from the sketch, it also replaces them when the stack is\nincremented. These degrees are then used to calculate biase s (some additional tricks are required\nto encode both the in- and out-degree of a vertex in one stack, and several stacks are needed per\nvertex to account for different degree thresholds that corr espond to different biases).\nThis is the logic of the algorithm in [KPV24]—in Section 6 we s how how it can be implemented\nwith an entirely classical algorithm that runs the quantum s ketch as a subroutine.\n2 Quantum Pair Sketch\nIn this section we will describe a quantum sketch QTthat summarizes a set Tcontained in a known\nuniverseU={0,1}m. It will require m= log|U|qubits to store and support both updates to T\nand queries that check (with probability 1/|T|) whether a given element or pair is contained in T.\nThis operation will be destructive : if the queried element is successfully identified as being inT,\nthe sketch is destroyed, and otherwise it is removed from T.\nFormally, the operations are as follows:\n6•create(T): Takes as input T⊆Uand returns the sketch QT.\n•update(π,QT): Takes as input a permutation π:U→Uand a sketch QT, and (in-place)\ntransforms QTtoQπ(T), whereπ(T) ={π(x) :x∈T}.\n•query_one(x,QT). Takes as input an element x∈Uand a sketch QT, and probabilistically\ntests whether x∈T. Returns an element of {∈,⊥}and modifies the sketch as follows:\n–Ifx∈T:\nWith probability 1/|T|destroyQTand return ∈.\nWith probability 1−1/|T|replaceQTwithQT\\{x}and return ⊥.\n–Ifx/\\e}a⊔io\\slash∈T:\nLeaveQTunchanged and return ⊥.\n•query_pair(x,y,QT): Takes as input elements x/\\e}a⊔io\\slash=yfromUand a sketch QT, and prob-\nabilistically tests whether {x,y} ⊆T. Returns an element of {+1,−1,⊥}and modifies the\nsketch as follows:\n–If{x,y} ⊆T:\nWith probability 2/|T|destroyQTand return +1.\nWith probability 1−2/|T|replaceQTwithQT\\{x,y}and return ⊥.\n–If|{x,y}∩T|= 1:\nWith probability 1/|T|destroyQTand return a randomly chosen r∈ {+1,−1}.\nWith probability 1−1/|T|replaceQTwithQT\\{x,y}and return ⊥.\n–If{x,y}∩T=∅:\nLeaveQTunchanged and return ⊥.\nWe note that, because of the no-cloning theorem [Wil17, p. 79 ], it is not possible to copy the\nsketch, or to check whether it contains some element without potentially destroying the sketch.\nIt may be unclear how the output of the query operations above may be construed as Yes\norNoanswers to queries. Any query that returns an answer besides ⊥is considered a success,\nand destroys the sketch. A successful answer for query_oneis∈, which is interpreted as Yes.\nThequery_pairoperation returns numerical values upon success. By design ing algorithms that\nconsider the numerical values in expectation , we may interpret +1asYesand0asNo. This\nis because when query_pair(x,y,QT)succeeds and {x,y} ⊆T, then it always returns +1. If\nquery_pair(x,y,QT)succeeds and |{x,y}∩T|= 1, the values ±1are returned with equal prob-\nability, and so they cancel out to 0 in expectation, which we i nterpret as No. This will suffice for\nmany applications.\nWe will make frequent use of an additional operation that rel ies only on the basic sketch op-\nerations defined above. We will want to add elements to Tduring the course of the sketch. If we\nhave a bound mon the maximum number of elements we will ever want to add, the n we addm\nextra “dummy” elements {d1,...,dm}to the universe U, and include those elements in the set T\nused when we initialize the sketch with create(T). Thetthtime we want to add a new element\nxtoT, we perform update(π,T)takingπto be the transposition that swaps dtandx. These\ndummy elements are not quite “free”—the size of the set Twill depend on m, and this will impact\nthe outcome probabilities for query operations on QT.\nOne more useful property of this sketch, which we will prove i n the following section, follows as\ndirect consequence of the definitions above.\n7Lemma 1. For any sequence of query_oneandquery_pairoperations applied to QT, interleaved\nin any way with updateoperations, there is a unique T′such that the sketch will become QT′after\nthese operations if none of them destroy the sketch . Moreover, the probability that none of the\noperations destroy the sketch is|T′|\n|T|.\nNote that in particular, this implies that if we perform any s equence of query_oneand\nquery_pairoperations on disjoint singletons and pairs, the distribution on outcomes is inde-\npendent of the ordering of the operations, as the probabilit y of each non- ⊥outcome of each query\nis proportional to the size of the set underlying the query at the time the query is made. This\nmeans that when we conduct a batch of disjoint queries it will not be necessary to worry about the\norder in which they are made, simplifying the description of our algorithms.\n3 Implementing the Pair Sketch\nIn this section we will show how to implement the sketch descr ibed in Section 2. This section is\nself-contained, presented in an elementary manner, and doe s not require any quantum computing\nbackground. However, this section may be skipped, since the quantum streaming algorithms in the\nsequel are purely classical beyond using the quantum pair sk etch in a black-box manner that does\nnot require understanding its implementation.\nTheorem 2. A quantum algorithm with log|U|qubits can implement the sketch Qdescribed in\nSection 2.\n3.1 Quantum Preliminaries\nWe start by describing three facts about quantum computing t hat suffice to construct the sketch.\nFor a more complete discussion, see e.g. [NC10]. In order to m ake this section more accessible, we\nuse a running example in the notation of traditional linear a lgebra along with the braket notation.\nFirst, we describe a superposition over qubit states. We wil l follow the standard in quantum\ninformation of using |ψ/a\\}⌊ra⌋ke⊔ri}h⊔to denote a (column) vector, and /a\\}⌊ra⌋ke⊔le{⊔ψ|to denote its conjugate transpose\n(i.e.,/a\\}⌊ra⌋ke⊔le{⊔ψ|=|ψ/a\\}⌊ra⌋ke⊔ri}h⊔†). For a set Sand complex vector space CS, we write the standard basis elements\nof the space as |s/a\\}⌊ra⌋ke⊔ri}h⊔for eachs∈S.\nFact3 (State) .Anm-qubitstate|ψ/a\\}⌊ra⌋ke⊔ri}h⊔is a unit vector in C2m.\nAs the name implies, such a state can be stored using mquantum bits (qubits). Note that this\npromises nothing about how we can interact with a state. Quan tum mechanics does not allow for\nrandom access to the entries of a state |ψ/a\\}⌊ra⌋ke⊔ri}h⊔, and extracting information from a state is typically a\ndestructive process.\n8Example:\nLetm= 2. Then|ψ/a\\}⌊ra⌋ke⊔ri}h⊔represents some column vector\n|ψ/a\\}⌊ra⌋ke⊔ri}h⊔=\nα1\nα2\nα3\nα4\n∈C4,/⌊ard⌊l|ψ/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 1,\nwhich requires 2qubits to store. The basis elements are denoted as\n|1/a\\}⌊ra⌋ke⊔ri}h⊔=\n1\n0\n0\n0\n|2/a\\}⌊ra⌋ke⊔ri}h⊔=\n0\n1\n0\n0\n|3/a\\}⌊ra⌋ke⊔ri}h⊔=\n0\n0\n1\n0\n|4/a\\}⌊ra⌋ke⊔ri}h⊔=\n0\n0\n0\n1\n\nNext we will describe how states can be computed.\nFact4 (Quantum Computation) .Aquantum computation starts with a fixed m-qubit state, typ-\nically|1/a\\}⌊ra⌋ke⊔ri}h⊔as defined in the example above, and applies a finite sequenc e of unitary matrices on\nC2m(linear transformations that preserve inner products and t herefore vector lengths) to produce\na state|ψ/a\\}⌊ra⌋ke⊔ri}h⊔:\n|ψ/a\\}⌊ra⌋ke⊔ri}h⊔=UlUl−1···U1|1/a\\}⌊ra⌋ke⊔ri}h⊔.\nEachUiis selected from a finite set of gates, andlis the length or running time of the computation.\nSinceU=Ul···U1is a unitary matrix, any quantum computation can be viewed as applying a\nunitary transformation to |1/a\\}⌊ra⌋ke⊔ri}h⊔. However, since there are any infinite number of unitaries, arbitrary\nunitaries cannot be implemented by quantum computation in f inite time. By the same token,\narbitrary states cannot be produced in finite time. As in the classical case, quantum computation\nthat is polynomial in length with respect to the number of qub its is of particular interest as a proxy\nfor tractable computation on a quantum computer.\nFinally, we will describe how we can extract classical infor mation from a state using projective2\nmeasurements.\nFact5 (Projective Measurement) .Let(Pi)i∈Ibe a collection of orthogonal projectors on C2m(i.e.,\nP2\ni=Pi=P†\ni), such that/summationtext\ni∈IPi=I2m. We interpret i∈Ias probabilistic outcomes, which\nwe will call measurement outcomes . We can measure a state|ψ/a\\}⌊ra⌋ke⊔ri}h⊔with these projectors, with the\nfollowing distribution on outcomes:\nFor eachi∈I, with probability /⌊ard⌊lPi|ψ/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2, return the measurement outcome i, and replace\nthe state |ψ/a\\}⌊ra⌋ke⊔ri}h⊔withPi|ψ/a\\}⌊ra⌋ke⊔ri}h⊔//⌊ard⌊lPi|ψ/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2.\n2This is only one way of formalizing quantum measurement, but it will suffice for our purposes.\n9Example:\nLet|ψ/a\\}⌊ra⌋ke⊔ri}h⊔= (α1,α2,α3,α4)T∈C4,/⌊ard⌊l|ψ/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 1. LetP(1,2,4)be a projective operator onto the\nsubspace generated by |1/a\\}⌊ra⌋ke⊔ri}h⊔,|2/a\\}⌊ra⌋ke⊔ri}h⊔,|4/a\\}⌊ra⌋ke⊔ri}h⊔, andP(3)be a projective operator onto the subspace generated\nby|3/a\\}⌊ra⌋ke⊔ri}h⊔:\nP(1,2,4)=|1/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔1|+|2/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔2|+|4/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔4|=\n1 0 0 0\n0 1 0 0\n0 0 0 0\n0 0 0 1\nP(3)=|3/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔3|=\n0 0 0 0\n0 0 0 0\n0 0 1 0\n0 0 0 0\n\nNote thatP(1,2,4)+P(3)=I4. Then the possible outcomes of the measurement of |ψ/a\\}⌊ra⌋ke⊔ri}h⊔are the\nfollowing:\n•(1,2,4)outcome with probability\n/⌊ard⌊lP(1,2,4)|ψ/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l(α1,α2,0,α4)T/⌊ard⌊l2\n2=|α1|2+|α2|2+|α4|2.\nThe state is updated to be (α1,α2,0,α4)T//radicalbig\n|α1|2+|α2|2+|α4|2.\n•(3)outcome with probability\n/⌊ard⌊lP(3)|ψ/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l(0,0,α3,0)T/⌊ard⌊l2\n2=|α3|2.\nThe state is updated to be (0,0,α3/|α3|,0)T= (0,0,1,0)T.\n3.2 Implementation\nFor anyT⊆U= [2m], we will implement the sketch QTas the superposition |ψ/a\\}⌊ra⌋ke⊔ri}h⊔=1√\n|T|/summationtext\nt∈T|t/a\\}⌊ra⌋ke⊔ri}h⊔\ninCU. By Fact 3 we can store the state created by create(T)withm= log|U|qubits. For the\nremainder ofthissection, wewillwrite |ψT/a\\}⌊ra⌋ke⊔ri}h⊔forthisstate. Thestate |ψT/a\\}⌊ra⌋ke⊔ri}h⊔canbeefficiently produced\nby a quantum computation, as dictated by Fact 4 (see e.g., Lem ma 1 in [FU15] and [SV24]).\nExample:\nLetU= [4]andT={1,2,3}. Then the state representing set Tis\n|ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1/radicalbig\n|T|/summationdisplay\nt∈T|t/a\\}⌊ra⌋ke⊔ri}h⊔=1√\n3\n1\n1\n1\n0\n∈C4,/⌊ard⌊l|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 1.\nTherefore, we need to prove the operations update,query_one, andquery_paircan be real-\nized on a quantum computer. We start with update(π,QT), recalling its definition:\n•update(π,QT): Takes as input a permutation π:U→Uand a sketch QT, and (in-place)\ntransforms QTtoQπ(T), whereπ(T) ={π(x) :x∈T}.\nLemma 6. update(π,T)is realizable on a quantum computer using mqubits.\nProof.LetVbe the linear transformation defined by acting on each stand ard basis element |u/a\\}⌊ra⌋ke⊔ri}h⊔,\nforu∈U, asV|u/a\\}⌊ra⌋ke⊔ri}h⊔=|π(u)/a\\}⌊ra⌋ke⊔ri}h⊔. Note that this is unitary, as it preserves vector lengths. T herefore, by\n10Fact 4, since |ψT/a\\}⌊ra⌋ke⊔ri}h⊔is produced by a quantum computation, a quantum computer may applyVto\n|ψT/a\\}⌊ra⌋ke⊔ri}h⊔, resulting in\nV|ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1/radicalbig\n|T|/summationdisplay\nt∈TV|t/a\\}⌊ra⌋ke⊔ri}h⊔=1/radicalbig\n|T|/summationdisplay\nt∈T|π(t)/a\\}⌊ra⌋ke⊔ri}h⊔=|ψπ(T)/a\\}⌊ra⌋ke⊔ri}h⊔\nand soQThas been replaced with Qπ(T).\nTheupdateoperations we will employ for the quantum streaming algorit hms described in this\nwork are each implementable using constant time on a quantum computer.\nExample:\nLetπ: [4]→[4]be defined as π(1) = 2,π(2) = 3,π(3) = 4,π(4) = 1. Then the linear\ntransformation corresponding to πis\nU=\n0 0 0 1\n1 0 0 0\n0 1 0 0\n0 0 1 0\n\nand, if applied to our |ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1√\n3(1,1,1,0)T, it will update the state to\nU|ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1√\n3\n0 0 0 1\n1 0 0 0\n0 1 0 0\n0 0 1 0\n\n1\n1\n1\n0\n=1√\n3\n0\n1\n1\n1\n=|ψ{2,3,4}/a\\}⌊ra⌋ke⊔ri}h⊔=|ψπ(T)/a\\}⌊ra⌋ke⊔ri}h⊔.\nNext, we show how to implement query_one(x,QT):\n•query_one(x,QT). Takes as input an element x∈Uand a sketch QT, and probabilistically\ntests whether x∈T. Returns an element of {∈,⊥}and modifies the sketch as follows:\n–Ifx∈T:\nWith probability 1/|T|destroyQTand return ∈.\nWith probability 1−1/|T|replaceQTwithQT\\{x}and return ⊥.\n–Ifx/\\e}a⊔io\\slash∈T:\nLeaveQTunchanged and return ⊥.\nLemma 7. query_one(x,QT)is realizable on a quantum computer using mqubits.\nProof.We define projectors P∈,P⊥as:\nP∈=|x/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔x|\nP⊥=I−P∈\nP∈projects onto the basis vector |x/a\\}⌊ra⌋ke⊔ri}h⊔, andP∈+P⊥=I, so by Fact 5 we can measure with these\nprojectors. If x∈T,/⌊ard⌊lP∈|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2=/vextenddouble/vextenddouble/vextenddouble|x/a\\}⌊ra⌋k⌉tri}ht√\nT/vextenddouble/vextenddouble/vextenddouble2\n=1\nTand so we get the outcomes:\n•With probability1\nT, return∈. As we discard the sketch in this case it does not matter what\nhappens to the state.\n11•With probability 1−1\nT, return⊥and|ψT/a\\}⌊ra⌋ke⊔ri}h⊔is replaced with P⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔normalized to length 1,\nso as\nP⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1/radicalbig\n|T|/summationdisplay\nt∈T\\{x}|t/a\\}⌊ra⌋ke⊔ri}h⊔=/radicalbig\n|T|−1/radicalbig\n|T||ψT\\{x}/a\\}⌊ra⌋ke⊔ri}h⊔\nand soafter normalization the state is |ψT\\{x}/a\\}⌊ra⌋ke⊔ri}h⊔and therefore QThas been replaced by QT\\{x}.\nSo whenx∈Twe have the desired distribution on outcomes. When x/\\e}a⊔io\\slash∈T,/⌊ard⌊lP∈|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 0,\nand so we always return ⊥andP⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔=|ψT/a\\}⌊ra⌋ke⊔ri}h⊔, so the sketch state is always unchanged, also as\ndesired.\nExample:\nThe current state of the sketch in this running example is |ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1√\n3(0,1,1,1)T, and it stores\nT={2,3,4}.\nLet the query be query_one(1,QT). The corresponding projectors are\nP∈=|1/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔1|=\n1 0 0 0\n0 0 0 0\n0 0 0 0\n0 0 0 0\nP⊥=|2/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔2|+|3/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔3|+|4/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔4|=\n0 0 0 0\n0 1 0 0\n0 0 1 0\n0 0 0 1\n\nThen the possible outcomes are\n•∈\nWith probability /⌊ard⌊lP∈|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l(0,0,0,0)T/⌊ard⌊l2\n2= 0, and the sketch is destroyed.\n•⊥\nWith probability /⌊ard⌊lP⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l1√\n3(0,1,1,1)T/⌊ard⌊l2\n2= 1, and the updated state is\n1√\n3(0,1,1,1)T=|ψT\\{1}/a\\}⌊ra⌋ke⊔ri}h⊔=|ψT/a\\}⌊ra⌋ke⊔ri}h⊔.\nSo our state remains unchanged. If the next query is query_one(4,QT), then we have:\nP∈=|4/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔4| P⊥=|1/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔1|+|2/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔2|+|3/a\\}⌊ra⌋ke⊔ri}h⊔/a\\}⌊ra⌋ke⊔le{⊔3|\nThe possible outcomes are\n•∈\nWith probability /⌊ard⌊lP∈|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l1√\n3(0,0,0,1)T/⌊ard⌊l2\n2= 1/3, and the sketch is destroyed.\n•⊥\nWith probability /⌊ard⌊lP⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l1√\n3(0,1,1,0)T/⌊ard⌊l2\n2= 2/3, and the updated state is\n1√\n2(0,1,1,0)T=|ψT\\{4}/a\\}⌊ra⌋ke⊔ri}h⊔.\nLet’s assume the second outcome occurred so that the sketch i s not destroyed, and we now have\nT={2,3}.\nFinally, we show how to implement query_pair(x,y,QT):\n12•query_pair(x,y,QT): Takes as input elements x/\\e}a⊔io\\slash=yfromUand a sketch QT, and prob-\nabilistically tests whether {x,y} ⊆T. Returns an element of {+1,−1,⊥}and modifies the\nsketch as follows:\n–If{x,y} ⊆T:\nWith probability 2/|T|destroyQTand return +1.\nWith probability 1−2/|T|replaceQTwithQT\\{x,y}and return ⊥.\n–If|{x,y}∩T|= 1:\nWith probability 1/|T|destroyQTand return a randomly chosen r∈ {+1,−1}.\nWith probability 1−1/|T|replaceQTwithQT\\{x,y}and return ⊥.\n–If{x,y}∩T=∅:\nLeaveQTunchanged and return ⊥.\nLemma 8. query_pair(x,y,QT)is realizable on a quantum computer using mqubits.\nProof.We define projectors P+1,P−1,P⊥as:\nP+1=1\n2(|x/a\\}⌊ra⌋ke⊔ri}h⊔+|y/a\\}⌊ra⌋ke⊔ri}h⊔)(/a\\}⌊ra⌋ke⊔le{⊔x|+/a\\}⌊ra⌋ke⊔le{⊔y|)\nP−1=1\n2(|x/a\\}⌊ra⌋ke⊔ri}h⊔−|y/a\\}⌊ra⌋ke⊔ri}h⊔)(/a\\}⌊ra⌋ke⊔le{⊔x|−/a\\}⌊ra⌋ke⊔le{⊔y|)\nP⊥=I−P+1−P−1\nP+1projects onto the vector|x/a\\}⌊ra⌋k⌉tri}ht+|y/a\\}⌊ra⌋k⌉tri}ht√\n2andP−1onto|x/a\\}⌊ra⌋k⌉tri}ht−|y/a\\}⌊ra⌋k⌉tri}ht√\n2, whileP+1+P−1+P⊥=I, so by Fact 5\nwe can measure with these projectors. We can now break down th e outcomes of this measurement\nby whether both xandyare inT, exactly one of them is, or neither of them is, and show that th e\ndistribution of outcomes is as desired in each case.\nFirstly, if {x,y} ⊆T, then/⌊ard⌊lP+1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 2/Tand/⌊ard⌊lP−1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 0, so the outcomes are:\n•With probability2\nT, return+1. As we discard the sketch in this case it does not matter what\nhappens to the state.\n•With probability 1−2\nT, return⊥and|ψT/a\\}⌊ra⌋ke⊔ri}h⊔is replaced with P⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔normalized to length 1,\nso as\nP⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1/radicalbig\n|T|/summationdisplay\nt∈T\\{x,y}|t/a\\}⌊ra⌋ke⊔ri}h⊔=/radicalbig\n|T|−2/radicalbig\n|T||ψT\\{x,y}/a\\}⌊ra⌋ke⊔ri}h⊔\nand so after normalization the state is |ψT\\{x,y}/a\\}⌊ra⌋ke⊔ri}h⊔and therefore QThas been replaced by\nQT\\{x,y}.\nSo we have the right distribution on outcomes when {x,y} ⊆T. Next, if |{x,y} ∩T|= 1, then\n/⌊ard⌊lP+1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2=/⌊ard⌊lP−1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 1/2T, so the outcomes are:\n•With probability1\nT, return+1. As we discard the sketch in this case it does not matter what\nhappens to the state.\n•With probability1\nT, return−1. As we discard the sketch in this case it does not matter what\nhappens to the state.\n•With probability 1−2\nT, return⊥and|ψT/a\\}⌊ra⌋ke⊔ri}h⊔is replaced with P⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔normalized to length 1,\nwhich as in the previous case is |ψT\\{x,y}/a\\}⌊ra⌋ke⊔ri}h⊔and therefore QThas been replaced by QT\\{x,y}.\n13Soourdistribution isrightinthis casetoo. Finally, if {x,y}∩T=∅,/⌊ard⌊lP+1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2=/⌊ard⌊lP−1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2= 0,\nso we always return, and P⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔=|ψT/a\\}⌊ra⌋ke⊔ri}h⊔and the sketch is always unchanged, as desired.\nExample:\nThecurrent stateofthesketch inthis runningexampleis |ψT/a\\}⌊ra⌋ke⊔ri}h⊔=1√\n2(0,1,1,0)T, anditstores T=\n{2,3}. To illustrate additional cases, we will also consider |ψS/a\\}⌊ra⌋ke⊔ri}h⊔=1√\n3(1,1,0,1)T, corresponding\ntoS={1,2,4}.\nLet the queries be query_pair(2,3,QT)andquery_pair(2,3,QS). For both the corresponding\nprojectors are\nP+1=1\n2\n0 0 0 0\n0 1 1 0\n0 1 1 0\n0 0 0 0\nP−1=1\n2\n0 0 0 0\n0 1−1 0\n0−1 1 0\n0 0 0 0\nP⊥=\n1 0 0 0\n0 0 0 0\n0 0 0 0\n0 0 0 1\n\nThen the possible outcomes are\n•+1\nForT: with probability /⌊ard⌊lP+1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l1√\n2(0,1,1,0)T/⌊ard⌊l2\n2= 1, and the sketch is de-\nstroyed.\nForS: with probability /⌊ard⌊lP+1|ψS/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l1\n2√\n3(0,1,1,0)T/⌊ard⌊l2\n2= 1/6, and the sketch is\ndestroyed.\n•−1\nForT: withprobability /⌊ard⌊lP−1|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l(0,0,0,0)T/⌊ard⌊l2\n2= 0, andthesketch isdestroyed.\nForS: with probability /⌊ard⌊lP−1|ψS/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l1\n2√\n3(0,1,−1,0)T/⌊ard⌊l2\n2= 1/6, and the sketch is\ndestroyed.\n•⊥\nForT: with probability /⌊ard⌊lP⊥|ψT/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l(0,0,0,0)T/⌊ard⌊l2\n2= 0.\nForS: with probability /⌊ard⌊lP⊥|ψS/a\\}⌊ra⌋ke⊔ri}h⊔/⌊ard⌊l2\n2=/⌊ard⌊l1√\n3(1,0,0,1)T/⌊ard⌊l2\n2= 2/3, and the updated state\nis1√\n2(1,0,0,1)T=|ψ{1,4}/a\\}⌊ra⌋ke⊔ri}h⊔=|ψS\\{2,3}/a\\}⌊ra⌋ke⊔ri}h⊔.\nThis example is illustrative of an important property of the sketch: the pair query to sketch QT\nalways succeeds and returns +1in the example above. Therefore, when the query is interpret ed\nas asking whether the sketch contains the pair, the +1always corresponds to Yesas desired, since\n{2,3} ⊆T.\nThis covers all the operations required of QT, proving Theorem 2. Finally, we will prove\nLemma 1.\nLemma 1. For any sequence of query_oneandquery_pairoperations applied to QT, interleaved\nin any way with updateoperations, there is a unique T′such that the sketch will become QT′after\nthese operations if none of them destroy the sketch . Moreover, the probability that none of the\noperations destroy the sketch is|T′|\n|T|.\nProof.We proceed by induction on t, the number of query_oneandquery_pairoperations in\nthe sequence. As updateoperations are deterministic, cannot destroy the sketch an d do not change\n14the size of the underlying set, the result holds trivially fo rt= 0. Now, suppose it holds for t. The\naforementioned observation about updatemeans that without loss of generality we may assume the\nfinal update in the sequence is a query_oneorquery_pairoperation. Let T′′be the underlying\nset of elements of the sketch before this last operation is ex ecuted, if the sketch is not destroyed by\nany previous operation. By the inductive hypothesis, T′′is deterministic, and the probability that\nno operation before the last one destroys the set is|T′′|\n|T|.\nNow, whether the last operation is query_oneorquery_pair, letXbe the set of elements\nqueried (so Xis either a singleton or a pair). Note that in each case the sum of the probability of\nall results that involve destroying the sketch is|X∩T′′|\n|T′′|. Furthermore, if the sketch is notdestroyed,\nall elements of Xare removed from the sketch, and so T′=T′′\\X. Therefore, T′is deterministic as\ndesired. Moreover, using the inductive hypothesis, the pro bability that the sketch is not destroyed\nafter alltquery operations is\n|T′′|\n|T′|/parenleftbigg\n1−|X∩T′′|\n|T′′|/parenrightbigg\n=|T′′|−|X∩T′′|\n|T|=|T′|\n|T|\ncompleting the proof.\n4 Boolean Hidden Matching in the Stream\nIn the Boolean Hidden Matching problem defined in the stream ing setting (see [GKK+08]) the\nalgorithm receives a string x∈ {0,1}nrepresenting set of vertices [n]each labeled by a bit xv, and\nanαn-edge partial matching Mon[n], with labels z∈ {0,1}M, as a stream of elements. The string\nupdates take the form (v,xv)forv∈[n], while the matching updates take the form (uv,zuv), for\nuv∈M. The updates can arrive in any order, and the two types of upda te can be intermingled.\nWearepromisedthateither, forevery uv∈M,xu⊕xv=zuv, orforevery such uv,xu⊕xv=zuv.\nThe objective of the problem is to return 0in the first case, and 1in the second.\nOverview of the algorithm. The algorithm will start with a set {(u,0,b)|u∈[n],b∈ {0,1}}\ncontained in the sketch. The first element in each tuple repr esents a vertex, the second represents\nthe current label of this vertex (in the beginning all the lab els are set to 0), while the last label is\nthere for a technical reason described later.\nEach time a new element arrives in the stream, our sketch will respond in one of two ways. If a\nnew vertex label (v,xv)has arrived and xv= 1, the sketch will update the label by performing an\nupdateoperation with the swap (v,0,b)↔(v,1,b)forb∈ {0,1}. If a new labeled edge (uv,zuv)\nhas arrived, the algorithm tries to recover the labels of uandvfrom the sketch. To do that, the\nalgorithm makes four query_pairqueries:\nquery_pair((u,0,0),(v,0,0))\nquery_pair((u,1,0),(v,1,0))\nquery_pair((u,0,1),(v,1,1))\nquery_pair((u,1,1),(v,0,1))\nNote that for each of the queries query_pair((u,a,c),(v,b,c)),cdenotes the parity of the labels\nofu,vbeing queried: c=a⊕b. This guarantees that all the queries in this step are of disj oint\npairs, and are thus independent. Since the edges in the strea m form a matching, all the queries\nthroughout the whole computation are of disjoint pairs as we ll.\n15If one of the queries returns +1, the algorithm has recovered zu,vand a guess at the current\nlabels ofuandv. Because query_pairis four times as likely to return +1when both of the\nelements queried are in the sketch as when only one is, the gue ss is correct with at least 2/3\nprobability. Then, the algorithm can continue classically by updating the labels of u,vas updates\nto them appear, and comparing their parity to zuvat the end.\nThis means that, as the probability of a query in each update r eturning +1isΘ(1/n), we have\n1) aΘ(α)probability of obtaining an answer and 2) a constant-factor gap between the probability\nof being right and being wrong in the event we do. So a majority vote ofΘ(1/α)copies of the\nalgorithm run in parallel suffices.\n4.1 Algorithm\nOur algorithm will use the pair sampling sketch with univers eU= [n]×{0,1}×{0,1}, which will\ntrivially embed in [2O(logn)]. It will be divided into a “quantum” stage, which lasts until the sketch\nreturns something other than ⊥, and a classical stage, which processes all the updates afte r this\nhappens.\nWe will define the permutation πv:U→Uas follows: for each b∈ {0,1}, swap(v,0,b)with\n(v,1,b).\nThe algorithm is formally presented as Algorithm 1 below.\n4.2 Correctness\nWe will now prove the correctness of this algorithm. First, w e describe the set maintained in the\nsketch.\nLemma 9. After processing any number of entire updates, if the quantu m stage has not yet termi-\nnated, the underlying set of Qis\n{(v,yv,b) :v∈[n],b∈ {0,1},(uv,zuv)has not yet arrived in the stream for any u∈[n]}\nwhereyv=xvif the update (v,xv)has already arrived in the stream, and is 0otherwise.\nProof.We proceed by induction on the number of updates processed. W hen0updates have been\nprocessed,y= 0nand no updates have yet arrived, so the result holds by the def inition of create.\nNow suppose it holds after tupdates, and we see a new update (v,xv). Thenyvbecomesxv.\nIfxv= 0, then no change will be made to the sketch, and the desired set also has not changed. If\nxv= 1,update(πv,Q)is executed, removing (v,0,b)from the sketch and replacing it with (v,1,b)\nfor eachb∈ {0,1}, and so the desired set is still maintained.\nNow suppose we see an update (uv,zuv). Then four queries will be performed, and if any\nreturn anything other than ⊥the quantum stage ends and so the lemma continues to hold triv ially.\nSo suppose they all return ⊥. Then (w,a,b)are removed from the sketch for w∈ {u,v}and\na,b∈ {0,1}, which asu,vare now edges incident to an update (uv,zuv)that arrived in the stream,\nmeans the desired set is still maintained.\nNext, we show that the algorithm is more likely to return a cor rect answer than an incorrect\none.\nLemma 10. With probability αthe algorithm will return the correct answer, and it returns an\nincorrect answer with probability at most α/2. Otherwise it returns ⊥.\n16Algorithm 1 Quantum Streaming Algorithm for Boolean Hidden Matching\n1:Q:=create([n]×{0}×{0,1}).\n2:Quantum Stage\n3:forstream updates σdo\n4:ifσ= (w,xw)then\n5: ifxw= 1then\n6: update(πw,Q)\n7: end if\n8:else ifσ= (uv,zuv)then\n9: fora,b∈ {0,1}do\n10: r:=query_pair((u,a,a⊕b),(v,b,a⊕b),Q)\n11: ifr= 1then\n12: c:=a⊕b⊕zuv\n13: Terminate the quantum stage and process all remaining updat es in the classical\nstage, sending uvandcto that stage.\n14: end if\n15: ifr=−1then\n16: Terminate the algorithm entirely, returning ⊥.\n17: end if\n18: end for\n19:end if\n20:end for\n21:Classical Stage\n22:forremaining stream updates σdo\n23:ifσ= (w,xw)then\n24: ifw=uorw=vthen\n25: c:=c⊕xw\n26: end if\n27:end if\n28:end for\n29:ifthe algorithm never reached the classical stage then\n30:return⊥\n31:else\n32:returnc\n33:end if\n17Proof.First note the algorithm can only terminate on updates of the form(uv,zuv). Consider the\nfourquery_pairoperations performed when (uv,zuv)arrives. Let Sbe the underlying set of the\nsketch before the operations are performed. By Lemma 9, Scontains (w,yu,b)forw∈ {u,v}and\nb∈ {0,1}, and no other elements that can affect the outcome of the quer y (besides their effect on\nthe size of the set).\nTherefore, for these four queries query_pair((u,a,a⊕b),(v,b,a⊕b)), there is one such that\ntwo elements of the pair queried are in S, two such that one is, and one such that neither is. By\nLemma 1, for each of these queries, the probability that the a lgorithm does not terminate before\nmaking that query (because of a query in a previous update or a n earlier query in this update)\nis1/|S′|, whereS′is the set at query time if the query happens. Note that the que ried pairs are\ndisjoint, so every element queried is in S′iff it is inS. By the definition of query_pair, this\nimplies that the probability that any given query returns +1andthe algorithm does not terminate\nbefore it is made is\n2\n|S′|·|S′|\n2n=1\nn\nfor the query with two elements in S,1\n4nfor each of the queries with one element in S, and0for\nthe other.\nTherefore, as there are αnsuch updates in total, the probability over all updates that we\nterminate on a +1returned by a query where both elements are in Sis\n1\nn·αn=α\nwhile the probability we terminate on a +1returned by a query where this is notthe case is\n1\n4n·2·αn=α\n2\nfrom the two out of each batch of four queries that only includ e one element in S.\nTherefore, as the algorithm only returns something other th an⊥when it terminates on a query\nreturning +1, it will suffice to show that, if the algorithm terminates on a query where both of the\nelements are in Sat the time, it always returns the correct answer.\nTo see this, first note that, by the description of Sgiven earlier in the proof, that query will\nbequery_pair((u,yu,yu⊕yv),(v,yv,yu⊕yv)), performed after seeing the update (uv,zuv). So\nif it terminates the quantum stage, it is by sending uvandyu⊕yv⊕zuvto the classical stage.\nNow forw=u,v, recall that ywisxwifxwhas already appeared in the stream (and therefore will\nnot appear in the classical stage) and 0if it has not (and so will appear in the classical stage).\nMoreover, if xwdoes appear in the classical stage, it will be XORed onto the b it we hold. So we\nare guaranteed to output xu⊕xv⊕zuv, which is exactly the desired outcome.\nWe are now ready to prove correctness.\nTheorem 11. There exists an quantum algorithm that solves the streaming Boolean Hidden Match-\ning problem with probability 2/3withO/parenleftbig1\nαlogn/parenrightbig\nquantum memory. The algorithm is classical except\nfor the use of the quantum sketch described in Section 2.\nProof.By the previous lemma, there is an αprobability of returning the correct answer and no\nmore than an α/2probability of returning an incorrect one. So by running Θ(1/α)copies of the\nalgorithm in parallel and taking a majority vote of their out puts, we can return the correct answer\nwith probability 2/3.\n185 Triangle Counting\nIn this section we prove that the quantum triangle counting a lgorithm introduced in [Kal22] can\nbe implemented as an algorithm that is classical other than i n using the sketch from Section 2.\nDefinition 12 (Triangle Counting) .In the (streaming) triangle counting problem, an m-edge\ngraphG= (V,E)is received as a stream of edges in an arbitrary order. The goa l of the problem is\nto return a number in ((1−ε)T,(1+ε)T)with probability 1−δ, whereTis the number of triangles\ninG: the number of (u,v,w)∈V3such thatuv,vw,wu are all inE, andε,δ >0are accuracy\nparameters.\nWe are given T′,∆Esuch thatT≥T′and no more than ∆Etriangles in Gshare any given\nedge.\nFormally the space complexity of a triangle counting algori thm is in terms of m,∆E, andT′,\nbut the standard convention is to assume T′= Ω(T)and so we can use Tinstead.\nWe will prove the following theorem, a “black boxed” version of Theorem 1of [Kal22].\nTheorem 13. For anyε,δ∈(0,1], there is a streaming algorithm that uses\nO/parenleftigg\nm8/5\nT6/5∆4/5\nElogn·1\nε2log1\nδ/parenrightigg\nquantum and classical bits in expectation to return a (1±ε)-multiplicative approximation to the\ntriangle count in an insertion-only graph stream with proba bility1−δ. This algorithm is entirely\nclassical except for its use of the sketch in Section 2.\nHeremis the number of edges in the stream, Tthe number of triangles, and ∆Ethe greatest\nnumber of triangles sharing any given edge.\nThe algorithm in [Kal22] is based on splitting TintoT<kandT>k, and estimating the former\nwithaquantum algorithm andthelatter withaclassical algo rithm. Wewillreproducethedefinition\nof these quantities here. kwill be a parameter that we choose to optimize the trade-off b etween\nthe complexity of the two estimators.\n5.1 Triangle Weights\nFix any ordering of the stream. For any edges e,f, we will write e/precedesorcurlyfifearrives before fin the\nstream. For any vertices u,v,w∈Vsuch thatuv,vw∈Eanduv/precedesorcurlyvw, let the degree between uv\nandvw,d→\nuvwbe the number of edges incident to vthat arrive in between uvandvw(not including\nuvorvwthemselves).\nFor any triple of vertices (u,v,w)∈V3let\nt<k\nuvw=/braceleftigg\n(1−1/k)d→\nuvw+d→\nuwvif{u,v,w}is a triangle in the graph and uv/precedesorcurlyuw/precedesorcurlyvw\n0 otherwise.\nLikewise, let\nt>k\nuvw=/braceleftigg\n1−(1−1/k)d→\nuvw+d→\nuwvif{u,v,w}is a triangle in the graph and uv/precedesorcurlyuw/precedesorcurlyvw\n0 otherwise.\nWe will write T<k,T>kfor/summationtext\n(u,v,w)∈V3t<k\nuvw,/summationtext\n(u,v,w)∈V3t>k\nuvw, respectively, so that T=T<k+T>k.\nFor any vertex u∈V, we will write T<k\nu=/summationtext\n(v,w)∈V2t<k\nuvwandT>k\nu=/summationtext\n(v,w)∈V2t>k\nuvw, so/summationtext\nu∈VT<k\nu=T<kand/summationtext\nu∈VT>k\nu=T>k.\n195.2 Approach\nBy Lemma 11 of [Kal22] (reproduced below), T>kcan be estimated by an entirely classical algo-\nrithm.\nLemma 14. For anyε,δ∈(0,1], there is a classical streaming algorithm, using\nO/parenleftigg\nm3/2\nT√\nk∆Elogn1\nε2log1\nδ/parenrightigg\nbits of space in expectation, that estimates T>ktoεTprecision with probability 1−δ.\nWe therefore need to estimate T<kwith a black-box algorithm, proving:\nLemma 15 (Black-box version of Lemma 7 of [Kal22]) .For anyε,δ∈(0,1], there is a streaming\nalgorithm, using\nO/parenleftigg/parenleftbiggkm\nT/parenrightbigg2\nlogn1\nε2log1\nδ/parenrightigg\nquantum and classical bits, that estimates T<ktoεTprecision with probability 1−δ. This algorithm\nis entirely classical except for its use of the sketch in Sect ion 2.\nTo understand the approach, it is helpful to first consider t he case where, for every triangle uvw\nwithuv/precedesorcurlyuw/precedesorcurlyvw, there are no other edges incident to vorw(note that in this case T=T<k.\nIn that case, we could use the following strategy:\n•Start with 2m“dummy” elements in the sketch.\n•Whenever an edge vwarrives, first query the pairs ((u,v),(u,w))for everyu∈V. Then swap\ntwo dummy elements for (v,w)and(w,v)in the sketch. Terminate with the value returned\nby the query if it is anything other than ⊥.\nThe query would have a 1/mchance3of returning +1for every such triangle uvwin the stream, as\nwhenvwarrives,(u,v)and(u,w)would both be in the sketch. Moreover, every pair query with\nnon-zero expectation (that is, the ones where both elements of the pair queried are in the sketch\nat the time of the query) corresponds to such a triangle: if (u,v)and(u,w)are being queried\nand both (u,v)and(u,w)are in the sketch, that implies that vwjust arrived and uv,uwarrived\nearlier in the stream. Therefore, multiplying the output of this algorithm by mgives as an unbiased\nestimator for the number of triangles with O/parenleftbig\nm2/parenrightbig\nvariance, and so averaging Θ/parenleftbigm\nT/parenrightbig\ncopies would\nsuffice for e.g. any constant accuracy.\nOf course, in practice, other edges can be incident to vandw. When do they cause us problems?\nWhen an edge incident to varrives between uvandvw, or an edge incident to warrives between\nuwandvw, as the resulting query will delete uvoruwfrom the graph. Recalling our definitions\nsection, this is precisely when d→\nuvw+d→\nuwv>0.\nOur solution is, for each edge, to only perform the query_pairoperation with probability 1/k,\ngiving us the chance of avoiding these troublesome edges, at the cost of only having a 1/kchance\nof querying ((u,v),(u,w))when we see vw. So now our probability of returning because of the\ntriangleuvwis proportional to\n1\nk(1−1/k)d→\nuvw+d→\nuwv=t<k\nuvw\nk\n3In fact, the chance grows as the sketch shrinks from previous queries deleting elements from it. However, by our\nLemma 1, this is exactly canceled out by the probability of th e algorithm terminating before the query.\n20if we order u,v,wsuch thatuv/precedesorcurlyuw/precedesorcurlyvw, and so we will need to repeat Θ/parenleftbig\nk2/parenrightbig\ntimes to estimate\nT<k.\nOne might note here that the definition of T<kseems to match what the algorithm achieves\nconveniently well. This is of course not a coincidence: [Kal 22] splits up Tthis way precisely because\nT<kcaptures something the quantum estimator can easily calcul ate, whileT>kcan be efficiently\ncalculated by a classical estimator. As the latter point is a lready entirely classical, we will not\ndiscuss it here: see Section 5 of [Kal22] for that algorithm.\n5.3 Algorithm\nWe now introduce our estimator for T<kusing the pair sampling sketch of Section 2 as a subroutine.\nOur universe for the sketch will be U= [n]2∪([2m]×{S}), whereSis a fixed label denoting a\n“scratch” element. Let g: [m]→ {0,1}be a fully independent hash function4such that\ng(ℓ) =/braceleftigg\n1with probability 1/k\n0otherwise.\nAlgorithm 2 Quantum streaming algorithm for estimating T<k\n1:Q:=create([2m]×{S}).\n2:ℓ:= 0\n3:foruv∈E:do\n4:ℓ:=ℓ+1\n5:ifg(ℓ) = 1then\n6: forw∈V:do\n7: r:=query_pair((w,u),(w,v),Q)\n8: ifr/\\e}a⊔io\\slash=⊥then return rkm\n9: end if\n10: end for\n11:end if\n12:update(πℓ,uv,Q)\n13:end for\n14:return0\nHereπℓ,uvdenotes the permutation executing the following swaps:\n•(2ℓ−1,S)for(u,v)\n•(2ℓ,S)for(v,u)\nSo asℓis incremented at each timestep, this operation swaps two “s cratch elements” for (u,v)and\n(v,u).\nLemma 16. For allℓ= 0,...,m, after the algorithm has processed ℓupdates, if it has not yet\nterminated the underlying set of Qis\nTℓ={(i,S) :i= 2ℓ+1,...,2m}∪Sℓ\n4Storing such a function would, in general, require Θ(mlogm)bits. However, we will only query it at any given\nvalue once, so it can be implemented by sampling random bits a nd discarding them after use. The use of hash\nfunction notation is for readability.\n21where\nSℓ=/braceleftbigg\n(u,v) :∃i∈[ℓ],uv=σi,∀\nj=i+1,...,ℓ(g(j) = 0∨v/\\e}a⊔io\\slash∈σj)/bracerightbigg\nandσidenotes the ithedge in the stream. The size of Tℓis|Tℓ|= 2m−2ℓ+|Sℓ|.\nProof.We proceed by induct', 'raytos.r.bsinfotech@gmail.com', 'John Kallaugher, Ojas Parekh, Nadezhda Voronova', '', '../pdf_files/671b4d5061bd0-How to Design a Quantum Streaming Algorithm Without Knowing Anything About Quantum Computing.pdf', '', 'Not Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(150, '4649313055', '26', 5, 6, 'Persuading a Credible Agent', '2024-11-02', '2024', 'How to optimally persuade an agent who has a private type? When elicitation is feasible, this amounts to a fairly standard principal-agent-style mechanism design problem, where the persuader employs a mechanism to first elicit the agent’s type and then plays the corresponding persuasion strategy based on the agent’s report. The optimal mechanism design problem in this setting is relatively well-understood in the literature, with incentive compatible (IC) mechanisms known to be optimal and computationally tractable. In this paper, we study this problem given a credible agent, i.e., if the agent claims they are of a certain type in response to the mechanism’s elicitation, then they will act optimally with respect to the claimed type, even if they are actually not of that type. Wepresent several interesting findings in this new setting that differ significantly from results in the non-credible setting. In terms of the structure of optimal mechanisms, we show that not only may IC mechanisms fail to be optimal, bu', 'Computational Complexity,Computer Science and Game Theory', 'arXiv:2410.23989v1  [cs.GT]  31 Oct 2024Persuading a Credible Agent\nJiarui Gan, Abheek Ghosh, Nicholas Teh\nUniversity of Oxford, UK\nAbstract\nHow to optimally persuade an agent who has a private type? When elicitation is feasible,\nthis amounts to a fairly standard principal-agent-style mechanism d esign problem, where the\npersuader employs a mechanism to ﬁrst elicit the agent’s type and th en plays the corresponding\npersuasion strategy based on the agent’s report. The optimal me chanism design problem in this\nsetting isrelativelywell-understoodinthe literature, with incentivec ompatible(IC) mechanisms\nknown to be optimal and computationally tractable. In this paper, w e study this problem given\nacredibleagent, i.e., ifthe agentclaims they areofa certain type in responset o the mechanism’s\nelicitation, thentheywill actoptimallywith respecttothe claimedtype , eveniftheyareactually\nnot of that type.\nWe presentseveralinterestingﬁndingsin this newsettingthat diﬀe r signiﬁcantlyfromresults\nin the non-credible setting. In terms of the structure of optimal m echanisms, we show that not\nonly may IC mechanisms fail to be optimal, but all mechanisms following t he standard ‘eliciting-\nthen-persuading’mechanismdesignstructuremaybesuboptimal. Toachieveoptimalityrequires\ntwo additional instruments— pre-signaling andnon-binding elicitation —which naturally result\nin multi-stage mechanisms. We characterize optimal mechanisms und er these design choices.\nBased on our characterization, we provide a polynomial-time algorith m for computing optimal\nmulti-stage mechanisms. We also discover that in scenarios that allow for it,partialinformation\nelicitation can be employed to improve the principal’s payoﬀeven furth er. Though, surprisingly,\nan unbounded number of rounds of information exchange between the principal and the agent\nmay be necessary to achieve optimality.\n1 Introduction\nInformation design (or Bayesian persuasion ) models scenarios where a principal strategically re-\nveals her private information to incentivize an agent to pla y preferred actions. For instance, a\nseller may want to reveal only partial details about her prod ucts to incentivize an agent to buy\na particular one, or a school may want to issue only coarse gra des to improve its students’ job\noutcomes [ Boleslavsky and Cotton ,2015;Kamenica ,2019;Ostrovsky and Schwarz ,2010].\nThe standard information design model assumes that the prin cipal knows the utility func-\ntion of the agent [ Kamenica and Gentzkow ,2011], which may not hold in practice. Numerous\nworks subsequently study a model where the principal does no t know the agent’s type but has a\nprior over it [ Alonso and Cˆ amara ,2018;Bernasconi et al. ,2023;Castiglioni et al. ,2020,2022,2023;\nGill and Sgroi ,2008;Kolotilin et al. ,2017;Perez-Richet ,2014]. The principal may try to design\nthe signaling scheme (i.e., strategically reveal her priva te information) to maximize her expected\nutility given only this prior. Another, possibly better, al ternative for the principal, if feasible, is\nto ask the agent to reveal his type before the principal sends her signal, through an elicitation\nprocess. In this case, the agent may be credible, i.e., take actions consistent with his reported type,\nor benon-credible , i.e., report any type and then play any, possibly inconsist ent, action afterward\n1(essentially, cheap talk). In this paper, we study such scen arios, with a particular focus on credible\nagents.\nEven though credibility has been relatively understudied i n the literature, it remains crucial in\nmany situations. One such scenario is when the principal and the agent both enjoy and want to\nprotect some form of reputation. This may happen, for exampl e, when the two parties are known\nbusinesses. The principal may still have private informati on about the state and the agent about\nhis private type, but the agent may stick with the contract (t ype) signed by both the parties at an\nearlier stage of the game. Besides reputation, the agent may also want to stick to the previously\nsettled type (contract) to avoid possible legal ramiﬁcatio ns. From a behavioral game-theoretic\nperspective, agents may also be averse to playing actions th at are inconsistent with their report\ndue to psychological and social reasons that cause bounded r ationality. In strategic scenarios,\ncredibility may also arise voluntarily when an agent intend s to behave consistently to change the\nprincipal’s belief about their behavior. Such phenomenon h ave been termed impersonation or\nimitative deception in various studies [ Gan et al. ,2019b;Kash and Parkes ,2010]. Our work is an\nattempt to capture these situations and understand the comp utational and algorithmic aspects of\nmechanism design against credible agents.\nWe aim to compute payoﬀ-maximizing mechanisms for the princi pal. In pursuit of this, we\nidentify several crucial design aspects: whether the princ ipal uses only incentive-compatible mecha-\nnisms; whethertheprincipalsendsothersignalsinadditio ntotheaction recommendations; whether\nthe agent reports other information in addition to his credi ble type report; and, in general, how\nmany rounds of communication between the principal and the a gent are necessary? As it turns out,\nthe presence of credibility changes the design of optimal me chanisms signiﬁcantly. It necessitates\nadditional design choices that would be unnecessary when th e agent is non-credible. We introduce\nnovel stages in the mechanism design and provide non-trivia l examples to demonstrate strict payoﬀ\nimprovements they achieve. Moreover, we characterize opti mal mechanisms under these additional\ndesign choices and prove the general optimaility they lead t o. The characterization also result in an\neﬃcient algorithm to compute optimal mechanisms, thereby h ighlighting both the computational\nand utility beneﬁts they oﬀer. Additionally, we provide matc hing hardness results that emerge\nwhen these additional design choices are not employed, ther eby highlighting their computational\nbeneﬁts.\n1.1 Our Results\nIn Section 3, we begin with a non-credible agent and observe that incenti ve compatible (IC) policies\nare without loss of optimality. Given this, we can compute th e optimal policy in polynomial time\nusing a linear programming (LP) formulation. For a credible agent, we show that if the principal\nrestricts herself to using only IC policies, then again she c an compute the optimal IC policy in\npolynomial time using an LP. However, optimal IC policies ma y not be optimal overall, in fact, can\nbe arbitrarily worse; we provide an example that demonstrat es this. We then show that computing\nan optimal policy exactly or approximately is NP-hard using a tight reduction from Maximum\nIndependent Set .\nIn Section 4, we go beyond two-stage interactions (of elicitation and si gnaling) and consider\ncases where the principal and the agent may interact over mul tiple rounds. For a non-credible\nagent, such interactions beyond two stages are redundant. H owever, with credible agents, we show\nthat two additional stages— pre-signaling andnon-binding elicitation —are necessary for achieving\noptimality. We also show via non-trivial examples that thes e additional stages can strictly improve\nthe principal’s utility. Surprisingly, these additional s tages also make the computation of optimal\nmechanisms tractable. To derive this result, we characteri ze the class of optimal mechanisms\n2and prove that a four-stage mechanism structure—involving (in order) pre-signaling, non-binding\nelicitation, bindingtypeelicitation, andsignaling—res ultsinICacrossmultiplestages andisw.l.o.g.\noptimalagainst acredibleagent. Thecharacterization can beviewedasarevelation principle,where\nnon-binding elicitation indeed reveals the agent’s true ty pe, despite them eventually imitating\nanother agent type. Based on the simple ﬁxed structure from t he characterization, we are able\nto formulate the computation of optimal mechanisms as an LP, which yields a polynomial-time\nalgorithm.\nFinally, in Section 6, we observe that a speciﬁc form of elicitation which we call partial in-\nformation elicitation can be used to further improve the principal’s utility. We sh ow that under\nthese information elicitation structures, an unbounded nu mber of rounds of information exchange\nbetween the principal and the agent may be necessary to achie ve optimality. We prove a tight Θ( n)\nbound on the depth of optimal mechanisms, when nature has npossible states.\nOur results highlight sharp contrasts between the computat ional and algorithmic aspects of\ncredible versus non-credible cases.\n1.2 Related Work\nWe build on the standard Bayesian persuasion model of Kamenica and Gentzkow [2011], which\nwas proposed to study the eﬀects of (the provision of) informa tion on the outcomes of strate-\ngic interactions. The model has attracted widespread inter est in both economics and theoretical\ncomputer science (e.g., [ Babichenko and Barman ,2017;Dughmi and Xu ,2016;Feng et al. ,2024;\nKolotilin et al. ,2017;Xu,2020]; also refer to the surveys by Dughmi [2017] andKamenica [2019]).\nModels with privateagent typebutwithoutcredibility has b eenwell-motivated inthe literature,\nin various forms of principal-agent problems (e.g., [ Conitzer and Sandholm ,2002;Myerson,1982]).\nThis is in general related to the economics concept of cheap t alk [Farrell and Rabin ,1996]. Several\nworks look into the Bayesian persuasion model where agents h ave a private type and reports it\n(possibly strategically) to the principal. Castiglioni et al. [2022] look into computational problems\ninamodelwheretheagent isasked toreporttheir typetoprin cipalafter theprincipalhave commit-\nted to a menu of signaling schemes. Subsequent work by Bernasconi et al. [2023] look into further\ncomputational questions in this model. Kolotilin et al. [2017] consider a model where the agent\nonly needs to choose between two actions, and both the princi pal’s and agent’s utilities are linearly\nrelated to the state and theagent’s type. They ask the questi on of whether the principal can beneﬁt\nby designing a complex mechanism under these assumptions. O ther works that consider models of\nBayesian persuasion where the agent has a private type inclu de [Gill and Sgroi ,2008;Perez-Richet ,\n2014]and[Alonso and Cˆ amara ,2018]. InonlineBayesian persuasion[ Castiglioni et al. ,2020,2023],\nthe agent has an unknown private type, and this type is chosen adversarially at each round, over\nmultiple principal-agent interactions. Such two-way info rmation exchanges may also take place in\nsequential interactions as studied more recently in [ Gan et al. ,2023].\nAnother related line of work is strategic communication wit h costly lying [ Kartik et al. ,2007;\nKartik,2009;Kephart and Conitzer ,2015,2016;Nguyen and Tan ,2021] or constraints on how\nthey can lie [ Yu,2011;Zhang et al. ,2021], which is somewhat the opposite of the cheap talk model\n[Crawford and Sobel ,1982]. However, these works focus mostly on direct cost or constr aints im-\nposed on the principal’s signaling or the agent’s reporting . The credibility constraint in our model\ncan be viewed as an implicit cost that depends on both the agen t’s report and their action: an\ninﬁnitely large cost is incurred if they act in ways diﬀerent f rom their report.\nOur model of a credible agent is related to various studies on impersonation orimitative de-\nceptionin algorithmic game theory [ Birmpas et al. ,2021;Gan et al. ,2019a,b;Kash and Parkes ,\n2010;Nguyen and Xu ,2019]. In these studies, an agent imitates the best responses of a nother\n3agent type to change the principal’s belief about their ince ntives. Such attempts can be eﬀective\nespecially when the principal learns the agent’s incentive s by querying the agent’s best responses\n[Blum et al. ,2014;Peng et al. ,2019]. From the principal’s perspective, to maximize the utilit y of\nher learning outcome amounts to the same mechanism problem w e study in this paper. Gan et al.\n[2019b] considered this mechanism design problem in normal-form S tackelberg games. In their\nmodel, the agent (follower) responds to the principal’s (le ader’s) strategy according to the utility\nfunction they report to the principal, so as to trick the prin cipal into permanently believing that\nthey are of the reported type. Despite the similarity, they d id not consider the broader set of ap-\nproaches we study in this paper. Indeed, a key diﬀerence is tha t in their model, the principal does\nnot have any information advantages over the agent (there is no hidden state of nature, and the\nprincipal only determines an action to play). Without such a dvantages, the standard mechanism\nstructure, which maps the type the agent reports to an outcom e, suﬃces for achieving optimality.\nThere are other recent works focusing on cheap-talk style co nversations in Bayesian settings,\nwhere multiple agents with their own private information en gage in conversations, through which\nthey strategically reveal their private information [ Mao et al. ,2022;Leme et al. ,2023;Arieli et al. ,\n2023]. Such conversations may proceed in multiple rounds, simil arly to multiple stages of informa-\ntion revelation and elicitation in the mechanism we design, but for diﬀerent fundamental reasons.\nCrucially, all information exchanges inthese modelsare ch eap, in thesensethat they donot directly\nchange the players’ payoﬀs, whereas in ours the agent’s repor ting is costly because of credibility:\nthe agent will suﬀer an inﬁnite cost if he behaves diﬀerently fr om the type he reports.\n2 Model and Preliminaries\nFor a set S, let ∆(S) denote the set of all probability distributions over S. Let [n] ={1,2,...,n}\nfor a positive integer n∈Z>0. In thestandard information design model [ Kamenica and Gentzkow ,\n2011], a principal (sender) wants to persuade an agent (receiver ) to take an action that is desirable\nto the principal. There is a set of actions A, and the payoﬀ of each action a∈Ato both the\nprincipal and the agent is determined by the state of nature θ∈Θ—we use v(θ,a) andu(θ,a)\nto denote those payoﬀs, respectively. We assume θis drawn from a common prior distribution µ,\nand the principal must commit to a signaling scheme π(·|θ)∈∆(G), where Gdenotes some set of\nsignals. For this standard model, the revelation principle tells that, without loss of generality, the\nset of signals corresponds to the set of actions, i.e., G=A. The goal we adopt from the perspective\nof a principal is to ﬁnd an optimal signaling strategy, which maximizes the principal’s expected\npayoﬀ for the outcome induced.\n2.1 Agent with Private Type\nIn many scenarios, the agent has a private utility function u nknown to the principal. The standard\nmodel can be extended to these scenarios as follows. Let Tbe a ﬁnite set of types for the agent.\nAn agent of type t∈Thas a utility function ut(θ,a). The probability that the agent is of type\nt∈Tisρ(t). The distribution ρ∈∆(T) is known to the principal. The utility function of the\nprincipal is v(θ,a), same as the standard model.\nWhen the principal cannot elicit any additional informatio n from the agent about his type, she\nhas to design her signaling scheme π(·|θ)∈∆(G), for each state θ, whereGdenotes the set of\nsignals, given only the knowledge about the distribution of typesρ. Letπ(θ,g) =π(g|θ)·µ(θ). We\nassume that the agent plays optimally given π. Formally, given π, we assume that an agent of type\ntplays an action awith probability απ,t(a|g) after getting a signal g∈Gfrom the principal; where\n4agent type t∼ρstateθ∼µ\nagent reports t′principal signals g\nagent plays aprincipal gets v(θ,a)\nagent gets ut(θ,a)\nFigure 1: Timeline.\nαπ,t(a|g)>0 only if playing amaximizes agent’s expected utility given gandπ. The expected\nutility of the agent with type tis given by\nE(θ,g)∼π,a∼απ,t(·|g)[ut(θ,a)] =/summationdisplay\nθ,gπ(θ,g)/summationdisplay\naαπ,t(a|g)·ut(θ,a). (1)\nThe expected utility of the principal is given by\nEt∼ρ,(θ,g)∼π,a∼απ,t(·|g)[v(θ,a)] =/summationdisplay\ntρ(t)/summationdisplay\nθ,gπ(θ,g)/summationdisplay\naαπ,t(a|g)·v(θ,a). (2)\nInthismodel,wheretheprincipalcannotelicitanyadditio nalinformationfromtheagent, Castiglioni et al.\n[2020] andXu[2020] prove that the problem of ﬁnding a signaling scheme πthat maximizes the\nprincipal’s utility is NP-hard to solve exactly or approxim ately. In particular, they show that for\nany constant 0≤ǫ <1, the principal cannot ﬁnd a policy that gives her an expecte d reward of at\nleast (1−ǫ) times the optimal reward in polynomial time unless P=NP.\n2.2 Type Elicitation\nIn this paper, we focus on the scenario with elicitation, i.e ., when the principal can ask the agent\nfor his type before sending a signal. The agent of type treports his type as t′∈T. The principal’s\nsignaling scheme πt′(·|θ) is a function of both θandt′. Letπt′(θ,g) =πt′(g|θ)·µ(θ). Figure 1\nillustrates the timeline of the process.\nWe consider both non-credible andcrediblereporting, focusing primarily on the latter. In the\nnon-credible case, the agent can report any type and then pla y any action afterward—the action\nneed not be consistent with the reported type. In contrast, i n the credible case, the agent needs\nto behave as if they are the reported type, i.e., if the agent r eports a type t′, then he must play an\naction that is optimal for the type t′given his posterior belief (as a function of the common prior\nand the signal hereceives from the principal). We formally i ntroducethe pre-signaling, non-binding\nelicitation, and partial elicitation in Sections 4and6.\n3 Non-credible vs. Credible Reporting\nLet us ﬁrst compare credible and non-credible reporting and present some algorithmic results.\n3.1 Non-credible Reporting\nWhen the agent is non-credible, we show that the principal ca n compute the optimal mechanism\nin polynomial time using an LP formulation.\nFirst, notice that, when the agent is non-credible, IC is w.l .o.g. using standard arguments: Any\nmechanism πof the principal will induce an optimal reporting strategy o f the agent given π, which\n5can be encapsulated in a meta-mechanism that simulates the b ehavior of the agent given his true\ntype. This meta-mechanism plays optimally for the agent and , therefore, is IC. It also provides the\nsame expected reward to the principal as the original mechan ismπ. So, the principal can optimize\nover IC signaling policies w.l.o.g. Let πtdenote the mechanism used by the principal when an agent\nreports type t. Letπt(θ,a) =πt(a|θ)·µ(θ) denote the marginal probability of ( θ,a). The following\nLP computes the optimal signaling mechanism for the princip al.\nmax\n(πt)t∈T/summationdisplay\nt∈Tρ(t)/summationdisplay\nθ,aπt(θ,a)·v(θ,a) (3)\nsubject to/summationdisplay\nθ,aπt(θ,a)·ut(θ,a)≥/summationdisplay\nθ,aπt′(θ,a)·ut(θ,f(a)),∀t,t′∈T, f:A→A,(4)\n/summationdisplay\naπt(θ,a) =µ(θ),∀t∈T,θ∈Θ, (5)\nπt∈∆(Θ×A), ∀t∈T. (6)\nSpeciﬁcally, the objective function captures the principa l’s expected payoﬀ under the agent’s truth-\nful response. Constraint ( 4) ensures that this truthful behavior is indeed incentivize d, where: the\nleft side is the agent’s expected payoﬀ for truth reporting, conditioned on type t; and the right side\ndescribes the payoﬀ the agent would obtain if he reports a diﬀe rent type t′and plays f(a) when he\ngets the recommendation to play a. This constraint also implicitly captures the following:\n/summationtext\nθπt(θ,a)·ut(θ,a)≥/summationtext\nθπt(θ,a)·ut(θ,a′),∀t∈T, a,a′∈A,\nso in addition to truthful type reporting πincentivizes, every action recommendation of πtis also\nIC. Since the constraint ( 4) is deﬁned for all f:A→A, it includes exponentially many linear\nconstraints. However, since fis not a function of the state θ, the constraint can be equivalently\nwritten as follows:\n/summationdisplay\nθ,aπt(θ,a)·ut(θ,a)≥/summationdisplay\namax\na′/summationdisplay\nθπt′(θ,a)·ut(θ,a′)\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\nz(t,t′,a),∀t,t′∈T. (7)\nWe can further substitute the maximization on the right side with an auxiliary variable z(t,t′,a)\nand force the variable to be an upper bound of the maximum valu e using the following additional\nconstraints, which is linear w.r.t. zandπ:\nz(t,t′,a)≥/summationdisplay\nθπt′(θ,a)·ut(θ,a′),∀t,t′∈T, a,a′∈A. (8)\nThis converts ( 4) to|T|2constraints in ( 7) and|T|2|A|2constraints in ( 8), with|T|2|A|additional\nvariables z(t,t′,a). Hence, the size of this new LP formulation is polynomial in the input size of\nthe problem. This gives a polynomial-time algorithm to comp ute an optimal mechanism against a\nnon-credible agent.\n3.2 Credible Reporting\nNow consider a credible agent. After reporting a type t′, the agent always behaves as if he is\nactually of type t′. Formally, say the agent has type tand reports type t′. Based on the reported\n6typet′and the state θ, the principal will send a signal g∈Gwith probability πt′(g|θ), where πt′is\nthe mechanism that the principal uses for a report t′; letπt′(θ,g) =πt′(g|θ)·µ(θ). After receiving\nthis signal g, the agent must imitate the reported type t′to remain credible, so he will select an\nactiona′that satisﬁes\na′∈argmax\na∈A/summationdisplay\nθπt′(θ,g)·ut′(θ,a).\nBut notice that the agent receives a payoﬀ based on his actual payoﬀ function utand is equal to/summationtext\nθπt′(θ,g)·ut(θ,a′).\nAswithanon-credibleagent, theprincipalcancomputetheo ptimalICmechanismforacredible\nagent using an LP, although with a slightly diﬀerent formulat ion (weaker constraints).\nmax\n(πt)t∈T/summationdisplay\nt∈Tρ(t)/summationdisplay\nθ,aπt(θ,a)·v(θ,a) (9)\nsubject to/summationdisplay\nθ,aπt(θ,a)·ut(θ,a)≥/summationdisplay\nθ,aπt′(θ,a)·ut(θ,a)∀t,t′∈T(10)\n/summationdisplay\nθπt(θ,a)·ut(θ,a)≥/summationdisplay\nθπt(θ,a)·ut(θ,a′)∀t∈T, a,a′∈A(11)\n/summationdisplay\naπt(θ,a) =µ(θ) ∀t∈T, θ∈Θ (12)\nπt∈∆(Θ×A) ∀t∈T(13)\nNotice that constraint ( 4) in the LP for a non-credible agent splits into constraints ( 10) and (11)\nfor a credible agent. Constraint ( 4) considers all possible deviations over reports and action s of the\nagent jointly, while ( 10) and (11) consider such deviations separately. Constraint ( 10) ensures IC in\nthe reporting stage of the game: it only considers reported- type deviations, because the principal\nknows that a credible agent is going to play consistently wit h his reported type. On the other hand,\nconstraint ( 11) ensures IC in the action stage of the game, by considering on ly action deviations;\nthis constraint is w.l.o.g. because we can apply the revelat ion principle to the last stage of the game\n(when the agent plays his action) and optimize only over poli cies that are IC (for this stage).\nAlthough the principal can eﬃciently compute the optimal IC mechanism for credible agents\nusing the LP above, the next example shows that using a non-IC mechanism can sometimes strictly\nimprove her utility. So, the class of IC policies is notwithout loss of optimality for credible agents.\nExample 3.1. Let there be two agent types T={t1,t2}, two states Θ ={θ1,θ2}, and four actions\nA={a,b,c,d}. The payoﬀ functions of the agent for the two types are given in the tables below.\na b c d\nθ14130\nθ21403\nTypet1a b c d\nθ10010\nθ20001\nTypet2\nThe principal gets payoﬀ 1if the agent plays actions cordand payoﬀ 0if the agent plays actions\naorb, irrespective of the state. Let the prior be uniform, µ(θ1) =µ(θ2) = 1/2.\nLet us ﬁrst consider what happens when a credible agent repor ts each of the possible types in\nthe above example.\n7•If the agent reports type t2, then by credibility she must act like an agent of type t2, irrespec-\ntive of her actual type. Notice that for type t2, the actions in{c,d}dominate those in {a,b}.\nIn particular, for any posterior belief about the state, say (p,1−p), that the agent may have\nafter receiving principal’s signal, he has payoﬀ 0 for playi ngaorbbut payoﬀ max( p,1−p)>0\nfor playing the better option among cord. So, after reporting type t2, the agent always plays\nan action that gives the principal payoﬀ 1.\n•On the other hand, if the agent reports type t1, she must always play an action in {a,b}and\nnever an action in {c,d}. In particular, action adominates action c, and action bdominates\nd. As the agent never plays cord, the principal only gets payoﬀ 0.\nIn an IC mechanism, an agent reports type tionly when he is actually ti, which happens with\nprobability ρ(ti). Therefore, the expected payoﬀ of the principal is 0 ×ρ(t1) +1×ρ(t2) =ρ(t2).\nOn the other hand, we propose the following non-IC mechanism that achieves an expected payoﬀ\n1, which is strictly greater than ρ(t2) ifρ(t1)>0.\nThe non-IC mechanism works as follows: If the agent reports t1, the principal does not give\nany information about the state to the agent, but if the agent reportst2, the principal fully reveals\nthe state. Intuitively, the principal trades information w ith the agent’s “promise” to act as the\nmore preferred type t2. This is eﬀective only when the agent is credible. Consider th e response of\na type-t1agent under this mechanism.\n•If he reports t1, as the principal does not reveal any information, the agent ’s posterior belief\nis the same as the prior (1 /2,1/2), and playing either of aorbgives him an expected payoﬀ\nof 5/2.\n•If he reports t2, the principal reveals the state, and depending upon whethe r the state is θ1\norθ2, he plays either cord(because he must imitate t2) and gets a payoﬀ of 3.\nSo, the type- t1agent is incentivized to report and act like t2. It is trivial to check that an agent of\ntypet2will report t2, too. Consequently, all agent types will report t2and play either cord, and\nthe principal gets expected payoﬀ 1. The ratio of between the expected payoﬀs for the principal\nfor the optimal and optimal-IC mechanism is 1 /ρ(t2)→∞asρ(t2)→0.\nGiven that IC mechanisms may not be optimal, the principal ma y want to optimize over all\npolicies, including non-IC mechanisms, too. The theorem be low says that even to compute an\napproximately optimal mechanism is NP-hard. The proof uses a tight reduction from Maximum\nIndependent Set , similarly to the approach by Gan et al. [2019b].1\nTheorem 1. Unless P=NP, there exists no polynomial-time1\n(|T|−1)1−ǫ-approximation algorithm\nfor computing a mechanism (against a credible agent) for any constant ǫ >0, even when there are\nonly two possible states of nature.\nIn the remainder of the paper, unless otherwise speciﬁed all our results assume a credible agent.\n4 Moving Beyond Two Stages\nWe have seen that the principal may beneﬁt by using non-IC mec hanisms. As it turns out, when\ncredibility is required, thereareeven moreinstrumentsth eprincipal can leverage to furtherimprove\nher payoﬀ. In this section, we demonstrate two such instrumen ts: (1) pre-signaling, and (2) non-\nbinding elicitation. Pre-signaling means that the princip al sends a signal before she elicits the\n1All omitted proofs can be found in the appendix.\n8agent type t∼ρstateθ∼µ\nagent reports t′principal signals g\nagent plays aprincipal gets v(θ,a)\nagent gets ut(θ,a)principal\npre-signals g′\nnon-binding elicitation\nand agent responds\nFigure 2: Timeline with pre-signaling and non-binding elic itation.\nagent’s type. Non-binding elicitation is a cheap-talk comm unication in addition to the agent’s type\nreporting. It asks the agent how they would like the mechanis m to proceed. Since the question is\nnot type related, it is non-binding; no restrictions are att ached to the agent’s answer on how they\nmust act subsequently.\nThese additional approaches naturally result in mechanism s involving more stages of interaction\nbetween the principal and the agent, beyond the two-stage el icitation-then-signaling paradigm\nstudied in the previous section; see Figure 2. We demonstrate the strict payoﬀ improvement of\nthese mechanisms, their general optimality, and more surpr isingly, the computational beneﬁts they\nbring: in sharp contrast to the intractability of the two-st age mechanisms, we present a polynomial\ntime algorithm to optimize this new type of mechanism.\n4.1 Pre-signaling\nIntuitively, pre-signaling aims to change the agent’s beli ef to inﬂuence their decision on which\ntype to imitate. In the following example, we compare mechan isms with/without pre-signaling,\nand show that pre-signaling oﬀers a strict improvement in pay oﬀ for the principal. For ease of\ndescription, we refer to a mechanism that does not use pre-si gnaling as an ESmechanism, where E\nandSrepresents the elicitation and signaling stages, respecti vely, in the mechanism. Similarly, we\nrefer to a mechanism that uses pre-signaling as an SESmechanism, where the ﬁrst Srefers to the\nadditional pre-signaling stage.\nExample 4.1. LetΘ ={α,β,γ},T={t0,t1}, andA={a,a′,b,b′}. The principal’s payoﬀ is 1for\nactionsa′andb′, and0for actions aandb, irrespective of the state. The agent’s payoﬀs are given\nin the table below. Moreover, the type and state distributio ns are uniform: ρ(t0) =ρ(t1) = 1/2,\nandµ(γ) =µ(α) =µ(β) = 1/3.\na a′b b′\nα,β,γ 0101\nTypet0a a′b b′\nα32−2−3\nβ−2−332\nγ0−100−10\nTypet1\nIn this example, the principal’s incentive is completely al igned with a type- t0agent but in\nconﬂict with type t1. Fort1, actions aandbstrictly dominate a′andb′, respectively. Hence, it\nis preferred that the agent acts according to t0. We will demonstrate that no ESmechanism can\n9persuade a type- t1agent to imitate t0, while there exists an SESmechanism that achieves this with\na positive probability.\n4.1.1 Without Pre-signaling\nWhen there is no pre-signaling, the key observation (Lemma 2) is that a type- t1agent will always\nreport truthfully. Since actions a′andb′are strictly dominated by aandb, a type- t1agent will\nthen never choose a′orb′. As a result, the principal gets payoﬀ 0 when the agent’s true type is\nt1, which happens with probability ρ(t1) = 0.5. Overall, the principal’s expected payoﬀ is at most\n0.5×0 + 0.5×1 = 0.5 (where 1 is the principal’s maximum attainable payoﬀ accor ding to the\nexample).\nLemma 2. In Example 4.1, a type-t1agent has no incentive to misreport his type as t0under any\nESmechanism.\nProof.Consider an arbitrary ESmechanism. For a type- t1agent, even without any additional\nsignal from the principal, they are able to secure an expecte d payoﬀ of 1 /3 by sticking to action a.\nNow suppose they misreport type t0, and we show that this leads to a contradiction.\nFor a type- t0agent, actions a′andb′strictly dominate aandb, respectively. Hence, when an\nagent acts as t0, they will play only a′orb′. This means the following for a type- t1agent for every\nθ∈Θ:\nP(a′|θ,t1)+P(b′|θ,t1) = 1,\nwherePdenotes the probability measure induced by the ESmechanism (and the agent’s best\nresponse to this mechanism). It follows that the payoﬀ of the type-t1agent would be:\n/summationdisplay\nθ∈Θ/summationdisplay\nx′∈{a′,b′}P(x′,θ|t1)·ut1(θ,x′) =/summationdisplay\nθ∈Θµ(θ)·/parenleftBig\nP(a′|θ,t1)·ut1(θ,a′)+P(b′|θ,t1)·ut1(θ,b′)/parenrightBig\n≤/summationdisplay\nθ∈Θµ(θ)·max/braceleftbig\nut1(θ,a′), ut1(θ,b′)/bracerightbig\n= 1/3·2+1/3·2+1/3·(−10)<0, (14)\nwhich is strictly lower than the minimum payoﬀ 1 /3 that is guaranteed by reporting truthfully.\nTherefore, a type- t1agent is always better oﬀ reporting truthfully.\n4.1.2 With Pre-signaling\nNow, consider the following mechanism that uses pre-signal ing. Suppose that, before the agent\nreports their type, the principal pre-signals gγwhen the state is γ, and pre-signals g¬γwhen it is\nany other state. Depending on the pre-signal sent, the game p roceeds as follows:\n1. When gγis sent, the agent knows with certainty that the state is γ.\n2. When g¬γis sent, the agent’s belief is a uniform distribution over αandβ.\nIn case 2, by using the following signaling strategy, the pri ncipal can obtain payoﬀ 1 subsequently:\nπt1(a|α) =πt1(a|β) = 1,and πt0(a′|α) =πt0(b′|β) = 1.\nSpeciﬁcally, πt1is uninformative as it always recommends a, whereas πt0completely diﬀerentiates\nαandβ. Under this mechanism, agents of both types will be incentiv ized to always (mis)report t0\nand perform the recommended actions. The principal obtains payoﬀ 1 as a result. Overall, since\nthe marginal probability of case 2 is µ(α)+µ(β) = 2/3, the principal can obtain payoﬀ at least 2 /3\nin expectation. This is a strict improvement compared with 0 .5 in the case without pre-signaling.\nThe analysis in Sections 4.1.1and4.1.2then implies the following.\n10/tildewideE\nS1 S2\nE1 E2\nSβ Sα1 2\ngβ,γ gα,γ\nt1 t2gβ,γ gα,γ\nt2 t1\ngγ gβ gγ gα\nFigure 3: A mechanism that uses non-binding elicitation.\nTheorem 3. There exists an instance where an optimal SESmechanism yields a strictly higher\npayoﬀ for the principal than any ESmechanism does.\n4.2 Non-binding Elicitation\nNon-binding elicitation can be thought of as a menu for the ag ent to choose how they would like\nthe mechanism to proceed. An example of mechanisms with non- binding elicitation is illustrated\nin Figure 3(we will shortly demonstrate that it oﬀers strict payoﬀ impro vement in Example 4.2).\nIn this mechanism, a non-binding elicitation stage is arran ged at the beginning of the mechanism.\nWe will use the notation /tildewideEto represent non-binding elicitation. At /tildewideE, the principal asks the agent\nto choose between two options labelled 1 and 2, respectively . Depending on the agent’s choice, the\nprincipal will subsequently proceed with one of the SESmechanisms. The elicitation at /tildewideEdoes not\ninvolve any type information and is therefore non-binding by nature: the agent’s report at /tildewideEdoes\nnot result in any credibility constraints on how they should behave subsequently.\nFollowing our previously established notation, we will ref er to such a mechanism as an /tildewideESES\nmechanism. We demonstrate in the following example that the re exists an /tildewideESESmechanism that\nstrictly outperforms any SESmechanism.\nExample 4.2. LetΘ ={α,β,γ},T={t1,t2}, andA={a,a′,b,b′,d}. Irrespective of the state,\nthe principal’s payoﬀ is 1for actions a′andb′, and0for all the other actions. The agent’s payoﬀs\nare given in the tables below, where all blank entries are −M, for some suﬃciently large constant,\nsayM >10000. The type and state distributions are uniform: µ(α) =µ(β) =µ(γ) = 1/3and\nρ(t1) =ρ(t2) = 1/2.\na a′b b′d\nα 1 0\nβ 320\nγ−1 0\nTypet1a a′b b′d\nα32 0\nβ 10\nγ−10\nTypet2\n114.2.1 With Non-binding (and Binding) Elicitation\nWe ﬁrst present an /tildewideESESmechanism that yields a payoﬀ strictly greater than 1 −δfor the principal\nin Example 4.2, whereδ= 10/M. The mechanism is illustrated in Figure 3. The non-binding\nelicitation at the beginning of the mechanism oﬀers two optio ns 1 and 2. The signaling strategies\nused at the signaling nodes S1,S3,Sα, andSβare deﬁned as follows.\n•We useπ1atS1, where:\nπ1(gα,γ|α) = 1, π 1(gβ,γ|β) = 1,and/braceleftBigg\nπ1(gα,γ|γ) = 1−δ\nπ1(gβ,γ|γ) =δ.\nNamely, π1is designed in a way that induces the following posterior bel iefs about the state\nwhen the agent receives gα,γandgβ,γ:\nP(·|gα,γ,S1) =/parenleftBig\n1\n2−δ,0,1−δ\n2−δ/parenrightBig\nandP(·|gβ,γ,S1) =/parenleftBig\n0,1\n1+δ,δ\n1+δ/parenrightBig\n,(15)\nwherePdenotes the probability measure induced by the mechanism an d the agent’s best\nresponse. The states in the subscript of each signal corresp ond to states in the support of the\nposteriors. It will also be useful to note that the marginal p robability of each signal is:\nP(gα,γ|S1) = (2−δ)/3,andP(gβ,γ|S1) = (1+ δ)/3.\n•The strategy π2used atS2is deﬁned symmetrically: we swap αwithβin the deﬁnition of\nπ1to obtain π2.\n•The strategies παandπβused at SαandSβare truth-revealing strategies: πα(gθ|θ) =\nπβ(gθ|θ) = 1 for all θ∈{α,β,γ}.\nAt each leaf node, the mechanism terminates and the agent tak es an action that complies with the\ncredibility constraint. If no type elicitation has taken pl ace along the path from the root to the leaf\nnode, the agent is free to take an optimal action of any type—w ithout loss of generality, they will\njust take an optimal action according to their actual type.\nThe mechanism ensures the principal a payoﬀ of 1 −δ, which is close to her payoﬀ upper bound\n1 in this example. Indeed, to ensure this high payoﬀ, the agent needs to be persuaded to play a′or\nb′almost all the time. Examining each state separately, we wil l ﬁnd that the incentives of types t1\nandt2align with the this goal at states αandβ, respectively, but not at the other states. Hence,\nwe need to incentivize a type- t1agent to act as t2with a suﬃciently high probability at state β,\nand incentivize a type- t2agent to act as t1at stateα. This is what the mechanism does: it keeps\nαandβmixed with γ(atS1andS2, respectively); subsequently, it “disentangles” αandβfromγ\n(atSαandSβ, respectively) only if the agent promises to act as t2andt1, respectively.\nThenon-bindingelicitation plays a role herebecause the wa ys we mix and disentangle the states\nneed to be designed diﬀerently for the two agent types. Indeed , the following lemma shows that\nthe design incentivizes each type tito choose the corresponding option iat/tildewideE.\nLemma 4. In Example 4.2, given the mechanism presented in Figure 3, for each i∈{1,2}the\noptimal strategy of a type- tiagent is to select option iat/tildewideE.\nFollowing the lemma, by symmetry, the principal obtains the same payoﬀ on t1andt2. Consider\nthe situation against a type- t1agent. It can be veriﬁed that (see the proof of Lemma 4for more\ndetails):\n12•Whengα,γis sent, the agent will react optimally by playing action a′, and the principal\nobtains payoﬀ 1.\n•Whengβ,γis sent, the agent acts as t2, playing b′when it is βanddwhen it is γ. The\nprincipal obtains payoﬀ P(β|gβ,γ,S1)·1 = 1/(1+δ).\nOverall, the principal’s payoﬀ is\nP(gα,γ|S1)×1+P(gβ,γ|S2)×1\n1+δ=2−δ\n3×1+1+δ\n3×1\n1+δ>1−δ.\n4.2.2 With Binding Elicitation Only\nConsider an arbitrary SESmechanism Π,2which only uses binding elicitation. We will argue that\nΠ yields payoﬀ at most 1 −δfor the principal. In what follows, let π: Θ→∆(G) be the signaling\nstrategy used in the pre-signaling step of Π, such that π(g)>0 for all g∈G. LetPdenote\nthe probability measure induced by Π (and the agent’s optima l response) and let Edenote the\nexpectation over P.\nThe proof of the 1 −δupper bound relies on the following lemmas. Lemma 5ﬁrst argues\nthat if Π were to achieve a high payoﬀ for the principal, there must be a high-payoﬀ signal gthat\nimpliesγwith a suﬃciently high probability. (Recall that vdenotes the principal’s payoﬀ function.)\nLemma6further shows that the principal must receive a high-payoﬀ s ignal that implies both αand\nβwith a suﬃciently high probability. With these observation s, we prove the 1 −δupper bound on\nthe performance of all SESmechanisms in Example 4.2and establish Theorem 7.\nLemma 5. Suppose that E(v)≥1−δin Example 4.2. Then, for any ǫ∈(0,1−δ), there exists a\nsignalg∈Gsuch that E(v|g)>1−δ−ǫandP(γ|g)≥1/4−δ/ǫ.\nProof sketch. The converse of the statement asserts the existence of ǫsuch that: for every g∈G, if\nP(γ|g)≥1/4−δ/ǫthenE(v|g)≤1−δ−ǫ. Indeed, since the prior probability is µ(γ) = 1/4, the\nmarginal probability of signals gsuch that P(γ|g)≥1/4−δ/ǫcannot be insigniﬁcant. Hence, if\nthe converse statement is true, then for a substantial porti on of signals would yield expected payoﬀ\nlower than 1−δ−ǫfor the principal, which would further lead to an overall pay oﬀ strictly lower\nthan the assumed value 1 −δ.\nLemma 6. Suppose that E(v)≥1−δin Example 4.2. Then there exists a signal g∈Gsuch that\nE(v|g)>1−11δ,P(α|g)>1/100, andP(β|g)>1/100.\nProof sketch. By Lemma 5some high-payoﬀ gmust imply γwith a signiﬁcant probability. Now\nthat there is no non-binding elicitation, both agent types w ill receive gwith some probability. For\ntypet1(and similarly for type t2and state β), the probability of αin the posterior conditioned\nongmust be suﬃciently high: otherwise either bordwill always strictly dominate other actions\n(e.g., consider the extreme case where P(α|g) = 0), leading to a low payoﬀ 0 for the principal and\na contradiction to the assumption that E(v|g)>1−11δ.\nTheorem 7. There exists an instance where an optimal /tildewideESESmechanism yields a strictly higher\npayoﬀ for the principal than any SESmechanism.\n2We will hereafter mostly use Π to denote a multi-stage mechan ism and use πto denote the signaling strategy in\nΠ for the pre-signaling stage.\n13Proof.We show that in Example 4.2noSESmechanism yields payoﬀ higher than 1 −δfor the\nprincipal. Consider an arbitrary SESmechanism and suppose for the sake of contradiction that it\nyields payoﬀ E(v)>1−δfor the principal.\nNote that the mechanism elicits the agent’s type in the secon d step. Consider the case where\nthe agent is of type t1and a signal gthat satisﬁes the conditions in Lemma 6is sent. Subsequently,\nwhen the mechanism elicits the agent’s type, the agent eithe r reports t1ort2. Consider each of\nthese two possible reports. We show that both cases lead to co ntradictions to complete the proof.\nCase 1: t1is reported. In this case, the type- t1agent will act truthfully. Consider the agent’s\nexpected payoﬀ E[ut1|t1,g] and the following upper bound on the payoﬀ:\nE[ut1|t1,g]≤P(β,a∨a′|t1,g)·(−M)+(1−P(β,a∨a′|t1,g))·3.\nIt must be E[ut1|t1,g]≥0 because the agent can stick to action dto secure payoﬀ 0. This gives\nP(β,a∨a′|t1,g)≤3\nM+3. Note that, for type t1, actionb′is strictly dominated by bordunder any\nstate distribution, which means P(β,b′|t1,g) = 0. Therefore,\nP(β,b∨d|t1,g) =P(β|t1,g)−P(β,a∨a′|t1,g)>1\n100−3\nM+3.\nSince the principal gets payoﬀ 0 when bordis played, we get that\nE(v|g)≤1−P(b∨d|g)≤1−P(t1,β,b∨d|g)\n= 1−P(t1|g)·P(β,b∨d|t1,g)≤1−1\n3·/parenleftBig\n1\n100−3\nM+3/parenrightBig\n<1−11δ\n(note that P(t1|g) =P(t1) =ρ(t1) = 1/3 by independence). This contradicts Lemma 6.\nCase 2: t2is reported. In this case, the agent will act according to type t2. We can replicate\nthe above arguments to show that P(α,a∨d|t1,g)>1\n100−3\nM+3, where we replace βwithα,a\nanda′withbandb′, respectively, and ut1withut2. Eventually, this also leads to the contradiction\nE(v|g)<1−11δ.\n5 Computing Optimal Multi-stage Mechanisms\n/tildewideESESandSESmechanisms are strictly better than ESmechanisms in terms of the payoﬀs they\ngenerate. But what do they imply computationally? Is it easi er or harder to compute optimal\n/tildewideESESandSESmechanisms? As it turns out, optimal SESmechanisms are still inapproximable by\nnoting that in the reduction for Theorem 1the principal does not beneﬁt from using pre-signaling\n(Theorem 8). But optimal /tildewideESESmechanisms, while generating even higher payoﬀs than SESs, are\neﬃciently computable. We next present an eﬃcient algorithm for/tildewideESESand demonstrate its general\noptimality among a broad class of multi-stage mechanisms.\nTheorem 8. Unless P = NP, there exists no polynomial-time1\n(|T|−1)1−ǫ-approximation algorithm\nfor computing an SESmechanism for any constant ǫ >0, even when there are only two possible\nstates of nature.\nProof.We use the same reduction as that in the proof of Theorem 1and note that the principal\ndoes not beneﬁt from using pre-signaling in the reduced inst ance.\n145.1 The General Optimality of /tildewideESES\nThe eﬃcient algorithm relies on a characterization of optim al/tildewideESESmechanisms. The character-\nization is quite general: it compares /tildewideESESmechanisms with all possible multi-stage mechanisms\ninvolving any number of signaling and binding or non-bindin g elicitation steps. We hereafter refer\nto this broader class of mechanisms as indeﬁnite-stage mechanisms . Similarly to themechanisms we\npresented previously, an indeﬁnite-stage mechanism can be history-dependent, specifying diﬀerent\nstrategies for diﬀerent nodes of the game tree. For binding el icitation, we consider only direct elici-\ntation, where the principal asks the agent directly “what is your type?” and the agent must choose\none type in Tas their answer to this question. (In the next section, we wil l further investigate a\nmore general type of elicitation that allows the principal t o elicit partial type information.)\nFor ease of description, in what follows, we assume that the t ype set contains ntypes:T=\n{t1,...,tn}. Since an /tildewideESESmechanism corresponds to a tree as we illustrated in Figure 3, we will\ndescribe the mechanism based on the tree. The tree contains t he following types of nodes:\n•Snodes. An Snoderepresents asignaling step, wheretheprincipalsends asignal according to\na strategy π: Θ→∆(G) for this node. The nodethen has |G|child nodes each corresponding\nto a distinct signal in G. When a signal gis drawn, the mechanism proceeds to the child\ncorresponding to g.\n•Enodes. An Enode represents to a binding elicitation step, where the age nt reports their\ntype. Each Enode has nchildren, each corresponding to a type in T. When the agent reports\na typet, the mechanism proceeds to the child corresponding to t.\n•/tildewideEnodes. An /tildewideEnode represents to a non-binding elicitation step, where th e agent selects a\nchild of this node, and the mechanism proceeds to the selecte d child. The root node of an\n/tildewideESESmechanism is always an /tildewideEnode.\n•Leaf nodes. At a leaf node, the mechanism terminates, and the agent performs an optimal\naction of the reported type . If no type elicitation takes place on the path to the leaf, we\nassume that the agent is free to choose an optimal action of an y type.3\nTo sidestep intricate corner cases, we follow the conventio n and assume that if there is a tie in the\nagent’s decision-making (whether to decide an action to pla y or a type to report), the mechanism\ndecides how to break the tie.\nThe characterization result, presented in the theorem belo w can be viewed as a generalized\nrevelation principle that involves multiple levels of IC or DIC in an /tildewideESESmechanism (where “D”\nemphasizes directrecommendation). Intuitively, the option the agent select s at/tildewideEreveals their true\ntype, though this does not mean that the agent needs to subseq uently act truthfully because of\nthe non-binding nature of this elicitation. Subsequently, the signaling strategy at each Sidirectly\nrecommends the agent a type to report, while those at Sijdirectly recommend actions.\nTheorem 9. For any indeﬁnite-stage mechanism Π, there exists an /tildewideESESmechanism Π′that yields\nas much payoﬀ for the principal as Πdoes and has the following properties.\ni.IC at/tildewideE: The root /tildewideEhasnchildren S1,...,Sn, which are all Snodes. Each type- tiagent is\nincentivized to choose the branch leading to Si.\n3W.l.o.g., the agent will choose an optimal action of their ac tual type. In fact, it is w.l.o.g. to assume that there\nis always one Enode on every path from the root to a leaf (see the proof of Theo rem9).\n15ii.DIC at Si: Each node SihasnEnode children Ei1,...,Ein. EachEijis associated with type\ntj, and atEija type-tiagent is incentivized to report tj. For each k= 1,...,n, reporting type\ntkatEijleads to an Snode child Sijk.\niii.DIC at Sijk: The signaling strategy used at each node Sijkdirectly recommends the agent an\naction to take, and the action is optimal for type tk.\nProof sketch. Given any Π, we construct an /tildewideESESmechanism Π′that ensures the stated properties\nwhile preserving the principal’s payoﬀ by following the ste ps below.\n•Step 1. Adding a new root. We make ncopies Π1,...,Πnof Π and attach each Πias a subtree\nto the root of Π′. Let the root node be an /tildewideEnode. Since all the copies are the same, each\ntypetiis incentivized to choose Πiand we get IC at the root.\n•Step 2. Removing /tildewideEnodes.Given IC at the root, in each branch Πi, we only need to consider\nthe response of ti. Hence, all the /tildewideEnodes in Πibecome redundant: we remove each /tildewideEnodee\nand reconnect the child of eselected by a type- tiagent to the parent of e.\n•Step 3. Merging Snodes.Next, we merge consecutive Snodes on every path as if signals\ngenerated in these consecutive signaling processes are gen erated at once: i.e., we treat the\ncombination of the signals as a meta-signal sent by the joint process.\nThe above operations yield a tree with ﬁve levels containing only/tildewideE,S,E,S, and leaf nodes,\nrespectively. We proceed as follows to achieve DIC at the Snodes.\n•Step 4. Ensuring DIC. The idea is to merge signals incentivizing the same response of the\nagent (i.e., reporting the same type or taking the same actio n) into a single signal. The signal\ncan be viewed as a recommendation to the agent (in terms of wha t to report and which action\nto take). Essentially, these merging operations will make m any nodes in Π indistinguishable\nto the agent, but if the agent follows the recommendations in the new mechanism, they would\nstill reach each leaf with the same probability as before, as if they respond optimally in Π. On\nthe other hand, since these merging operations reduce infor mation, the agent cannot devise\nany better response to improve their payoﬀ. Hence, the agent i s incentivized to follow the\nrecommendations and this ensures DIC.\n5.2 An LP Formulation\nThe characterization in Theorem 9ﬁxes the structure of mechanism. The only parameters to be\noptimized are the strategies at the Snodes, including πi: Θ→∆(T) at each Si, andπijk: Θ→\n∆(A) at each Sijk, where the signal spaces of the strategies are determined by the DIC properties.\nAt a high level, this results in an extensive-form game . We formulate the problem of optimizing\nthe principal’s commitment in this game as an LP. The variabl es of the LP are as follows; each of\nthem corresponds to the marginal probabilities of a path on t he game tree, and the feasible space\nof the variables can be characterized by a set of ﬂow constrai nts.\n•πi(tj|θ) fori,j∈{1,...,n}, which represents the strategy πi.\n•φijk(a|θ) fori,j∈{1,...,n}anda∈A, which represents the product πi(gj|θ)·πijk(ga|θ)\nand indirectly represents πijk. We use these variables instead of πijk(ga|θ) to avoid quadratic\nterms in our formulation.\n16The objective of the LP is to maximize the expected payoﬀ of th e principal yielded by the\nmechanism. Under the IC and DIC conditions, this can be expre ssed as follows (where we highlight\nthe variables in blue):\nmax/summationdisplay\nθ∈Θn/summationdisplay\ni=1n/summationdisplay\nj=1/summationdisplay\na∈Aρ(ti)·µ(θ)·φijj(a|θ)·v(a,θ),\nNamely, the expression assume that each type tiis incentivized to select option iat/tildewideE, report tj\nat eachEij, and play the action recommended by each πijj. These conditions are enforced next\nthrough the constraints of the LP:\n•The ﬂow constraint ensures the product encoded in φijkcorrespond to a feasible πijk:\n/summationdisplay\na∈Aφijk(a|θ)=πi(tj|θ) for alli,j,k∈{1,...,n}andθ∈Θ\nφijk(a|θ)≥0 for all i,j,k∈{1,...,n}, a∈A,andθ∈Θ\nWe also have that πi(·|θ)∈∆(T) for alliandθ, which ensure that πiis a valid strategy.\n•The following constraint ensures DIC at each Sijk, i.e., it is optimal for the imitated type tk\nto play the recommended action a, rather than any other action b:\n/summationdisplay\nθµ(θ)·φijk(a|θ)·utk(a,θ)≥/summationdisplay\nθµ(θ)·φijk(a|θ)·utk(b,θ)\nfor alla,b∈Aandi,j,k∈{1,...,n}.\nNamely, the left side is the marginal payoﬀ of a type- tkagent for playing action awhenais\nrecommended, and the right side is that for playing any other actionb.\n•Given the above constraint, we introduce the following addi tional variable uti(Sℓjk) to capture\na type-tiagent’s maximum attainable payoﬀ at each Sℓjk:\nuti(Sℓjk)=/summationdisplay\na∈A/summationdisplay\nθµ(θ)·φℓjk(a|θ)·uti(a,θ).\nThe following constraint then ensures DIC at each Eij, i.e., it is optimal for an agent whose\nactual type istito report the recommended type tj, rather than any other type tk:\nuti(Sijj)≥uti(Sijk) for alli,j,k∈{1,...,n}.\n•Finally, the following constraint ensures IC at /tildewideE, so that each type tiis incentivized to select\noptioni, rather than any other option ℓ:\nn/summationdisplay\nj=1uti(Sijj)≥n/summationdisplay\nj=1max\nk=1,...,nuti(Sℓjk) for alli,ℓ∈{1,...,n}.(16)\nOn the right side, the payoﬀ is yield when the agent selects op tionℓand subsequently reports\nan optimal type tkat each node Eℓj; hence, there is a maximization operator over k. As\nin Section 3, the constraint can be linearized by further introducing an auxiliary variable\nuti(Eℓj), along with constraints uti(Eℓj)≥uti(Sℓjk) for allk, to capture an upper bound on\nmaxk=1,...,nuti(Sℓjk). With this the right side of ( 16) can be replaced with uti(Sℓjk).\nGiven the LP, the tractability of optimal indeﬁnite-stage m echanisms then follows readily.\nTheorem 10. An optimal indeﬁnite-stage mechanism can be computed in pol ynomial time.\n176 Further Improvement: Partial Information Elicitation\nIn the mechanisms we have looked at so far, a binding elicitat ion directly queries the agent’s type.\nIn some scenarios, elicitation might be implemented in a les s direct format. For example, the\nprincipal may ask the agent “are you type t1or not?”, or present several subsets of types and\nask the agent which subset contains the agent’s type. After a subset is reported, the principal\nmay follow up with more questions to identify smaller subset s containing the agent’s type (that\nthey want to imitate) until eventually pinning down the type in a singleton. Essentially, this splits\none canonical elicitation step into multiple steps interle aved with singling steps. We refer to such\nelicitation as partial information elicitation (PIE) and mechanisms using partial elicitation as PIE\nmechanisms .\nPIE is still binding, sothat once an agent identiﬁes a subsetcontaining his true type, heneeds to\nsubsequently report and behave in consistency with this sub set. This is crucial; indeed, such partial\nelicitation does not provide any added value when the agent i s non-credible, as we demonstrated\npreviously. In the next example, we demonstrate that PIE can strictly improve the principal’s\npayoﬀ (when the agent is credible).\n6.1 Strict Payoﬀ Improvement by Partial Elicitation\nExample 6.1. LetΘ ={α,β},T={t0,t1,t2}, andA={a,a′,b,b′}. The principal gets payoﬀ 1for\nthe state-action pairs (α,a′)and(β,b′), and0for all other pairs. The agent’s payoﬀs are given in the\ntable below, where all blank entries are −1. The state is distributed uniformly: µ(α) =µ(β) = 1/2.\nThe type distribution is: ρ(t0) = 1andρ(t1) =ρ(t2) = 0(i.e., only t0actually appears).4\na a′b b′\nα10−2−3\nβ−2−310\nTypet0a a′b b′\nα 1\nβ 1\nTypet1a a′b b′\nα 1\nβ 1\nTypet2\n6.1.1 With PIE Mechanism\nConsider the following PIE mechanism. The principal ﬁrst as ks the agent whether their type is t0.\n•If the answer is “yes”, then no information will be sent subse quently, and the agent decides\nan action to take. (By credibility, this action needs to be op timal for t0.)\n•If the answer is “no”, then the principal will send a signal th at reveals the true state, and\nthen ask the agent to identify their type from the set T\\{t0}(given that the agent has denied\nthat their type is t0). Finally, the agent performs an optimal action of the type t hey selected.\nIt can be veriﬁed that the above mechanism yields payoﬀ 1 for t he principal, which is the\nmaximum possible payoﬀ of the principal in this example. Spe ciﬁcally (note that we only need to\nconsider a type- t0agent in this case because the other types have probability 0 ):\n•A type-t0agent will deny that their type is t0in response to the principal’s ﬁrst question: If\nthey reported t0, no information would be provided, in which case states αandβwould still\nbe equally likely according to their belief. Consequently, the agent’s expected payoﬀ would\nbe negative for all possible actions.\n4For simplicity, we use zero-probability types in this examp le. One can also construct a similar but more sophis-\nticated example where all types have non-zero probabilitie s.\n18•Subsequently, when the principal reveals α, the agent will be incentivized to report and act\nast1, responding with t1’s optimal action a′. When the principal reveals β, the agent will act\nast2and respond with t2’s optimal action b′. In both states, the agent gets payoﬀ 0 (strictly\nhigher than the above case), and the principal gets payoﬀ 1.\n6.1.2 With Non-PIE Mechanism\nNow consider an arbitrary non-PIE (indeﬁnite-stage) mecha nism Π. We show that Π yields payoﬀ\nlower than 1 for the principal.\nLemma 11. Any non-PIE mechanism Πyields payoﬀ lower than 1for the principal in Example 6.1.\nProof.Suppose for the sake of contradiction that Π yields payoﬀ 1 fo r the principal. W.l.o.g. Π is\nan/tildewideESESmechanism as we argued in Section 5.\nSincein the example the probability t1andt2actually appear is zero, only a type- t0agent would\ncontribute to the principal’s payoﬀ. Consider the distribut ion induced by Π and a type- t0agent’s\noptimal response over tuples ( θ,t)∈Θ×T, wheretis the type the agent reports. Let ( θ,t) be\nan arbitrary tuple with a positive probability in this distr ibution. It must be that t/\\e}atio\\slash=t0. Indeed,\nif the agent acts according to t0, they will play aorbas the other actions are strictly dominated.\nSince the principal’s payoﬀ is 0 for both aandb, the principal will get 0 with a positive probability,\ncontradicting the assumption that Π yields payoﬀ 1 for the pr incipal.\nAs a result, we have t∈{t1,t2}. Ift=t1, it must be θ=α. Indeed, a type- t1agent can only be\nincentivized to play a′according to the payoﬀ deﬁnition, whereas the principal’s p ayoﬀ for ( β,a′)\nis 0. Consider further the binding elicitation step (which i s not partial elicitation as Π is non-PIE)\nand the agent’s posterior belief p∈∆(Θ) at this step. There are two possible cases:\n•p(α) = 1. In this case, a type- t0agent would in fact be better oﬀ reporting t0and playing\na, instead of reporting t1(and playing a′); the payoﬀ is 1 for the former and 0 for the latter.\nHence,p(α) = 1 is not possible.\n•p(α)<1 (and hence p(β)>0). In this case, since p(β)>0, with a positive probability the\nstate-action pair ( β,a′) will be realized (given the assumption that the agent will a ct ast=t1\nsubsequently). This means that the principal will receive p ayoﬀ 0 with a positive probability,\nwhich contradicts the assumption that Π yields payoﬀ 1 for th e principal, too.\nBy symmetry, the case where t=t2also leads to contradictions. The assumption that Π yields\npayoﬀ 1 for the principal does not hold.\nThe above result and the PIE mechanism we presented above est ablish the following result.\nTheorem 12. There exists an instance where an optimal PIE mechanism yields a strictly higher\npayoﬀ for the principal than any non-PIE mechanisms do.\n6.2 Suboptimality of Constant-Step PIE Mechanisms\nIt might be tempting to think that, similarly to the case of no n-PIE mechanisms, it is without loss\nof optimailty to consider PIE mechanisms with a constant dep th. Surprisingly, as we demonstrate\nusing the following example, this is not the case: in this exa mple, the depths of allthe optimal PIE\nmechanisms grow with the size of the instance.\n19a1a2... a n−1ana′\n1a′\n2... a′\nn−1a′\nn\nθ11 0\nθ2 1 0 0−M\n.........\nθn−10 1−M 0\nθn 1 1\nTypet0a1... a i... a′\ni...\nθ10\n......\nθi 0 1/M\n...\nTypeti\nTable1: Theagent’s payoﬀsinExample 6.2. Thepayoﬀsofanagent oftype ti(foreach i= 1,...,n)\nis the same as those of type t0, with the exception of the i+1 entries highlighted in gray (payoﬀs\nin the blank entries are all the same as type t0).\nExample 6.2. LetΘ ={θ1,...,θn},T={t0,t1,...,tn}, andA={a1,...,a n}∪{a′\n1,...,a′\nn}.\nThe principal gets payoﬀ 1for the state-action pairs (θi,a′\ni)for alli= 1,...,n, and gets 0for all\nother pairs. The agent’s payoﬀs are given in Table 1, where we let M= 2n3n. The parameters\nare non-negative only on the diagonal from (θ1,a1)to(θn,an)and in the entry (θn,a′\nn). The state\nis distributed uniformly: µ(θ1) =···=µ(θn) = 1/n. The type distribution is: ρ(t0) = 1and\nρ(t1) =···=ρ(tn) = 0(i.e., only t0actually appears).\n6.2.1 An Optimal PIE Mechanism\nAnn-step PIE mechanism is illustrated in Figure 4. The mechanism begins with an Enode,E0, and\nasks the agent whether they are of type tior not at each subsequent node Ei: answering “yes” leads\nto termination of the mechanism, while answering “no” leads to continuation of the mechanism\nto nodeSi+1. At each Si, the signaling strategy signals gideterministically if the state is θi, and\nsignalsg>i, otherwise.\nRecall that t0is the only type that appears with a positive probability. It can be veriﬁed that\na type-t0agent is (weakly)5incentivized to respond as follows:\n•Act astiand play action a′\niupon receiving gi, whereby he receives payoﬀ 0. Indeed, according\nto the construction, we have P(θi|gi) = 1, so thetype- t0agent could only bebetter oﬀ playing\nai. However, playing aiis blocked by the credibility constraint because upon reach ingSiit\nmust be that the agent has denied that they are of types t0,...,ti−1; playing aicannot be\njustiﬁed as an optimal action of any of the remaining types in this case.\n•Report¬tiat eachEi. This can be veriﬁed by noting that the agent’s posterior bel ief at\nEiis a uniform distribution over θi+1,...,θn. Any of ai+1,...,anis optimal for the type- t0\nagent and gives payoﬀ 1 /(n−i). In comparison, if the agent keeps reporting ¬tjat the each\nsubsequent Ejand acts as type tjupon receiving gjas described above, he will be persuaded\nto play precisely a′\njat eachθj, whereby he gets the same overall payoﬀ 1 /(n−i) (thanks in\nparticular to the payoﬀ 1 for ( θn,a′\nn)). Hence, it is optimal to report ¬tiat eachEi.\nSince action a′\niis played at every θi, the principal always gets payoﬀ 1, which is also the maximum\npossible payoﬀ in this example. Hence, the PIE mechanism is o ptimal.\n5One can change the 0’s on the diagonal from ( θ1,a′\n1) to (θn−1,an−1) to a suﬃciently small number to strongly\nincentivize the agent and, with extra bookkeeping, prove th at the example still works.\n20Ei\nSi+1ti¬tiSi\nEigi g>i\nFigure 4: A optimal mechanism for Example 6.2,i∈{0,1,...,n−1}.Enis a terminal node.\nIntuitively, the PIE mechanism works by revealing a state θionly after the agent denies his type\nbeing any of t1,...,ti−1. This is crucial as otherwise the agent would have been bette r oﬀ acting\nas any arbitrary type in this range, whose optimal action is ai. Moreover, eliciting the exact type\nimmediately at any Eiwould not work as that would only encourage the agent to repor ttiand\nplay one of the actions ai+1,...,a n, leading to payoﬀ 0 for the principal. We next formally analy ze\nthe lower bound on the depths of optimal PIE mechanisms.\n6.2.2 Depth of Optimal PIE Mechanisms\nWe demonstrate an Ω( n) lower bound on the depths of the optimal PIE mechanisms, for a class of\ninstances with npossible states. Consider an arbitrary optimal PIE mechani sm Π. Given the PIE\nmechanism we presented above, for Π to be optimal, it must yie ld payoﬀ 1 for the principal. We\nwill show that to achieve this payoﬀ, Π must have Ω( n) levels.\nSince type t0is the only type that actually appears, an argument similar t o the proof of The-\norem9implies that there is no need for Π to use any /tildewideEnode. We can then assume w.l.o.g. that\nΠ starts with an Enode, and subsequently the levels alternate between SandEnodes (with the\nexception of leaf nodes, which can appear at any level). For e ach node xin Π, we deﬁne the\nfollowing sets:\n•Tx⊆T, which contains the types that are notexcluded by the agent’s answers at the Enodes\non the path from the root to x.\n•Θx⊆Θ, whichisthesupportoftheagent’s posteriorat x, i.e.,θ∈Θifandonlyif P(θ|x)>0,\nwherePis the probability measure induced by Π.\nTo simplify the notation, we write pxas the distribution such that px(θ) :=P(θ|x) for each θ.\nThe next two lemmas follow by noting that to yield payoﬀ 1 for t he principal requires each a′\ni\nto be played exactly at state θi, and this behavior can be induced only when the agent acts', 'rararararararararara@gmail.com', 'Jiarui Gan, Abheek Ghosh, Nicholas Teh', '', '../pdf_files/67262e0e1ae69-Persuading a Credible Agent.pdf', '2024-11-06', 'Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(151, '2341628535', '1', 1, 1, 'Persuading a Credible Agent', '2024-11-02', '2024', 'How to optimally persuade an agent who has a private type? When elicitation is feasible, this amounts to a fairly standard principal-agent-style mechanism design problem, where the persuader employs a mechanism to first elicit the agent’s type and then plays the corresponding persuasion strategy based on the agent’s report. The optimal mechanism design problem in this setting is relatively well-understood in the literature, with incentive compatible (IC) mechanisms known to be optimal and computationally tractable. In this paper, we study this problem given a credible agent, i.e., if the agent claims they are of a certain type in response to the mechanism’s elicitation, then they will act optimally with respect to the claimed type, even if they are actually not of that type. Wepresent several interesting findings in this new setting that differ significantly from results in the non-credible setting. In terms of the structure of optimal mechanisms, we show that not only may IC mechanisms fail to be optimal, bu', 'Computational Complexity,Computer Science and Game Theory', 'Information\ndesign\n(or\nBayesian\npersuasion)\nmodels\nscenarios\nwhere\na\nprincipal\nstrategically\nre\nveals\nher\nprivate\ninformation\nto\nincentivize\nan\nagent\nto\nplay\npreferred\nactions.\nFor\ninstance,\na\nseller\nmay\nwant\nto\nreveal\nonly\npartial\ndetails\nabout\nher\nproducts\nto\nincentivize\nan\nagent\nto\nbuy\na\nparticular\none,\nor\na\nschool\nmay\nwant\nto\nissue\nonly\ncoarse\ngrades\nto\nimprove\nits\nstudents’\njob\noutcomes\n[Boleslavsky\nand\nCotton,\n2015;\nKamenica,\n2019;\nOstrovsky\nand\nSchwarz,\n2010].\nThe\ncharacterization\nalso\nresult\nin\nan\nefficient\nalgorithm\nto\ncompute\noptimal\nmechanisms,\nthereby\nhighlighting\nboth\nthe\ncomputational\nand\nutility\nbenefits\nthey\noffer.\nAdditionally,\nwe\nprovide\nmatching\nhardness\nresults\nthat\nemerge\nwhen\nthese\nadditional\ndesign\nchoices\nare\nnot\nemployed,\nthereby\nhighlighting\ntheir\ncomputational\nbenefits.The\nstandard\ninformation\ndesign\nmodel\nassumes\nthat\nthe\nprincipal\nknows\nthe\nutility\nfunc\ntion\nof\nthe\nagent\n[Kamenica\nand\nGentzkow,\n2011],\nwhich\nmay\nnot\nhold\nin\npractice.\nNumerous\nworks\nsubsequently\nstudy\na\nmodel\nwhere\nthe\nprincipal\ndoes\nnot\nknow\nthe\nagent’s\ntype\nbut\nhas\na\nprior\nover\nit\n[Alonso\nand\nCˆ\namara,\n2018;\nBernasconi\net\nal.,\n2023;\nCastiglioni\net\nal.,\n2020,\n2022,\n2023;\nGill\nand\nSgroi,\n2008;\nKolotilin\net\nal.,\n2017;\nPerez-Richet,\n2014].\nThe\nprincipal\nmay\ntry\nto\ndesign\nthe\nsignaling\nscheme\n(i.e.,\nstrategically\nreveal\nher\nprivate\ninformation)\nto\nmaximize\nher\nexpected\nutility\ngiven\nonly\nthis\nprior.\nAnother,\npossibly\nbetter,\nalternative\nfor\nthe\nprincipal,\nif\nfeasible,\nis\nto\nask\nthe\nagent\nto\nreveal\nhis\ntype\nbefore\nthe\nprincipal\nsends\nher\nsignal,\nthrough\nan\nelicitation\nprocess.\nIn\nthis\ncase,\nthe\nagent\nmay\nbe\ncredible,\ni.e.,\ntake\nactions\nconsistent\nwith\nhis\nreported\ntype,\nor\nbe\nnon-credible,\ni.e.,\nreport\nany\ntype\nand\nthen\nplay\nany,\npossibly\ninconsistent,\naction\nafterward\n1\n(essentially,\ncheap\ntalk).\nIn\nthis\npaper,\nwe\nstudy\nsuch\nscenarios,\nwith\na\nparticular\nfocus\non\ncredible\nagents.\nIt\nnecessitates\nadditional\ndesign\nchoices\nthat\nwould\nbe\nunnecessary\nwhen\nthe\nagent\nis\nnon-credible.\nWe\nintroduce\nnovel\nstages\nin\nthe\nmechanism\ndesign\nand\nprovide\nnon-trivial\nexamples\nto\ndemonstrate\nstrict\npayoff\nimprovements\nthey\nachieve.\nMoreover,\nwe\ncharacterize\noptimal\nmechanisms\nunder\nthese\nadditional\ndesign\nchoices\nand\nprove\nthe\ngeneral\noptimaility\nthey\nlead\nto.', 'raytos.r.bsinfotech@gmail.com', 'Jiarui Gan, Abheek Ghosh, Nicholas Teh', '', '../pdf_files/67262e2b059b9-test2.pdf', '', 'Not Accepted'),
(152, '5253047250', '1', 1, 1, 'The Rule of Law: A Thought Pattern', '2024-11-02', '2024', 'he interdisciplinary revival in rule of law studies over the last quarter century has produced an impressive diversity of views about the ideal\'s content, priority, and value. That diversity has sometimes encouraged the skeptical view that it has no conceptual core or nature, and is either \'essentially contested\' or else only empty political rhetoric. I argue that amongst the various views about the rule of law developed over the centuries, there is a discernible, recurring thought pattern upon which the many variations have been proliferated. Whatever else it is, the rule of law is realized when a political community has an efficacious legal system with certain enabling and pervasive characteristics, which protects its members from something presumed in that community to be undesirable, often identified as the arbitrary exercise of power. I explain and illustrate each aspect of this pattern, and draw a few lessons about how it guides, or fails to guide, current rule-of-law debates.', 'philosophy of law,jurisprudence,legal theory,rule of law,law and society', '1 \n To appear in  Eleanor C owan, Kit  Morrell, Andrew Pettinger, and Michael Sevel ( eds), The Rule  of Law in Ancient \nRome (Oxford Univ ersity Press, forthcoming 2025) .  Do not quote or di stribute without permission of  the author.  \n \n \n The Rule of Law: A Thought Pattern  \nMichael Sevel1 \nSenior L ecturer in Jurisprudence  \nUniversity o f Sydney Law School  \n \nABSTRACT  \nThe interdisciplinary  revival in rule of law studies  over the last quarter century  has produced an \nimpressive diversity of views about the ideal ’s content, priority, and value. That diversity has  \nsometimes  encouraged the skeptical  view that it  has no conceptual core or nature, and is either \n‘essentially contested’ or else only empty political rhetoric.  I argue that among st the various \nviews about the rule of law developed over the centuries, there is a discernible, recurring thought \npattern upon which the many  variations have been proliferated .  Whatever else it is, the rule of \nlaw is realized when  a political community ha s an efficacious legal system  with certain enabling \nand pervasive characteristics, which protects its members from something presumed in that \ncommunity to be undesirable, often identified as the arbitrary exercise of power.  I explain and \nillustrate each aspect of this pattern, and draw a few lessons about how it guides, or fails to \nguide,  current  rule-of-law debates.  \n \n \n \nI. Introduction  \nWhile there is some evidence that the rule of law was achieved , at least  to some degree , around \nthe Mediterranean before the flourishing of Athens in the fifth century BC E,2 the appearance of \nthe first extant systematic reflections about  it coincided with the very beginnings of  legal and  \n \n1 I thank the Institute of Advanced Study, Durham University, and the Bingham Centre for the Rule of Law for \ngenerous support in writing this chapter.  \n2 Cf. Michael Gagarin, Early Greek Law  (University of California Press, 1989).  \n', 'raytos.r.bsinfotech@gmail.com', 'Eleanor Cowan, Kit Morrell, Andrew Pettinger, and Michael Sevel ', '', '../pdf_files/67262f51e2ab4-The Rule of Law A Thought Pattern.pdf', '2024-11-05', 'Accepted'),
(153, '5338725044', '26', 5, 6, 'The Rule of Law: A Thought Pattern', '2024-11-02', '2024', 'How to optimally persuade an agent who has a private type? When elicitation is feasible, this amounts to a fairly standard principal-agent-style mechanism design problem, where the persuader employs a mechanism to first elicit the agent’s type and then plays the corresponding persuasion strategy based on the agent’s report. The optimal mechanism design problem in this setting is relatively well-understood in the literature, with incentive compatible (IC) mechanisms known to be optimal and computationally tractable. In this paper, we study this problem given a credible agent, i.e., if the agent claims they are of a certain type in response to the mechanism’s elicitation, then they will act optimally with respect to the claimed type, even if they are actually not of that type. Wepresent several interesting findings in this new setting that differ significantly from results in the non-credible setting. In terms of the structure of optimal mechanisms, we show that not only may IC mechanisms fail to be optimal, bu', 'philosophy of law,jurisprudence,legal theory,rule of law,law and society', 'Information\ndesign\n(or\nBayesian\npersuasion)\nmodels\nscenarios\nwhere\na\nprincipal\nstrategically\nre\nveals\nher\nprivate\ninformation\nto\nincentivize\nan\nagent\nto\nplay\npreferred\nactions.\nFor\ninstance,\na\nseller\nmay\nwant\nto\nreveal\nonly\npartial\ndetails\nabout\nher\nproducts\nto\nincentivize\nan\nagent\nto\nbuy\na\nparticular\none,\nor\na\nschool\nmay\nwant\nto\nissue\nonly\ncoarse\ngrades\nto\nimprove\nits\nstudents’\njob\noutcomes\n[Boleslavsky\nand\nCotton,\n2015;\nKamenica,\n2019;\nOstrovsky\nand\nSchwarz,\n2010].\nThe\ncharacterization\nalso\nresult\nin\nan\nefficient\nalgorithm\nto\ncompute\noptimal\nmechanisms,\nthereby\nhighlighting\nboth\nthe\ncomputational\nand\nutility\nbenefits\nthey\noffer.\nA\nfinal\npoint\nabout\nthis\naspect\nof\nthe\npattern\nis\nin\nregard\nto\nthe\nlast\nclause:\nthat\nlaw\nmust\n“rule.”\nThis\nis\nnot\nthe\ntautology\nit\nappears;\nrather,\nit\nrefers\nto\nthe\nneed\nfor\nefficacious\nlaw.\nIt\nis\nperhaps\npart\nof\nthe\neveryday\nconcept\nof\nlaw\nthat\nwhere\nit\nis\nproper\nto\neven\nspeak\nof\nvalid\nlaw,\nthere\nmust\nbe\nlaw\nthat\nis\n“in\nforce.”\nSome\ntheorists\ntake\nthat\nto\nmean\nthat\nthere\nis\nat\nleast\na\ncredible\nthreat\nof\nthe\nuse\nof\ncoercion\nby\nlaw-applying\ninstitutions\nto\ncompel\ncompliance\nwith\nlegal\nrequirements.\nAdditionally,\nwe\nprovide\nmatching\nhardness\nresults\nthat\nemerge\nwhen\nthese\nadditional\ndesign\nchoices\nare\nnot\nemployed,\nthereby\nhighlighting\ntheir\ncomputational\nbenefits.The\nstandard\ninformation\ndesign\nmodel\nassumes\nthat\nthe\nprincipal\nknows\nthe\nutility\nfunc\ntion\nof\nthe\nagent\n[Kamenica\nand\nGentzkow,\n2011],\nwhich\nmay\nnot\nhold\nin\npractice.\nNumerous\nworks\nsubsequently\nstudy\na\nmodel\nwhere\nthe\nprincipal\ndoes\nnot\nknow\nthe\nagent’s\ntype\nbut\nhas\na\nprior\nover\nit\n[Alonso\nand\nCˆ\namara,\n2018;\nBernasconi\net\nal.,\n2023;\nCastiglioni\net\nal.,\n2020,\n2022,\n2023;\nGill\nand\nSgroi,\n2008;\nKolotilin\net\nal.,\n2017;\nPerez-Richet,\n2014].\nThe\nprincipal\nmay\ntry\nto\ndesign\nthe\nsignaling\nscheme\n(i.e.,\nstrategically\nreveal\nher\nprivate\ninformation)\nto\nmaximize\nher\nexpected\nutility\ngiven\nonly\nthis\nprior.\nAnother,\npossibly\nbetter,\nalternative\nfor\nthe\nprincipal,\nif\nfeasible,\nis\nto\nask\nthe\nagent\nto\nreveal\nhis\ntype\nbefore\nthe\nprincipal\nsends\nher\nsignal,\nthrough\nan\nelicitation\nprocess.\n\'Practicability\',\nor\nthe\nneed\nthat\nlaws\nnot\ndemand\nthe\nimpossible,\nis\nlikewise\na\nrelational\nconcept,\nbut\nit\nrefers\nto\nthe\nrelationship\nbetween\na\nlaw\'s\nsubstantive\nrequirements,\npermits,\nor\nprohibitions\nand\na\nperson\'s\nability\nto\nact.In\nthis\ncase,\nthe\nagent\nmay\nbe\ncredible,\ni.e.,\ntake\nactions\nconsistent\nwith\nhis\nreported\ntype,\nor\nbe\nnon-credible,\ni.e.,\nreport\nany\ntype\nand\nthen\nplay\nany,\npossibly\ninconsistent,\naction\nafterward\n1\n(essentially,\ncheap\ntalk).\nIn\nthis\npaper,\nwe\nstudy\nsuch\nscenarios,\nwith\na\nparticular\nfocus\non\ncredible\nagents.\nIt\nnecessitates\nadditional\ndesign\nchoices\nthat\nwould\nbe\nunnecessary\nwhen\nthe\nagent\nis\nnon-credible.\nWe\nintroduce\nnovel\nstages\nin\nthe\nmechanism\ndesign\nand\nprovide\nnon-trivial\nexamples\nto\ndemonstrate\nstrict\npayoff\nimprovements\nthey\nachieve.\nMoreover,\nwe\ncharacterize\noptimal\nmechanisms\nunder\nthese\nadditional\ndesign\nchoices\nand\nprove\nthe\ngeneral\noptimaility\nthey\nlead\nto.', 'rararararararararara@gmail.com', 'Eleanor Cowan, Kit Morrell, Andrew Pettinger, and Michael Sevel ', '', '../pdf_files/67262fd96b3be-test3.pdf', '', 'Not Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(154, '7538355660', '1', 1, 1, 'Pagbuo ng Lunsarang Aralin  at Gawain sa Ugnayang  Wika’t Lipunan Bilang  Interbensiyon sa Bagong  Kadawyan sa Antas Primarya', '2024-11-02', '2023', 'Layunin ng pananaliksik ang makabuo ng mga lunsarang aralin at gawaing angkla sa MELCs o Most Essential Learning Competencies sa primaryang antas. Pangunahing metodo ang disenyong palarawan at pagbuo ng mga lokalisado at kontekstuwalisadong may temang katutubo, kabuhayan, kalinangan, kapaligiran, at diskursong kasarian na angkop sa pagtuturo sa anyong modyular, harapan, o blended. Ginamit ang sarbey at panayam sa mga piling kalahok. Lumabas sa pag-aaral na epektibo ang mga aralin kapag nakadikit sa karanasan, kaligiran, at interes ng mga mag-aaral. Ang mga kontekstuwalisadong aralin na pinagtibay sa konteksto ng pandemya at bagong kadawyan o new normal ay mainam na gamiting sandigang kaalaman sa kasanayan at kahusayang komunikatibo sa Filipino at iba pang kaugnay na disiplina.', 'Bagong kadawyan,Filipino,kurikulum,lunsarang aralin,pandemya', 'The Normal Lights\nVolume 17,  No. 1 (2023)\nVillanueva, V.M., Malabanan, J.C., Abenes, R.D., Payapaya, R.C., & Palting, J.D . (2023). Pagbuo ng lunsarang \naralin at gawain sa ugnayang wika’t lipunan bilang interbensiyon sa bagong kadawyan sa antas primarya. The Normal \nLights , 17(1), pp. 189–218\nCorresponding Author: villanueva.vm@pnu.edu.phPagbuo ng Lunsarang Aralin \nat Gawain sa Ugnayang \nWika’t Lipunan Bilang \nInterbensiyon sa Bagong \nKadawyan  sa Antas Primarya \nVoltaire M. Villanueva\nvillanueva.vm@pnu.edu.ph\nJoel C. Malabanan\nRodrigo D. Abenes\nPamantasang Normal ng Pilipinas-Maynila\nRachel C. Payapaya\nPamantasang Normal ng Pilipinas-Mindanao\nJulievic D. Palting\nPamantasang Normal ng Pilipinas-Hilagang Luzon\nAbstrak: Layunin ng pananaliksik ang makabuo ng \nmga lunsarang aralin at gawaing angkla sa MELCs o \nMost Essential Learning Competencies sa primaryang \nantas. Pangunahing metodo ang disenyong palarawan at \npagbuo ng mga lokalisado at kontekstuwalisadong may \ntemang katutubo, kabuhayan, kalinangan, kapaligiran, at \ndiskursong kasarian na angkop sa pagtuturo sa anyong \nmodyular, harapan, o blended . Ginamit ang sarbey at \npanayam sa mga piling kalahok. Lumabas sa pag-aaral \nna epektibo ang mga aralin kapag nakadikit sa karanasan, \nkaligiran, at interes ng mga mag-aaral. Ang mga \nkontekstuwalisadong aralin na pinagtibay sa konteksto \nng pandemya at bagong kadawyan  o new normal  ay 190The Normal Lights\nVolume 17,  No. 1 (2023)\nmainam na gamiting sandigang kaalaman sa kasanayan at \nkahusayang komunikatibo sa Filipino at iba pang kaugnay \nna disiplina. \nSusing Salita:  Bagong kadawyan, Filipino, kurikulum, \nlunsarang aralin, pandemya\nIntroduksiyon\nSa hamon ng pagtuturo sa panahon ng bagong kadawyan o \nnew normal , ang paglikha ng angkop na nilalaman at gawain \nbilang interbensiyon ay lubos na kailangan. Mahalagang \nangkop ang nilalaman at pagsasanay sa mga kalakarang \numiiral sa bagong kadawyan o new normal na tumutugon sa \nSDG 2030, Ambisyon Natin 2040, at global na pamantayan. \nMarapat na tugunan sa pamamagitan ng paglikha ng mga \nkagamitang panturo. \nBilang guro, maituturing na manggagawa at alagad ng \nsining at agham (Belvez, 2000). Kaugnay nito, pananagutan \nng guro na maging epektibo (Bernales at Villafuerte, 2008). \nMagkatuwang ang pagtuturo-pagkatuto sa pagpapabisa, \npagpapalakas, at pagsasakabuluhan ng prosesong pedagohikal \n(Villanueva, 2018). Palagi nang kakabit ng metodolohiyang \npagtuturo-pagkatuto-paksa ang mga konseptong dulog, \npamaraan/metodolohiya, teknik, at estratehiya bilang iisa \ndahil sa hindi nagkakalayong ugnayan ng mga nasabing \nkonsepto (Badayos, 2008). Sa panahon ng pandemya, ang \nguro ay marapat sumabay sa hamon ng pagbabago para \nmalinang ang kaalaman, kasanayan, at kakayahan ng mga \nmag-aaral na mahilig sa gadgets  at may ibang karanasan \n(Evangelista, 2022). Mula sa mga magkakaugnay na kaisipan, \nmarapat na magtagpo ang konsepto sa batayang kaalaman na \nmagsisilbing lunsaran sa ugnayang pedagohikal.\nMula sa mga interbensiyong lunsarang aralin, \nlagi at laging masasabik ang mga guro’t mag-aaral 191The Normal Lights\nVolume 17,  No. 1 (2023)\nna hanapin ang konteksto ng mga aralin na kadikit ng \nkanilang karanasan at bayang sinilangan. Makatutulong \nang pag-aaral sa kongkretisasyon ng indihinisasyon, \nlokalisasyon, at kontekstuwalisasyon bilang lente’t teorya \nng masaya, mabunga’t makabuluhang pagtuturo tungo \nsa lohikal, siyentipiko’t makabayang pagkatuto. Mula sa \nugnayang nilalaman-gawain, mabibigyang-konsiderasyon \nang integratibong teorya na nagbibigay-espasyo sa \npagpapahalagang lokal sa espasyong nasyonal o pook global.\nSa pamamagitan ng pag-aaral, pangkalatahang \nlayunin nitong makabuo ng mga materyal panturo. Ang \nsumusunod ang tiyak na layunin:\n1. masuri at maidisenyo ang nilalaman-gawain \nbilang interbensiyon sa pagkatuto;\n2. maiugnay sa pagbuo ang batayang lunsarang \naralin at kasanayang komunikatibo sa:\na. kabuhayan \nb. kalikasan \nc. katutubo \nd. kalinangan \ne. kasarian\n3. mataya ang ugnayang nilalaman at kasanayan \nmula sa lunsarang aralin batay sa interes, \npartisipasyon, awtentikong bunga ng pagkatuto.\nMetodolohiya\nDeskriptibong-debelopmental ang pag-aaral gamit ang \nparadima ng aksiyong pananaliksik. Bahagi at katangian \nng aksiyong pananaliksik ang pagpaplano, pagbuo, \npagmamasid, at pagtalakay kaugnay sa paglikha ng lunsarang \naralin at gawain sa panahon ng pandemya at new normal . \nPinagplanuhan ang mga talatanungan sa sarbey at panayam \nbilang instrumento na napagtibay ng yugto ng pagtataya ang 192The Normal Lights\nVolume 17,  No. 1 (2023)\npangangailangang bumuo ng mga aralin at gawain bilang \ninterbensiyon na magtatampok sa ugnayang wika, kultura, \nat lipunan sa konteksto ng pandemya. Nagkaroon ng pagpili \nng 10-15 kalahok mula sa mga kampus ng kalahok na \npamantasan para sa mga itinataguyod na adbokasiya. Mula \nsa mga halimbawang nabuong lunsarang aralin at gawain na \npinagtibay ng sarbey at panayam, nalikom ang mga datos na \nbatayan kung paano nakatulong sa pagkatuto ng mga mag-\naaral.\nHamon, Kalakaran, at Tugon sa Pagtuturo sa \nPanahon ng New Normal\nAng mga pamantayan o batayang pangnilalaman at \npangkasanayan bilang tugon sa katanungang ano at paano \nituturo ang isang asignatura ay masasagot ng Gabay \nPangkurikulum. Naging bunga nito ang pagbuo ng MELCs \nna hinalaw rin sa Gabay Pangkurikulum. Naging daan sa \npagpili at pagpipino sa anyo ng pagpapaunti ng mga dapat \nituro at makita sa kagamitang pampagtuturo partikular sa \npanahon ng pandemya at bagong kadawyan . Kung kaya, \nang kompetensi sa Filipino ay nagbibigay ng mga makro at \nmaykrong kasanayan sa komunikasyon. Ang mga kasanayan \nay inaasahang magtatawid sa paglinang ng mga kaugnay \npang kasanayan sa Filipino bilang interdisiplinaryo. Kadikit \nng mga kasanayang nakapaloob sa kompetensi sa MELCs \nang pagbibigay-pansin sa mayamang kultura ng bayan, \nrehiyon, bansa, at daigdig. Sa konteksto batay sa Gabay \nPangkurikulum na pinagbatayan din ng pagpapayaman ng \nMELCs sa antas elementarya, kinakailangang nagagamit \nang wikang Filipino upang madaling maunawaan at \nmaipaliwanag ang mga kaalaman sa araling pangnilalaman, \nmagamit ang angkop at wastong salita sa pagpapahayag ng \nsariling kaisipan, damdamin o karanasan nang may lubos \nna paggalang sa kultura (Gabay Pangkurikulum sa Filipino, \n2016). Kung kaya’t ang pagtatagpo ng modelong pamana at 193The Normal Lights\nVolume 17,  No. 1 (2023)\npangkasanayan ang magbibigay ng kabuluhan para maging \nsentro ng batayang konseptuwal sa paglikha ng iba’t ibang \nlunsarang aralin na tatalakay sa ugnayang wika at lipunan. \nKaugnay ng reporma ukol sa MELCs ang ilang mga \npag-aaral sa kalakaran ng pagtuturo ng wika at panitikan \nsa panahon ng pandemya. Sa pag-aaral ni Guvenc (2022), \nmalaking pagbabago sa kalakaran ng pagtuturo sa wika at \npanitikan dulot ng pandemya. Sa kabila ng pagbabago ng \nmodalidad na online , nakita pa rin ang pagnanais ng kapwa \nguro at mag-aaral na maging malikhain, puno ng partisipasyon \nat motibasyon ang mga gawain, at paglikha ng iba’t ibang \nmakabuluhang pagkatuto. Sa ganitong konteksto, nagbago rin \nang proseso ng pagtuturo at pagtataya. Kaugnay nito, lente at \nperspektiba sa pagtuturo ng literatura at wika ang ipinanukala \nni Abarquez (2021) kaugnay ng tatlong mahahalagang tema: \nlayunin sa programa, dulog sa pagkatuto, at bagong paraang \npedagohikal. Sa ganitong lente at perspektiba, magagabayan \nang guro sa mga tuon at direksyon sa hamon ng pagtuturo.\nAng kakanyahan ng wika at kultura maging ng \nlipunan ay nakadepende o nakaugnay sa isa’t isa. Ang \nugnayang wika at kultura sa lipunan sa pananaw pangmundo \nang magiging komprehensibong sandigan sa paliwanag sa \ntiyak na katangian ng pagkakakilanlan ng isang grupong \netnolinggwistiko. Ang wika ay inimbento at nilinang ng tao \nupang maging paraan ng paglipat ng tao ng mga kaalaman \n(Constantino, 2002). Samakatuwid, nagsisilbing instrumento \nang wika kasama ang kultura sa daluyan ng namamayaning \nugnayan sa bawat isa sa lipunang ginagalawan. \nAng pagtatamo ng mga batayang kasanayan mula sa \nisang tiyak na lunsarang aralin ay mabibigyang-katuparan \nsa pamamagitan ng disenyo o pamamaraan kung paano ito \nmapagtatagumpayan. Ang pagtatagpo ng nakasanayang 4A: \nactivity, abstraction, analysis, at application  sa 4K:kahulugan, \nkatangian, kahalagahan, at kaugnayan ang magbibigay-194The Normal Lights\nVolume 17,  No. 1 (2023)\nkahalagahan upang ang mga lunsarang araling nabuo na \nnagpapakita ng iba’t ibang tema ay matiyak na magdudulot \nng mabungang kaalaman at karanasan sa mga mag-aaral. \nKonsepto at Konteksto ng Lunsarang Aralin \nat Gawain Mula sa Pagpaplano, Pagbuo, \nPagmamasid, at Pagtalakay\na obserbasyon, kung hindi kulang ay hindi angkop ang \n \n \n \nLunsarang Aralin (4K)  \n \nACES at 4K  \n(kahulugan, \nkatangian, \nkaugnayan)  \n \nWika at \nLipunan:  \nPandemya \nat Bagong \nKadawyan  \n \nModelong \nPangkasanayan \nat Pamana:  \nMELCS  \n 195The Normal Lights\nVolume 17,  No. 1 (2023)\nBatay sa obserbasyon, kung hindi kulang ay hindi \nangkop ang mga lunsarang aralin. Kaya’t interbensiyon \nang paglikha ng mga angkop na lunsaran at kaugnay na \nmakabago at inobatibong gawaing kadikit ng karanasan \nbilang konteksto sa pagkatuto. Sa ganitong gawain \nmakikita ang pagkatuto mula sa aktibong pakikilahok ng \nmga mag-aaral sa mga pagsasanay tungo sa pagpapalakas \nng kaakuhan, kamalayan, kalinangan, at kasaysayan. \nBilang interbensiyon, produkto ng proseso sa paglikha ng \nkomprehensibo at epektibong lunsarang aralin ang temang \npagbabatayan ng mga gawain at pagsasanay. \nResulta at Diskusyon ng mga Datos\nPagsusuri Para sa Angkop na Disenyo \nng Nilalaman at Gawain\nMula sa mga umiiral na kalakaran, maraming kasanayan \nang hindi lubusang naimapa. Sa ganitong resulta mula \nsa sarbey at panayam, hindi tuwiran ang magiging \nesensiyal na batayan sa dulog pedagohikal mula sa \nugnayang layunin, paksa, at gawain na sentral na batayan \nsa makabuluhang pagtuturo para matamo ang pagkatuto. \nPara sa interbensiyong nilalaman at paraan sa iba’t ibang \nlunsarang aralin, layuning ilatag, pag-ugnayin, at piliin \nang mga angkop na kasanayan sa mga lunsarang aralin \npara malinang ang mga kasanayan sa mga gawain. \nSa kasalukuyang kalagayan ng sistemang \nedukasyong pambansa kasabay ng pagluluwal ng Most \nEssential Learning Competencies  nanatiling integral \nna bahagi ang mga kompetensing dapat matamo. \nSamakatuwid, ang paghubog ng mga kasanayan sa \nkurikulum ng Filipino ay makatutulong upang maging \nkontekstwalisado ang pagkatuto. Sa ganitong pananaw, 196The Normal Lights\nVolume 17,  No. 1 (2023)\nito ang dapat maging disenyo ng batayang nilalaman at \ngawain sa mga nabuong lunsarang aralin. \nTalahanayan 1 \nKasanayan sa MELCs sa Bawat Antas\nAntas/Baitang Kasanayan sa MELCs\nBaitang 1• Nasasagot ang mga tanong sa tekstong \npang-impormasyon.\n• Nagagamit ang magalang na pananalita sa \nangkop na sitwasyon.\n• Nakasusulat ng malalaki at maliliit na \nletra.\n• Nabibigkas nang wasto ang tunog ng bawat \nletra ng alpabetong Filipino. \nBaitang 2• Nagagamit ang naunang kaalaman o \nkaranasan sa pag- unawa.\n• Napagyayaman ang talasalitaan sa \npamamagitan ng paghanap ng maikling \nsalitang matatagpuan sa loob ng isang \nmahabang salita at bagong salita mula sa \nsalitang-ugat.\n• Naibibigay ang susunod na mangyayari.\n• Nagagamit ang mga salitang kilos sa pag-\nuusap.\nBaitang 3• Nababasa ang mga salitang may tatlong \npantig pataas, klaster, salitang iisa ang \nbaybay ngunit magkaiba ang bigkas at \nsalitang hiram.\n• Nababaybay nang wasto ang mga salitang \nnatutunan sa aralin.\n• Nailalarawan ang mga elemento ng \nkuwento.\n• Nakapagbibigay ng wakas mula sa \nbinasang kuwento\nSa talahanayan 1, ipinakita ang mga kasanayang \nesensiyal batay sa pinagyamang kurikulum tugon at \nkaalinsabay ng umiiral na pandemya. Naging malinaw ang 197The Normal Lights\nVolume 17,  No. 1 (2023)\ndistribusyon ng mga kasanayan sa kasanayan sa pagtanggap \ngaya ng pagbasa, pakikinig, at panonood patungo sa \npaglikha gaya ng pagsasalita at pagsusulat. Ang mga ito \nang pangunahing konsiderasyon sa interbensiyong nilikha \nsa pagitan ng lunsarang aralin at makabago at inobatibong \ngawain na nakapaloob sa ( Pag-unawa sa Napakinggan, \nWikang Binibigkas, Gramatika, Kamalayang Ponolohiya, \nPag-unlad ng Talasalitaan, Palabigkasan at Pagkilala sa \nSalita, Kaalaman sa Aklat at Limbag, Pag-unawa sa Binasa, \nPagsulat at Pagbabaybay, Komposisyon, Estratehiya \nsa Pag-aaral, Pagpapahalaga sa Wika at Panitikan ) \nBatayang Pangkurikulum 2016. Mula sa direktang pahayag \nng kinapanayam:\n“Sa pagpaplano at pagbuo, gabay lamang \nang CG at MELCs pero dapat updated  o \nnapapanahon ang babasahing teksto. (Kalahok \n5NL)” \nBagaman hindi idinisenyo sa MELCs ang \nkategorisasyon ng mga makrong kasanayan, litaw pa rin \nmula sa isinagawang interbensiyon ang mga kasanayan \ndapat matamo ng mag-aaral. Nasa makapangyarihang guro \npa rin bilang tagalikha ang tugon sa epektibong pagtuturo \n(Belvez, 2000). Mahalagang maunawaan ng guro ang halaga \nng sining at agham ng pagtuturo sa tulong ng konsepto \nat konteksto ng pedagohiya, (Kapur, 2020). Malaki ang \nhamon sa guro sa kaniyang pagpaplano na palakasin ang \npagtatampok sa bayan para mahubog ang kasanayang \nnakadikit sa diwang makabayan o nasyonalismo (San Juan, \n2017). Samakatuwid, laging konsiderasyon sa anomang \nplano, proyekto’t gawain, at iba’t ibang interbensiyon ang \npagsusuri sa kasanayang dapat matamo.198The Normal Lights\nVolume 17,  No. 1 (2023)\nTalahanayan 2 \nKaalaman at Kasanayan mula sa MELCs\nBaitang Kaalaman Kasanayan\n1• Pilipino ay binubuo ng \nmga pangkat - etniko\n• Mga Salitang \nmagkatugma o \nmagkatunog• Nakapaglalarawan ng \nmga bagay, tao, hayop, \npangyayari, at lugar \n(F1WG-IIIc-d-4)\n• Natutukoy ang mga \nsalitang magkatugma \n(F1KP -IIIc - 8)\n2• Paggamit ng \nkasingkahulugan, \nkasalungat, pagbibigay \nng halimbawa, o \npagbibigay ng kahulugan \nbatay sa pagkagamit sa \nisang sitwasyon\n• Sumusuportang kaisipan \nsa pangunahing kaisipan \nng tekstong binasa• Naiuugnay sa sariling \nkaranasan ang nabasang \nteksto. (F2PN-IIb-2)\n• Nakapagbibigay \nng kahulugan ng \nisang salita sa isang \nsitwasyon. (F2WG-\nIIg-h-5)\n• Maibigay ang mga \nsumusuportang kaisipan \nsa pangunahing kaisipan \nng tekstong binasa. \n(F2PB-IVi-11)\nSalik. 3• Salitang-kilos\n• Diptonggo: mga \nsalitang may patinig at \nmalapatinig• Naiuugnay ang binasa \nsa sariling karanasan \n(F3PB-IIa-1)\n• Nakabubuo ng mga \nsalitang may diptonggo \nmula sa tekstong binasa \n(F3KP -IVi -11) \nSa talahanayan 2, malinaw ang ugnayang kaalaman \nat kasanayan na litaw sa itinakda ng Batayang Kurikulum at \nMELCs. Bago makabuo ng mga angkop na gawain, marapat \nna mabatid ang esensiyal na ugnayan ng nilalaman at \nkasanayan. Ito ang batayan ng disenyong kontekstuwalisado \npara palutangin ang tema ng mga lunsarang aralin na \nnakadikit sa danas, kapaligiran, gulang, interes, at iba pang 199The Normal Lights\nVolume 17,  No. 1 (2023)\nsalik. Sa talahanayan kaugnay ng pagtatamo ng kaalamang \npanggramatika, mainam na hindi lamang nagtatapos sa \nkaalaman ng pagbasa ng alpabeto at pagbuo ng mga salita \nmula sa bawat titik nito natatapos ang kanilang pagkatuto, \nkailangang maipaunawa sa mag-aaral ang kahalagahan ng \nasignatura sa konsepto ng kanilang identidad at kultura. Mula \nsa pahayag ng kalahok na guro sa Hilagang Luzon:\n“Ang kalinangang Ilokano ay nagpapakita ng \nugnayang kapaligiran, katutubo, at kultura na \ndapat madama at maranasan ng mga mag-aaral \nlalo sa mga iba’t ibang teksto.” (Kalahok 3M)\nMalinaw para kina Badayos (2008) at Villanueva \n(2018) na marapat na magkaugnay ang kaalaman at kasanayan \nbilang esensiyal na batayan ng pagpaplano, pagbuo, at \npagpapatupad ng mga simulain at prinsipyong pedagohikal. \nSamakatuwid, masinop na pinili ang mga kasanayang dapat \nlinangin batay sa kahingian at pangangailangan ng konteksto.\nPigura 1 \nKasanayan sa Konteksto ng Karanasan, Panahon, at \nPangyayaring Panlipunan\n \nIpinakita sa pigura 1  ang bisa ng karanasan, panahon, \nat pangyayaring panlipunan ay ugat ng aktibong pakikilahok. \n200The Normal Lights\nVolume 17,  No. 1 (2023)\nPara sa nakapanayam:\n“Ang pandemya ay danas na kuhaan mga \naralin at gawain para matiyak ang pagkatuto.” \n(Kalahok4V)\nTalahanayan 3 \nLunsarang Aralin sa mga Paksa sa Wika at Panitikan\nBaitang Paksa sa Wika at Panitikan Lunsarang Aralin\n1 Tula“Batang Manobo, Batang \nMatalino”\n“Dinengdeng”\n“Muyang”\n2Balita\nMaikling Kuwento“Balitang Baha”\n“Sa Kumang”\n“Balag”\n3Pandiwa\nDiptonggo\nPanghalip na Pananong \nTula\nMaikling Kuwento\nMusikang Bayan“Tuob  ni Mama Sol”\n“Ang Banbanting ni Apong”\n“Hindi Maaaring Kainin ang \nMalagkit araw-araw”\n“Pantay Lamang”\n“Ang Nanay ko ay Tatay”\n“Igalang ang Bawat Kasarian”\n  \nAng lunsarang aralin na inihanda sa Talahanayan \n3 ay naglalaman ng mga pagsasanay. Litaw mula sa mga \nlunsarang aralin ang kahalagahan ng kalinangang bayan \nmula sa ugnayang panlipunan at kasanayang matatamo sa \naralin. Binigyang-puwang sa mga layuning nakatala sa pag-\niisa-isa sa bawat katangiang kinapapalooban ng kasanayang \nkomunikatibo. Sa ganitong datos, inilalahad na dapat maging \nlantad ang wika na magtutulay sa karanasan kabilang ang \nkultura at kalinangan ng bawat mag-aaral upang lubos na \nmatamo ang mabilis at epektibong pagkatuto.201The Normal Lights\nVolume 17,  No. 1 (2023)\nPigura 2 \nKasanayang Komunikatibo sa Lunsarang Aralin\nMalinaw ang implikasyong nalilinang ang mga \nkasanayan kung kontekstuwalisado ang aralin bilang salik sa \nmatagumpay na haplos-pedagohikal. Patunay ang kakayahan \nng mga mag-aaral sa pagsunod-sunod sa pangyayari, \npagkukuwento, paglalarawan, pagpapahayag ng sariling \nideya at damdamin, at iba pang kasanayang komunikatibo \nsa inaasahan nitong bunga (Persaud, 2021). Ang mga \naspektong dapat maisaalang-alang upang tuluyang matamo \nang kasanayang komunikatibo ay dapat na makita sa mga \npagsasanay upang mataya kung gaano kalawak ang mga \nkaalaman at kasanayang natamo ng mag-aaral.\nPigura 3 \nNilalaman, Ideya, Daloy, at Paraan ng Lunsarang Aralin sa \nPaglinang ng Kasanayang Komunikatibo\n202The Normal Lights\nVolume 17,  No. 1 (2023)\nMarapat ang disenyo sa pagbuo ay nagtutugma ang \nnilalaman at paraan. Pinagtitibay nito ang kalidad ng bawat \nlunsarang aralin na magtutuloy sa pagtatamo ng inaasahang \nprodukto sa kasanayang komunikatibo. Mula sa pahayag sa \nnaging panayam ng isang kalahok:\n“Walang imposible sa kagamitang nagtatampok \nsa identidad ng mag-aaral at ng kaniyang lugar.” \n(Kalahok 2NL)\nMalinaw ang implikasyong nagiging posible ang \npagkatuto kung ang disenyo at paraan ng pagpapatupad ng \niba’t ibang gawaing nakaugat sa mga lunsarang aralin ay \nnagpapatingkad sa konteksto.\nPagdisenyo at Pagbuo ng mga Aralin at Gawain \nPatungong Kasanayang Komunikatibo \nSa pagdidisenyo at pagbuo ng lunsarang aralin, \nkonsiderasyon ang kasanayang komunikatibo na marapat \nlinangin na nakabatay sa iba’t ibang konteksto gaya ng \nkapaligiran, kalinangan, kasarian, katutubo, at kabuhayan \nna tuwirang may epekto sa karanasan ng mag-aaral at \nkomunidad na kinabibilangan. Tumutukoy ang kasanayang \nkomunikatibo sa makatotohanang paggamit ng mga \nmakrong kasanayan sa komunikasyon sa araw-araw. Para \nkay Hirschman at Wood (2019), malaki ang gampanin kung \npaanong ang kaalaman ay magiging kasanayan ng mag-aaral \nkaugnay ng kakayahang komunikatibo na pangunahing \nsalik sa ika-21 siglong edukasyon. Samakatuwid, bunga \nng ugnayang nilalaman at pagsasanay ang kasanayang \nkomunikatibo na dapat matamo at matutuhan sa iba’t ibang \nuri ng lunsarang aralin. 203The Normal Lights\nVolume 17,  No. 1 (2023)\nTalahanayan 4 \nKasanayang Komunikatibo Batay sa Tiyak na Lunsarang Aralin\nBaitang Halimbawang Kasanayang \nKomunikatiboTiyak na Halimbawa sa \nAralin\n1 paggamit ng magkatugmang \nsalitapagpares at paggamit ng \nmga salitang magkatugma\n2 paggamit ng salitang \nmagkasingkahulugan, \nmagkasalungat, at iba pang \nkonteksto pagbibigay ng kahulugan \nng mga salitang umiiral sa \npamayanan\n3 pagbuo ng tiyak na salita \nmula sa natutuhan sa aralinpagbuo at pagpapakahulugan \nsa nalikhang salita\nSa talahanayan 4, naging sentro ang paglalapat mula \nsa halimbawa ng kahusayang komunikatibo sa pamamagitan \nng paggamit ng mga natutuhan sa natamong kaalamang \npangwika. Ito ang malinaw na salik sa pagmamapa, \npagtatapat-tapat, at pag-uugnay ng mga nilalaman at \ngawaing magbibigay-daan sa paglinang sa kasanayan sa \nkomunikasyon na magtatawid sa iba pang ika-21 siglong \nkasanayan sa online , harapan, o pinaghalo o blended  na \nparaan (Oyeleke, 2018). Ang mga kasanayan ay marapat na \nangkop sa panahon at henerasyon ng mga mag-aaral upang \nlubos itong maging mahalaga (Dimock, 2019). Esensiyal \nsa ugnayang kasanayang komunikatibo ang kaalaman sa \nwika na magbibigay-kasanayan sa talastasang kadikit ng \niba pang mga tema. Samakatuwid, madaling tukuyin kung \npaano maiisa-isa ang mga kasanayan subalit mapanghamon \nkung paano ito masisigurong matatamo at matutuhan. \nSa ganitong konteksto, marapat na maging makabago at \ninobatibo ang isang estratehiya o anomang pagsasanay \nupang bigyang-katuturan at kabuluhan ang isang lunsarang \naralin. May implikasyon sa pagdidisenyo at pagbuo ng mga \ndaloy ng gawaing kadalasan ay nakapadron sa abstraksiyon, \npagsusuri, at paglalapat. Mula sa 4As ay malinaw ang \nlayuning matamo ang kasanayang komunikatibo bilang 204The Normal Lights\nVolume 17,  No. 1 (2023)\npaglampas sa kombensyonal at tradisyonal na paraan ng \npagtuturo. Sa pahayag ng kalahok:\n“Praktikal sa pagkatuto na magamit ang nilalaman \nsa pang-araw-araw na buhay. Ito ang batayan na \nesensiyal ang aralin at gawain sapagkat nailalapat \nang mga natutuhan sa iba’t ibang sitwasyon.” \n(Kalahok 1M)\nMay pagpapakahulugan at pagsasakatuturan ang \nhamon ng paglinang ng mag-aaral ng mga kasanayang \nkadikit ng komunikasyon bilang paglalarawan sa kakayahang \nkomunikatibo. Esensiyal sa pagdidisenyo at pagbuo ang \npagtukoy sa mga kaalaman at kasanayang dapat magkaugnay \nna karaniwang nagmula sa dokumento ng Kagawaran ng \nEdukasyon na marapat pagyamanin ng gurong tagapagpatupad \nsa pagpili ng angkop na nilalaman at gawaing pampagkatuto.\nTalahanayan 5 \nKasanayan sa Pagsulat at Pagsasalita Batay sa Tiyak na \nLunsarang Aralin\nBaitang Makrong Kasanayan Paraan sa Pagtatamo ng \nMakrong Kasanayan\n1. Pagsulat\npaglikha ng mga salitang \nmagkatugma\nPagsasalita\npagpapaganda ng pahayag sa \npamamagitan ng pagpili ng \nsasabihing angkop na salitang may \ntugma Pagbibigay ng mga salitang \nkadikit ng pang-araw-araw \nna danas mula sa pagkain \n(Dinengdeng) at iba pang \nkaugnay na mga katutubong \nkulay.\n2. Pagsulat\npaglikha ng pangungusap na \nnagpapahayag ng kaugnay at \nsuportang kaisipanPagtatampok sa \nlokalisadong babasahin \nukol sa “Balag” upang \niugnay ang pangunahin at \nsuportang kaisipan. 205The Normal Lights\nVolume 17,  No. 1 (2023)\nPagsasalita\npagpapahayag ng sumusuportang \nkaisipan sa pangunahing kaisipan \nng teksto\n3. Pagsulat\npagbuo ng talatang naglalahad ng \nsariling karanasan\nPagsasalita\npagpapahayag ng pangyayari \nkaugnay ng tiyak na sitwasyon/\nkaranasan Pagpapabasa/pagpaparinig \nng awit ng diskursong \npangkasarian tungo sa \npagbuo ng paghihinuha.\n \nIpinakita ng talahanayan 5 ang ugnayan ng makrong \nkasanayan. Kailangang bigyang-pansin ang ugnayang \npagsulat at pagsasalita na pangunahing laman at katangian \nng interbensiyon sa mga lunsarang aralin at makabago at \ninobatibong gawain. Malaki ang gampanin ng mga lokalisado \nat kontekstuwalisadong lunsarang aralin na tumatalakay \nsa kaligiran ng bawat mag-aaral kadikit ng kabuhayan, \nkalinangan, katutubo, kalikasan, at diskursong pangkasarian. \nAng kasanayang komunikatibo ay nagiging mabunga at \nproduktibo kung kaugnay ito ng iba’t ibang esensiyal at \nmakabuluhang kasanayan na hinalaw sa kurikulum at \npinagtibay ng mga malikhain, masining, at makatuturang \ngawaing pampagkatuto.\nAng holistikong pagkatuto ng mag-aaral ay \nmaisasakatuparan kung isinasagawa ang integrasyon ng mga \ntiyak na pagpapahalaga. Ang kasanayang komunikatibo na \ntumutukoy sa kahusayan sa paggamit ng wika sa talastasan ay \nmay katangiang gamitin sa tama, moralistiko, at makatuwirang \npamamaraan. Sa ganitong aspekto, malaki ang gampanin \nng pagpaplano at pagbuo ng mga lunsarang aralin na laging \nbatayan ang magiging sangkap na pagpapahalaga. Sa pahayag \nsa panayam ng isang kalahok:\n“Malaking gampanin ang adbokasiya ng PNU 206The Normal Lights\nVolume 17,  No. 1 (2023)\nbilang kuhaan ng lasa at timpla ng tema ng mga \nnilalaman at gawaing pampagkatuto.” (Kalahok \n4MM)\nAng bawat tema na kaakibat ng gawain, programa, \nat pagkakakilanlan ay magkakaugnay na sentro ng itinatuyod \nng kalahok na pamantasan bilang sentro sa edukasyong \npangguro. Sa ganitong paraan, lalong pinatingkad ang \nitinataguyod na 5K ng kalahok na pamantasan sapagkat \nidinikit ito sa panahon. Ang panahon ang malinaw na \nindikasyon ng kontekstuwalisasyon na pinabisa pa ng \nsangkap at lasang indihinisasyon at lokalisasyon. Sa ganitong \nestilo ng paglikha ng lunsarang aralin, malinaw na nagiging \nkonsiderasyon ang pandaigdigang pananaw ng mga mag-\naaral upang asahang madali at magaan nilang maiuugnay ang \nbawat esensiyal na kaalaman sa pang-araw-araw na buhay. \nMalinaw ang matingkad na tema kung direktang nakaugnay \nat makikita sa wika na tumatagos sa aspektong panlipunan. Sa \npaliwanag ni Salazar (1979), impukan, hanguan, at kuhanan \nang wika ng kultura upang mabigyang-linaw at pakahulugan \nang kalinangang bayan. Sa ilang mga halimbawang aralin, \nkitang-kitang ang ugnayang wika, kultura, at lipunan. \nMapapansin ang ilang piling halimbawa:\nSa tulang “Dinengdeng”  para sa Baitang 1, \nmalinaw mula sa pamagat na ang akda ay mula sa \nKailokuhan kung saan naroon ang PNU-NL. Sa \ntula, ginamit ang mga salitang Balay  at katuray  \npara maisama sa saknong na magpapakita ng \nmga salitang magkakatunog na pinagtugma ang \ngulay at balay maging ang malunggay at katuray. \nSa tulang ito, ang mga salitang sininop na pinili \nupang magpares ang tunog na magkatugma ay \npagpapamalas ng buhay, kabuhayan, at lipunan \nng mga Ilokano na kilala sa pagiging mahilig \nsa gulay. Kapansin-pansin sa huling bahagi sa \npaggamit ng salitang Inang para sa nanay ng 207The Normal Lights\nVolume 17,  No. 1 (2023)\nmga Ilokano pero mas naging makabuluhan ito \nsa pag-uugnay ng lutong ulam na Dinengdeng \nna kapara sa pagbuo ng salita na upang maging \nmasining at malikhain ay marapat na dumaan sa \npagpili at pagpino ng mga salitang magkatunog \nat may tugma.\nSarap ng Dinengdeng  na sinandok\nInihain ni Inang sa mangkok\nTulad ng mga tugmang salitang binalot\nLinaw at ligaya ang mapupulot.\nLalong napalutang ang kulturang Ilokano mula sa \nakda sa Baitang 2 ukol sa Kumang  na sinamahan ng iba pang \nmga salita gaya ng singkaw, arado, eras, pupugan, ammuyo, \ntandam,  at iba pa. Sa akda, naging madaling maunawaan ang \nmga salitang katutubo o Ilokano sapagkat tinumbasan ang \nmga salita nang kagyat na palarawang paliwanag gaya ng \nsumusunod na halimbawa:\nSa mga akda mula Mindanao, malinaw sa mga \nsalita ang ugnayang wika, kultura, at lipunan na mahalagang \nmaituro ng guro at matutuhan ng mga mag-aaral upang \nmapalakas ang kakayahang maiugnay ang kaakuhan, \nkalinangan, kamalayan, at kasaysayan ng lipunang Pilipino \n(Villanueva, 2016). Naging tuon sa Baitang 1 ang tula ukol sa \nbuhay, kultura, at lipunang Manobo. Batay sa tula, ipinakikita \nna ang mga Manobo ay Pilipino at dapat ipagmalaki. Isinama \nsa tula ang kaligiran at ang kaakuhan bilang pagkakakilanlan \nng mga Manobo bilang Pilipino.\nTama ang basa mo\nBatang Manobo ako\nSa Mindanao nakatira\nKasama ang pamilya208The Normal Lights\nVolume 17,  No. 1 (2023)\nSa lunsarang akda para sa Baitang 2, sentro ang \nbalita sa naranasang baha o kalamidad. Pero, mas ipinakita \nsa akda ang lipunang nagbabayanihan, nagdadamayan, at \nnagtutulungan sa kabila ng mapinsalang dulot ng kalikasan. \nAng mga tiyak na salita na kadikit ng lipunang Pilipino ay \nmasasalamin sa halimbawang akda:\nAyon kay Kapitan Edwin, lider ng samahan, \nbawat miyembro ay may tiyak na tungkulin sa \npanahon ng lamay: may tagaluto, tagahugas, \ntaga-igib, tagadasal, tagasilbi ng pagkain. Sa \npuntod naman, grupo ni Hernan ang gagawa.\nNaging litaw ang ugnayang wika, kultura, lipunan sa \npanahon ng pandemya sa akda sa Baitang 3 na pinamagatang \n“Tuob  ni Mama Sol”. Sumentro ang maikling kuwento sa \npag-uugnay sa panahong nararanasan sa pandemya. Ang \ntuob ay katumbas ng suob upang pasingawin ang katawan \nna pinaniniwalaang gamot at paraan upang matanggal ang \nkagaw  o virus. \nMakabuluhang binigyang-diin ang programa, gawain, \nat pagkakakilanlan ng Pamantasan sa tuwirang ugnayan ng \ntema at paksa ng lunsarang aralin upang palutangin ang wika, \nkultura, at lipunan ng mamamayan at pamayanan.\nSang-ayon ang mga naging kalahok sa temang pag-\niikutan ng iba’t ibang lunsarang-aralin. Sa mga tema ng \nakda, umiikot ang iba’t ibang K na katumbas ng katutubo, \nkalinangan, kabuhayan, at diskursong kasarian na kadikit ng \ngawain, programa, at adbokasiya ng kalahok na pamantasan. \nIlan sa mga halimbawang tema ay ang sumusunod na akda:\nKatutubo:\nDinengdeng  (tula)\nSa Kumang (maikling kuwento)\nAng Banbanting ni Apong (maikling kuwento)209The Normal Lights\nVolume 17,  No. 1 (2023)\nKalinangan:\nBatang Manobo, Batang Pilipino (tula)\nBalitang Baha (balita)\nTuob  ni Mama Sol (maikling kuwento)\nKabuhayan:\nMuyang (tula)\nBalag (maikling kuwento)\nHindi Maaaring Kainin ang Malagkit Araw-araw \n(sanaysay)\nKasarian: \nPantay Lamang (tula)\nAng Nanay Ko ay Tatay (maikling kuwento)\nIgalang ang Bawat Kasarian (tula at awit)\nMatagumpay na itinatanghal ang ugnayang wika, \nkultura, at lipunan sa misyon at bisyon ng Pamantasang \nNormal ng Pilipinas sa pagdidisenyo, pagbuo, pagpapatupad \nat pagtataya ng mga lunsarang aralin na ang pangunahing \nnilalaman at mga gawain ay kontekstuwalisado at lokalisado. \nLubos ang pagsang-ayon ng mga naging kalahok sa ugnayang \ngawain, programa, at adbokasiya ng kalahok na pamantasan. \nAng mga naging batayan sa ugnayang misyon at bisyon mula \nsa makikitang lunsarang aralin ay magiging direksiyon sa \nsusunod pang mga pag-aaral at pananaliksik mula sa domeyn \nng pagtuturo, pananaliksik at publikasyon.210The Normal Lights\nVolume 17,  No. 1 (2023)\nPagtataya sa Ambag ng Batayang Nilalaman at \nKasanayan sa Pagkatuto\nMalaking usapin sa sektor ng edukasyon ang pagkakaroon \nng isang maayos, sistematiko, at tematikong kurikulum. \nGayundin, isang mahalagang kasangkapan ang kurikulum \nupang makabuo ng pinakamainam na pedagohiya sa pagtuturo \nna lilikha ng isang kawili-wiling lugar pampagkatuto. \nMaisasakatuparan lamang iyon kung maayos na maihahanay \nang mga kasanayan na nakapaloob sa MELCs na ginagamit \nsa kasalukuyang modalidad ng edukasyon. \nSa pagkakaroon ng ganitong modalidad ng pagtuturo, \nhindi maikakailang maraming naapektuhan na larangan tulad \nng Filipino. Dahil dito, mahalagang maayos na maihanay ang \nmga mahahalagang kompetensi sa kurikulum. Gayunman, \nhindi kumpleto ang pananaliksik kung hindi mabisang \nmatataya ang mga binuong lunsarang aralin upang tiyakin \nang kabisaan, kaangkupan, at kahusayan nito sa paglinang ng \nkakayahang pangkomunikatibo. \nMalinaw na ipinakita ng datos ang lubos na pagsang-\nayon ng mga kalahok na nakabasa, nakagamit, at nakasaksi \nkung paano mahusay na napagtagpo ang nilalaman at mga \nbinuong pagsasanay upang makuha ang interes ng mga mag-\naaral. Indikasyon ang mataas na bahagdan ng pagsang-ayon na \nnatumbok ng mga mananaliksik na lumikha ng mga lunsaran \nang bawat temang inilalarawan tulad ng katutubo, kabuhayan, \nkalinangan, kapaligiran, at diskursong pangkasarian. Malaki \nang gampanin ng resultang ito upang maipakita na sa bawat \nsangay o kampus ng kalahok na pamantasan, anoman ang \ntema ng lunsarang aralin ay mahalagang may kakayahan itong \numugnay sa wika, kultura at lipunan na susi sa epektibong \npagtuturo at pagpapakilala sa Filipino. \nNarito ang ilang pahayag mula sa mga kinapanayam \nna guro mula sa Focus Group Discussion  (FGD) bilang \npagtataya sa pagdidisenyo, pagbuo, at pagpapatupad ng 211The Normal Lights\nVolume 17,  No. 1 (2023)\nugnayang nilalaman at gawaing angkla sa tema’t adbokasiya \nng kalahok na pamantasan: \nKinapanayam 1: \nAng bawat isa ay magkatugma at batay sa layunin \nng aralin. (Kalahok 3NL)\nKinapanayam 2: \nAng nilalaman ay ang kabuuang konsepto, mga \nimportanteng mga prinsipyo at kaalaman na \ndapat matutunan ng isang mag-aaral habang ang \nkasanayan ay isang payak at specific na task kung \nsaan ang isang mag-aaral ay dapat na matuto at \nmasanay sa kaniyang sariling pang-araw-araw na \ngawain. (Kalahok 7NL)\nKinapanayam 3: \nAng kaibahan ng nilalaman at pagsasanay sa \naming nabasang lunsarang – aralin ay mas madali \nitong maintindihan dahil may mga larawan at \nang sitwasyon sa aralin ay nakahango sa ating \nnaranasan ngayon. (Kalahok 4M)\nMula sa naging panayam, epektibo at mahusay \nang mga binuong lunsarang aralin na may kinalaman sa \nugnayang wika, kultura at lipunan. Samakatuwid, malinaw \nna indikasyon ang datos na ito na kung ang guro ay may \nmalinaw na pag-unawa sa kaniyang larangan ay makalilikha \nito ng mga gawain o pagsasanay na sapat at lapat sa interes \nng mga mag-aaral. Malinaw na mahihinuha sa resultang \nito na hindi nalimitahan ng tema o panahon ang kahusayan \nat kakayahan ng bawat pagsasanay sa lunsarang aralin na \nhasain, paunlarin, at pukawin ang interes ng mag-aaral na \nmatuto sa kabila ng hamon ng kasalukuyang modalidad \ndulot ng pandemya. Kung kaya, ang pagsang-ayon ng \nmga kalahok ay indikasyon na madaling nauunawaan 212The Normal Lights\nVolume 17,  No. 1 (2023)\nang lunsaran, kadikit ng kamalayan ng mag-aaral, at \nkontekstwalisado sa kanilang karanasan. \nLutang na lutang ang resulta na lubos na sinasang-\nayunan ng mga kalahok na bukod sa mga naunang kabisaan ng \nlunsaran pagdating sa nilalaman, pagsasanay at kakayahang \nkomunikatibo. Indikasyon ang datos na ito na holistiko ang \npagkakalikha sa mga lunsarang aralin sapagkat malinaw \nnitong naipapakita ang ugnayang wika, kultura at lipunan \nupang higit na maging epektibo ang pagtuturo at pagkatuto \nng mga mag-aaral sa bagong kadawyan o new normal.  \nNarito ang ilan pang pahayag mula sa naganap na \nfocus group discussion (FGD):\nKinapanayam 1: \nMahalaga na ang aralin sa Filipino ay kadikit \nng karanasan ng mga mag-aaral upang mas \nmadaling maproseso sa isipan at mas madaling \nmaintindihan ito. Hindi na kailangan ng \nmahabang pagpapaliwanag kapag naranasan o \nmay dating kaalaman na sila tungkol sa anumang \naralin. (Kalahok 2V)\nKinapanayam 2: \nLubos na magagamit ng mag-aaral ang \nugnayang nilalaman at kasanayan sa aralin sa \npamamagitan ng pagsagot sa mga gawain na \nnaaangkop sa mga aralin. (Kalahok1 MM)\nAng mga pahayag ay pagpapatunay kung paano \nnailakip sa mga lunsaran ang ideya at konsepto ng karanasan \nng mga mag-aaral sa iba’t ibang sangay o kampus ng kalahok \nna pamantasan. Samakatuwid, tunay ang pahayag ng mga \nteorya at mga naunang pag-aaral na sa bawat lilikhaing \ngawain, estratehiya o maging lunsaran mahalagang \ninuugnay o inilalapit ito sa karanasan at kamalayan ng mga 213The Normal Lights\nVolume 17,  No. 1 (2023)\nmag-aaral upang madali nilang maunawaan at pagtuonan \nng interes. \nMalinaw ang bahagdan ng pagsang-ayon ng mga \nkalahok hinggil sa kung gaano karami ang bunga ng pagkatuto \nna iniluwal ng nilalaman at pagsasanay sa mga lunsarang \naralin. Sa mga binuong lunsarang aralin mahihinuha na \nkung pagtutuonan lamang ang nakasanayan at hindi lalagpas \nsa pagiging inobatibong guro, mananatiling nakakahon sa \ntradisyunal at nakasanayan lamang na paraan ng pagtuturo \nna malaki ang posibilidad na hindi mapukaw ang interes \nng mga mag-aral. Sa tulong ng mga ganitong lunsaran na \nkontekswalisado sa ugnayang wika, kultura, at lipunan tiyak \nna aasahan ang epektibo at holistikong bunga ng pagkatuto. \n Makikita ang lubos na pagsang-ayon ng mga kalahok \npagdating sa kabisaan ng lunsarang aralin pagdating sa taglay \nnitong yaman sa ugnayang karanasan at nilalaman sa ugnayang \nwika,kultura at lipunan. Ang pagkakaroon ng resultang \nnaglalahad ng pagiging epektibo ng mga binuong lunsaran ay \npagpapatunay rin na hindi lamang limitado ang pagkatuto sa \nnilalaman ng libro o ng anomang naunang nailimbag ng mga \nmodyul o lunsaran sapagkat tulad ng panahon ang interes ng \nmga mag-aaral sa pagkatuto ay nagbabago. Samantala, ang \nhangarin ng MELCs na salain ang mga esensiyal na kaalaman \nay mahalagang nakaugat sa pagbuo ng lunsarang aralin na \nesensiyal na konsiderasyon ang kaugnayan sa wika, kultura \nat lipunan ng mag-aaral upang matiyak ang pagtatamo ng \npanghabambuhay na pagkatuto.\n Narito ang ilan pang piling pahayag mula sa naganap \nna Focus Group Discussion (FGD) : \nKinapanayam 1: \nHigit na matutugunan ang mga lunsarang-aralin \nat pagsasanay lampas sa MELCs at angkop na \nsitwasyon na ating kinakaharap kapag ang mga 214The Normal Lights\nVolume 17,  No. 1 (2023)\nguro ay patuloy na gagawa ng mga module o \nlearning activity sheets na batay level ng pag-\nunawa o angkop sa baitang at karanasan ng mga \nmag-aaral. (Kalahok 4MM)\nKinapanayam 2: \nMapapatuloy ng guro ang paglikha ng aralin at \npagsasanay kadikit ng karanasan ng mag-aaral \nsa pamamagitan ng paggawa ng mga modules at \nactivity sheets. (Kalahok 6NL)\nMay implikasyong sa dinamismo ng panahon, \nkahingiang makasunod sa pagbabago ang mga guro. \nSamakatuwid, ang kabisaan ng paglikha ng mga lunsarang \naralin ay nakasalalay sa kung paano hinahasa ng guro ang \nkaniyang sarili upang makalikha ng dekalibre at inobatibong \ngawain at mga pagsasanay na kontekswalisado sa ugnayang \nwika, kultura at lipunan. \nKongklusyon at Rekomendasyon\nAng ugnayang lunsarang aralin at makabago at inobatibong \ngawain bilang interbensiyon ay sandigan ng makabuluhang \npagtuturo. Dito nagmumula ang iba’t ibang batayang \nkaalaman na pundasyon sa paglinang ng angkop na mga \nkasanayan. Sa lunsaran kukuha at hahango ng mga batayang \nnilalaman sa anyo ng pagpapatanggap ng impormasyon sa \nparaang pagbasa, pakikinig, o panonood na mahalagang \nmatutuhan ng mga mag-aaral. \nSa kalakaran sa pagtuturo ng/sa Filipino, kapareho rin \nang umiiral na sistema kung paano lumilikha at gumagamit \nng mga lunsarang aralin mula at hango sa mga batayan \nat sanayang aklat. Gayunpaman, hindi mapasusubalian \nang kahalagahan nito at lalong napabibisa sa tulong ng \nmga pinasimulan at pinagyamang pagsasanay upang ang 215The Normal Lights\nVolume 17,  No. 1 (2023)\nlunsarang aralin ay maging daan sa paglinang at pagtatamo \nng inaasahang kasanayan batay sa tiyak na batayang \npangkaalaman at pangnilalaman. Masasabing lahat ng ito \nay kaugnay sa mithiin at adhikaing magamit para sa hangad \nna kakayahang komunikatibo. Sa ganitong paraan, ang mga \nnaitakda at umiiral na kasanayan sa iba’t ibang makrong \nkasanayan sa komunikasyon mula sa Batayang Pangkurikulum \nat MELCs ay mahalagang sandigan sa paglikha ng lunsarang \naralin na litaw agad ang mga kasanayan na pagtitibayin sa \npamamagitan ng mga inobatibo at makabagong gawain. \nSa kasalukuyang kalakaran, marapat ding \nmalinang sa bawat guro ang kakayahang makabuo ng \nmga napapanahon, lokalisado, at kontekstuwalidong mga \nlunsarang aralin upang makahikayat sa mga mag-aaral na \nmakisangkot sa mga gawaing pagkatuto dahil kaugnay ito \nng danas sa pamayanang kinabibilangan. Ang pananaliksik \nay nagpakita ng praktika sa pagsasakapangyarihan ng guro \nbilang tagaplano, tagabuo, tagadisenyo, at tagapagpatupad ng \nmga lunsarang aralin kaugnay ng makabago at inobatibong \npagsasanay o gawain. \nAng kabisaan at pagiging epektibo ng isang produkto \nay mahalagang mataya, matasa, at masubok. Bagamat hindi \nhumantong ang kasalukuyang pananaliksik sa malawakang \npagpapagamit sa mag-aaral upang matiyak ang kabisaan nito, \nmarapat magkaroon ng panimulang pagtataya sa nabuong \nlunsaran batay sa ugnayan sa kasanayang pangkomunikatibo \nna lilinang sa interes, partisipasyon, at awtentikong bunga \nng pagkatuto ng mag-aaral. Mula sa sarbey at panayam sa \nmga naging gurong kalahok, nagkaroon ng paghihinuha \nmula sa naging pagsusuri sa mga tinayang lunsarang aralin \nang lubhang pagsang-ayon na magiging sandigan ang mga \nnabuong lunsarang aralin na may sangkap lokalisasyon \nat kontekstuwalisasyon. Litaw sa nabuong aralin ang \npagsasaalang-alang sa interes ng mga mag-aaral mula sa iba’t \nibang pagsasanay na tiyak na magiging bunga ng lubusang 216The Normal Lights\nVolume 17,  No. 1 (2023)\npartisipasyon ng mga mag-aaral sa iba’t ibang gawaing \npampagkatuto. \nSa umiiral na Bagong Kadawyan o New Normal  na \nibinunga ng pandemya, malawakang reporma ang marapat na \nmaging tugon ng mga guro, paaralan, at mananaliksik para sa \niba’t ibang naghihintay na hamon. Ang pagbuo ng lokalisado \nat kontekstuwalisadong lunsarang aralin ay manipestasyon \nng pagkilala at pagpapahalaga sa pangunahing dahilan ng \npagtuturo— ang mag-aaral. \nSa mga susunod na pag-aaral at pananaliksik, \nmagandang padron ang pag-aaral sa paglikha ng polisiya \nsa mga paaralan, dibisyon, at sangay ukol sa pagpaplano \nat pagbuo ng iba’t ibang lunsarang araling nakadikit sa \nkalinangang bayan upang lalong pagtagpuin ang wika, \nkultura, at lipunan. Magandang maging inisyatibo ng bawat \nkahingian sa antas pampaaralan hanggang pandibisyon ang \npanawagang makalikha ang mga guro ng mga lunsarang \naralin upang patingkarin ang kaakuhan, kamalayan, \nkalinangan, at kasaysayan na pinagtibay ng mga inobatibo \nat makabagong pagsasanay kaugnay ng praktika at aral ng \npang-araw-araw na buhay. \n■ ■ ■\nSanggunian\nAbarquez, A. (2021). Lens of language and literature pro -\ngrams in the new normal educational setting amidst \npandemic . https://eric.ed.gov/?id=EJ1322044. \nBadayos, P.B. (2008). Metodolohiya sa pagtuturo at \npagkatuto ng/sa Filipino: Mga teorya, simulain, at \nistratehiya. Mutya Publishing House.\nBelvez, P.M. (2000). Ang sining at agham ng pagtuturo:  \nAklat sa pamamaraan ng pagtuturo ng filipino at/sa \nfilipino.  Rex Publication.217The Normal Lights\nVolume 17,  No. 1 (2023)\nConstantino, P.C. (2005). Filipino at Pagpaplanong Pang -\nwika.  Sentro ng Wikang Filipino- Diliman.\nDepartment of Education.  (2020).  DM no. 89, s. 2020 \nclarifications on the use of the most essential learning \ncompetencies (MELCs) and other related issues. \nhttps://depeddasma.edu.ph/dm-%20no-%20%20\n%2089-s-2020-clarifications-on-the-use-of-the-most-\nessential-learning-competencies-MELCs-and-%20\nother-related. \nDepartment of Education.  (2020). Filipino MELCs. De -\npartment of Education. https://drive.google.com/\nfile/d/1FzyAPihxhfVNQmeaNbxpMK2K_tvyY9KA/\nviewDepEdMELCs.\nDepartment of Education. (2016).  Gabay Pangkurikulum sa \nFilipino.\nDepartment of Education. (2020). MELCs Guidelines. \nhttps://commons.deped.gov.ph/MELCs-Guidelines.\npdf.\nDimock, M. (2019) Defining Generations: where mil -\nlennials end and generation z begins.  Pew Re -\nsearch Center. https://www.pewresearch.\norg/short-reads/2019/01/17/where-millenni -\nals-end-and-generation-z-begins/\nEvangelista, R A. (2022). Ang guro sa panahon ng pande -\nmya sa kurikulum sa pagtuturo ng filipino sa bagong \nnormal . 7 Eyes Productions Book Publishing.\nHirschman, K., at Wood, B. (2019). 21st century learners: \nChanging conceptions of knowledge, learning and \nthe child. New Zealand Annual Review of Education, \n23(1), 20-35. https://www.researchgate.net/\npublication/331102962_21st_Century_Learners_\nChanging_Conceptions_of_Knowledge_Learning_\nand_the_Child\nKapur, R. (2020). Understanding the meaning and \nsignificance of pedagogy . https://www.researchgate.218The Normal Lights\nVolume 17,  No. 1 (2023)\nnet/publication/345156519_Understanding_the_\nMeaning_and_Significance_of_Pedagogy\nOyeleke, O. (2018). Promoting effective teaching \nand learning in online environment: A blend of \npedagogical and andragogical models. Bulgarian \nJournal of Science & Education Policy, 12 (1).\nPersaud, C. (2021). Pedagogy: What educator’ s need to \nknow. Top Hat. Retrieved from https://resourced.pro -\nmetheanworld.com/pedagogy-learning-practices/\nSan Juan, D.M. (2017). Guro, Paaralan, at Bayan: maka -\nbayang pagsusuri sa kasalukuyang sistema ng edu -\nkasyon sa Pilipinas. Pambansang Samahan sa Ling -\nguwistika, at Literaturang Filipino, Ink 1 (2), 10-34. \nhttps:psllf.org/kawing-1-2/ \nVillafuerte, P.V ., at Bernales, R.A. (2008). Pagtuturo ng/sa \nFilipino: Mga Teorya at Praktika. Mutya Publishing \nHouse.\nVillanueva, V .M. (2018). #ABKD: Ako bibo kase dapat (al -\npabeto ng inobatibo at makabagong guro ng araling \npanlipunan, edukasyon sa pagpapakatao, at Filipino.  \nVMV Publishing House. ', 'raytos.r.bsinfotech@gmail.com', 'Voltaire M. Villanueva,  Joel C. Malabanan,  Rodrigo D. Abenes,  Rachel C. Payapaya, at  Julievic D. Palting', '', '../pdf_files/6726323745d23-Pagbuo_ng_Lunsarang_Aralin_at_Gawain_sa.pdf', '2024-11-06', 'Accepted'),
(156, '4503981166', '26', 5, 6, 'Pagbuo ng Lunsarang Aralin  at Gawain sa Ugnayang  Wika’t Lipunan Bilang  Interbensiyon sa Bagong  Kadawyan sa Antas Primarya', '2024-11-02', '2023', 'How to optimally persuade an agent who has a private type? When elicitation is feasible, this amounts to a fairly standard principal-agent-style mechanism design problem, where the persuader employs a mechanism to first elicit the agent’s type and then plays the corresponding persuasion strategy based on the agent’s report. The optimal mechanism design problem in this setting is relatively well-understood in the literature, with incentive compatible (IC) mechanisms known to be optimal and computationally tractable. In this paper, we study this problem given a credible agent, i.e., if the agent claims they are of a certain type in response to the mechanism’s elicitation, then they will act optimally with respect to the claimed type, even if they are actually not of that type. Wepresent several interesting findings in this new setting that differ significantly from results in the non-credible setting. In terms of the structure of optimal mechanisms, we show that not only may IC mechanisms fail to be optimal, bu', 'Bagong kadawyan,Filipino,kurikulum,lunsarang aralin,pandemya', 'Ang\nmga\nkasanayan\nay\nmarapat\nna\nangkop\nsa\npanahon\nat\nhenerasyon\nng\nmga\nmag-aaral\nupang\nlubos\nitong\nmaging\nmahalaga\n(Dimock,\n2019).\nEsensiyal\nsa\nugnayang\nkasanayang\nkomunikatibo\nang\nkaalaman\nsa\nwika\nna\nmagbibigay-kasanayan\nsa\ntalastasang\nkadikit\nng\niba\npang\nmga\ntema.\nSamakatuwid,\nmadaling\ntukuyin\nkung\npaano\nmaiisa-isa\nang\nmga\nkasanayan\nsubalit\nmapanghamon\nkung\npaano\nito\nmasisigurong\nmatatamo\nat\nmatutuhan.\nSa\nganitong\nkonteksto,\nmarapat\nna\nmaging\nmakabago\nat\ninobatibo\nang\nisang\nestratehiya\no\nanomang\npagsasanay\nupang\nbigyang-katuturan\nat\nkabuluhan\nang\nisang\nlunsarang\naralin.\nKaya,\nkapag\nnagtuturo\ntayo,\ndapat\ntayong\nmakabuo\nng\nmga\nbago\nat\nmalikhaing\nparaan\nupang\ngawing\nkapana-panabik\nat\nmakabuluhan\nang\nmga\naralin.\nSa\npanahon\nng\npandemya,\nnagkaroon\nng\nmalaking\npagba\nbago\nsa\nkung\npaano\nkami\nnagtuturo\nng\nwika\nat\nmga\nkuwento,\ntulad\nng\nipinakita\nsa\npag-aaral\nni\nGuvenc\n(2022).', 'rararararararararara@gmail.com', 'Voltaire M. Villanueva,  Joel C. Malabanan,  Rodrigo D. Abenes,  Rachel C. Payapaya, at  Julievic D. Palting', '', '../pdf_files/6726330591daa-test4.pdf', '', 'Not Accepted');
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `date_published`, `document_status`) VALUES
(157, '2811806775', '1', 1, 1, 'Persuading a Credible Agent', '2024-11-05', '2024', 'skdkdnfnfnnffegrggrgrvfvrtvteetgrgegevethgteegtethtveethvrtvtrvt tf f rtvtfvtfvyfvrybyfbyfbyfbyfy  fybrybyfvtfvtfvftrtvrtb\r\n', 'technology', 'Ang\nmga\nkasanayan\nay\nmarapat\nna\nangkop\nsa\npanahon\nat\nhenerasyon\nng\nmga\nmag-aaral\nupang\nlubos\nitong\nmaging\nmahalaga\n(Dimock,\n2019).\nEsensiyal\nsa\nugnayang\nkasanayang\nkomunikatibo\nang\nkaalaman\nsa\nwika\nna\nmagbibigay-kasanayan\nsa\ntalastasang\nkadikit\nng\niba\npang\nmga\ntema.\nSamakatuwid,\nmadaling\ntukuyin\nkung\npaano\nmaiisa-isa\nang\nmga\nkasanayan\nsubalit\nmapanghamon\nkung\npaano\nito\nmasisigurong\nmatatamo\nat\nmatutuhan.\nSa\nganitong\nkonteksto,\nmarapat\nna\nmaging\nmakabago\nat\ninobatibo\nang\nisang\nestratehiya\no\nanomang\npagsasanay\nupang\nbigyang-katuturan\nat\nkabuluhan\nang\nisang\nlunsarang\naralin.\nKaya,\nkapag\nnagtuturo\ntayo,\ndapat\ntayong\nmakabuo\nng\nmga\nbago\nat\nmalikhaing\nparaan\nupang\ngawing\nkapana-panabik\nat\nmakabuluhan\nang\nmga\naralin.\nSa\npanahon\nng\npandemya,\nnagkaroon\nng\nmalaking\npagba\nbago\nsa\nkung\npaano\nkami\nnagtuturo\nng\nwika\nat\nmga\nkuwento,\ntulad\nng\nipinakita\nsa\npag-aaral\nni\nGuvenc\n(2022).', 'raytos.r.bsinfotech@gmail.com', 'Jiarui Gan, Abheek Ghosh, Nicholas Teh', '', '../pdf_files/6729e0247be6d-test4.pdf', '', 'Not Accepted'),
(158, '1523396935', '31', 5, 5, 'Persuading a Credible Agent', '2024-11-06', '2024', 'skdkdnfnfnnffegrggrgrvfvrtvteetgrgegevethgteegtethtveethvrtvtrvt tf f rtvtfvtfvyfvrybyfbyfbyfbyfy  fybrybyfvtfvtfvftrtvrtb\r\n', 'technology,data', 'Ang\nmga\nkasanayan\nay\nmarapat\nna\nangkop\nsa\npanahon\nat\nhenerasyon\nng\nmga\nmag-aaral\nupang\nlubos\nitong\nmaging\nmahalaga\n(Dimock,\n2019).\nEsensiyal\nsa\nugnayang\nkasanayang\nkomunikatibo\nang\nkaalaman\nsa\nwika\nna\nmagbibigay-kasanayan\nsa\ntalastasang\nkadikit\nng\niba\npang\nmga\ntema.\nSamakatuwid,\nmadaling\ntukuyin\nkung\npaano\nmaiisa-isa\nang\nmga\nkasanayan\nsubalit\nmapanghamon\nkung\npaano\nito\nmasisigurong\nmatatamo\nat\nmatutuhan.\nSa\nganitong\nkonteksto,\nmarapat\nna\nmaging\nmakabago\nat\ninobatibo\nang\nisang\nestratehiya\no\nanomang\npagsasanay\nupang\nbigyang-katuturan\nat\nkabuluhan\nang\nisang\nlunsarang\naralin.\nKaya,\nkapag\nnagtuturo\ntayo,\ndapat\ntayong\nmakabuo\nng\nmga\nbago\nat\nmalikhaing\nparaan\nupang\ngawing\nkapana-panabik\nat\nmakabuluhan\nang\nmga\naralin.\nSa\npanahon\nng\npandemya,\nnagkaroon\nng\nmalaking\npagba\nbago\nsa\nkung\npaano\nkami\nnagtuturo\nng\nwika\nat\nmga\nkuwento,\ntulad\nng\nipinakita\nsa\npag-aaral\nni\nGuvenc\n(2022).', 'rarararasdad@gmail.com', 'Jiarui Gan, Abheek Ghosh, Nicholas Teh', '', '../pdf_files/672add9484391-test4.pdf', '', 'Not Accepted');

-- --------------------------------------------------------

--
-- Table structure for table `archive_research_views`
--

CREATE TABLE `archive_research_views` (
  `id` int(11) NOT NULL,
  `archive_research_id` varchar(13) NOT NULL,
  `student_id` int(11) NOT NULL,
  `date_of_views` date NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `archive_research_views`
--

INSERT INTO `archive_research_views` (`id`, `archive_research_id`, `student_id`, `date_of_views`) VALUES
(367, '2147483647', 1, '2024-10-18'),
(368, '2147483647', 1, '2024-10-18'),
(369, '2147483647', 1, '2024-10-18'),
(370, '2147483647', 1, '2024-10-18'),
(371, '2147483647', 1, '2024-10-18'),
(372, '2147483647', 1, '2024-10-18'),
(373, '2147483647', 1, '2024-10-18'),
(374, '2147483647', 1, '2024-10-18'),
(375, '2147483647', 1, '2024-10-18'),
(376, '2147483647', 1, '2024-10-18'),
(377, '2147483647', 1, '2024-10-18'),
(378, '2147483647', 1, '2024-10-18'),
(379, '2147483647', 1, '2024-10-18'),
(380, '2147483647', 1, '2024-10-18'),
(381, '2147483647', 1, '2024-10-18'),
(382, '2147483647', 1, '2024-10-18'),
(383, '2147483647', 1, '2024-10-18'),
(384, '2147483647', 1, '2024-10-18'),
(385, '2147483647', 1, '2024-10-18'),
(386, '2147483647', 1, '2024-10-18'),
(387, '2147483647', 1, '2024-10-18'),
(388, '2147483647', 1, '2024-10-18'),
(389, '2147483647', 1, '2024-10-18'),
(390, '2147483647', 1, '2024-10-18'),
(391, '2147483647', 1, '2024-10-18'),
(392, '2147483647', 1, '2024-10-18'),
(393, '2147483647', 1, '2024-10-18'),
(394, '2147483647', 1, '2024-10-18'),
(395, '2147483647', 1, '2024-10-18'),
(396, '2147483647', 1, '2024-10-18'),
(397, '2147483647', 1, '2024-10-18'),
(398, '2147483647', 1, '2024-10-18'),
(399, '2147483647', 1, '2024-10-18'),
(400, '2147483647', 1, '2024-10-18'),
(401, '2147483647', 1, '2024-10-18'),
(402, '2147483647', 1, '2024-10-18'),
(403, '2147483647', 1, '2024-10-18'),
(404, '2147483647', 1, '2024-10-18'),
(405, '2147483647', 1, '2024-10-18'),
(406, '2147483647', 1, '2024-10-18'),
(407, '2147483647', 1, '2024-10-18'),
(408, '2147483647', 1, '2024-10-18'),
(409, '2147483647', 1, '2024-10-18'),
(410, '2147483647', 1, '2024-10-18'),
(411, '2147483647', 1, '2024-10-18'),
(412, '2147483647', 1, '2024-10-18'),
(413, '2147483647', 1, '2024-10-18'),
(414, '2147483647', 1, '2024-10-18'),
(415, '2147483647', 1, '2024-10-18'),
(416, '2147483647', 1, '2024-10-18'),
(417, '2147483647', 1, '2024-10-18'),
(418, '2147483647', 1, '2024-10-18'),
(419, '2147483647', 1, '2024-10-18'),
(420, '2147483647', 1, '2024-10-18'),
(421, '2147483647', 1, '2024-10-18'),
(422, '2147483647', 1, '2024-10-18'),
(423, '2147483647', 1, '2024-10-18'),
(424, '2147483647', 1, '2024-10-18'),
(425, '2147483647', 1, '2024-10-18'),
(426, '2147483647', 1, '2024-10-18'),
(427, '2147483647', 1, '2024-10-18'),
(428, '1367181168', 1, '2024-10-18'),
(429, '1367181168', 1, '2024-10-18'),
(430, '1367181168', 1, '2024-10-18'),
(431, '1367181168', 1, '2024-10-18'),
(432, '1367181168', 1, '2024-10-18'),
(433, '1367181168', 1, '2024-10-18'),
(434, '1367181168', 1, '2024-10-18'),
(435, '1367181168', 1, '2024-10-18'),
(436, '1367181168', 1, '2024-10-18'),
(437, '1367181168', 1, '2024-10-18'),
(438, '1367181168', 1, '2024-10-18'),
(439, '1367181168', 1, '2024-10-18'),
(440, '1367181168', 1, '2024-10-18'),
(441, '1367181168', 1, '2024-10-18'),
(442, '1367181168', 1, '2024-10-18'),
(443, '1367181168', 1, '2024-10-18'),
(444, '2147483647', 1, '2024-10-19'),
(445, '2147483647', 1, '2024-10-19'),
(446, '2147483647', 1, '2024-10-19'),
(447, '1337397493', 1, '2024-10-19'),
(448, '2147483647', 1, '2024-10-19'),
(449, '2147483647', 1, '2024-10-19'),
(450, '2147483647', 1, '2024-10-19'),
(451, '2147483647', 1, '2024-10-20'),
(452, '2147483647', 1, '2024-10-20'),
(453, '2147483647', 1, '2024-10-20'),
(454, '2147483647', 1, '2024-10-20'),
(455, '2147483647', 1, '2024-10-20'),
(456, '2147483647', 1, '2024-10-20'),
(457, '2147483647', 1, '2024-10-20'),
(458, '2147483647', 1, '2024-10-20'),
(459, '2147483647', 1, '2024-10-20'),
(460, '2147483647', 1, '2024-10-20'),
(461, '2147483647', 1, '2024-10-20'),
(462, '2147483647', 1, '2024-10-20'),
(463, '2147483647', 1, '2024-10-20'),
(464, '2147483647', 1, '2024-10-20'),
(465, '2147483647', 1, '2024-10-20'),
(466, '2147483647', 1, '2024-10-20'),
(467, '2147483647', 1, '2024-10-20'),
(468, '2147483647', 1, '2024-10-20'),
(469, '2147483647', 1, '2024-10-20'),
(470, '2147483647', 1, '2024-10-20'),
(471, '2147483647', 1, '2024-10-20'),
(472, '1791740225', 1, '2024-10-20'),
(473, '2147483647', 1, '2024-10-23'),
(474, '2147483647', 1, '2024-10-23'),
(475, '2147483647', 1, '2024-10-23'),
(476, '2147483647', 1, '2024-10-23'),
(477, '2147483647', 1, '2024-10-23'),
(478, '2147483647', 1, '2024-10-23'),
(479, '1367181168', 1, '2024-10-23'),
(480, '1367181168', 1, '2024-10-23'),
(481, '2147483647', 1, '2024-10-24'),
(482, '2147483647', 1, '2024-10-24'),
(483, '2147483647', 1, '2024-10-24'),
(484, '2147483647', 1, '2024-10-24'),
(485, '2147483647', 1, '2024-10-24'),
(486, '2147483647', 1, '2024-10-24'),
(487, '2147483647', 1, '2024-10-25'),
(488, '2147483647', 1, '2024-10-25'),
(489, '2147483647', 1, '2024-10-25'),
(490, '2147483647', 1, '2024-10-25'),
(491, '2147483647', 1, '2024-10-25'),
(492, '2147483647', 1, '2024-10-25'),
(493, '2147483647', 1, '2024-10-25'),
(494, '2147483647', 1, '2024-10-25'),
(495, '2147483647', 1, '2024-10-25'),
(496, '2147483647', 1, '2024-10-25'),
(497, '2147483647', 1, '2024-10-25'),
(498, '1513286657', 1, '2024-10-25'),
(499, '1791740225', 1, '2024-10-25'),
(500, '1791740225', 1, '2024-10-25'),
(501, '1513286657', 1, '2024-10-25'),
(502, '2147483647', 1, '2024-10-26'),
(503, '1513286657', 1, '2024-10-26'),
(504, '2147483647', 1, '2024-10-26'),
(505, '1513286657', 1, '2024-10-26'),
(506, '1513286657', 1, '2024-10-26'),
(507, '1513286657', 1, '2024-10-26'),
(508, '2147483647', 1, '2024-10-26'),
(509, '2147483647', 1, '2024-10-26'),
(510, '2147483647', 1, '2024-10-26'),
(511, '2147483647', 1, '2024-10-26'),
(512, '2147483647', 1, '2024-10-26'),
(513, '2147483647', 1, '2024-10-26'),
(514, '2147483647', 1, '2024-10-26'),
(515, '2147483647', 1, '2024-10-26'),
(516, '2147483647', 1, '2024-10-26'),
(517, '2147483647', 1, '2024-10-26'),
(518, '2147483647', 1, '2024-10-26'),
(519, '2147483647', 1, '2024-10-26'),
(520, '2147483647', 1, '2024-10-26'),
(521, '2147483647', 1, '2024-10-26'),
(522, '2147483647', 1, '2024-10-26'),
(523, '2147483647', 1, '2024-10-26'),
(524, '2147483647', 1, '2024-10-26'),
(525, '2147483647', 1, '2024-10-26'),
(526, '2147483647', 1, '2024-10-26'),
(527, '2147483647', 1, '2024-10-26'),
(528, '5345625905', 1, '2024-10-26'),
(529, '5345625905', 1, '2024-10-26'),
(530, '5345625905', 1, '2024-10-26'),
(531, '5345625905', 1, '2024-10-26'),
(532, '5345625905', 1, '2024-10-26'),
(533, '5345625905', 1, '2024-10-26'),
(534, '5345625905', 1, '2024-10-26'),
(535, '5345625905', 1, '2024-10-26'),
(536, '5345625905', 1, '2024-10-26'),
(537, '5345625905', 1, '2024-10-26'),
(538, '5345625905', 1, '2024-10-26'),
(539, '5345625905', 1, '2024-10-26'),
(540, '5345625905', 1, '2024-10-26'),
(541, '5345625905', 1, '2024-10-26'),
(542, '5345625905', 1, '2024-10-26'),
(543, '5345625905', 1, '2024-10-26'),
(544, '5345625905', 1, '2024-10-26'),
(545, '5345625905', 1, '2024-10-26'),
(546, '5345625905', 1, '2024-10-26'),
(547, '5345625905', 1, '2024-10-26'),
(548, '5118052229', 1, '2024-10-26'),
(549, '5118052229', 1, '2024-10-26'),
(550, '5118052229', 1, '2024-10-26'),
(551, '5118052229', 1, '2024-10-26'),
(552, '5118052229', 1, '2024-10-26'),
(553, '5118052229', 1, '2024-10-26'),
(554, '5118052229', 1, '2024-10-26'),
(555, '5118052229', 1, '2024-10-26'),
(556, '5118052229', 1, '2024-10-26'),
(557, '5118052229', 1, '2024-10-26'),
(558, '5118052229', 1, '2024-10-26'),
(559, '5118052229', 1, '2024-10-26'),
(560, '5118052229', 1, '2024-10-26'),
(561, '5118052229', 1, '2024-10-26'),
(562, '5118052229', 1, '2024-10-26'),
(563, '5118052229', 1, '2024-10-26'),
(564, '5118052229', 1, '2024-10-26'),
(565, '5118052229', 1, '2024-10-26'),
(566, '5118052229', 1, '2024-10-26'),
(567, '5118052229', 1, '2024-10-26'),
(568, '5118052229', 1, '2024-10-26'),
(569, '5118052229', 1, '2024-10-26'),
(570, '5118052229', 1, '2024-10-26'),
(571, '5118052229', 1, '2024-10-26'),
(572, '5118052229', 1, '2024-10-26'),
(573, '5118052229', 1, '2024-10-26'),
(574, '9936450399', 1, '2024-10-26'),
(575, '9936450399', 1, '2024-10-26'),
(576, '9936450399', 1, '2024-10-26'),
(577, '9936450399', 1, '2024-10-26'),
(578, '9936450399', 1, '2024-10-26'),
(579, '9936450399', 1, '2024-10-26'),
(580, '9936450399', 1, '2024-10-26'),
(581, '9936450399', 1, '2024-10-26'),
(582, '9936450399', 1, '2024-10-26'),
(583, '9936450399', 1, '2024-10-26'),
(584, '9936450399', 1, '2024-10-26'),
(585, '9936450399', 1, '2024-10-26'),
(586, '9936450399', 1, '2024-10-26'),
(587, '9936450399', 1, '2024-10-26'),
(588, '9936450399', 1, '2024-10-26'),
(589, '9936450399', 1, '2024-10-26'),
(590, '9936450399', 1, '2024-10-26'),
(591, '9936450399', 1, '2024-10-26'),
(592, '9936450399', 1, '2024-10-26'),
(593, '9936450399', 1, '2024-10-26'),
(594, '9936450399', 1, '2024-10-26'),
(595, '9936450399', 1, '2024-10-26'),
(596, '9936450399', 1, '2024-10-26'),
(597, '9936450399', 1, '2024-10-26'),
(598, '9936450399', 1, '2024-10-26'),
(599, '9936450399', 1, '2024-10-26'),
(600, '9936450399', 1, '2024-10-26'),
(601, '9936450399', 1, '2024-10-26'),
(602, '9936450399', 1, '2024-10-26'),
(603, '9936450399', 1, '2024-10-26'),
(604, '9936450399', 1, '2024-10-26'),
(605, '1510283503', 1, '2024-10-26'),
(606, '1510283503', 1, '2024-10-26'),
(607, '1510283503', 1, '2024-10-26'),
(608, '1510283503', 1, '2024-10-26'),
(609, '1510283503', 1, '2024-10-26'),
(610, '1510283503', 1, '2024-10-26'),
(611, '1510283503', 1, '2024-10-26'),
(612, '1510283503', 1, '2024-10-26'),
(613, '1510283503', 1, '2024-10-26'),
(614, '1510283503', 1, '2024-10-26'),
(615, '1510283503', 1, '2024-10-26'),
(616, '1510283503', 1, '2024-10-26'),
(617, '1510283503', 1, '2024-10-26'),
(618, '1510283503', 1, '2024-10-26'),
(619, '1510283503', 1, '2024-10-26'),
(620, '1510283503', 1, '2024-10-26'),
(621, '1510283503', 1, '2024-10-26'),
(622, '1510283503', 1, '2024-10-26'),
(623, '1510283503', 1, '2024-10-26'),
(624, '1510283503', 1, '2024-10-26'),
(625, '1510283503', 1, '2024-10-26'),
(626, '1510283503', 1, '2024-10-26'),
(627, '1510283503', 1, '2024-10-26'),
(628, '1510283503', 1, '2024-10-26'),
(629, '1510283503', 1, '2024-10-26'),
(630, '1510283503', 1, '2024-10-26'),
(631, '1510283503', 1, '2024-10-26'),
(632, '1510283503', 1, '2024-10-26'),
(633, '1510283503', 1, '2024-10-26'),
(634, '1510283503', 1, '2024-10-26'),
(635, '1510283503', 1, '2024-10-26'),
(636, '1510283503', 1, '2024-10-26'),
(637, '1510283503', 1, '2024-10-26'),
(638, '1510283503', 1, '2024-10-26'),
(639, '1510283503', 1, '2024-10-26'),
(640, '1510283503', 1, '2024-10-26'),
(641, '1510283503', 1, '2024-10-26'),
(642, '1510283503', 1, '2024-10-26'),
(643, '1510283503', 1, '2024-10-26'),
(644, '1510283503', 1, '2024-10-26'),
(645, '1510283503', 1, '2024-10-26'),
(646, '9848906603', 1, '2024-10-26'),
(647, '9848906603', 1, '2024-10-26'),
(648, '9848906603', 1, '2024-10-26'),
(649, '9848906603', 1, '2024-10-26'),
(650, '9848906603', 1, '2024-10-26'),
(651, '9848906603', 1, '2024-10-26'),
(652, '9848906603', 1, '2024-10-26'),
(653, '9848906603', 1, '2024-10-26'),
(654, '9848906603', 1, '2024-10-26'),
(655, '9848906603', 1, '2024-10-26'),
(656, '9848906603', 1, '2024-10-26'),
(657, '9848906603', 1, '2024-10-26'),
(658, '9848906603', 1, '2024-10-26'),
(659, '9848906603', 1, '2024-10-26'),
(660, '9848906603', 1, '2024-10-26'),
(661, '9848906603', 1, '2024-10-26'),
(662, '9848906603', 1, '2024-10-26'),
(663, '9848906603', 1, '2024-10-26'),
(664, '9848906603', 1, '2024-10-26'),
(665, '9848906603', 1, '2024-10-26'),
(666, '9848906603', 1, '2024-10-26'),
(667, '9848906603', 1, '2024-10-26'),
(668, '9848906603', 1, '2024-10-26'),
(669, '9848906603', 1, '2024-10-26'),
(670, '9848906603', 1, '2024-10-26'),
(671, '9848906603', 1, '2024-10-26'),
(672, '9848906603', 1, '2024-10-26'),
(673, '9848906603', 1, '2024-10-26'),
(674, '9848906603', 1, '2024-10-26'),
(675, '9848906603', 1, '2024-10-26'),
(676, '9848906603', 1, '2024-10-26'),
(677, '9848906603', 1, '2024-10-26'),
(678, '9848906603', 1, '2024-10-26'),
(679, '9848906603', 1, '2024-10-26'),
(680, '9848906603', 1, '2024-10-26'),
(681, '9848906603', 1, '2024-10-26'),
(682, '9848906603', 1, '2024-10-26'),
(683, '9848906603', 1, '2024-10-26'),
(684, '9848906603', 1, '2024-10-26'),
(685, '9848906603', 1, '2024-10-26'),
(686, '9848906603', 1, '2024-10-26'),
(687, '9848906603', 1, '2024-10-26'),
(688, '9848906603', 1, '2024-10-26'),
(689, '9848906603', 1, '2024-10-26'),
(690, '9848906603', 1, '2024-10-26'),
(691, '9848906603', 1, '2024-10-26'),
(692, '9848906603', 1, '2024-10-26'),
(693, '9848906603', 1, '2024-10-26'),
(694, '9848906603', 1, '2024-10-26'),
(695, '9848906603', 1, '2024-10-26'),
(696, '9848906603', 1, '2024-10-26'),
(697, '9848906603', 1, '2024-10-26'),
(698, '9848906603', 1, '2024-10-26'),
(699, '9848906603', 1, '2024-10-26'),
(700, '9848906603', 1, '2024-10-26'),
(701, '9848906603', 1, '2024-10-26'),
(702, '9848906603', 1, '2024-10-26'),
(703, '9848906603', 1, '2024-10-26'),
(704, '9848906603', 1, '2024-10-26'),
(705, '9848906603', 1, '2024-10-26'),
(706, '9848906603', 1, '2024-10-26'),
(707, '9848906603', 1, '2024-10-26'),
(708, '9848906603', 1, '2024-10-26'),
(709, '9848906603', 1, '2024-10-26'),
(710, '9848906603', 1, '2024-10-26'),
(711, '9848906603', 1, '2024-10-26'),
(712, '9848906603', 1, '2024-10-26'),
(713, '9848906603', 1, '2024-10-26'),
(714, '9848906603', 1, '2024-10-26'),
(715, '9848906603', 1, '2024-10-26'),
(716, '9848906603', 1, '2024-10-26'),
(717, '9848906603', 1, '2024-10-26'),
(718, '9848906603', 1, '2024-10-26'),
(719, '9848906603', 1, '2024-10-26'),
(720, '2903777565', 1, '2024-10-26'),
(721, '2903777565', 1, '2024-10-26'),
(722, '2903777565', 1, '2024-10-26'),
(723, '2903777565', 1, '2024-10-26'),
(724, '2903777565', 1, '2024-10-26'),
(725, '2903777565', 1, '2024-10-26'),
(726, '2903777565', 1, '2024-10-26'),
(727, '3500495012', 1, '2024-10-26'),
(728, '3500495012', 1, '2024-10-26'),
(729, '3500495012', 1, '2024-10-26'),
(730, '3500495012', 1, '2024-10-26'),
(731, '3500495012', 1, '2024-10-26'),
(732, '3500495012', 1, '2024-10-26'),
(733, '3500495012', 1, '2024-10-26'),
(734, '3500495012', 1, '2024-10-26'),
(735, '3500495012', 1, '2024-10-26'),
(736, '3500495012', 1, '2024-10-26'),
(737, '3500495012', 1, '2024-10-26'),
(738, '3500495012', 1, '2024-10-26'),
(739, '3500495012', 1, '2024-10-26'),
(740, '2724633467', 1, '2024-10-26'),
(741, '2724633467', 1, '2024-10-26'),
(742, '2724633467', 1, '2024-10-26'),
(743, '2724633467', 1, '2024-10-26'),
(744, '2724633467', 1, '2024-10-26'),
(745, '2724633467', 1, '2024-10-26'),
(746, '2724633467', 1, '2024-10-26'),
(747, '2724633467', 1, '2024-10-26'),
(748, '2724633467', 1, '2024-10-26'),
(749, '2724633467', 1, '2024-10-26'),
(750, '2724633467', 1, '2024-10-26'),
(751, '2724633467', 1, '2024-10-26'),
(752, '2724633467', 1, '2024-10-26'),
(753, '2724633467', 1, '2024-10-26'),
(754, '2724633467', 1, '2024-10-26'),
(755, '2724633467', 1, '2024-10-26'),
(756, '2724633467', 1, '2024-10-26'),
(757, '2724633467', 1, '2024-10-26'),
(758, '2724633467', 1, '2024-10-26'),
(759, '2724633467', 1, '2024-10-26'),
(760, '2724633467', 1, '2024-10-26'),
(761, '5483354843', 1, '2024-10-26'),
(762, '5483354843', 1, '2024-10-26'),
(763, '5483354843', 1, '2024-10-26'),
(764, '5483354843', 1, '2024-10-26'),
(765, '5483354843', 1, '2024-10-26'),
(766, '5483354843', 1, '2024-10-26'),
(767, '5483354843', 1, '2024-10-26'),
(768, '5483354843', 1, '2024-10-26'),
(769, '5483354843', 1, '2024-10-26'),
(770, '5483354843', 1, '2024-10-26'),
(771, '5483354843', 1, '2024-10-26'),
(772, '5483354843', 1, '2024-10-26'),
(773, '5483354843', 1, '2024-10-26'),
(774, '5483354843', 1, '2024-10-26'),
(775, '5483354843', 1, '2024-10-26'),
(776, '5483354843', 1, '2024-10-26'),
(777, '5483354843', 1, '2024-10-26'),
(778, '5483354843', 1, '2024-10-26'),
(779, '5483354843', 1, '2024-10-26'),
(780, '5483354843', 1, '2024-10-26'),
(781, '5483354843', 1, '2024-10-26'),
(782, '5483354843', 1, '2024-10-26'),
(783, '5483354843', 1, '2024-10-26'),
(784, '5483354843', 1, '2024-10-26'),
(785, '5483354843', 1, '2024-10-26'),
(786, '5483354843', 1, '2024-10-26'),
(787, '5483354843', 1, '2024-10-26'),
(788, '5483354843', 1, '2024-10-26'),
(789, '5483354843', 1, '2024-10-26'),
(790, '5483354843', 1, '2024-10-26'),
(791, '5483354843', 1, '2024-10-26'),
(792, '5483354843', 1, '2024-10-26'),
(793, '5483354843', 1, '2024-10-26'),
(794, '5483354843', 1, '2024-10-26'),
(795, '5483354843', 1, '2024-10-26'),
(796, '5483354843', 1, '2024-10-26'),
(797, '5483354843', 1, '2024-10-26'),
(798, '2724633467', 1, '2024-10-26'),
(799, '2724633467', 1, '2024-10-26'),
(800, '2724633467', 1, '2024-10-26'),
(801, '2724633467', 1, '2024-10-26'),
(802, '2724633467', 1, '2024-10-26'),
(803, '2724633467', 1, '2024-10-26'),
(804, '2724633467', 1, '2024-10-26'),
(805, '2724633467', 1, '2024-10-26'),
(806, '2724633467', 1, '2024-10-26'),
(807, '2724633467', 1, '2024-10-26'),
(808, '2724633467', 1, '2024-10-26'),
(809, '2724633467', 1, '2024-10-26'),
(810, '2724633467', 1, '2024-10-26'),
(811, '2724633467', 1, '2024-10-26'),
(812, '2724633467', 1, '2024-10-26'),
(813, '2724633467', 1, '2024-10-26'),
(814, '2724633467', 1, '2024-10-26'),
(815, '2724633467', 1, '2024-10-26'),
(816, '5483354843', 1, '2024-10-26'),
(817, '2903777565', 1, '2024-10-28'),
(818, '8870456450', 26, '2024-10-31'),
(819, '6630943655', 26, '2024-11-01'),
(820, '3344063245', 26, '2024-11-02'),
(821, '4154877948', 26, '2024-11-02'),
(822, '2341628535', 1, '2024-11-02'),
(823, '5253047250', 1, '2024-11-02'),
(824, '9415845918', 1, '2024-11-02'),
(825, '9749167622', 1, '2024-11-02'),
(826, '3015686003', 1, '2024-11-02'),
(827, '3015686003', 1, '2024-11-02'),
(828, '3015686003', 1, '2024-11-02'),
(829, '2724633467', 26, '2024-11-04'),
(830, '4503981166', 26, '2024-11-04'),
(831, '9848906603', 1, '2024-11-04'),
(832, '5477905649', 1, '2024-11-04'),
(833, '5477905649', 1, '2024-11-04'),
(834, '5477905649', 1, '2024-11-04'),
(835, '5477905649', 1, '2024-11-04'),
(836, '5477905649', 1, '2024-11-04'),
(837, '5477905649', 1, '2024-11-04'),
(838, '5477905649', 1, '2024-11-04'),
(839, '5477905649', 1, '2024-11-04'),
(840, '5477905649', 1, '2024-11-04'),
(841, '2724633467', 27, '2024-11-04'),
(842, '2724633467', 27, '2024-11-04'),
(843, '7538355660', 1, '2024-11-04'),
(844, '7538355660', 1, '2024-11-05'),
(845, '5345625905', 1, '2024-11-05'),
(846, '5253047250', 1, '2024-11-05'),
(847, '5253047250', 1, '2024-11-05'),
(848, '5253047250', 1, '2024-11-05'),
(849, '5253047250', 1, '2024-11-05'),
(850, '9848906603', 1, '2024-11-05');

-- --------------------------------------------------------

--
-- Table structure for table `course`
--

CREATE TABLE `course` (
  `id` int(11) NOT NULL,
  `department_id` int(11) NOT NULL,
  `course_name` varchar(250) NOT NULL,
  `course_status` varchar(80) NOT NULL DEFAULT 'Active'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `course`
--

INSERT INTO `course` (`id`, `department_id`, `course_name`, `course_status`) VALUES
(1, 1, 'BS Information Technology', 'Active'),
(2, 1, 'BS Computer Science', 'Active'),
(3, 3, 'BSIT Major in Food Technology', 'Active'),
(4, 2, 'BS Architecture', 'Active'),
(5, 5, 'BSBA Major in Marketing Management', 'Active'),
(6, 5, 'BS Office Administration', 'Active'),
(7, 4, 'BS Computer Engineering', 'Not Activated'),
(8, 4, 'BS Civil Engineering', 'Not Activated'),
(9, 6, 'BS Secondary Education Major in TLE', 'Active'),
(10, 6, 'BTLE Major in Home Economics', 'Active'),
(11, 4, 'BS Electronics and Communication Engineering', 'Not Activated'),
(12, 4, 'BS Electronics Engineering', 'Active'),
(13, 4, 'BS Electrical Engineering', 'Active'),
(14, 7, 'BS Hospitality Management', 'Active'),
(15, 1, 'BS Psychology', 'Active'),
(16, 1, 'BS Mathematics', 'Active'),
(17, 6, 'Bachelor in Special Needs Education', 'Active'),
(18, 8, 'BS Criminology', 'Active'),
(19, 5, 'BS Public Administration', 'Active'),
(20, 7, 'BS Hospitality Management Major in Hotel Management', 'Active'),
(21, 7, 'BS Hospitality Management Major in Culinary Arts', 'Active'),
(22, 7, 'BS Hospitality Management Major in Cruise Line Operations', 'Active'),
(23, 2, 'Bachelor of Fine Arts Major in Visual Communication', 'Active'),
(24, 6, 'BTLE Major in Industrial Arts', 'Active'),
(25, 10, 'BS Computer Technology', 'Active');

-- --------------------------------------------------------

--
-- Table structure for table `departments`
--

CREATE TABLE `departments` (
  `id` int(11) NOT NULL,
  `dept_code` varchar(50) NOT NULL,
  `name` varchar(150) NOT NULL,
  `description` varchar(1000) NOT NULL,
  `department_status` varchar(20) NOT NULL DEFAULT 'Active'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `departments`
--

INSERT INTO `departments` (`id`, `dept_code`, `name`, `description`, `department_status`) VALUES
(1, 'CAS', 'College of Arts and Science', '', 'Active'),
(2, 'CAFA', 'College of Architecture and Fine Arts', '', 'Active'),
(3, 'CIT', 'College of Industrial Technology', '', 'Active'),
(4, 'CEN', 'College of Engineering', '', 'Not Activated'),
(5, 'CBPA', 'College of Business and Public Administration', '', 'Active'),
(6, 'COE', 'College of Education', '', 'Active'),
(7, 'CHM', 'College of Hospitality Management', '', 'Active'),
(8, 'CCJE', 'College of Criminology and Justice Education', '', 'Active'),
(10, 'CCS', 'College of Computer Studies', '', 'Not Activated');

-- --------------------------------------------------------

--
-- Table structure for table `plagiarism_results`
--

CREATE TABLE `plagiarism_results` (
  `id` int(11) NOT NULL,
  `archive_id` int(11) NOT NULL,
  `submitted_sentence` text NOT NULL,
  `existing_sentence` text NOT NULL,
  `similar_archive_id` int(11) NOT NULL,
  `similarity_percentage` float NOT NULL,
  `is_plagiarized` tinyint(1) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `plagiarism_results`
--

INSERT INTO `plagiarism_results` (`id`, `archive_id`, `submitted_sentence`, `existing_sentence`, `similar_archive_id`, `similarity_percentage`, `is_plagiarized`) VALUES
(952, 151, 'information design or bayesian persuasion models scenarios where a principal strategically re veals her private information to incentivize an agent to play preferred actions', '1 introduction information design or bayesian persuasion  models scenarios where a principal strategically re-veals her private information to incentivize an agent to pla y preferred actions', 150, 88.1267, 1),
(953, 151, 'for instance a seller may want to reveal only partial details about her products to incentivize an agent to buy a particular one or a school may want to issue only coarse grades to improve its students job outcomes boleslavsky and cotton 2015 kamenica 2019 ostrovsky and schwarz 2010', 'for instance a seller may want to reveal only partial details about her prod ucts to incentivize an agent to buy a particular one or a school may want to issue only coarse gra des to improve its students job outcomes  boleslavsky and cotton 2015kamenica 2019ostrovsky and schwarz 2010', 150, 82.5248, 1),
(954, 151, 'the characterization also result in an efficient algorithm to compute optimal mechanisms thereby highlighting both the computational and utility benefits they offer', 'the characterization also result in an eﬃcient algorithm to compute optimal mechanisms thereby h ighlighting both the computational and utility beneﬁts they oﬀer', 150, 61.8616, 1),
(955, 151, 'additionally we provide matching hardness results that emerge when these additional design choices are not employed thereby highlighting their computational benefitsthe standard information design model assumes that the principal knows the utility func tion of the agent kamenica and gentzkow 2011 which may not hold in practice', 'the standard information design model assumes that the prin cipal knows the utility func-tion of the agent  kamenica and gentzkow 2011 which may not hold in practice', 150, 66.3342, 1),
(956, 151, 'additionally we provide matching hardness results that emerge when these additional design choices are not employed thereby highlighting their computational benefitsthe standard information design model assumes that the principal knows the utility func tion of the agent kamenica and gentzkow 2011 which may not hold in practice', 'additionally we provide matc hing hardness results that emerge when these additional design choices are not employed ther eby highlighting their computational beneﬁts', 150, 54.6868, 1),
(957, 151, 'numerous works subsequently study a model where the principal does not know the agents type but has a prior over it alonso and cˆ amara 2018 bernasconi et al 2023 castiglioni et al 2020 2022 2023 gill and sgroi 2008 kolotilin et al 2017 perez-richet 2014', 'numerous works subsequently study a model where the principal does no t know the agents type but has a prior over it  alonso and cˆ amara 2018bernasconi et al', 150, 62.3734, 1),
(958, 151, 'the principal may try to design the signaling scheme ie strategically reveal her private information to maximize her expected utility given only this prior', 'the principal may try to design the signaling scheme ie strategically reveal her priva te information to maximize her expected utility given only this prior', 150, 89.0953, 1),
(959, 151, 'another possibly better alternative for the principal if feasible is to ask the agent to reveal his type before the principal sends her signal through an elicitation process', 'another possibly better al ternative for the principal if feasible is to ask the agent to reveal his type before the principal sends her signal through an elicitation process', 150, 89.7723, 1),
(960, 151, 'in this case the agent may be credible ie take actions consistent with his reported type or be non-credible ie report any type and then play any possibly inconsistent action afterward 1 essentially cheap talk', 'in this case the agent may be credible ie take actions consistent with his reported type or benon-credible  ie report any type and then play any possibly inconsist ent action afterward 1essentially cheap talk', 150, 82.2546, 1),
(961, 151, 'in this paper we study such scenarios with a particular focus on credible agents', 'in this paper we study such scen arios with a particular focus on credible agents', 150, 78.3927, 1),
(962, 151, 'it necessitates additional design choices that would be unnecessary when the agent is non-credible', 'it necessitates additional design choices that would be unnecessary when th e agent is non-credible', 150, 91.6953, 1),
(963, 151, 'we introduce novel stages in the mechanism design and provide non-trivial examples to demonstrate strict payoff improvements they achieve', 'we introduce novel stages in the mechanism design and provide non-trivia l examples to demonstrate strict payoﬀ improvements they achieve', 150, 81.1479, 1),
(964, 151, 'moreover we characterize optimal mechanisms under these additional design choices and prove the general optimaility they lead to', 'moreover we characterize opti mal mechanisms under these additional design choices and prove the general optimaility they lead t o', 150, 83.2223, 1),
(965, 153, 'information design or bayesian persuasion models scenarios where a principal strategically re veals her private information to incentivize an agent to play preferred actions', 'information design or bayesian persuasion models scenarios where a principal strategically re veals her private information to incentivize an agent to play preferred actions', 151, 100, 1),
(966, 153, 'for instance a seller may want to reveal only partial details about her products to incentivize an agent to buy a particular one or a school may want to issue only coarse grades to improve its students job outcomes boleslavsky and cotton 2015 kamenica 2019 ostrovsky and schwarz 2010', 'for instance a seller may want to reveal only partial details about her products to incentivize an agent to buy a particular one or a school may want to issue only coarse grades to improve its students job outcomes boleslavsky and cotton 2015 kamenica 2019 ostrovsky and schwarz 2010', 151, 100, 1),
(967, 153, 'the characterization also result in an efficient algorithm to compute optimal mechanisms thereby highlighting both the computational and utility benefits they offer', 'the characterization also result in an efficient algorithm to compute optimal mechanisms thereby highlighting both the computational and utility benefits they offer', 151, 100, 1),
(968, 153, 'additionally we provide matching hardness results that emerge when these additional design choices are not employed thereby highlighting their computational benefitsthe standard information design model assumes that the principal knows the utility func tion of the agent kamenica and gentzkow 2011 which may not hold in practice', 'additionally we provide matching hardness results that emerge when these additional design choices are not employed thereby highlighting their computational benefitsthe standard information design model assumes that the principal knows the utility func tion of the agent kamenica and gentzkow 2011 which may not hold in practice', 151, 100, 1),
(969, 153, 'numerous works subsequently study a model where the principal does not know the agents type but has a prior over it alonso and cˆ amara 2018 bernasconi et al 2023 castiglioni et al 2020 2022 2023 gill and sgroi 2008 kolotilin et al 2017 perez-richet 2014', 'numerous works subsequently study a model where the principal does not know the agents type but has a prior over it alonso and cˆ amara 2018 bernasconi et al 2023 castiglioni et al 2020 2022 2023 gill and sgroi 2008 kolotilin et al 2017 perez-richet 2014', 151, 100, 1),
(970, 153, 'the principal may try to design the signaling scheme ie strategically reveal her private information to maximize her expected utility given only this prior', 'the principal may try to design the signaling scheme ie strategically reveal her private information to maximize her expected utility given only this prior', 151, 100, 1),
(971, 153, 'another possibly better alternative for the principal if feasible is to ask the agent to reveal his type before the principal sends her signal through an elicitation process', 'another possibly better alternative for the principal if feasible is to ask the agent to reveal his type before the principal sends her signal through an elicitation process', 151, 100, 1),
(972, 153, 'practicability or the need that laws not demand the impossible is likewise a relational concept but it refers to the relationship between a laws substantive requirements permits or prohibitions and a persons ability to actin this case the agent may be credible ie take actions consistent with his reported type or be non-credible ie report any type and then play any possibly inconsistent action afterward 1 essentially cheap talk', 'in this case the agent may be credible ie take actions consistent with his reported type or be non-credible ie report any type and then play any possibly inconsistent action afterward 1 essentially cheap talk', 151, 71.9582, 1),
(973, 153, 'in this paper we study such scenarios with a particular focus on credible agents', 'in this paper we study such scenarios with a particular focus on credible agents', 151, 100, 1),
(974, 153, 'it necessitates additional design choices that would be unnecessary when the agent is non-credible', 'it necessitates additional design choices that would be unnecessary when the agent is non-credible', 151, 100, 1),
(975, 153, 'we introduce novel stages in the mechanism design and provide non-trivial examples to demonstrate strict payoff improvements they achieve', 'we introduce novel stages in the mechanism design and provide non-trivial examples to demonstrate strict payoff improvements they achieve', 151, 100, 1),
(976, 153, 'moreover we characterize optimal mechanisms under these additional design choices and prove the general optimaility they lead to', 'moreover we characterize optimal mechanisms under these additional design choices and prove the general optimaility they lead to', 151, 100, 1),
(977, 156, 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 154, 100, 1),
(978, 156, 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 154, 100, 1),
(979, 156, 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 154, 100, 1),
(980, 156, 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 154, 100, 1),
(981, 156, 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 'kaugnay ng reporma ukol sa melcs ang ilang mga pag-aaral sa kalakaran ng pagtuturo ng wika at panitikan sa panahon ng pandemya', 154, 50.7514, 1),
(982, 156, 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 'sa pag-aaral ni guvenc 2022 malaking pagbabago sa kalakaran ng pagtuturo sa wika at panitikan dulot ng pandemya', 154, 58.8674, 1),
(983, 157, 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 156, 100, 1),
(984, 157, 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 156, 100, 1),
(985, 157, 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 156, 100, 1),
(986, 157, 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 156, 100, 1),
(987, 157, 'kaya kapag nagtuturo tayo dapat tayong makabuo ng mga bago at malikhaing paraan upang gawing kapana-panabik at makabuluhan ang mga aralin', 'kaya kapag nagtuturo tayo dapat tayong makabuo ng mga bago at malikhaing paraan upang gawing kapana-panabik at makabuluhan ang mga aralin', 156, 100, 1),
(988, 157, 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 156, 100, 1),
(989, 158, 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 154, 100, 1),
(990, 158, 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 156, 100, 1),
(991, 158, 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 'ang mga kasanayan ay marapat na angkop sa panahon at henerasyon ng mga mag-aaral upang lubos itong maging mahalaga dimock 2019', 157, 100, 1),
(992, 158, 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 154, 100, 1),
(993, 158, 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 156, 100, 1),
(994, 158, 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 'esensiyal sa ugnayang kasanayang komunikatibo ang kaalaman sa wika na magbibigay-kasanayan sa talastasang kadikit ng iba pang mga tema', 157, 100, 1),
(995, 158, 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 154, 100, 1),
(996, 158, 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 156, 100, 1),
(997, 158, 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 'samakatuwid madaling tukuyin kung paano maiisa-isa ang mga kasanayan subalit mapanghamon kung paano ito masisigurong matatamo at matutuhan', 157, 100, 1),
(998, 158, 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 154, 100, 1),
(999, 158, 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 156, 100, 1),
(1000, 158, 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 'sa ganitong konteksto marapat na maging makabago at inobatibo ang isang estratehiya o anomang pagsasanay upang bigyang-katuturan at kabuluhan ang isang lunsarang aralin', 157, 100, 1),
(1001, 158, 'kaya kapag nagtuturo tayo dapat tayong makabuo ng mga bago at malikhaing paraan upang gawing kapana-panabik at makabuluhan ang mga aralin', 'kaya kapag nagtuturo tayo dapat tayong makabuo ng mga bago at malikhaing paraan upang gawing kapana-panabik at makabuluhan ang mga aralin', 156, 100, 1),
(1002, 158, 'kaya kapag nagtuturo tayo dapat tayong makabuo ng mga bago at malikhaing paraan upang gawing kapana-panabik at makabuluhan ang mga aralin', 'kaya kapag nagtuturo tayo dapat tayong makabuo ng mga bago at malikhaing paraan upang gawing kapana-panabik at makabuluhan ang mga aralin', 157, 100, 1),
(1003, 158, 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 'kaugnay ng reporma ukol sa melcs ang ilang mga pag-aaral sa kalakaran ng pagtuturo ng wika at panitikan sa panahon ng pandemya', 154, 52.2003, 1),
(1004, 158, 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 'sa pag-aaral ni guvenc 2022 malaking pagbabago sa kalakaran ng pagtuturo sa wika at panitikan dulot ng pandemya', 154, 59.5076, 1),
(1005, 158, 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 156, 100, 1),
(1006, 158, 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 'sa panahon ng pandemya nagkaroon ng malaking pagba bago sa kung paano kami nagtuturo ng wika at mga kuwento tulad ng ipinakita sa pag-aaral ni guvenc 2022', 157, 100, 1);

-- --------------------------------------------------------

--
-- Table structure for table `plagiarism_summary`
--

CREATE TABLE `plagiarism_summary` (
  `id` int(11) NOT NULL,
  `archive_id` int(11) NOT NULL,
  `similar_archive_id` int(11) NOT NULL,
  `plagiarism_percentage` float NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `plagiarism_summary`
--

INSERT INTO `plagiarism_summary` (`id`, `archive_id`, `similar_archive_id`, `plagiarism_percentage`) VALUES
(26, 151, 150, 84.2907),
(27, 153, 151, 83.7113),
(28, 156, 154, 84.9365),
(29, 157, 156, 100),
(30, 158, 157, 285.285);

-- --------------------------------------------------------

--
-- Table structure for table `students_data`
--

CREATE TABLE `students_data` (
  `id` int(11) NOT NULL,
  `department_id` int(11) NOT NULL,
  `course_id` int(11) NOT NULL,
  `student_id` varchar(20) NOT NULL,
  `first_name` varchar(70) NOT NULL,
  `middle_name` varchar(70) NOT NULL,
  `last_name` varchar(70) NOT NULL,
  `phone_number` varchar(15) NOT NULL,
  `student_email` varchar(200) NOT NULL,
  `student_password` varchar(200) NOT NULL,
  `profile_picture` varchar(200) DEFAULT NULL,
  `verification_code` int(8) NOT NULL,
  `verify_status` varchar(80) NOT NULL DEFAULT 'Not Verified',
  `school_verify` varchar(100) NOT NULL DEFAULT 'For Approval'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `students_data`
--

INSERT INTO `students_data` (`id`, `department_id`, `course_id`, `student_id`, `first_name`, `middle_name`, `last_name`, `phone_number`, `student_email`, `student_password`, `profile_picture`, `verification_code`, `verify_status`, `school_verify`) VALUES
(1, 1, 1, '214-01311M', 'Rolly', '', 'Raytos', '912312312', 'raytos.r.bsinfotech@gmail.com', '21232f297a57a5a743894a0e4a801fc3', '../imageFiles/6725a1ade8774-aiahsopretty.jpg', 669682, 'Verified', 'Approved'),
(2, 1, 1, '214-01312M', 'Rolly', '', 'Raytos', '912312312', 'raytos.bsinfotech@gmail.com', '21232f297a57a5a743894a0e4a801fc3', '../imageFiles/6725bd10cad43-user-account.png', 969922, 'Verified', 'Approved'),
(24, 3, 3, '214-01313M', 'Alex Jonas', '', 'David', '912312312', 'alexjonasdavid@gmail.com', '21232f297a57a5a743894a0e4a801fc3', '../imageFiles/6725bcf289504-user-account.png', 373056, 'Verified', 'Approved'),
(26, 5, 6, '214-01314M', 'thankss', 'mmgmmm', 'awwe', '912312312', 'rararararararararara@gmail.com', '21232f297a57a5a743894a0e4a801fc3', '../imageFiles/6724741c47115-aiah ineffable beauty.jpg', 977284, 'Verified', 'Approved'),
(29, 8, 18, '214-01316M', 'Rolly', '', 'Raytos', '912312312', 'awawaw@gmail.com', 'c5292975de7059d632489fa881f9f920', NULL, 951945, 'Verified', 'Approved'),
(30, 5, 6, '214-01317M', 'Cha ', '', 'Paningbstsn', '09123456789', 'paningbatan.c.bsinfotech@gmail.com', '2637a5c30af69a7bad877fdb65fbd78b', NULL, 604135, 'Verified', 'Approved'),
(31, 5, 5, '214-01319M', 'Maddie', '', 'Pia', '912312312', 'rarararasdad@gmail.com', 'c5292975de7059d632489fa881f9f920', NULL, 578644, 'Verified', 'Approved');

-- --------------------------------------------------------

--
-- Table structure for table `system_notification`
--

CREATE TABLE `system_notification` (
  `id` int(11) NOT NULL,
  `student_id` int(12) NOT NULL,
  `logs` varchar(200) NOT NULL,
  `logs_date` varchar(50) NOT NULL,
  `logs_time` varchar(50) NOT NULL,
  `status` varchar(100) NOT NULL DEFAULT 'Unread'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `system_notification`
--

INSERT INTO `system_notification` (`id`, `student_id`, `logs`, `logs_date`, `logs_time`, `status`) VALUES
(1, 1, 'You successfully logged in to your account.', 'January / 03 Wednesday / 2024', '9:00 PM', 'Read'),
(2, 1, 'You successfully logged out to your account.', 'January / 03 Wednesday / 2024', '9:10 PM', 'Read'),
(3, 1, 'You successfully logged in to your account.', 'January / 03 Wednesday / 2024', '10:00 PM', 'Read'),
(4, 3, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:31 AM', 'Unread'),
(5, 3, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:36 AM', 'Unread'),
(6, 3, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:41 AM', 'Unread'),
(7, 3, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:43 AM', 'Unread'),
(8, 3, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:46 AM', 'Unread'),
(9, 3, 'You successfully submitted your research paper.', 'January / 04 Thursday / 2024', '7:47 AM', 'Unread'),
(10, 3, 'You successfully logged out to your account.', 'January / 04 Thursday / 2024', '7:49 AM', 'Unread'),
(11, 4, 'You successfully logged in to your account.', 'January / 04 Thursday / 2024', '7:54 AM', 'Unread'),
(12, 4, 'You successfully logged out to your account.', 'January / 04 Thursday / 2024', '8:09 AM', 'Unread'),
(13, 1, 'You successfully logged in to your account.', 'January / 06 Saturday / 2024', '3:39 PM', 'Read'),
(14, 8, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '2:58 PM', 'Unread'),
(15, 8, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '2:59 PM', 'Unread'),
(16, 8, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:00 PM', 'Unread'),
(17, 8, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:01 PM', 'Unread'),
(18, 11, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:21 PM', 'Unread'),
(19, 11, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:21 PM', 'Unread'),
(20, 11, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:22 PM', 'Unread'),
(21, 11, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:22 PM', 'Unread'),
(22, 11, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:29 PM', 'Unread'),
(23, 11, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:29 PM', 'Unread'),
(24, 11, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:32 PM', 'Unread'),
(25, 11, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:32 PM', 'Unread'),
(26, 11, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:32 PM', 'Unread'),
(27, 11, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:32 PM', 'Unread'),
(28, 13, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:37 PM', 'Unread'),
(29, 13, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:38 PM', 'Unread'),
(30, 1, 'You successfully logged in to your account.', 'January / 07 Sunday / 2024', '3:39 PM', 'Read'),
(31, 1, 'You successfully logged out to your account.', 'January / 07 Sunday / 2024', '3:44 PM', 'Read'),
(32, 1, 'You successfully logged in to your account.', 'January / 18 Thursday / 2024', '9:40 PM', 'Read'),
(33, 1, 'Profile picture updated successfully.', 'January / 18 Thursday / 2024', '9:44 PM', 'Read'),
(34, 12, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '1:47 PM', 'Read'),
(35, 12, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '1:51 PM', 'Read'),
(36, 12, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '2:12 PM', 'Read'),
(37, 12, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '2:17 PM', 'Read'),
(38, 12, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '2:49 PM', 'Read'),
(39, 12, 'You successfully logged in to your account.', 'January / 24 Wednesday / 2024', '10:09 PM', 'Read'),
(40, 12, 'You successfully logged in to your account.', 'January / 25 Thursday / 2024', '2:31 PM', 'Unread'),
(41, 12, 'You successfully submitted your research paper.', 'January / 25 Thursday / 2024', '2:53 PM', 'Unread'),
(42, 12, 'You successfully submitted your research paper.', 'January / 25 Thursday / 2024', '2:55 PM', 'Unread'),
(43, 12, 'You successfully submitted your research paper.', 'January / 25 Thursday / 2024', '3:22 PM', 'Unread'),
(44, 12, 'You successfully logged out to your account.', 'January / 25 Thursday / 2024', '3:24 PM', 'Unread'),
(45, 14, 'You successfully logged in to your account.', 'January / 25 Thursday / 2024', '3:25 PM', 'Unread'),
(46, 14, 'You successfully submitted your research paper.', 'January / 25 Thursday / 2024', '3:25 PM', 'Unread'),
(47, 14, 'You successfully logged out to your account.', 'January / 25 Thursday / 2024', '3:26 PM', 'Unread'),
(48, 12, 'You successfully logged in to your account.', 'January / 25 Thursday / 2024', '10:58 PM', 'Unread'),
(49, 12, 'You successfully logged in to your account.', 'January / 25 Thursday / 2024', '11:24 PM', 'Unread'),
(50, 12, 'You successfully submitted your research paper.', 'January / 25 Thursday / 2024', '11:24 PM', 'Unread'),
(51, 12, 'You successfully logged in to your account.', 'January / 26 Friday / 2024', '5:03 PM', 'Unread'),
(52, 22, 'You successfully logged in to your account.', 'September / 21 Saturday / 2024', '6:29 PM', 'Read'),
(53, 22, 'You successfully logged out to your account.', 'September / 21 Saturday / 2024', '7:21 PM', 'Read'),
(54, 22, 'You successfully logged in to your account.', 'September / 21 Saturday / 2024', '8:02 PM', 'Read'),
(55, 22, 'You successfully submitted your research paper.', 'September / 21 Saturday / 2024', '8:03 PM', 'Read'),
(56, 22, 'You successfully logged in to your account.', 'September / 24 Tuesday / 2024', '10:22 AM', 'Read'),
(57, 22, 'You successfully logged out to your account.', 'September / 24 Tuesday / 2024', '10:23 AM', 'Read'),
(58, 22, 'You successfully logged in to your account.', 'September / 24 Tuesday / 2024', '10:35 AM', 'Read'),
(59, 22, 'You successfully logged out to your account.', 'September / 24 Tuesday / 2024', '10:37 AM', 'Read'),
(60, 22, 'You successfully logged in to your account.', 'October / 04 Friday / 2024', '11:46 AM', 'Read'),
(61, 22, 'You successfully logged in to your account.', 'October / 07 Monday / 2024', '8:29 PM', 'Read'),
(62, 22, 'You successfully logged in to your account.', 'October / 08 Tuesday / 2024', '9:49 AM', 'Read'),
(63, 22, 'You successfully logged in to your account.', 'October / 08 Tuesday / 2024', '8:00 PM', 'Read'),
(64, 22, 'You successfully logged in to your account.', 'October / 09 Wednesday / 2024', '3:11 PM', 'Read'),
(65, 22, 'You successfully logged in to your account.', 'October / 09 Wednesday / 2024', '8:16 PM', 'Read'),
(66, 22, 'You successfully logged in to your account.', 'October / 10 Thursday / 2024', '2:33 PM', 'Read'),
(67, 22, 'You successfully logged out to your account.', 'October / 10 Thursday / 2024', '2:35 PM', 'Read'),
(68, 22, 'You successfully logged in to your account.', 'October / 10 Thursday / 2024', '2:35 PM', 'Read'),
(69, 22, 'You successfully logged in to your account.', 'October / 10 Thursday / 2024', '7:55 PM', 'Read'),
(70, 22, 'You successfully logged out to your account.', 'October / 10 Thursday / 2024', '10:36 PM', 'Read'),
(71, 22, 'You successfully logged in to your account.', 'October / 10 Thursday / 2024', '10:38 PM', 'Read'),
(72, 22, 'You successfully logged in to your account.', 'October / 11 Friday / 2024', '3:30 PM', 'Read'),
(73, 22, 'You successfully logged out to your account.', 'October / 11 Friday / 2024', '4:57 PM', 'Read'),
(74, 22, 'You successfully logged in to your account.', 'October / 11 Friday / 2024', '5:08 PM', 'Read'),
(75, 22, 'You successfully logged in to your account.', 'October / 11 Friday / 2024', '5:57 PM', 'Read'),
(76, 22, 'You successfully logged in to your account.', 'October / 11 Friday / 2024', '8:30 PM', 'Read'),
(77, 22, 'Profile picture updated successfully.', 'October / 11 Friday / 2024', '9:55 PM', 'Read'),
(78, 22, 'Profile picture updated successfully.', 'October / 11 Friday / 2024', '9:57 PM', 'Read'),
(79, 22, 'Profile picture updated successfully.', 'October / 11 Friday / 2024', '9:57 PM', 'Read'),
(80, 22, 'You successfully logged in to your account.', 'October / 12 Saturday / 2024', '2:01 PM', 'Read'),
(81, 22, 'You successfully updated your information.', 'October / 12 Saturday / 2024', '4:27 PM', 'Read'),
(82, 22, 'You successfully updated your information.', 'October / 12 Saturday / 2024', '4:32 PM', 'Read'),
(83, 22, 'You successfully logged in to your account.', 'October / 12 Saturday / 2024', '4:41 PM', 'Read'),
(84, 22, 'You successfully logged out to your account.', 'October / 12 Saturday / 2024', '4:44 PM', 'Read'),
(85, 22, 'You successfully logged in to your account.', 'October / 12 Saturday / 2024', '4:44 PM', 'Read'),
(86, 22, 'You successfully updated your information.', 'October / 12 Saturday / 2024', '5:00 PM', 'Read'),
(87, 22, 'You successfully updated your information.', 'October / 12 Saturday / 2024', '5:04 PM', 'Read'),
(88, 22, 'You successfully updated your password.', 'October / 12 Saturday / 2024', '5:14 PM', 'Read'),
(89, 22, 'You successfully logged in to your account.', 'October / 12 Saturday / 2024', '8:56 PM', 'Read'),
(90, 22, 'You successfully logged out to your account.', 'October / 12 Saturday / 2024', '11:55 PM', 'Read'),
(91, 22, 'You successfully logged in to your account.', 'October / 13 Sunday / 2024', '3:17 PM', 'Read'),
(92, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:19 PM', 'Read'),
(93, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:22 PM', 'Read'),
(94, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:26 PM', 'Read'),
(95, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:27 PM', 'Read'),
(96, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:27 PM', 'Read'),
(97, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:27 PM', 'Read'),
(98, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:28 PM', 'Read'),
(99, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:30 PM', 'Read'),
(100, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:30 PM', 'Read'),
(101, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:33 PM', 'Read'),
(102, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:34 PM', 'Read'),
(103, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '3:37 PM', 'Read'),
(104, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '4:30 PM', 'Read'),
(105, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '4:33 PM', 'Read'),
(106, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '4:38 PM', 'Read'),
(107, 22, 'You successfully logged in to your account.', 'October / 13 Sunday / 2024', '5:30 PM', 'Read'),
(108, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:32 PM', 'Read'),
(109, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:34 PM', 'Read'),
(110, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:37 PM', 'Read'),
(111, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:37 PM', 'Read'),
(112, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:38 PM', 'Read'),
(113, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:38 PM', 'Read'),
(114, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:49 PM', 'Read'),
(115, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:49 PM', 'Read'),
(116, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:50 PM', 'Read'),
(117, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:50 PM', 'Read'),
(118, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:52 PM', 'Read'),
(119, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:52 PM', 'Read'),
(120, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:53 PM', 'Read'),
(121, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:53 PM', 'Read'),
(122, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:57 PM', 'Read'),
(123, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '5:57 PM', 'Read'),
(124, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '6:03 PM', 'Read'),
(125, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '6:03 PM', 'Read'),
(126, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '6:05 PM', 'Read'),
(127, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '6:05 PM', 'Read'),
(128, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '6:13 PM', 'Read'),
(129, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '6:27 PM', 'Read'),
(130, 22, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '6:29 PM', 'Read'),
(131, 22, 'You successfully logged out to your account.', 'October / 13 Sunday / 2024', '6:56 PM', 'Read'),
(132, 22, 'You successfully logged in to your account.', 'October / 13 Sunday / 2024', '7:08 PM', 'Read'),
(133, 22, 'You successfully logged out to your account.', 'October / 13 Sunday / 2024', '8:20 PM', 'Read'),
(134, 22, 'You successfully logged in to your account.', 'October / 13 Sunday / 2024', '8:45 PM', 'Read'),
(135, 22, 'You successfully logged out to your account.', 'October / 13 Sunday / 2024', '9:05 PM', 'Read'),
(136, 23, 'You successfully logged in to your account.', 'October / 13 Sunday / 2024', '9:27 PM', 'Read'),
(137, 23, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '9:28 PM', 'Read'),
(138, 23, 'You successfully submitted your research paper.', 'October / 13 Sunday / 2024', '9:29 PM', 'Read'),
(139, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '1:29 PM', 'Read'),
(140, 22, 'You successfully logged out to your account.', 'October / 14 Monday / 2024', '1:33 PM', 'Read'),
(141, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '1:46 PM', 'Read'),
(142, 22, 'You successfully submitted your research paper.', 'October / 14 Monday / 2024', '1:47 PM', 'Read'),
(143, 22, 'You successfully submitted your research paper.', 'October / 14 Monday / 2024', '1:50 PM', 'Read'),
(144, 22, 'You successfully submitted your research paper.', 'October / 14 Monday / 2024', '1:53 PM', 'Read'),
(145, 22, 'You successfully submitted your research paper.', 'October / 14 Monday / 2024', '1:58 PM', 'Read'),
(146, 22, 'You successfully submitted your research paper.', 'October / 14 Monday / 2024', '2:59 PM', 'Read'),
(147, 22, 'You successfully submitted your research paper.', 'October / 14 Monday / 2024', '3:01 PM', 'Read'),
(148, 22, 'You successfully submitted your research paper.', 'October / 14 Monday / 2024', '3:05 PM', 'Read'),
(149, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '8:07 PM', 'Read'),
(150, 22, 'You successfully logged out to your account.', 'October / 14 Monday / 2024', '8:47 PM', 'Read'),
(151, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:29 PM', 'Read'),
(152, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:31 PM', 'Read'),
(153, 23, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:37 PM', 'Unread'),
(154, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:37 PM', 'Read'),
(155, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:39 PM', 'Read'),
(156, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:40 PM', 'Read'),
(157, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:40 PM', 'Read'),
(158, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:41 PM', 'Read'),
(159, 22, 'You successfully logged in to your account.', 'October / 14 Monday / 2024', '9:46 PM', 'Read'),
(160, 22, 'You successfully updated your password.', 'October / 14 Monday / 2024', '10:51 PM', 'Read'),
(161, 22, 'You successfully updated your password.', 'October / 14 Monday / 2024', '10:52 PM', 'Read'),
(162, 22, 'You successfully updated your information.', 'October / 14 Monday / 2024', '10:53 PM', 'Read'),
(163, 22, 'You successfully updated your information.', 'October / 14 Monday / 2024', '10:53 PM', 'Read'),
(164, 22, 'You successfully logged out to your account.', 'October / 14 Monday / 2024', '11:05 PM', 'Unread'),
(165, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:25 PM', 'Unread'),
(166, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:25 PM', 'Unread'),
(167, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:27 PM', 'Unread'),
(168, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:30 PM', 'Unread'),
(169, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:32 PM', 'Unread'),
(170, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:41 PM', 'Unread'),
(171, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:43 PM', 'Unread'),
(172, 22, 'You successfully logged out to your account.', 'October / 17 Thursday / 2024', '4:44 PM', 'Unread'),
(173, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:44 PM', 'Unread'),
(174, 22, 'You successfully logged out to your account.', 'October / 17 Thursday / 2024', '4:46 PM', 'Unread'),
(175, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:46 PM', 'Unread'),
(176, 22, 'You successfully logged out to your account.', 'October / 17 Thursday / 2024', '4:46 PM', 'Unread'),
(177, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '4:47 PM', 'Unread'),
(178, 22, 'You successfully logged in to your account.', 'October / 17 Thursday / 2024', '10:41 PM', 'Unread'),
(179, 22, 'You successfully logged out to your account.', 'October / 17 Thursday / 2024', '10:43 PM', 'Unread'),
(180, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '4:41 PM', 'Read'),
(181, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '4:44 PM', 'Read'),
(182, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '4:48 PM', 'Read'),
(183, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '4:58 PM', 'Read'),
(184, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '5:04 PM', 'Read'),
(185, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '9:33 PM', 'Read'),
(186, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '9:34 PM', 'Read'),
(187, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '9:37 PM', 'Read'),
(188, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '9:42 PM', 'Read'),
(189, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '9:44 PM', 'Read'),
(190, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '9:45 PM', 'Read'),
(191, 1, 'You successfully logged out to your account.', 'October / 18 Friday / 2024', '9:45 PM', 'Read'),
(192, 1, 'You successfully logged in to your account.', 'October / 18 Friday / 2024', '10:48 PM', 'Read'),
(193, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '10:48 PM', 'Read'),
(194, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '10:48 PM', 'Read'),
(195, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '10:51 PM', 'Read'),
(196, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '10:56 PM', 'Read'),
(197, 1, 'You successfully submitted your research paper.', 'October / 18 Friday / 2024', '11:00 PM', 'Read'),
(198, 1, 'You successfully logged out to your account.', 'October / 18 Friday / 2024', '11:31 PM', 'Read'),
(199, 1, 'You successfully logged in to your account.', 'October / 19 Saturday / 2024', '3:32 PM', 'Read'),
(200, 1, 'You successfully submitted your research paper.', 'October / 19 Saturday / 2024', '3:32 PM', 'Read'),
(201, 2, 'You successfully logged in to your account.', 'October / 19 Saturday / 2024', '5:26 PM', 'Unread'),
(202, 2, 'You successfully submitted your research paper.', 'October / 19 Saturday / 2024', '5:27 PM', 'Unread'),
(203, 1, 'You successfully logged in to your account.', 'October / 19 Saturday / 2024', '11:00 PM', 'Read'),
(204, 1, 'You successfully submitted your research paper.', 'October / 19 Saturday / 2024', '11:01 PM', 'Read'),
(205, 1, 'You successfully submitted your research paper.', 'October / 19 Saturday / 2024', '11:03 PM', 'Read'),
(206, 1, 'You successfully submitted your research paper.', 'October / 19 Saturday / 2024', '11:06 PM', 'Read'),
(207, 1, 'You successfully submitted your research paper.', 'October / 19 Saturday / 2024', '11:08 PM', 'Read'),
(208, 1, 'You successfully logged in to your account.', 'October / 20 Sunday / 2024', '4:50 PM', 'Read'),
(209, 1, 'You successfully logged in to your account.', 'October / 20 Sunday / 2024', '4:53 PM', 'Read'),
(210, 1, 'You successfully logged in to your account.', 'October / 23 Wednesday / 2024', '10:53 PM', 'Read'),
(211, 1, 'You successfully logged in to your account.', 'October / 24 Thursday / 2024', '3:08 PM', 'Read'),
(212, 1, 'You successfully logged out to your account.', 'October / 24 Thursday / 2024', '4:23 PM', 'Read'),
(213, 1, 'You successfully logged in to your account.', 'October / 25 Friday / 2024', '3:05 PM', 'Read'),
(214, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:34 PM', 'Read'),
(215, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:37 PM', 'Read'),
(216, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:40 PM', 'Read'),
(217, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:42 PM', 'Read'),
(218, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:43 PM', 'Read'),
(219, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:44 PM', 'Read'),
(220, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:46 PM', 'Read'),
(221, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:47 PM', 'Read'),
(222, 1, 'You successfully submitted your research paper.', 'October / 25 Friday / 2024', '3:48 PM', 'Read'),
(223, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '9:28 AM', 'Read'),
(224, 1, 'You successfully logged out to your account.', 'October / 26 Saturday / 2024', '10:11 AM', 'Read'),
(225, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '10:14 AM', 'Read'),
(226, 1, 'You successfully logged out to your account.', 'October / 26 Saturday / 2024', '10:53 AM', 'Read'),
(227, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '10:53 AM', 'Read'),
(228, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '3:32 PM', 'Read'),
(229, 1, 'You successfully logged out to your account.', 'October / 26 Saturday / 2024', '3:44 PM', 'Read'),
(230, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '3:44 PM', 'Read'),
(231, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '3:45 PM', 'Read'),
(232, 1, 'You successfully logged out to your account.', 'October / 26 Saturday / 2024', '3:50 PM', 'Read'),
(233, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '3:54 PM', 'Read'),
(234, 1, 'You successfully logged in to your account.', 'October / 26 Saturday / 2024', '5:13 PM', 'Read'),
(235, 1, 'You successfully logged in to your account.', 'October / 28 Monday / 2024', '9:56 PM', 'Read'),
(236, 1, 'You successfully logged out to your account.', 'October / 28 Monday / 2024', '10:29 PM', 'Read'),
(237, 1, 'You successfully logged in to your account.', 'October / 28 Monday / 2024', '10:53 PM', 'Read'),
(238, 1, 'You successfully logged out to your account.', 'October / 28 Monday / 2024', '10:55 PM', 'Read'),
(239, 1, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '7:37 AM', 'Read'),
(240, 1, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '8:54 AM', 'Read'),
(241, 1, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '12:09 PM', 'Read'),
(242, 1, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '12:09 PM', 'Read'),
(243, 1, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '6:38 PM', 'Read'),
(244, 1, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '6:38 PM', 'Read'),
(245, 1, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '8:06 PM', 'Read'),
(246, 1, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '8:06 PM', 'Read'),
(247, 24, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '8:06 PM', 'Unread'),
(248, 24, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '9:58 PM', 'Unread'),
(249, 24, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '10:00 PM', 'Unread'),
(250, 214, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '10:08 PM', 'Unread'),
(251, 214, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '10:12 PM', 'Unread'),
(252, 24, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '10:13 PM', 'Unread'),
(253, 24, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '10:13 PM', 'Unread'),
(254, 214, 'You successfully logged in to your account.', 'October / 30 Wednesday / 2024', '10:17 PM', 'Unread'),
(255, 214, 'alexjonasdavid@gmail.com + ', 'October / 30 Wednesday / 2024', '10:24 PM', 'Unread'),
(256, 214, 'alexjonasdavid@gmail.com + alexjonasdavid@gmail.com', 'October / 30 Wednesday / 2024', '10:31 PM', 'Unread'),
(257, 214, 'alexjonasdavid@gmail.com + alexjonasdavid@gmail.com', 'October / 30 Wednesday / 2024', '10:32 PM', 'Unread'),
(258, 214, 'alexjonasdavid@gmail.com', 'October / 30 Wednesday / 2024', '10:34 PM', 'Unread'),
(259, 3, 'alexjonasdavid@gmail.com', 'October / 30 Wednesday / 2024', '10:41 PM', 'Unread'),
(260, 24, 'alexjonasdavid@gmail.com', 'October / 30 Wednesday / 2024', '10:52 PM', 'Unread'),
(261, 24, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '10:53 PM', 'Unread'),
(262, 24, 'alexjonasdavid@gmail.com', 'October / 30 Wednesday / 2024', '10:55 PM', 'Unread'),
(263, 24, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '10:58 PM', 'Unread'),
(264, 24, 'alexjonasdavid@gmail.com', 'October / 30 Wednesday / 2024', '11:03 PM', 'Unread'),
(265, 24, 'You successfully logged out to your account.', 'October / 30 Wednesday / 2024', '11:10 PM', 'Unread'),
(266, 25, 'You successfully logged in to your account.', 'October / 31 Thursday / 2024', '11:13 PM', 'Unread'),
(267, 25, 'You successfully logged out to your account.', 'October / 31 Thursday / 2024', '11:14 PM', 'Unread'),
(268, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:54 PM', 'Read'),
(269, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:57 PM', 'Read'),
(270, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:58 PM', 'Read'),
(271, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(272, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(273, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(274, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(275, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(276, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(277, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(278, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(279, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(280, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(281, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(282, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(283, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(284, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(285, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(286, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(287, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(288, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(289, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(290, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(291, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(292, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(293, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(294, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(295, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(296, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(297, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(298, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(299, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(300, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(301, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(302, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(303, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(304, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(305, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(306, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(307, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(308, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(309, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(310, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(311, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(312, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(313, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(314, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(315, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(316, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(317, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(318, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(319, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(320, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(321, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(322, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(323, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(324, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(325, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(326, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(327, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(328, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(329, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(330, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(331, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(332, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(333, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(334, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(335, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(336, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(337, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(338, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(339, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(340, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(341, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(342, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(343, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(344, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(345, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(346, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(347, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(348, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(349, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(350, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(351, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(352, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(353, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(354, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(355, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(356, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(357, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(358, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(359, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(360, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(361, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(362, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(363, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(364, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(365, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(366, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(367, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(368, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(369, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(370, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(371, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(372, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(373, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(374, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(375, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(376, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(377, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(378, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(379, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(380, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(381, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(382, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(383, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(384, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(385, 26, 'You successfully updated your information.', 'October / 31 Thursday / 2024', '11:59 PM', 'Read'),
(386, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:00 AM', 'Read'),
(387, 26, 'You successfully logged in to your account.', 'November / 01 Friday / 2024', '10:42 AM', 'Read'),
(388, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:04 PM', 'Read'),
(389, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:38 PM', 'Read'),
(390, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:40 PM', 'Read'),
(391, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:42 PM', 'Read'),
(392, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:42 PM', 'Read'),
(393, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:42 PM', 'Read'),
(394, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:43 PM', 'Read'),
(395, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:45 PM', 'Read'),
(396, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:48 PM', 'Read'),
(397, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:48 PM', 'Read'),
(398, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '12:51 PM', 'Read'),
(399, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:02 PM', 'Read'),
(400, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:03 PM', 'Read'),
(401, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:05 PM', 'Read'),
(402, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:05 PM', 'Read'),
(403, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:06 PM', 'Read'),
(404, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:07 PM', 'Read'),
(405, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(406, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(407, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(408, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(409, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(410, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(411, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(412, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(413, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(414, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(415, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(416, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(417, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(418, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(419, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(420, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(421, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(422, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(423, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(424, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(425, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(426, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(427, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(428, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(429, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(430, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(431, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(432, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(433, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(434, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(435, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(436, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(437, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(438, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(439, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(440, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(441, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(442, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(443, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(444, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(445, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(446, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(447, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(448, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(449, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(450, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(451, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(452, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(453, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(454, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(455, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(456, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(457, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(458, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(459, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(460, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:09 PM', 'Read'),
(461, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:10 PM', 'Read'),
(462, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:10 PM', 'Read'),
(463, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:15 PM', 'Read'),
(464, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:15 PM', 'Read'),
(465, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:17 PM', 'Read'),
(466, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:18 PM', 'Read'),
(467, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:18 PM', 'Read'),
(468, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:24 PM', 'Read');
INSERT INTO `system_notification` (`id`, `student_id`, `logs`, `logs_date`, `logs_time`, `status`) VALUES
(469, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:24 PM', 'Read'),
(470, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:24 PM', 'Read'),
(471, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:33 PM', 'Read'),
(472, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:34 PM', 'Read'),
(473, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:37 PM', 'Read'),
(474, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:38 PM', 'Read'),
(475, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:38 PM', 'Read'),
(476, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:38 PM', 'Read'),
(477, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:39 PM', 'Read'),
(478, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:39 PM', 'Read'),
(479, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:41 PM', 'Read'),
(480, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:42 PM', 'Read'),
(481, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:43 PM', 'Read'),
(482, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:45 PM', 'Read'),
(483, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:46 PM', 'Read'),
(484, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:52 PM', 'Read'),
(485, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:53 PM', 'Read'),
(486, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:55 PM', 'Read'),
(487, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '1:55 PM', 'Read'),
(488, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '2:04 PM', 'Read'),
(489, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '2:04 PM', 'Read'),
(490, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '2:04 PM', 'Unread'),
(491, 26, 'You successfully updated your information.', 'November / 01 Friday / 2024', '2:04 PM', 'Unread'),
(492, 26, 'Profile picture updated successfully.', 'November / 01 Friday / 2024', '2:24 PM', 'Unread'),
(493, 26, 'Profile picture updated successfully.', 'November / 01 Friday / 2024', '2:24 PM', 'Unread'),
(494, 26, 'Profile picture updated successfully.', 'November / 01 Friday / 2024', '2:24 PM', 'Unread'),
(495, 26, 'Profile picture updated successfully.', 'November / 01 Friday / 2024', '2:24 PM', 'Unread'),
(496, 26, 'You successfully logged out to your account.', 'November / 01 Friday / 2024', '2:25 PM', 'Unread'),
(497, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '11:39 AM', 'Read'),
(498, 1, 'Profile picture updated successfully.', 'November / 02 Saturday / 2024', '11:51 AM', 'Read'),
(499, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '11:51 AM', 'Read'),
(500, 26, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:11 PM', 'Unread'),
(501, 26, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '12:18 PM', 'Unread'),
(502, 26, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '12:18 PM', 'Unread'),
(503, 26, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:24 PM', 'Unread'),
(504, 26, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '12:25 PM', 'Unread'),
(505, 26, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:37 PM', 'Unread'),
(506, 26, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '12:38 PM', 'Unread'),
(507, 26, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '12:39 PM', 'Unread'),
(508, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:41 PM', 'Read'),
(509, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '12:41 PM', 'Read'),
(510, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:58 PM', 'Read'),
(511, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '12:58 PM', 'Read'),
(512, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '12:59 PM', 'Read'),
(513, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '1:00 PM', 'Read'),
(514, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:04 PM', 'Read'),
(515, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '1:04 PM', 'Read'),
(516, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:07 PM', 'Read'),
(517, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '1:08 PM', 'Read'),
(518, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:16 PM', 'Read'),
(519, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '1:17 PM', 'Read'),
(520, 24, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:47 PM', 'Unread'),
(521, 24, 'Profile picture updated successfully.', 'November / 02 Saturday / 2024', '1:47 PM', 'Unread'),
(522, 24, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '1:47 PM', 'Unread'),
(523, 2, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '1:47 PM', 'Unread'),
(524, 2, 'Profile picture updated successfully.', 'November / 02 Saturday / 2024', '1:48 PM', 'Unread'),
(525, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '6:47 PM', 'Read'),
(526, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '6:50 PM', 'Read'),
(527, 26, 'rararararararararara@gmail.com', 'November / 02 Saturday / 2024', '8:29 PM', 'Unread'),
(528, 26, 'rararararararararara@gmail.com', 'November / 02 Saturday / 2024', '8:31 PM', 'Unread'),
(529, 26, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '8:38 PM', 'Unread'),
(530, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:33 PM', 'Read'),
(531, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '9:33 PM', 'Read'),
(532, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '9:34 PM', 'Read'),
(533, 26, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:34 PM', 'Unread'),
(534, 26, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '9:35 PM', 'Unread'),
(535, 26, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '9:35 PM', 'Unread'),
(536, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:35 PM', 'Read'),
(537, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '9:36 PM', 'Read'),
(538, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:49 PM', 'Read'),
(539, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '9:49 PM', 'Read'),
(540, 26, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:49 PM', 'Unread'),
(541, 26, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '9:50 PM', 'Unread'),
(542, 26, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '9:50 PM', 'Unread'),
(543, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:50 PM', 'Read'),
(544, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '9:50 PM', 'Read'),
(545, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '9:55 PM', 'Read'),
(546, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '9:57 PM', 'Read'),
(547, 26, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '9:57 PM', 'Unread'),
(548, 26, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '9:57 PM', 'Unread'),
(549, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '10:06 PM', 'Read'),
(550, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '10:07 PM', 'Read'),
(551, 1, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '10:10 PM', 'Read'),
(552, 1, 'You successfully logged out to your account.', 'November / 02 Saturday / 2024', '10:11 PM', 'Read'),
(553, 26, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '10:11 PM', 'Unread'),
(554, 26, 'You successfully submitted your research paper.', 'November / 02 Saturday / 2024', '10:11 PM', 'Unread'),
(555, 1, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '10:15 PM', 'Read'),
(556, 24, 'You successfully logged in to your account.', 'November / 02 Saturday / 2024', '11:06 PM', 'Unread'),
(557, 1, 'You successfully logged in to your account.', 'November / 03 Sunday / 2024', '11:29 AM', 'Read'),
(558, 1, 'You successfully logged out to your account.', 'November / 03 Sunday / 2024', '1:19 PM', 'Read'),
(559, 26, 'You successfully logged in to your account.', 'November / 03 Sunday / 2024', '1:19 PM', 'Unread'),
(560, 1, 'You successfully logged in to your account.', 'November / 03 Sunday / 2024', '2:57 PM', 'Read'),
(561, 1, 'You successfully logged out to your account.', 'November / 03 Sunday / 2024', '5:04 PM', 'Read'),
(562, 1, 'You successfully logged in to your account.', 'November / 03 Sunday / 2024', '5:10 PM', 'Read'),
(563, 1, 'You successfully logged out to your account.', 'November / 03 Sunday / 2024', '6:03 PM', 'Read'),
(564, 1, 'You successfully logged in to your account.', 'November / 03 Sunday / 2024', '6:17 PM', 'Read'),
(565, 1, 'You successfully logged out to your account.', 'November / 03 Sunday / 2024', '6:17 PM', 'Read'),
(566, 1, 'You successfully logged in to your account.', 'November / 03 Sunday / 2024', '6:19 PM', 'Read'),
(567, 1, 'You successfully logged out to your account.', 'November / 03 Sunday / 2024', '6:19 PM', 'Read'),
(568, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '10:46 AM', 'Read'),
(569, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '10:53 AM', 'Read'),
(570, 24, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '1:09 PM', 'Unread'),
(571, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '1:22 PM', 'Read'),
(572, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '1:54 PM', 'Read'),
(573, 26, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '7:51 PM', 'Unread'),
(574, 26, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:09 PM', 'Unread'),
(575, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:09 PM', 'Read'),
(576, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:13 PM', 'Read'),
(577, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:14 PM', 'Read'),
(578, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:20 PM', 'Read'),
(579, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:43 PM', 'Read'),
(580, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:43 PM', 'Read'),
(581, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:43 PM', 'Read'),
(582, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:44 PM', 'Read'),
(583, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:44 PM', 'Read'),
(584, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:44 PM', 'Read'),
(585, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:44 PM', 'Read'),
(586, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:46 PM', 'Read'),
(587, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '9:56 PM', 'Read'),
(588, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '9:57 PM', 'Read'),
(589, 27, 'Profile picture updated successfully.', 'November / 04 Monday / 2024', '10:11 PM', 'Read'),
(590, 27, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '10:11 PM', 'Read'),
(591, 29, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '11:51 PM', 'Unread'),
(592, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '11:51 PM', 'Read'),
(593, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '11:52 PM', 'Read'),
(594, 1, 'You successfully logged in to your account.', 'November / 04 Monday / 2024', '11:54 PM', 'Read'),
(595, 1, 'You successfully logged out to your account.', 'November / 04 Monday / 2024', '11:54 PM', 'Read'),
(596, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '10:32 AM', 'Read'),
(597, 1, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '10:42 AM', 'Read'),
(598, 27, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:17 AM', 'Read'),
(599, 27, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '11:17 AM', 'Read'),
(600, 27, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:18 AM', 'Read'),
(601, 27, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '11:19 AM', 'Unread'),
(602, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:43 AM', 'Read'),
(603, 24, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:47 AM', 'Unread'),
(604, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '5:04 PM', 'Read'),
(605, 1, 'You successfully submitted your research paper.', 'November / 05 Tuesday / 2024', '5:06 PM', 'Read'),
(606, 1, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '5:08 PM', 'Read'),
(607, 30, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '5:12 PM', 'Unread'),
(608, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '5:14 PM', 'Read'),
(609, 1, 'You successfully logged out to your account.', 'November / 05 Tuesday / 2024', '5:49 PM', 'Read'),
(610, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '10:00 PM', 'Read'),
(611, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '10:26 PM', 'Unread'),
(612, 1, 'You successfully logged in to your account.', 'November / 05 Tuesday / 2024', '11:16 PM', 'Unread'),
(613, 31, 'You successfully submitted your research paper.', 'November / 06 Wednesday / 2024', '11:08 AM', 'Unread'),
(614, 31, 'You successfully logged out to your account.', 'November / 06 Wednesday / 2024', '11:08 AM', 'Unread'),
(615, 30, 'You successfully recover your account.', 'November / 06 Wednesday / 2024', '11:44 AM', 'Unread');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `admin_account`
--
ALTER TABLE `admin_account`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `admin_systemnotification`
--
ALTER TABLE `admin_systemnotification`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `archive_research`
--
ALTER TABLE `archive_research`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `archive_research_views`
--
ALTER TABLE `archive_research_views`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `course`
--
ALTER TABLE `course`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `departments`
--
ALTER TABLE `departments`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `plagiarism_results`
--
ALTER TABLE `plagiarism_results`
  ADD PRIMARY KEY (`id`),
  ADD KEY `archive_id` (`archive_id`),
  ADD KEY `similar_archive_id` (`similar_archive_id`);

--
-- Indexes for table `plagiarism_summary`
--
ALTER TABLE `plagiarism_summary`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `students_data`
--
ALTER TABLE `students_data`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `system_notification`
--
ALTER TABLE `system_notification`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `admin_account`
--
ALTER TABLE `admin_account`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=7;

--
-- AUTO_INCREMENT for table `admin_systemnotification`
--
ALTER TABLE `admin_systemnotification`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=291;

--
-- AUTO_INCREMENT for table `archive_research`
--
ALTER TABLE `archive_research`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=159;

--
-- AUTO_INCREMENT for table `archive_research_views`
--
ALTER TABLE `archive_research_views`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=851;

--
-- AUTO_INCREMENT for table `course`
--
ALTER TABLE `course`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=27;

--
-- AUTO_INCREMENT for table `departments`
--
ALTER TABLE `departments`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=11;

--
-- AUTO_INCREMENT for table `plagiarism_results`
--
ALTER TABLE `plagiarism_results`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=1007;

--
-- AUTO_INCREMENT for table `plagiarism_summary`
--
ALTER TABLE `plagiarism_summary`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=31;

--
-- AUTO_INCREMENT for table `students_data`
--
ALTER TABLE `students_data`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=32;

--
-- AUTO_INCREMENT for table `system_notification`
--
ALTER TABLE `system_notification`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=616;

--
-- Constraints for dumped tables
--

--
-- Constraints for table `plagiarism_results`
--
ALTER TABLE `plagiarism_results`
  ADD CONSTRAINT `plagiarism_results_ibfk_1` FOREIGN KEY (`archive_id`) REFERENCES `archive_research` (`id`),
  ADD CONSTRAINT `plagiarism_results_ibfk_2` FOREIGN KEY (`similar_archive_id`) REFERENCES `archive_research` (`id`);
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
