-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Dec 04, 2024 at 09:03 AM
-- Server version: 10.4.32-MariaDB
-- PHP Version: 8.2.12

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `research_repository`
--

-- --------------------------------------------------------

--
-- Table structure for table `admin_account`
--

CREATE TABLE `admin_account` (
  `id` int(11) NOT NULL,
  `uniqueID` varchar(200) NOT NULL,
  `first_name` varchar(100) NOT NULL,
  `middle_name` varchar(100) NOT NULL,
  `last_name` varchar(100) NOT NULL,
  `complete_address` varchar(300) NOT NULL,
  `phone_number` varchar(13) NOT NULL,
  `admin_email` varchar(200) NOT NULL,
  `admin_password` varchar(200) NOT NULL,
  `admin_profile_picture` varchar(500) DEFAULT NULL,
  `role_id` int(11) DEFAULT NULL,
  `admin_status` varchar(10) NOT NULL DEFAULT 'Active',
  `verification_code` int(8) NOT NULL,
  `verify_status` varchar(80) NOT NULL DEFAULT 'Not Verified',
  `online_offlineStatus` varchar(50) NOT NULL DEFAULT 'Offline',
  `delete_flag` int(11) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `admin_account`
--

INSERT INTO `admin_account` (`id`, `uniqueID`, `first_name`, `middle_name`, `last_name`, `complete_address`, `phone_number`, `admin_email`, `admin_password`, `admin_profile_picture`, `role_id`, `admin_status`, `verification_code`, `verify_status`, `online_offlineStatus`, `delete_flag`) VALUES
(1, '6745cf4203d9a', 'Roy', '', 'Raytos', '1321321231212', '091231231', 'raytos.r.bsinfotech@gmail.com', '52c22378cc6a55621dc67fd2022153fe', '../imageFiles/674eb31d33aa6-1000001245.png', 1, 'Active', 814557, 'Verified', 'Offline', 0),
(7, '6745cf4203d9b', 'Aiah', '', 'Arceta', '1321321231212', '09123123123', 'raytos.bsinfotech@gmail.com', '52c22378cc6a55621dc67fd2022153fe', '../imageFiles/674de5dfa5b6b-aiahh.jpg', 6, 'Active', 814557, 'Verified', 'Offline', 0),
(8, '6745cf4203d9d', 'Rolly', '', 'Raytos', 'diyan lang ', '09123123123', 'raytos@gmail.com', '52c22378cc6a55621dc67fd2022153fe', NULL, 2, 'Active', 0, 'Verified', 'Offline', 0),
(11, '674ea8b226f25', 'Rolly', '', 'Raytos', 'EARIST', '09123123312', 'raytosss@gmail.com', '52c22378cc6a55621dc67fd2022153fe', NULL, 3, 'Active', 0, 'Verified', 'Offline', 1),
(12, '674eacb7619c4', 'Rolly', '', 'Raytos', 'EARIST', '09123123312', 'example@gmail.com', '52c22378cc6a55621dc67fd2022153fe', NULL, 3, 'Active', 0, 'Verified', 'Offline', 0);

-- --------------------------------------------------------

--
-- Table structure for table `admin_download_logs`
--

CREATE TABLE `admin_download_logs` (
  `id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `archive_id` varchar(13) NOT NULL,
  `download_date` datetime NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `admin_download_logs`
--

INSERT INTO `admin_download_logs` (`id`, `user_id`, `archive_id`, `download_date`) VALUES
(1, 1, '4549105180', '2024-11-29 22:19:46'),
(2, 1, '4549105180', '2024-11-30 15:34:25'),
(3, 1, '1006535740', '2024-12-01 22:42:48'),
(4, 1, '9693078778', '2024-12-02 17:37:34'),
(5, 1, '1426822786', '2024-12-03 00:48:54'),
(6, 1, '2903531004', '2024-12-03 01:32:42'),
(7, 1, '5992067688', '2024-12-03 01:40:41'),
(8, 1, '7130462724', '2024-12-03 01:40:49'),
(9, 1, '6115264080', '2024-12-03 01:40:54'),
(10, 1, '5288511527', '2024-12-03 13:51:40'),
(11, 1, '6554972894', '2024-12-03 15:23:29');

-- --------------------------------------------------------

--
-- Table structure for table `admin_systemnotification`
--

CREATE TABLE `admin_systemnotification` (
  `id` int(11) NOT NULL,
  `admin_id` bigint(12) NOT NULL,
  `logs` varchar(200) NOT NULL,
  `logs_date` varchar(50) NOT NULL,
  `logs_time` varchar(50) NOT NULL,
  `status` varchar(100) NOT NULL DEFAULT 'Unread'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `admin_systemnotification`
--

INSERT INTO `admin_systemnotification` (`id`, `admin_id`, `logs`, `logs_date`, `logs_time`, `status`) VALUES
(1, 1, 'You logged out.', 'November / 27 Wednesday / 2024', '5:13 PM', 'Read'),
(2, 1, 'You logged in.', 'November / 27 Wednesday / 2024', '5:25 PM', 'Read'),
(3, 1, 'You logged out.', 'November / 27 Wednesday / 2024', '5:25 PM', 'Read'),
(4, 1, 'You logged in.', 'November / 27 Wednesday / 2024', '5:26 PM', 'Read'),
(5, 1, 'You logged out.', 'November / 27 Wednesday / 2024', '5:27 PM', 'Read'),
(6, 1, 'You logged in.', 'November / 27 Wednesday / 2024', '9:38 PM', 'Read'),
(7, 1, 'You logged out.', 'November / 27 Wednesday / 2024', '9:39 PM', 'Read'),
(8, 1, 'You logged in.', 'November / 27 Wednesday / 2024', '11:50 PM', 'Read'),
(9, 1, 'You logged in.', 'November / 28 Thursday / 2024', '4:16 PM', 'Read'),
(10, 1, 'You logged in.', 'November / 28 Thursday / 2024', '4:51 PM', 'Read'),
(11, 1, 'You logged out.', 'November / 28 Thursday / 2024', '4:55 PM', 'Read'),
(12, 1, 'You logged in.', 'November / 28 Thursday / 2024', '5:01 PM', 'Read'),
(13, 1, 'You logged out.', 'November / 28 Thursday / 2024', '5:02 PM', 'Read'),
(14, 1, 'You logged in.', 'November / 28 Thursday / 2024', '5:02 PM', 'Read'),
(15, 1, 'You logged out.', 'November / 28 Thursday / 2024', '5:02 PM', 'Read'),
(16, 1, 'You logged in.', 'November / 28 Thursday / 2024', '5:02 PM', 'Read'),
(17, 1, 'You logged out.', 'November / 28 Thursday / 2024', '5:02 PM', 'Read'),
(20, 1, 'You logged in.', 'November / 29 Friday / 2024', '4:27 PM', 'Read'),
(21, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:44 PM', 'Read'),
(22, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:45 PM', 'Read'),
(23, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:49 PM', 'Read'),
(24, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:50 PM', 'Read'),
(25, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:53 PM', 'Read'),
(26, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:54 PM', 'Read'),
(27, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:55 PM', 'Read'),
(28, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:57 PM', 'Read'),
(29, 1, 'You submitted a new research paper.', 'November / 29 Friday / 2024', '4:58 PM', 'Read'),
(30, 1, 'You logged out.', 'November / 29 Friday / 2024', '5:00 PM', 'Read'),
(31, 1, 'You logged in.', 'November / 29 Friday / 2024', '9:51 PM', 'Read'),
(32, 1, 'You logged in.', 'November / 29 Friday / 2024', '10:15 PM', 'Read'),
(33, 1, 'You logged out.', 'November / 29 Friday / 2024', '10:26 PM', 'Read'),
(34, 1, 'You logged in.', 'November / 30 Saturday / 2024', '2:40 PM', 'Read'),
(35, 1, 'You logged out.', 'November / 30 Saturday / 2024', '3:06 PM', 'Read'),
(36, 1, 'You logged in.', 'November / 30 Saturday / 2024', '3:34 PM', 'Read'),
(37, 1, 'You added a new admin.', 'November / 30 Saturday / 2024', '3:37 PM', 'Read'),
(38, 1, 'You logged out.', 'November / 30 Saturday / 2024', '3:42 PM', 'Read'),
(39, 1, 'You logged in.', 'November / 30 Saturday / 2024', '3:42 PM', 'Read'),
(40, 1, 'You logged out.', 'November / 30 Saturday / 2024', '3:44 PM', 'Read'),
(41, 7, 'You logged in.', 'November / 30 Saturday / 2024', '3:45 PM', 'Read'),
(42, 7, 'You logged out.', 'November / 30 Saturday / 2024', '3:46 PM', 'Read'),
(43, 1, 'You logged in.', 'November / 30 Saturday / 2024', '3:46 PM', 'Read'),
(44, 1, 'You logged out.', 'November / 30 Saturday / 2024', '3:50 PM', 'Read'),
(45, 7, 'You logged in.', 'November / 30 Saturday / 2024', '3:50 PM', 'Read'),
(46, 7, 'You logged out.', 'November / 30 Saturday / 2024', '3:50 PM', 'Read'),
(47, 1, 'You logged in.', 'November / 30 Saturday / 2024', '3:50 PM', 'Read'),
(48, 1, 'You logged out.', 'November / 30 Saturday / 2024', '3:50 PM', 'Read'),
(49, 7, 'You logged in.', 'November / 30 Saturday / 2024', '3:50 PM', 'Read'),
(50, 7, 'You logged out.', 'November / 30 Saturday / 2024', '3:55 PM', 'Read'),
(51, 1, 'You logged in.', 'November / 30 Saturday / 2024', '3:55 PM', 'Read'),
(52, 1, 'You logged out.', 'November / 30 Saturday / 2024', '4:01 PM', 'Read'),
(53, 7, 'You logged in.', 'November / 30 Saturday / 2024', '4:01 PM', 'Read'),
(54, 7, 'You logged out.', 'November / 30 Saturday / 2024', '4:05 PM', 'Read'),
(55, 1, 'You logged in.', 'November / 30 Saturday / 2024', '4:06 PM', 'Read'),
(56, 1, 'You logged out.', 'November / 30 Saturday / 2024', '4:08 PM', 'Read'),
(57, 1, 'You logged in.', 'November / 30 Saturday / 2024', '4:09 PM', 'Read'),
(58, 1, 'You logged out.', 'November / 30 Saturday / 2024', '4:09 PM', 'Read'),
(59, 7, 'You logged in.', 'November / 30 Saturday / 2024', '4:09 PM', 'Read'),
(60, 7, 'You logged out.', 'November / 30 Saturday / 2024', '4:12 PM', 'Read'),
(61, 1, 'You logged in.', 'November / 30 Saturday / 2024', '4:12 PM', 'Read'),
(62, 1, 'You added a new course.', 'November / 30 Saturday / 2024', '4:20 PM', 'Read'),
(63, 1, 'You changed the status of BS Architecture to active.', 'November / 30 Saturday / 2024', '4:34 PM', 'Read'),
(64, 1, 'You changed the status of College of Business and Public Administration to active.', 'November / 30 Saturday / 2024', '4:39 PM', 'Read'),
(65, 1, 'You changed the status of Rolly Raytos to not active.', 'November / 30 Saturday / 2024', '4:39 PM', 'Read'),
(69, 1, 'You approved Roy Raytos account.', 'November / 30 Saturday / 2024', '4:47 PM', 'Read'),
(70, 1, 'You approved Carlo Dalisay account.', 'November / 30 Saturday / 2024', '4:47 PM', 'Read'),
(71, 1, 'You approved Rolly Raytos', 'November / 30 Saturday / 2024', '4:48 PM', 'Read'),
(72, 1, 'You deleted an account of Carlo Dalisay.', 'November / 30 Saturday / 2024', '5:05 PM', 'Read'),
(73, 1, 'You deleted an account of Roy Raytos.', 'November / 30 Saturday / 2024', '5:09 PM', 'Read'),
(74, 1, 'You deleted College of Criminology and Justice Education department.', 'November / 30 Saturday / 2024', '5:28 PM', 'Read'),
(75, 1, 'You added a new department.', 'November / 30 Saturday / 2024', '5:29 PM', 'Read'),
(76, 1, 'You deleted adasdsa course.', 'November / 30 Saturday / 2024', '5:31 PM', 'Read'),
(77, 1, 'You blocked Rolly Raytos.', 'November / 30 Saturday / 2024', '5:36 PM', 'Read'),
(78, 1, 'You unblock Rolly Raytos.', 'November / 30 Saturday / 2024', '5:37 PM', 'Read'),
(79, 1, 'You changed the status of Rolly Raytos to active.', 'November / 30 Saturday / 2024', '6:04 PM', 'Read'),
(80, 1, 'You deleted an account of Rolly Raytos.', 'November / 30 Saturday / 2024', '6:06 PM', 'Read'),
(81, 1, 'You changed the status of Rolly Raytos to not active.', 'November / 30 Saturday / 2024', '6:12 PM', 'Read'),
(82, 1, 'You changed the status of Aiah Arceta to active.', 'November / 30 Saturday / 2024', '6:12 PM', 'Read'),
(83, 1, 'You logged in.', 'November / 30 Saturday / 2024', '9:41 PM', 'Read'),
(84, 1, 'You logged out.', 'November / 30 Saturday / 2024', '11:05 PM', 'Read'),
(85, 1, 'You logged in.', 'December / 01 Sunday / 2024', '12:46 AM', 'Read'),
(86, 1, 'You logged out.', 'December / 01 Sunday / 2024', '12:58 AM', 'Read'),
(87, 1, 'You logged in.', 'December / 01 Sunday / 2024', '2:16 PM', 'Read'),
(88, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '2:17 PM', 'Read'),
(89, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '2:29 PM', 'Read'),
(90, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '2:32 PM', 'Read'),
(91, 1, 'You logged out.', 'December / 01 Sunday / 2024', '2:32 PM', 'Read'),
(92, 1, 'You logged in.', 'December / 01 Sunday / 2024', '2:38 PM', 'Read'),
(93, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '2:39 PM', 'Read'),
(94, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '2:40 PM', 'Read'),
(95, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '2:41 PM', 'Read'),
(96, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '2:56 PM', 'Read'),
(97, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:08 PM', 'Read'),
(98, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:10 PM', 'Read'),
(99, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:15 PM', 'Read'),
(100, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:24 PM', 'Read'),
(101, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:24 PM', 'Read'),
(102, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:26 PM', 'Read'),
(103, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:27 PM', 'Read'),
(104, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:27 PM', 'Read'),
(105, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:28 PM', 'Read'),
(106, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:34 PM', 'Read'),
(107, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:35 PM', 'Read'),
(108, 1, 'You added a new research paper.', 'December / 01 Sunday / 2024', '3:38 PM', 'Read'),
(109, 1, 'You logged out.', 'December / 01 Sunday / 2024', '4:53 PM', 'Read'),
(110, 1, 'You logged in.', 'December / 01 Sunday / 2024', '4:53 PM', 'Read'),
(111, 1, 'You logged out.', 'December / 01 Sunday / 2024', '8:09 PM', 'Read'),
(112, 1, 'You logged in.', 'December / 01 Sunday / 2024', '8:10 PM', 'Read'),
(113, 1, 'You logged out.', 'December / 01 Sunday / 2024', '8:57 PM', 'Read'),
(114, 1, 'You logged in.', 'December / 01 Sunday / 2024', '10:40 PM', 'Read'),
(115, 1, 'You blocked Carlo Dalisay.', 'December / 01 Sunday / 2024', '10:45 PM', 'Read'),
(116, 1, 'You changed the status of College of Arts and Science to not active.', 'December / 01 Sunday / 2024', '10:45 PM', 'Read'),
(117, 1, 'You changed the status of College of Arts and Science to active.', 'December / 01 Sunday / 2024', '10:45 PM', 'Read'),
(118, 1, 'You changed the status of Bachelor of Fine Arts Major in Visual Communication to not active.', 'December / 01 Sunday / 2024', '10:45 PM', 'Read'),
(119, 1, 'You changed the status of Bachelor of Fine Arts Major in Visual Communication to active.', 'December / 01 Sunday / 2024', '10:45 PM', 'Read'),
(120, 1, 'You logged out.', 'December / 01 Sunday / 2024', '10:46 PM', 'Read'),
(121, 7, 'You logged in.', 'December / 01 Sunday / 2024', '10:48 PM', 'Read'),
(122, 7, 'You logged out.', 'December / 01 Sunday / 2024', '10:48 PM', 'Read'),
(123, 1, 'You logged in.', 'December / 02 Monday / 2024', '11:24 AM', 'Read'),
(124, 1, 'You logged out.', 'December / 02 Monday / 2024', '11:27 AM', 'Read'),
(125, 1, 'You logged in.', 'December / 02 Monday / 2024', '11:27 AM', 'Read'),
(126, 1, 'You logged out.', 'December / 02 Monday / 2024', '11:29 AM', 'Read'),
(127, 1, 'You logged in.', 'December / 02 Monday / 2024', '11:29 AM', 'Read'),
(128, 1, 'You logged out.', 'December / 02 Monday / 2024', '11:29 AM', 'Read'),
(129, 1, 'You logged in.', 'December / 02 Monday / 2024', '5:34 PM', 'Read'),
(130, 1, 'You added a new research paper.', 'December / 02 Monday / 2024', '5:37 PM', 'Read'),
(131, 1, 'You blocked Mark Carlo  Dalisay.', 'December / 02 Monday / 2024', '5:38 PM', 'Read'),
(132, 1, 'You unblock Mark Carlo  Dalisay.', 'December / 02 Monday / 2024', '5:38 PM', 'Read'),
(133, 1, 'You changed the status of College of Criminology and Justice Education to not active.', 'December / 02 Monday / 2024', '5:38 PM', 'Read'),
(134, 1, 'You changed the status of College of Business and Public Administration to not active.', 'December / 02 Monday / 2024', '5:38 PM', 'Read'),
(135, 1, 'You changed the status of College of Business and Public Administration to active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(136, 1, 'You changed the status of College of Criminology and Justice Education to active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(137, 1, 'You changed the status of College of Computer Studies to active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(138, 1, 'You changed the status of College of Engineering to active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(139, 1, 'You changed the status of College of Architecture and Fine Arts to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(140, 1, 'You changed the status of College of Business and Public Administration to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(141, 1, 'You changed the status of College of Criminology and Justice Education to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(142, 1, 'You changed the status of College of Computer Studies to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(143, 1, 'You changed the status of College of Hospitality Management to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(144, 1, 'You changed the status of College of Engineering to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(145, 1, 'You changed the status of College of Education to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(146, 1, 'You changed the status of College of Industrial Technology to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(147, 1, 'You changed the status of Aiah Arceta to not active.', 'December / 02 Monday / 2024', '5:39 PM', 'Read'),
(148, 1, 'You logged out.', 'December / 02 Monday / 2024', '5:40 PM', 'Read'),
(149, 1, 'You logged in.', 'December / 02 Monday / 2024', '5:40 PM', 'Read'),
(150, 1, 'You logged out.', 'December / 02 Monday / 2024', '5:41 PM', 'Read'),
(151, 1, 'You logged in.', 'December / 02 Monday / 2024', '8:48 PM', 'Read'),
(152, 1, 'You added a new department.', 'December / 02 Monday / 2024', '8:49 PM', 'Read'),
(153, 1, 'You deleted College of Computer Studies department.', 'December / 02 Monday / 2024', '8:49 PM', 'Read'),
(154, 1, 'You added a new department.', 'December / 02 Monday / 2024', '8:49 PM', 'Read'),
(155, 1, 'You deleted BS Computer Technology course.', 'December / 02 Monday / 2024', '8:50 PM', 'Read'),
(156, 1, 'You changed the status of College of Computer Studies to not active.', 'December / 02 Monday / 2024', '9:09 PM', 'Read'),
(157, 1, 'You deleted College of Computer Studies department.', 'December / 02 Monday / 2024', '9:10 PM', 'Read'),
(158, 1, 'You successfully updated a BS Information Technology course.', 'December / 02 Monday / 2024', '9:11 PM', 'Read'),
(159, 1, 'You logged out.', 'December / 02 Monday / 2024', '9:25 PM', 'Read'),
(160, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '12:30 AM', 'Read'),
(161, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '12:46 AM', 'Read'),
(162, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '12:47 AM', 'Read'),
(163, 1, 'You added a new research paper.', 'December / 03 Tuesday / 2024', '12:50 AM', 'Read'),
(164, 1, 'You blocked Rolly Raytos.', 'December / 03 Tuesday / 2024', '12:51 AM', 'Read'),
(165, 1, 'You deleted an account of Mark Gelo Dalisay.', 'December / 03 Tuesday / 2024', '12:51 AM', 'Read'),
(166, 1, 'You changed the status of College of Architecture and Fine Arts to active.', 'December / 03 Tuesday / 2024', '12:51 AM', 'Read'),
(167, 1, 'You changed the status of College of Business and Public Administration to active.', 'December / 03 Tuesday / 2024', '12:51 AM', 'Read'),
(168, 1, 'You changed the status of College of Criminology and Justice Education to active.', 'December / 03 Tuesday / 2024', '12:51 AM', 'Read'),
(169, 1, 'You changed the status of College of Arts and Science to not active.', 'December / 03 Tuesday / 2024', '12:51 AM', 'Read'),
(170, 1, 'You changed the status of College of Architecture and Fine Arts to not active.', 'December / 03 Tuesday / 2024', '12:51 AM', 'Read'),
(171, 1, 'You changed the status of College of Business and Public Administration to not active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(172, 1, 'You changed the status of College of Criminology and Justice Education to not active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(173, 1, 'You changed the status of BS Electrical Engineering to not active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(174, 1, 'You changed the status of BS Electronics Engineering to not active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(175, 1, 'You changed the status of BS Computer Science to not active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(176, 1, 'You changed the status of Aiah Arceta to active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(177, 1, 'You changed the status of Rolly Raytos to active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(178, 1, 'You changed the status of Rolly Raytos to not active.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Read'),
(180, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '12:53 AM', 'Read'),
(181, 7, 'You logged in.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(182, 7, 'You unblock Rolly Raytos.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(183, 7, 'You changed the status of College of Business and Public Administration to active.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(184, 7, 'You changed the status of College of Criminology and Justice Education to active.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(185, 7, 'You changed the status of College of Arts and Science to active.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(186, 7, 'You changed the status of College of Engineering to active.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(187, 7, 'You logged out.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(188, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(189, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '12:54 AM', 'Read'),
(190, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:03 AM', 'Read'),
(191, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:11 AM', 'Read'),
(192, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:11 AM', 'Read'),
(193, 1, 'You changed the status of College of Criminology and Justice Education to not active.', 'December / 03 Tuesday / 2024', '1:13 AM', 'Read'),
(194, 1, 'You changed the status of College of Business and Public Administration to not active.', 'December / 03 Tuesday / 2024', '1:13 AM', 'Read'),
(195, 1, 'You changed the status of College of Arts and Science to not active.', 'December / 03 Tuesday / 2024', '1:13 AM', 'Read'),
(196, 1, 'You changed the status of College of Computer Studies to not active.', 'December / 03 Tuesday / 2024', '1:13 AM', 'Read'),
(197, 1, 'You changed the status of College of Engineering to not active.', 'December / 03 Tuesday / 2024', '1:13 AM', 'Read'),
(198, 1, 'You changed the status of College of Arts and Science to active.', 'December / 03 Tuesday / 2024', '1:14 AM', 'Read'),
(199, 1, 'You changed the status of College of Architecture and Fine Arts to active.', 'December / 03 Tuesday / 2024', '1:14 AM', 'Read'),
(200, 1, 'You changed the status of College of Business and Public Administration to active.', 'December / 03 Tuesday / 2024', '1:14 AM', 'Read'),
(201, 1, 'You changed the status of College of Criminology and Justice Education to active.', 'December / 03 Tuesday / 2024', '1:21 AM', 'Read'),
(202, 1, 'You changed the status of College of Computer Studies to active.', 'December / 03 Tuesday / 2024', '1:21 AM', 'Read'),
(203, 1, 'You changed the status of College of Engineering to active.', 'December / 03 Tuesday / 2024', '1:21 AM', 'Read'),
(204, 1, 'You changed the status of College of Hospitality Management to active.', 'December / 03 Tuesday / 2024', '1:21 AM', 'Read'),
(205, 1, 'You changed the status of College of Industrial Technology to active.', 'December / 03 Tuesday / 2024', '1:21 AM', 'Read'),
(206, 1, 'You changed the status of College of Education to active.', 'December / 03 Tuesday / 2024', '1:21 AM', 'Read'),
(207, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:30 AM', 'Read'),
(208, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:31 AM', 'Read'),
(209, 1, 'You added a new research paper.', 'December / 03 Tuesday / 2024', '1:33 AM', 'Read'),
(210, 1, 'You blocked Rolly Raytos.', 'December / 03 Tuesday / 2024', '1:34 AM', 'Read'),
(211, 1, 'You unblock Rolly Raytos.', 'December / 03 Tuesday / 2024', '1:34 AM', 'Read'),
(212, 1, 'You changed the status of College of Architecture and Fine Arts to not active.', 'December / 03 Tuesday / 2024', '1:34 AM', 'Read'),
(213, 1, 'You changed the status of College of Arts and Science to not active.', 'December / 03 Tuesday / 2024', '1:34 AM', 'Read'),
(214, 1, 'You changed the status of College of Business and Public Administration to not active.', 'December / 03 Tuesday / 2024', '1:34 AM', 'Read'),
(215, 1, 'You changed the status of College of Criminology and Justice Education to not active.', 'December / 03 Tuesday / 2024', '1:34 AM', 'Read'),
(216, 1, 'You changed the status of BS Architecture to not active.', 'December / 03 Tuesday / 2024', '1:35 AM', 'Read'),
(217, 1, 'You changed the status of BS Criminology to not active.', 'December / 03 Tuesday / 2024', '1:35 AM', 'Read'),
(218, 1, 'You changed the status of BS Computer Science to active.', 'December / 03 Tuesday / 2024', '1:35 AM', 'Read'),
(219, 1, 'You changed the status of Aiah Arceta to not active.', 'December / 03 Tuesday / 2024', '1:35 AM', 'Read'),
(220, 1, 'You changed the status of Rolly Raytos to active.', 'December / 03 Tuesday / 2024', '1:35 AM', 'Read'),
(221, 1, 'You changed the status of Aiah Arceta to active.', 'December / 03 Tuesday / 2024', '1:35 AM', 'Read'),
(222, 1, 'You changed the status of Rolly Raytos to not active.', 'December / 03 Tuesday / 2024', '1:35 AM', 'Read'),
(223, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:36 AM', 'Read'),
(224, 7, 'You logged in.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(225, 7, 'You changed the status of Bachelor in Special Needs Education to not active.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(226, 7, 'You changed the status of Bachelor of Fine Arts Major in Visual Communication to not active.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(227, 7, 'You changed the status of BS Computer Science to not active.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(228, 7, 'You blocked Rolly Raytos.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(229, 7, 'You logged out.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(230, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(231, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:37 AM', 'Read'),
(232, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:40 AM', 'Read'),
(233, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:40 AM', 'Read'),
(234, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:40 AM', 'Read'),
(235, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:41 AM', 'Read'),
(236, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:41 AM', 'Read'),
(237, 1, 'You unblock Rolly Raytos.', 'December / 03 Tuesday / 2024', '1:43 AM', 'Read'),
(238, 1, 'You changed the status of College of Criminology and Justice Education to active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(239, 1, 'You changed the status of College of Computer Studies to not active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(240, 1, 'You changed the status of College of Engineering to not active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(241, 1, 'You changed the status of College of Criminology and Justice Education to not active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(242, 1, 'You changed the status of College of Hospitality Management to not active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(243, 1, 'You changed the status of Bachelor of Fine Arts Major in Visual Communication to active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(244, 1, 'You changed the status of BS Computer Engineering to active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(245, 1, 'You changed the status of BS Computer Science to active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(246, 1, 'You changed the status of Aiah Arceta to not active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(247, 1, 'You changed the status of Aiah Arceta to active.', 'December / 03 Tuesday / 2024', '1:44 AM', 'Read'),
(248, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:46 AM', 'Read'),
(249, 7, 'You logged in.', 'December / 03 Tuesday / 2024', '1:46 AM', 'Read'),
(250, 7, 'You logged out.', 'December / 03 Tuesday / 2024', '1:46 AM', 'Read'),
(251, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '2:01 AM', 'Read'),
(252, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '2:02 AM', 'Read'),
(253, 7, 'You logged in.', 'December / 03 Tuesday / 2024', '2:02 AM', 'Read'),
(254, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '9:27 AM', 'Read'),
(255, 1, 'You changed the status of College of Business and Public Administration to active.', 'December / 03 Tuesday / 2024', '9:32 AM', 'Read'),
(256, 1, 'You added a new research paper.', 'December / 03 Tuesday / 2024', '10:19 AM', 'Read'),
(257, 1, 'You added a new course.', 'December / 03 Tuesday / 2024', '10:25 AM', 'Read'),
(258, 1, 'You deleted ADASDDASDASD course.', 'December / 03 Tuesday / 2024', '10:25 AM', 'Read'),
(259, 1, 'You added a new course.', 'December / 03 Tuesday / 2024', '10:25 AM', 'Read'),
(260, 1, 'You deleted ADASDDASDASD course.', 'December / 03 Tuesday / 2024', '10:25 AM', 'Read'),
(261, 1, 'You added a new department.', 'December / 03 Tuesday / 2024', '10:30 AM', 'Read'),
(262, 1, 'You deleted College of Architecture and Fine Arts department.', 'December / 03 Tuesday / 2024', '10:30 AM', 'Read'),
(263, 1, 'You updated Rolly Raytos info.', 'December / 03 Tuesday / 2024', '11:52 AM', 'Read'),
(264, 1, 'You changed the status of College of Computer Studies to active.', 'December / 03 Tuesday / 2024', '12:24 PM', 'Read'),
(265, 1, 'You changed the status of College of Business and Public Administration to not active.', 'December / 03 Tuesday / 2024', '12:24 PM', 'Read'),
(266, 1, 'You changed the status of College of Industrial Technology to not active.', 'December / 03 Tuesday / 2024', '12:24 PM', 'Read'),
(267, 1, 'You changed the status of College of Education to not active.', 'December / 03 Tuesday / 2024', '12:24 PM', 'Read'),
(268, 1, 'You updated the BS Computer Science course.', 'December / 03 Tuesday / 2024', '12:27 PM', 'Read'),
(269, 1, 'You updated the BS Computer Science course.', 'December / 03 Tuesday / 2024', '12:29 PM', 'Read'),
(270, 1, 'You updated the BS Computer Science course.', 'December / 03 Tuesday / 2024', '12:31 PM', 'Read'),
(271, 1, 'You changed the status of Bachelor of Fine Arts Major in Visual Communication to not active.', 'December / 03 Tuesday / 2024', '12:31 PM', 'Read'),
(272, 1, 'You changed the status of BS Computer Engineering to not active.', 'December / 03 Tuesday / 2024', '12:31 PM', 'Read'),
(273, 1, 'You successfully Updated a Department.', 'December / 03 Tuesday / 2024', '12:33 PM', 'Read'),
(274, 1, 'You successfully Updated a Department.', 'December / 03 Tuesday / 2024', '12:33 PM', 'Read'),
(275, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '12:54 PM', 'Read'),
(276, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '12:54 PM', 'Read'),
(277, 6554972894, 'Roy Raytos submitted a new research paper.', 'December / 03 Tuesday / 2024', '1:04 PM', 'Read'),
(278, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:07 PM', 'Read'),
(279, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '1:42 PM', 'Read'),
(280, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '1:43 PM', 'Read'),
(281, 1, 'You changed the status of College of Arts and Science to active.', 'December / 03 Tuesday / 2024', '1:46 PM', 'Read'),
(282, 1, 'You changed the status of College of Architecture and Fine Arts to active.', 'December / 03 Tuesday / 2024', '1:46 PM', 'Read'),
(283, 1, 'You added a new research paper.', 'December / 03 Tuesday / 2024', '1:50 PM', 'Read'),
(284, 1, 'You blocked Rolly Raytos.', 'December / 03 Tuesday / 2024', '1:53 PM', 'Read'),
(285, 1, 'You updated Roy Raytos’s information.', 'December / 03 Tuesday / 2024', '2:34 PM', 'Read'),
(286, 1, 'You updated Roy Raytos’s information.', 'December / 03 Tuesday / 2024', '2:35 PM', 'Read'),
(287, 1, 'You updated Roy Raytos’s information.', 'December / 03 Tuesday / 2024', '2:37 PM', 'Read'),
(288, 1, 'You updated Roy Raytos’s information.', 'December / 03 Tuesday / 2024', '2:38 PM', 'Read'),
(289, 1, 'You unblock Rolly Raytos.', 'December / 03 Tuesday / 2024', '2:40 PM', 'Read'),
(290, 1, 'You blocked Rolly Raytos.', 'December / 03 Tuesday / 2024', '2:40 PM', 'Read'),
(291, 1, 'You unblock Rolly Raytos.', 'December / 03 Tuesday / 2024', '2:40 PM', 'Read'),
(292, 1, 'You added a new department.', 'December / 03 Tuesday / 2024', '2:41 PM', 'Read'),
(293, 1, 'You changed the status of COLLEGE OF CATCATCAT to not active.', 'December / 03 Tuesday / 2024', '2:41 PM', 'Read'),
(294, 1, 'You changed the status of COLLEGE OF CATCATCAT to active.', 'December / 03 Tuesday / 2024', '2:41 PM', 'Read'),
(295, 1, 'You successfully updated a department.', 'December / 03 Tuesday / 2024', '2:41 PM', 'Read'),
(296, 1, 'You deleted COLLEGE OF CATCATCAT department.', 'December / 03 Tuesday / 2024', '2:41 PM', 'Read'),
(297, 1, 'You successfully updated a department.', 'December / 03 Tuesday / 2024', '2:41 PM', 'Read'),
(298, 1, 'You changed the status of Bachelor in Special Needs Education to active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(299, 1, 'You changed the status of Bachelor of Fine Arts Major in Visual Communication to active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(300, 1, 'You changed the status of BS Architecture to active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(301, 1, 'You changed the status of BS Civil Engineering to active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(302, 1, 'You changed the status of College of Arts and Science to not active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(303, 1, 'You changed the status of College of Architecture and Fine Arts to not active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(304, 1, 'You changed the status of College of Computer Studies to not active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(305, 1, 'You changed the status of College of Architecture and Fine Arts to active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(306, 1, 'You changed the status of College of Arts and Science to active.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(307, 1, 'You added a new course.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(308, 1, 'You updated the BS Exampleee course.', 'December / 03 Tuesday / 2024', '2:42 PM', 'Read'),
(309, 1, 'You deleted BS Exampleee course.', 'December / 03 Tuesday / 2024', '2:43 PM', 'Read'),
(310, 1, 'You updated the BS Exampleee course.', 'December / 03 Tuesday / 2024', '2:43 PM', 'Read'),
(311, 1, 'You added a new admin.', 'December / 03 Tuesday / 2024', '2:44 PM', 'Read'),
(312, 1, 'You updated Rolly Raytos info.', 'December / 03 Tuesday / 2024', '2:44 PM', 'Read'),
(313, 1, 'You deleted an account of Rolly Raytos.', 'December / 03 Tuesday / 2024', '2:44 PM', 'Read'),
(314, 1, 'You updated Rolly Raytos info.', 'December / 03 Tuesday / 2024', '2:44 PM', 'Read'),
(316, 1, 'You successfully updated your password.', 'December / 03 Tuesday / 2024', '2:45 PM', 'Read'),
(317, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '2:48 PM', 'Read'),
(318, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '2:50 PM', 'Read'),
(319, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '2:50 PM', 'Read'),
(320, 7, 'You logged in.', 'December / 03 Tuesday / 2024', '2:51 PM', 'Read'),
(321, 7, 'You logged out.', 'December / 03 Tuesday / 2024', '2:54 PM', 'Read'),
(322, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '2:54 PM', 'Read'),
(323, 1, 'You added a new research paper.', 'December / 03 Tuesday / 2024', '2:57 PM', 'Read'),
(324, 1, 'You blocked Rolly Raytos.', 'December / 03 Tuesday / 2024', '2:58 PM', 'Read'),
(325, 1, 'You unblock Rolly Raytos.', 'December / 03 Tuesday / 2024', '2:58 PM', 'Read'),
(326, 1, 'You added a new department.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(327, 1, 'You changed the status of College of Example to not active.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(328, 1, 'You changed the status of College of Example to active.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(329, 1, 'You successfully updated a department.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(330, 1, 'You deleted College of Example department.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(331, 1, 'You successfully updated a department.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(332, 1, 'You changed the status of College of Business and Public Administration to active.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(333, 1, 'You changed the status of College of Criminology and Justice Education to active.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(334, 1, 'You changed the status of College of Computer Studies to active.', 'December / 03 Tuesday / 2024', '2:59 PM', 'Read'),
(335, 1, 'You added a new course.', 'December / 03 Tuesday / 2024', '3:00 PM', 'Read'),
(336, 1, 'You changed the status of BS CatDog to not active.', 'December / 03 Tuesday / 2024', '3:00 PM', 'Read'),
(337, 1, 'You changed the status of BS CatDog to active.', 'December / 03 Tuesday / 2024', '3:00 PM', 'Read'),
(338, 1, 'You updated the BS  Example course.', 'December / 03 Tuesday / 2024', '3:00 PM', 'Read'),
(339, 1, 'You deleted BS  Example course.', 'December / 03 Tuesday / 2024', '3:00 PM', 'Read'),
(340, 1, 'You updated the BS  Example course.', 'December / 03 Tuesday / 2024', '3:00 PM', 'Read'),
(341, 1, 'You added a new admin.', 'December / 03 Tuesday / 2024', '3:01 PM', 'Read'),
(342, 1, 'You changed the status of Rolly Raytos to not active.', 'December / 03 Tuesday / 2024', '3:01 PM', 'Read'),
(343, 1, 'You updated Rolly Raytos info.', 'December / 03 Tuesday / 2024', '3:01 PM', 'Read'),
(345, 1, 'You successfully updated your password.', 'December / 03 Tuesday / 2024', '3:02 PM', 'Read'),
(346, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '3:04 PM', 'Read'),
(347, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '3:21 PM', 'Read'),
(348, 1, 'You blocked Rolly Raytos.', 'December / 03 Tuesday / 2024', '3:24 PM', 'Read'),
(349, 1, 'You added a new department.', 'December / 03 Tuesday / 2024', '3:25 PM', 'Read'),
(350, 1, 'You changed the status of College of Example to not active.', 'December / 03 Tuesday / 2024', '3:25 PM', 'Read'),
(351, 1, 'You changed the status of College of Example to active.', 'December / 03 Tuesday / 2024', '3:25 PM', 'Read'),
(352, 1, 'You deleted College of Example department.', 'December / 03 Tuesday / 2024', '3:25 PM', 'Read'),
(353, 1, 'You added a new department.', 'December / 03 Tuesday / 2024', '3:25 PM', 'Read'),
(354, 1, 'You changed the status of College of Business and Public Administration to not active.', 'December / 03 Tuesday / 2024', '3:26 PM', 'Read'),
(355, 1, 'You changed the status of College of Criminology and Justice Education to not active.', 'December / 03 Tuesday / 2024', '3:26 PM', 'Read'),
(356, 1, 'You changed the status of College of Computer Studies to not active.', 'December / 03 Tuesday / 2024', '3:26 PM', 'Read'),
(357, 1, 'You changed the status of College of Architecture and Fine Arts to not active.', 'December / 03 Tuesday / 2024', '3:26 PM', 'Read'),
(358, 1, 'You added a new course.', 'December / 03 Tuesday / 2024', '3:26 PM', 'Read'),
(359, 1, 'You updated the BS Exa course.', 'December / 03 Tuesday / 2024', '3:26 PM', 'Read'),
(360, 1, 'You deleted BS Exa course.', 'December / 03 Tuesday / 2024', '3:27 PM', 'Read'),
(361, 1, 'You updated the BS Exa course.', 'December / 03 Tuesday / 2024', '3:27 PM', 'Read'),
(362, 1, 'You changed the status of Aiah Arceta to not active.', 'December / 03 Tuesday / 2024', '3:27 PM', 'Read'),
(363, 1, 'You changed the status of Rolly Raytos to active.', 'December / 03 Tuesday / 2024', '3:27 PM', 'Read'),
(364, 1, 'You changed the status of Rolly Raytos to active.', 'December / 03 Tuesday / 2024', '3:27 PM', 'Read'),
(365, 1, 'You changed the status of Aiah Arceta to active.', 'December / 03 Tuesday / 2024', '3:27 PM', 'Read'),
(366, 1, 'You updated Aiah Arceta info.', 'December / 03 Tuesday / 2024', '3:27 PM', 'Read'),
(367, 0, 'December / 03 Tuesday / 2024', '3:28 PM', '1', 'Unread'),
(368, 1, 'You successfully updated your password.', 'December / 03 Tuesday / 2024', '3:29 PM', 'Read'),
(369, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '3:31 PM', 'Read'),
(370, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '3:36 PM', 'Read'),
(371, 4134983947, 'Rolly Raytos submitted a new research paper.', 'December / 03 Tuesday / 2024', '6:39 PM', 'Unread'),
(372, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '6:42 PM', 'Read'),
(373, 1, 'You updated Aiah Arceta info.', 'December / 03 Tuesday / 2024', '6:43 PM', 'Read'),
(374, 1, 'You logged out.', 'December / 03 Tuesday / 2024', '6:47 PM', 'Read'),
(375, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '6:49 PM', 'Read'),
(376, 1, 'You added a new role: CAS', 'December / 03 Tuesday / 2024', '11:31 PM', 'Read'),
(377, 1, 'You changed the status of Roy Raytos to active.', 'December / 03 Tuesday / 2024', '11:35 PM', 'Read'),
(378, 1, 'You changed the status of Roy Raytos to not active.', 'December / 03 Tuesday / 2024', '11:35 PM', 'Read'),
(379, 1, 'You changed the status of Roy Raytos to active.', 'December / 03 Tuesday / 2024', '11:35 PM', 'Read'),
(380, 1, 'You updated role: CAS', 'December / 04 Wednesday / 2024', '12:42 AM', 'Read'),
(381, 1, 'You changed the status of CAS to active.', 'December / 04 Wednesday / 2024', '12:44 AM', 'Read'),
(382, 1, 'You changed the status of CAS to not active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(383, 1, 'You changed the status of CAS to active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(384, 1, 'You changed the status of CAS to not active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(385, 1, 'You changed the status of CAS to active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(386, 1, 'You changed the status of CAS to not active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(387, 1, 'You changed the status of CAS to active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(388, 1, 'You changed the status of CAS to not active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(389, 1, 'You changed the status of CAS to active.', 'December / 04 Wednesday / 2024', '12:45 AM', 'Read'),
(390, 1, 'You changed the status of College of Computer Studies to active.', 'December / 04 Wednesday / 2024', '12:54 AM', 'Read'),
(391, 1, 'You added a new role: CCS', 'December / 04 Wednesday / 2024', '12:55 AM', 'Read'),
(392, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '12:56 AM', 'Read'),
(393, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:00 AM', 'Read'),
(394, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:01 AM', 'Read'),
(395, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:02 AM', 'Read'),
(396, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:03 AM', 'Read'),
(397, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:06 AM', 'Read'),
(398, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:07 AM', 'Read'),
(399, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:11 AM', 'Read'),
(400, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:11 AM', 'Read'),
(401, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:11 AM', 'Read'),
(402, 1, 'You updated Rolly Raytos info.', 'December / 04 Wednesday / 2024', '1:11 AM', 'Read'),
(403, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '1:12 AM', 'Unread'),
(404, 12, 'You logged in.', 'December / 04 Wednesday / 2024', '1:14 AM', 'Read'),
(405, 12, 'You logged out.', 'December / 04 Wednesday / 2024', '1:28 AM', 'Read'),
(406, 12, 'You logged in.', 'December / 04 Wednesday / 2024', '1:28 AM', 'Read'),
(407, 12, 'You logged out.', 'December / 04 Wednesday / 2024', '1:48 AM', 'Read'),
(408, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '1:49 AM', 'Unread'),
(409, 1, 'You updated role: CAS', 'December / 04 Wednesday / 2024', '1:51 AM', 'Unread'),
(410, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '1:51 AM', 'Unread'),
(411, 12, 'You logged in.', 'December / 04 Wednesday / 2024', '1:51 AM', 'Read'),
(412, 12, 'You logged out.', 'December / 04 Wednesday / 2024', '1:58 AM', 'Read'),
(413, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '1:58 AM', 'Unread'),
(414, 1, 'You updated role: CAS', 'December / 04 Wednesday / 2024', '1:59 AM', 'Unread'),
(415, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '1:59 AM', 'Unread'),
(416, 12, 'You logged in.', 'December / 04 Wednesday / 2024', '1:59 AM', 'Read'),
(417, 12, 'You logged out.', 'December / 04 Wednesday / 2024', '2:14 AM', 'Read'),
(418, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '2:15 AM', 'Unread'),
(419, 1, 'You added a new role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '2:19 AM', 'Unread'),
(420, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '2:21 AM', 'Unread'),
(421, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '2:21 AM', 'Unread'),
(422, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '2:36 AM', 'Unread'),
(423, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '2:37 AM', 'Unread'),
(424, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '2:37 AM', 'Unread'),
(425, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '10:55 AM', 'Unread'),
(426, 1, 'You updated role: CAS', 'December / 04 Wednesday / 2024', '12:23 PM', 'Unread'),
(427, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '12:23 PM', 'Unread'),
(428, 12, 'You logged in.', 'December / 04 Wednesday / 2024', '12:23 PM', 'Read'),
(429, 12, 'You changed the status of Bachelor in Special Needs Education to not active.', 'December / 04 Wednesday / 2024', '12:26 PM', 'Read'),
(430, 12, 'You changed the status of Bachelor in Special Needs Education to active.', 'December / 04 Wednesday / 2024', '12:26 PM', 'Read'),
(431, 12, 'You changed the status of BS Computer Engineering to active.', 'December / 04 Wednesday / 2024', '12:26 PM', 'Read'),
(432, 12, 'You changed the status of BS Architecture to not active.', 'December / 04 Wednesday / 2024', '12:27 PM', 'Read'),
(433, 12, 'You changed the status of BS Architecture to active.', 'December / 04 Wednesday / 2024', '12:27 PM', 'Read'),
(434, 12, 'You logged out.', 'December / 04 Wednesday / 2024', '12:32 PM', 'Read'),
(435, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '12:32 PM', 'Unread'),
(436, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '12:32 PM', 'Unread'),
(437, 12, 'You logged in.', 'December / 04 Wednesday / 2024', '12:32 PM', 'Read'),
(438, 12, 'You logged out.', 'December / 04 Wednesday / 2024', '12:58 PM', 'Read'),
(439, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '12:58 PM', 'Unread'),
(440, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '12:59 PM', 'Unread'),
(441, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '1:00 PM', 'Unread'),
(442, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '1:07 PM', 'Unread'),
(443, 1, 'You changed the status of Aiah Arceta to not active.', 'December / 04 Wednesday / 2024', '1:07 PM', 'Unread'),
(444, 1, 'You changed the status of Aiah Arceta to active.', 'December / 04 Wednesday / 2024', '1:08 PM', 'Unread'),
(445, 1, 'You changed the status of Aiah Arceta to not active.', 'December / 04 Wednesday / 2024', '1:08 PM', 'Unread'),
(446, 1, 'You changed the status of Aiah Arceta to active.', 'December / 04 Wednesday / 2024', '1:08 PM', 'Unread'),
(447, 1, 'You changed the status of Aiah Arceta to not active.', 'December / 04 Wednesday / 2024', '1:08 PM', 'Unread'),
(448, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '1:10 PM', 'Unread'),
(449, 12, 'You logged in.', 'December / 04 Wednesday / 2024', '1:11 PM', 'Read'),
(450, 12, 'You logged out.', 'December / 04 Wednesday / 2024', '1:20 PM', 'Unread'),
(451, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '1:20 PM', 'Unread'),
(452, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '1:27 PM', 'Unread'),
(453, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '1:28 PM', 'Unread'),
(454, 1, 'You changed the status of BS Civil Engineering to not active.', 'December / 04 Wednesday / 2024', '1:28 PM', 'Unread'),
(455, 1, 'You changed the status of BS Civil Engineering to active.', 'December / 04 Wednesday / 2024', '1:28 PM', 'Unread'),
(456, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '2:42 PM', 'Unread'),
(457, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '3:38 PM', 'Unread'),
(458, 1, 'You logged in.', 'December / 04 Wednesday / 2024', '3:46 PM', 'Unread'),
(459, 1, 'You updated role: DEPARTMENT', 'December / 04 Wednesday / 2024', '3:47 PM', 'Unread'),
(460, 1, 'You updated role: SUPER ADMIN', 'December / 04 Wednesday / 2024', '3:51 PM', 'Unread'),
(461, 1, 'You added a new role: DEPARTMENT', 'December / 04 Wednesday / 2024', '3:51 PM', 'Unread'),
(462, 1, 'You changed the status of Aiah Arceta to active.', 'December / 04 Wednesday / 2024', '3:51 PM', 'Unread'),
(463, 1, 'You updated Aiah Arceta info.', 'December / 04 Wednesday / 2024', '3:51 PM', 'Unread'),
(464, 1, 'You logged out.', 'December / 04 Wednesday / 2024', '3:51 PM', 'Unread'),
(465, 7, 'You logged in.', 'December / 04 Wednesday / 2024', '3:52 PM', 'Read'),
(466, 7, 'You changed the status of College of Arts and Science to not active.', 'December / 04 Wednesday / 2024', '3:53 PM', 'Read'),
(467, 7, 'You changed the status of College of Arts and Science to active.', 'December / 04 Wednesday / 2024', '3:53 PM', 'Read'),
(468, 7, 'You logged out.', 'December / 04 Wednesday / 2024', '3:53 PM', 'Read'),
(469, 7, 'You logged in.', 'December / 04 Wednesday / 2024', '3:54 PM', 'Read'),
(470, 7, 'You logged out.', 'December / 04 Wednesday / 2024', '3:56 PM', 'Read'),
(471, 7, 'You logged in.', 'December / 04 Wednesday / 2024', '3:56 PM', 'Read'),
(472, 7, 'You logged out.', 'December / 04 Wednesday / 2024', '3:57 PM', 'Read'),
(473, 7, 'You logged in.', 'December / 04 Wednesday / 2024', '3:57 PM', 'Read'),
(474, 7, 'You logged out.', 'December / 04 Wednesday / 2024', '3:58 PM', 'Unread');

-- --------------------------------------------------------

--
-- Table structure for table `archive_research`
--

CREATE TABLE `archive_research` (
  `id` int(11) NOT NULL,
  `archive_id` varchar(13) NOT NULL,
  `student_id` varchar(20) NOT NULL,
  `department_id` int(11) NOT NULL,
  `course_id` int(11) NOT NULL,
  `project_title` varchar(200) NOT NULL,
  `dateOFSubmit` varchar(50) NOT NULL,
  `project_year` varchar(80) NOT NULL,
  `project_abstract` varchar(5000) NOT NULL,
  `keywords` varchar(255) NOT NULL,
  `content` text NOT NULL,
  `research_owner_email` varchar(200) NOT NULL,
  `project_members` varchar(700) NOT NULL,
  `project_picture` varchar(800) NOT NULL,
  `documents` varchar(700) NOT NULL,
  `file_size` bigint(20) NOT NULL,
  `page_count` int(11) NOT NULL,
  `word_count` int(11) NOT NULL,
  `character_count` int(11) NOT NULL,
  `submission_date` timestamp NOT NULL DEFAULT current_timestamp() ON UPDATE current_timestamp(),
  `date_published` varchar(80) NOT NULL,
  `document_status` varchar(200) NOT NULL DEFAULT 'Not Accepted',
  `read_status` tinyint(1) NOT NULL,
  `inbox_read` tinyint(1) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `archive_research`
--

INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(1, '7281507465', '51', 5, 5, 'WIRELESS MULTI-ACCESS WITH PROJECTION SYSTEM ', '2024-11-27 17:21:15.147430', '2024', 'A video projector is the most common form of projector used today. Slide projectors and overhead projectors have been replaced by video projectors, which are automated versions of the older projectors. In the 1990s and early 2000s, these older projectors were largely replaced with digital video projectors, but old analog projectors are still in use in some areas. Handheld projectors that project images using lasers or LEDs are the most recent forms of projectors. If there is too much ambient light, their estimates are difficult to see. The use of pictures to Interact and appreciate the world around us has expanded as a result of technological advances. The ase of internet technology has transformed users into active participants who can connect with their audiences using words.', 'Wireless,System,Device,Projector,Digital', 'WIRELESS MULTI -ACCESS WITH PROJECTION SY STEM  \nDimpas Lesther, Jami n Gabriel, Per ez Reza Lyn, Jazon Jean Roann, \nMendez Julius, Bautista  Rica Mae, Larona Raven  \n \nDepartment: College of \nEngineering  Course:  Computer Engineering\n \nINTRODUCTION  \nThe Love of projector is most \nlikely derived from the earliest \nmethod of picture projection, weites \ndates back to prenintary and is \nperformed in the form of primitive \nshadow play. It was the first phase \nin the projector\'s growth.  \nA video projector is the most \ncommon form of projector used today. \nSlide projectors and overhead \nprojectors have been replaced by \nvideo projectors, which are \nautomated versions of the older \nprojectors. In the 1990s and early \n2000s, these older projectors w ere \nlargely replaced with digital video \nprojectors, but old analog \nprojectors are still in use in some \nareas. Handheld projectors that \nproject images using lasers or LEDs \nare the most recent forms of \nprojectors. If there is too much \nambient light,  their estimates are \ndifficult to see.  \nThe use of pictures to Interact \nand appreciate the world around us \nhas expanded as a result of \ntechnological advances. The ase of \ninternet technology has transformed \nusers into active participants who \ncan connect with their audiences \nusing words.  \nTechnology that provides \nphotos, video, and applications \ngives customers with a range of \nresources to use to attract and \nprovoke the attention of their \naudience. The combination of words \nand pictures has a strong impact on \nhow ideas are communicated.  \nSetting up the projector and \nconnection ties for a wired \nconnection presentation requires \ntime. Professional workers need a system that is effective, fast, \ndependable, simple to use, and, most \nimportant, thus less expensive. A \nsystem that can keep up with the \nmodern or advance and seems to be \nquick to carry and set  up. \nAs a result, the latest \nInnovation aims to provide wireless \nmulti-access connectivity to \nreplace old presentation methods \nwith a compact, wireless, and \nsimple-to-use system for \npresentations, videos, images, \nlesson plans, and business \nproposals.  \nAnother aim of this project is \nto build a wireless visual \naccessibility system that will \nenable users to provide an excellent \npresentation. An android phone, \nlaptop, or tablet can be used to \nmonitor it.  \n \nGENERAL OBJECTIVE  \nThis study aimed to develop a \nWIRELESS MULTI ACCESS WITH \nPROJECTION SYSTEM.  \n \nSPECIFIC OBJECTIVE  \n• To have a battery -operated \nprojector that can last up to \n3-5 hours and can be used in an \nemergency.  \n• To connect as the projector\'s \ncontroller using Macs, \nlaptops, 10S/Android phones \nand tablets.  \n• To provide users with a \nwireless microphone having a \ndistance of 5 meters for their \npresentation.  \n STATEMENT OF THE PROBLEM  \nThis design project seeks to \nanswer the following questions:  \n1. What are the characteristics \nof the device / system in terms of \nprojecting which is currently used?  \n2. What improvement can be made \nout of the existing device/system?  \n3. What new device / system can \nbe derived with the improvement?  \n4. What is the level of \nassessment of the group of \nrespondents on the developed device \n/ system with the following \ncriteria? Is there significant \ndifference?  \n4.1 Functionality  \n4.2 Usability  \n4.3 Reliability  \n4.4 Efficiency  \n4.5 Maintainability  \n5. What claims can be made from \nthe developed device / system?  \n \nMETHODOLOGY  \nSampling is a method for \nselecting a sample from a person or \na wide group of people for a \nspecific research purpose. One of \nthe most important factors in \ndetermining the accuracy of a sample \nis sampling. (Pooja Bhardwaj, 2019)  \nResearchers begin with a \npresentation of some findings used \nin sampling since probability is the \nfoundation of sampling theory. This \nis accompanied by some of the most \ncritical expected value outcomes. \nBoth topics in the sense of sampling \nare applicable to  all forms of \npopulations and parameters, so the \nclassical sampling principle is \nconsidered distribution free. \nConfidence interval claims \nregarding sample statistics, on the \nother hand, presuppose that the \nderived distributions are \nestablished. In practice , the \ncentral-limit theorem and \nestimators that approach normality \nare used. In reality, modern sample \nsurveys are multi -characteristic, \nmaking many of the findings  \navailable from general estimation \ntheory Lepractical. As a result. the use of complex distributions and the \nmaximum-likelihood approach are \nseldom considered. Similarly, an \nestimator that is less expensive or \neasier to use is often favored over \nanother which requires considerable \ncomputations and may have a smaller \nvariance. It is not right, however, \nto conclude that more efficient \nestimation theory cannot be used to \ngood effect in surveys where they \nare necessary and where there is a \nhigh degree of experti se and \nresources available. (Harold F. \nHuddleston, 1990)  \nNon-probability sampling is \ncommon in experimental or trial \nstudies, and it does not reflect the \ntarget population. Non -probability \nsampling relies on subjective \njudgment and makes use of the most \nconvenient units from the \npopulation. For personal interview \nsurveys, non -probability sampling \nmethods save money, but the \nresulting samples look a lot like \nprobability sample res ults. Thus the \nparticipants in purposive sampling \nare chosen subjectively by the \nresearcher. The researcher\'s \njudgment is used to make the \ndecision. Respondents are not chosen \nat random, but rather based on the \ninterviewers\' judgment. As a result, \nthe like lihood of inclusion for any \ngiven sample is unknown a single \nunit. (Oztas Ayhan, 2011)  \n \nEVALUATION  \n The project was evaluated based \non the following criteria namely:  \n• Functionality  \n● Usability  \n● Reliability  \n● Efficiency  \n● Maintainability  \n \nSTATISTICAL TREATEMENT  \nThe mean was used as the tool \nfor evaluating the project. T  \nThe formula is:  \n𝑋=Σx\n𝑁 \n \n Where,  \nΣ, represents the summation  \nX, represents scores  \nN, represents number of scores  \n \nThe Likert scale was u sed of \ndescriptive ratings.  \nTable 1.  The Likert Scale for \nDescriptive Ratings \nNumerical \nScale Average \nResponse Descriptive \nRating Verbal \nInterpretation  \n5 4.51 – \n5.00 Excellent   E \n4 3.51 – \n4.50 Very Good  VG \n3 2.51 – \n3.50 Good  G \n2 1.50 – \n2.50 Fair  F \n1 1.00 – \n1.50 Poor  P \n \n \nEQUAL VARIANCE NOT ASSUMED  \nWhen the two independent \nsamples are assumed to be drawnfrom \nthe populations with equal variances \n(1.e., 012  ≠ 022), the test \nstatistic t is computed as:  \n \n𝑡= 𝑥1−𝑥2\n√𝑠1\n𝑛1+𝑠2\n𝑛2 \nWhere, \nx1 = Mean of the first sample  \nx2 = Mean of the second sample  \nn1 = Sample size (i.e., number \nof observations) offirst \nsample \nn2 = Sample size (i.e., number \nof observations)of second \nsample \ns1 = Standard deviation of \nfirst samples  \ns2 = Standard deviation of \nsecond sample  \nThe calculated t value is then \ncompared to the  critical t value \nfrom the t distribution table with  \ndegree of freedom . \n \n \n DATA GATHERING PRO CEDURE \n1. Create questionnaires.  \n2. Present the questionnaires to \nthe evaluators.  \n3. Distribute a list of questions \nto a group of people that the \nresearchers will actually collect \ndata from.  \n4. Analyze and interpret the data \ncollected.  \n5. The results are collected in \nreal-time for researchers to \ndecide corrective measures.  \n6. Collective data came from \nprovided questionnaires are \nprocessed in order to become \nuseful information.  \n \nSUMMARY OF FINDINGS  \nThis chapter shows the findings \nresuiting from this study.  \nSOP 1. Who is the beneficiary of \nthis project?  \nThis device will let users \n(Professors, Teacher, Students, \nMissionaries or etc.) to use a \nprojector that have ability to \noperate with the use of android \nphone, laptop, macs also have a \nbuilt-in speaker and battery \nconnected to the device. Moreover, \nthe proposed device will help the \nusers to replace laptops and \ncomputers so that the cost is \nreduced.  \nSOP 2. How establishments? can it \nhelp in schools, offices and other  \nMany people can benefit to \nthis- benefitting from more \napplicable and better learning \nretention as a result. Because of \nWIMPS, students can focus more on \nlistening rather than only writing \ndown things that are only useful to \nthem. Moreover, it reduces taki ng \ndown of incorrect and irrelevant \nnotes. The use of WIMPS also makes \nbetter use of time as well. There\'s \nno need of  \nmanual writing because it can \nnow be projected through the use of \nmobile phones, laptops, macs. \nWhether it is making school or \nbusiness presentations, projector \nsystem can add stars to the outcome \nof the work. The WIMPS helps you to presentation not just presentation \nwith images but also videos coming \nto the user\'s phone. It also has a \nbuilt-in speaker so amplifiers are \nnot in need anymore.  \nSOP 3. Is the device can still be \nused in the places where electricity \nis not available?  \nYes, because this system is \nbattery operated that can last up to \n3-4 hours and it is designed to \nthose places that are resided near \nthe mountains where there is a \nnecessity in electricity.  \nSOP 4. What is the assessment of the \nthree groups of respondents namely; \nStudents, Professors, and \nPractitioners in terms of the \nfollowing criteria?  \nIs there any significant \ndifference? The following criteria \nweze being assessed by the two \nstudents, professors and \npractitioners. groups of \nrespondents both  students, \nprofessors and parti tioners. \n \nTable 2: Summary of Assessment of on \nthe Wireless Multi -Acccess with \nProjection System \nCriteria Stud\nents  Prof\nesso\nr Comm\nunit\ny Comp\nosit\ne \nMean V\nI RA\nNK \n1.Functi\nonality 4.83  4.70 5.00 4.84 E 4.\n5 \n2.Usabil\nity 4.90  4.85 5.00 4.92 E 2 \n3.Reliab\nility 4.95  4.85 5.00 4.93 E 1 \n4.Effici\nency 4.83  4.90 4.97 4.90 E 3 \n5.Mainta\ninabilit\ny 4.77  4.77 5.00 4.84 E 4.\n5 \nOverall \nComposit\ne     4.89 E  \n \nTable 2. shows the result of the \nover all assessment of the three \ngroups of respondents, namely: \nStudents, Professionals and \nCommunity. The overall composite \nmean has a numerical value of 4.89 \ninterpreted as \"Excellent\".  \nRank 1 is\" Reliability\" with a \ncomposite mean of 4.92 and \nInterpreted as \"Excellent \".  \nRank 4.5 are\" Funnctionality\" \nand \"Maintainability\" with \ncomposite means of 4.84 and \ninterpreted as Excellent \".  Rank 2 is U sability\" with a \ncomposite mean of 4.92 and \ninterpreted as \"Excellent \".  \nRank 3 is “Efficiency ” with a \ncomposite mean of 4.90 and \ninterpreted as “Excellent ”. \n \nCONCLUSION  \nBased on the findings of the \nstudy, the following conclusions are  \ndrawn; \nA. According to the evaluation \nresult of the functionality of \nthe system, the level at which \nperformance determines \ncompleteness, accuracy, and \nappropriateness are defined as \n\"Excellent\" by students, \nprofessors and in the \ncommunity. which means that the \nfunctionality of Wireless \nMulti-Access with Projection \nSystem provided specific tasks \nand user goals, accuracy of \nresulting in the required level \nof precision, and facilitated \nthe achievements of the \nspecified task and the \nobjectives.  \nB. According to the evaluation \nresults of the usability of the \nsystem, the level at which \navailability is set and access \nis defined as \"Excellent\" by \nstudents, professors and in the \ncommunity, which means that the \nusability of Wireless Multi - \nAccess Projec tion System has \nfeatures that make it easier to \noperate and control. Can be \nused by people with the widest \nrange of characteristics and \nabilities to achieve a \nspecified context of use.  \nC. According to the evaluation \nresult of the reliability of \nthe system, the degree to which \nthe sets maturity and  \navailability were interpreted \nas \"Excellent\" by the students, \nprofessors and practitioners, \nwhich means that the \nreliability of Wireless Multi \nAccess with Projection System \nhas met the needs for \nreliability under normal \noperation and It was \noperational and  was accessible \nwhen required for use.  D. According to the evaluation \nresult of the efficiency of the \nsystem, the degree to which the \nsets time behavior, resource \nutilization and capacity were \ninterpreted as \"Excellent or \nHighly Accepted\" by the \nstudents, professors and \npractitioners, which mea ns \nthat the efficiency of Wireless \nMulti Access with Projection \nSystem met the requirements of \nperforming its functions.  \nE. According to the evaluation \nresult of the maintainability \nof the system, the degree to \nwhich the aets modularity, \nreusability and modifiability \nwere interpreted as \"Excellent \nHighly Accepted\" by the \nstudents, professors and \npractitioners, which means \nthat the maintainability of \nWireless Multi Access with \nProjection System was composed \nof discrete components such \nthat a change to one component \nhad minimal impact on other \ncomponents, an asset can be \nused in more than one system, \nor in building other assets  and \ncan be  effectively and \nefficiently modified without \nintroducing defects or \ndegrading existing  systems \nquality.  ', 'raytos.bsinfotech@gmail.com', 'Dimpas Lesther, Jamin Gabriel, Perez Reza Lyn, Jazon Jean Roann,  Mendez Julius, Bautista Rica Mae, Larona Raven ', '', '../pdf_files/6746e485321d7-WIRELESS MULTI-ACCESS WITH PROJECTION SYSTEM.pdf', 159729, 5, 2025, 13151, '2024-12-03 04:43:00', '2024-11-27', 'Accepted', 0, 1),
(2, '1704859159', '51', 5, 5, 'WATER CONTAMINANT DETECTOR APPLICATION', '2024-11-27 17:30:40.990151', '2024', 'Water pollution is often considered one of the primary reasons why our planet is on the brink of destruction. The more polluted our sources of water is becoming, the more likely the human race will slowly to become extinct. Despite the fact that there aree facilities which purify and clean water on a daily basis, there are still other people who rely on other water sources in desperate times and don’t have access to clean water.', 'Water,Detector,Application,Innovation,Pollution', 'WATERCONTAMINANTDETECTORAPPLICATION\nArielJ.GarciaJr.,JohnJoshuaV.Layaog,AbigailJ.Purificacion,MarycelG.Zapanta.\nDepartment:CollegeofArtsandScienceCourse:ComputerScience\nINTRODUCTION\nWaterisknownasthemostimportantsourceoflifeasitisabletosustainthedailyneedofalllivingcreaturesonEarth.Ithelpsinplantandanimalgrowth,andhumansarealsomadeupof75%water.Thesearejustafewexamplesofhowwaterissignificantinnourishinglifeinourplanet.\nMostnotably,waterisknownasthemainsourceoflifefortheEarth.Humans,forexample,needwaterfordrinkinginordertostayhealthyandhydrated;wealsousethisforhygienicusesinordertostayproperandclean.Animalsandplantscan’tlivewithoutwaterasitisinofthebasicneedsinordertogrowbig,strongandhealthy.Basicallyspeaking,waterisanessentialpartofourecosystemandtherefore,wecannotaffordtoloseit.\nWaterpollutionisoftenconsideredoneoftheprimaryreasonswhyourplanetisonthebrinkofdestruction.Themorepollutedoursourcesofwaterisbecoming,themorelikelythehumanracewillslowlytobecomeextinct.Despitethefactthatthereareefacilitieswhichpurifyandcleanwateronadailybasis,therearestillotherpeoplewhorelyonotherwatersourcesindesperatetimesanddon’thaveaccesstocleanwater.\nAsidefrompollutingoursources,contaminatedwaterisslowlycausingdiseasesuponthehumanracewithoutusnoticing.Sincewaterisalsopartofourecosystem,wewillloseoursourcesoffood,supplies,andeventually,life.Althoughthereareinstrumentsthatprovidewiththecontentsofwater,itonlyprovidesparameters.Thefactofthematteristhattheseinstrumentsmaymeasureparameters;theydon’tshowthepossiblecausesuponconsumingthewaterorusingit.ThispHLevelsandTurbidityareoneofthemostcommonandimportantforwaterquality.Thewaterhashydrogenionsandhydroxylions.Whenthereareequalnumbersofboth,thewaterisneutral.Acidiccancausetoxicheavymetalstobereleasedintothewater.AcidrainandminingoperationscanlowerthepHofwaterbodies.ThisiswhatpHismeasuredfor.Thereductioninwaterqualityofthiscommonmeasuredasknownasturbidityisthecontentofsuspendedsolidinwater,isalsoreferredtoas“cloudiness”ofthewater.Ittakestheturbidityreadingstomonitordredgingandconstructionprojects,examinemicroscopicaquaticplantlife,andmonitorsurface,storm,andwastewater.\nThisstudyisconductedforustobeabletodeterminethepHlevel,andturbidityofwaterandwhetherornotitissafeforhumanconsumptionoruse.\nGENERALOBJECTIVE\nThisstudyaimstodesignanddevelopafaceshieldwithabodytemperaturescannerandrecordingsystemusingasystemofidentificationthatallowstheusertoinstantlyaccessinformationfortracking,collecting,andsecuringdatathatcanuseduringthispandemic.\nSPECIFICOBJECTIVESTheSpecificobjectivesofthisprojectare:•TodesignanddevelopaWaterContaminantDetectorApplication\n•Todevelopamobileapplicationthatcandisplayandpassedthecontaminationofwaterdatatothesystem.•DevelopawebsiteforregistrationofDetectorapplicationself-assessmenttogenerateaQuickResponse(QR)codeafterregistrationandcompletingtheself-assessment.\nSTATEMENTOFTHEPROBLEM\nThisprojectaimstobuildaproposedWaterContaminantDetectorApplication.Itseekstoanswerthefollowingresearchquestions:\n1.Whatisthestatusofexistingwatercontaminantdetector?\n2.Howtoenablerealtimetodetectifwateriscontaminated?\n3.Howassesstheproposedresearchstudyintermsofthefollowing:a.Functionality;b.Reliability;c.Compatibility;d.Portability;e.Usability;f.Maintainability;g.Efficiency;h.Security;\n4.Isthereasignificanceanddifferencebetweentheusersandexpertsintheassessmentoftheproposedresearchstudy?METHODOLOGY\nThischapterdiscussestheresearchdesign,populationandsampling,respondentsofthestudy,researchinstrument,datagatheringprocedures,andstatisticaltreatmentofdatausedbytheresearchers.Thisstudyprovidedinformationontheresearchontheresearchmethodsofstudy.ThequestionnaireresearchmethodhadbeenchosentodeterminethefactorstoconsiderincreatingtheWaterContaminantDetectorApplicationwiththeuseofthecorrespondents’answeronthesurveyquestionnaire.Theresultsweretalliedasresultsonthebasisofwhattoputandhowatheexperimentationwasbeingprocessedinawaythattheuserwillbesatisfied.\nEvaluationMethod\nTheprojectwasevaluatedonthefollowingcriteria,namely:Functionality,Usability,Reliability,Efficiency,andMaintainability.A.StatisticalTreatmentThemeanwasusedasthetoolforevaluatingtheproject.TheFormulais:𝑥\n=\nΣ𝑋/𝑁\nWhere:\nΣ\n,representsthesummationXrepresentsscoresNrepresentsnumberofscoresTheLikertscalewasusedfordescriptiveratings.\nSUMMARYOFFINDINGS\nTheanalysisandinterpretationofthedatabasedontheexperimentalprocedureandgatheredinformationonhowtocompletetheprocessofbuildingtheWaterContaminantDetectorApplicationarepresentedaccordinglyinthisstudy.\nTheresearchersuseddifferenttoolssuchassurveyquestionnairestogathernecessarydataandinformationforthedevelopmentoftheapplicationwherethesurveyquestionnaireswererequiredandfacilitatedtothe20respondents.\nRank1is“Usability“withacompositemeanof4.10andinterpretedas“Excellent.\"Rank5is“Maintainability“withacompositemeanof3.83andinterpretedas“VerySatisfactory.\"Rank2is“Functionality“withacompositemeanof4.03andinterpretedas“VerySatisfactory.Rank3is“Reliability“withacompositemeanof4.02\nandinterpretedas“VerySatisfactory.\"\nRank4is“Efficiency“withacompositemeanof3.93andinterpretedas“VerySatisfactory.\"ThedatashowsthattheFaceshieldwithbodytemperaturescannerandRecordingsystemintermsofitsfunctionality,usability,reliability,efficiency,andmaintainabilityisviewedasaVerySatisfactorydevicebythegroupofStudentsandProfessors,andCommunity.\nCONCLUSIONSBasedonthesummaryoffindings,theresearcherscameupwiththefollowingconclusions:\n1.Whenitcomestodeterminingifwateriscontaminated,thereneedstobemoreparametersaswellasothersensorssincewatercontaminationisnotmeanttobeknownforonlytwofactors.Mostoftherespondentshaveanswered,andinkey,“Moreparameters”sincethepresentdaywaatercontaminationdetectorsonlyscanforoneparameter.Theresearchershavesinceidentifiedthatthestudycanbeastarttoanall-in-onedevicethatcandetectwatercontamination.\n2.Therespondents’assessmentonthe“WaterContaminantDetectorApplication”hasallowedtheresearcherstoimmediatelytakenoteonwhatboththeapplicationandthedevicemayneedandimprove.Amajorityoftheimprovementsareforthedevicewhichisthereasonwhymostoftherespondentshaveansweredthatthestudyneedsmoredevicewhichintermwillresultinmoreparametersthatneedtobeanalyzedinordertoidentifyifthewateriscontaminated.\nRECOMMENDATION\nTheresearchersrecommendtothefutureresearchersthattheWaterContaminantDetectorApplicationcanbeimprovedmorebyenhancingitsfeaturesbasedontheresultsofthesurveys.Cansequentthefollowingrecommendationsarepresented:\n1.Theresearcherswouldliketosuggesttoenhanceandtodevelopmoresystemcapabilities.Thisrecommendationisbasedonthekeyinterviewwordsandfunctionfromthesurveyquestionnairesuchas“Moreparameters”,“Requiresmoredevices”,“Thedeviceandapplicationis90%estimatedcertainoftheresult”,and“TheapplicationcannotinstalltoaniOS”.Thesearesomeofthefacedpointsthatneedspecialattention.\n2.Theresearcherswouldliketorecommendtomakeitmoreknowledgeable,andexcitingfortheusertoexploreitforeducationalandentertainmentpurposes.', 'raytos.bsinfotech@gmail.com', 'Ariel J. Garcia Jr., John Joshua V. Layaog, Abigail J. Purificacion,  Marycel G. Zapanta', '', '../pdf_files/6746e6c03157e-Water Contaminant Detector Application.pdf', 83514, 5, 40, 6893, '2024-12-03 04:43:00', '2024-11-27', 'Accepted', 0, 0),
(3, '9835465462', '51', 5, 5, 'UTILIZATION OF LEMONGRASS AS A MAIN INGREDIENTS  IN PREPARATION OF CANDY', '2024-11-27 17:33:04.685502', '2024', 'Lemongrass, commonly called “tanglad” in Tagalog, is a plant that is commonly used in Asian cuisine but which may provide therapeutic and medical benefits. It is a good source of Vitamin A, B, and C which are very potent antioxidants; lemongrass is a very good quencher of unstable free radicals that can react with and damage molecules that cause aging. Antioxidants reduces the appearance of wrinkles an fine lines. Easily available from any ethnic store, health food store, online merchant or in the aisle of the supermarket, its anti-bacterial, anti-microbial, and therapeutic properties make lemongrass a useful alternative or complementary remedy for a wide spectrum of common ailments.', 'Tanglad,Lemongrass,Development,Product,Diet', 'UTILIZATIONOFLEMONGRASSASAMAININGREDIENTSINPREPARATIONOFCANDY\nRommelDG.Aquino,Ma.JovilynT.Alegre,VladimirA.Eguirra,NestorB.LansanganJr.\nDepartment:CollegeofIndustrialTechnologyCourse:BSITMajorinFoodTechnology\nINTRODUCTION\nToday,theglobaldemandforahealthierdietisincreasing,consumersattentionisintheconnectionoftheirdietandhealth,theybecomeverydemandinginseekingproductsoftheirwants.Thisresultforthecandydevelopertolookforanewproductthatwillfittotheneedsandwantsoftheconsumers.\nAnewProductDevelopmentisthetermusedtodescribethecompleteprocessofbringinganewproducttomarket.Anewproductisonethatistotallynewordifferentversionofsomethingalreadyonthemarket.Newproductsaredevelopedbecauseofdemandenthusedbychanginglifestyles,convenience,healthorfitness.\nDevelopingnewproductisachallengetothedeveloper,especiallythattherearemorenewexistingproductsareconstantlybeingdesignanddeveloped.Candy(alsocalledassweetsorlollies)ismadebydissolvingcrystallizedsugarinwaterormilktoformasyrup,whichisboileduntilitreachesthedesiredconcentrationorstartstocaramelize.Candycomesinawidevarietyoftextures,fromsoftandchewytohardandbrittle.Thetextureofcandydependsontheingredientsandthetemperaturesthatthecandydependsprimarilyonthesugarconcentration.Asthesyrupisheated,itboils,waterevaporates,thesugarconcentrationincreasesandtheboilingpointrises.Agiventemperaturecorrespondstoaparticularsugarconcentration.\nLemongrass,commonlycalled“tanglad”inTagalog,isaplantthatiscommonlyusedinAsiancuisinebutwhichmayprovidetherapeuticandmedicalbenefits.ItisagoodsourceofVitaminA,B,andCwhichareverypotentantioxidants;lemongrassisaverygoodquencherofunstablefreeradicalsthatcanreactwithanddamagemoleculesthatcauseaging.Antioxidantsreducestheappearanceofwrinklesanfinelines.Easilyavailablefromanyethnicstore,healthfoodstore,onlinemerchantorintheaisleofthesupermarket,itsanti-bacterial,anti-microbial,andtherapeuticpropertiesmakelemongrassausefulalternativeorcomplementaryremedyforawidespectrumofcommonailments.\nHowever,thisplantshavenotreallybeenusedbeyondthetraditionalpurposesithasservedformostconsumers.Theirconsumptionhasmainlybeentobeapartofadishbutnotfortheirsoleusage.\nTherefore,theresearchersencouragedtoconductastudyofproducingthelemongrasscandyistodevelopanewflavourofcandythattheconsumerswilldelightfullyenjoythetaste,andasidefromthenutritionalbenefitsitcouldgive,itwillbetherapeuticapplicationpreventinggastrointestinalproblems,stomachaches,diarrhea,bowelspasms,vomiting,fever,fluheadaches,infectiousillness,colds,rheumatismandcankillcancercells.\nSTATEMENTOFTHEPROBLEM\nTheprimaryconcerndealsontheutilizationoflemongrassasamainingredientinthepreparationofcandy.Specially,itseekstoanswerthefollowing:\n1.Whatarethecommonflavourstobemixedinproducingcandy?2.Howdothetwogroupsofrespondentsassessedthelemongrasscandyonthequalitycharacteristicsintermsof:1.1.Appearance;1.2.Flavour;1.3.Taste;and1.4.Texture?\n3.Isthereasignificantdifferencebetweenthelemongrasscandybrandsxandyintermsofappearance,texture,flavour,andtaste?\n4.Isthereasignificantdifferencethelemongrassofthetwogroupsofrespondentsastolemongrasscandy`squalitycharacteristics?\n5.Isthereasignificantrelationshipamongthequalitycharacteristicsoflemongrasscandy?\nMETHODOLOGY\nTheresearchersusedthedescriptiveandexperimentalmethod.Thedescriptivemethodofresearchattemptstodescribeandexplainconditionsofthepresentbyusingsubjectsandquestionnairestofullydescribeaphenomenonandexperimentalmethodisthisdesignismostappropriateincontrolledsettingssuchaslaboratoriesanditattemptstoexplorecauseandeffectrelationshipswherecausescanbemanipulatedtoproducedifferentkindsofeffects.(Airasian,P.,etal.(2006).\nEvaluationMethod\nSUMMARYOFFINDINGS\nThefollowingarethespecificproblemsandtheirsummarizedfindings:1.Thecommonflavourstobemixedinproducinglemongrasscandyareorangehas26or52%,calamansihas12or24%lemonhas10or20%,anddalandanhas4or8%.Theresearchersdecidedtoproducehighestflavourswhichistheorangeflavourbrandedasxandcalamansiflavourasbrandyfortheexperimentalresearch.2.ThetwogroupsofrespondentsdoassessedthequalitycharacteristicsoflemongrasscandyasinBrandXhasa=7.08withtheverballyinterpretationofLikeModeratelywhileinBrandYhasa7.83withtheverballyinterpretationofLikeVeryMuch3.Thereisnosignificantdifferencebetweenthelemongrasscandybrandsxandyintermsofappearance,texture,flavour,andtaste,isingeneral,thecomputedt-valueof1.314whichislowerthanthecriticalvalueof1.684at0.05levelofsignificanceandwasinterpretedasnotsignificantthereforethehypothesisisaccepted.4.Thereisnosignificantdifferencebetweentheassessmentsofthetwogroupsofrespondentsastolemongrasscandy`squalitycharacteristics,thecomputedt-valueof1.314whichisalowerthanthecriticalvalueof1.684at0.05levelofsignificanceandwasinterpretedasnotsignificantthereforethehypothesisisaccepted5.Thereisnosignificantrelationshipamongthequalitycharacteristicsoflemongrasscandyoftheobtainedoverallt-valueis0.0125with3degreeoffreedomfelllowerthanthecriticalvalueof1.943,at0.05levelofsignificanceandwereinterpretedasnotsignificantthereforethehypothesisisaccepted.\nCONCLUSIONS\nFromthecitedfindings,theresearchersarrivedatthefollowingconclusion:1.Lemongrasscanbemixedwiththedifferentfruitflavourssuchasorangeandcalamansi.2.BrandYismostpreferredfruitflavouroflemongrassbothstudentsandemployees.3.Thetwofruitflavourscanbemarketabletobothemployeesandstudents.4.StudentswantthebrandXwhichistheorangeflavourbecauseofthesweetness.5.Lemongrasscandycanbeproducedwithadistinctfeature.\nRECOMMENDATION\n1.Explorewithotherfruitflavoursthathasnutrientssidefromorangeandcalamansi.\n2.Developedamarketingplanorfeasibilitystudytofindouttheviabilityandprofitabilityoflemongrasscandy.\n3.Marketthebrandyfortheemployeesandbrandxforthestudents,specificallyinEARIST.\n4.PresentthelemongrasscandytotheDOSTandFDAfortheproducttesting.', 'raytos.bsinfotech@gmail.com', 'Rommel DG. Aquino, Ma. Jovilyn T. Alegre, Vladimir A. Eguirra, Nestor  B. Lansangan Jr.', '', '../pdf_files/6746e750764c2-Utilization of Lemon Grass As A Main Ingredients in Preparation in Candy.pdf', 695651, 4, 28, 5730, '2024-12-03 04:43:00', '2024-11-27', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(7, '6005762357', '6745cf4203d9a', 6, 10, 'Public sentiments on the fourth industrial revolution: An unsolicited public opinion poll from Twitter', '2024-11-29 16:44:11.743933', '2024', 'This article explores public perceptions on the Fourth Industrial Revolution (4IR) through  an \r\nanalysis of social media discourse across six European countries. Using sentiment analysis and \r\nmachine learning techniques on a dataset of tweets and media articles, we assess how the public \r\nreacts to the integration of technologies such as artificial intelligence, robotics, and blockchain \r\ninto society. The results highlight a significant polarization of opinions, with a shift from neutral \r\nto more definitive stances either embracing or resisting technological impacts. Positive sentiments \r\nare often associated with technological enhancements in quality of life and economic \r\nopportunities, whereas concerns focus on issues of privacy, data security, and ethical \r\nimplications. This polarization underscores the need for policymakers to engage proactively with \r\nthe public to address fears and harness the benefits of 4IR technologies. The findings also \r\nadvocate for digital literacy and public awareness programs to mitigate misinformation and foster \r\nan informed public discourse on future technological integration. This study contributes to the \r\nongoing debate on aligning technological advances with societal values and needs, emphasizing \r\nthe role of informed public opinion in shaping effective policy.', 'Fourth Industrial Revolution,Social media analytics,Technology acceptance', '1   \n \nPublic sentiments on the fourth industrial \nrevolution:  \nAn unsolicited public opinion poll from Twitter  \n \nDiletta Abbonato1,2 \n \n1DEMS, University of Milan -Bicocca  \n2BETA, Strasbourg University  \n \n \nKeywords:  Fourth  Industrial  Revolution,  Social  media  analytics,  Technology  acceptance  \n \nThis article  explores  public  perceptions  on the Fourth  Industrial  Revolution  (4IR)  through  an  \nanalysis  of social  media  discourse  across  six European  countries.  Using  sentiment  analysis  and \nmachine  learning  techniques  on a dataset  of tweets  and media  articles,  we assess  how  the public  \nreacts  to the integration  of technologies  such  as artificial  intelligence,  robotics,  and blockchain  \ninto society.  The results  highlight  a significant  polarization  of opinions,  with  a shift  from  neutral  \nto more  definitive  stances  either  embracing  or resisting  technological  impacts.  Positive  sentiments  \nare often  associated  with  technological  enhancements  in quality  of life and economic  \nopportunities,  whereas  concerns  focus  on issues  of privacy,  data  security,  and ethical  \nimplications.  This polarization  underscores  the need  for policymakers  to engage  proactively  with  \nthe public  to address  fears  and harness  the benefits  of 4IR technologies.  The findings  also \nadvocate  for digital  literacy  and public  awareness  programs  to mitigate  misinformation  and foster  \nan informed  public  discourse  on future  technological  integration.  This study  contributes  to the \nongoing  debate  on aligning  technological  advances  with  societal  values  and needs,  emphasizing  \nthe role of informed  public  opinion  in shaping  effective  policy.  \n \n1 Introduction  \nThere  is an increasing  call for data  policy  and governance  to be aligned  with  societal  values  and \nneeds,  and worthy  of public  trust,  such  that it is necessary  to understand  peoples  perception  \nand experience  in relation  to data  and data -driven  technologies.  This interaction  takes  different  \nforms,  including  public  discourse  on regulatory  policies  (Douglas,  2012),  consumer  prefer ences  \nimpacting  upon  product  development  (Hekkert  et al., 2007),  and grassroots  movements  \nadvocating  ethical  considerations  in technology  use (Jasanoff,  2005).  In this article,  we delve  \ninto the Fourth  Industrial  Revolution  (4IR henceforth)  (Schwab,  2017),  providing  a first large -\nscale  study  of public  opinion  on its associated  technologies.  In particular,  we refer  to artificial  \nintelligence  (AI),  robotics,  blockchain,  cloud  computing,  the Internet  of Things  (Iot)  and virtual  \nreality,  which  are reshaping  societal  processes  and systems  (Geels,  2002;  Orben  and Przybylski,  \n2019).  However,  4IR is not only  a technological  phenomenon;  it is deeply  human  and societal  \nin nature  (Yun and Liu, 2019).  The introduction  of these  advanced  technologies  in everyday  life 2  can disrupt  existing  social  structures  with  a corresponding  threat  in terms  of inequalities  and  \nthe need  for new  governance  models  (Rainie  and Anderson,  2017).  Society  is not a mere  \npassive  recipient  of these  shifts  (Sartori  and Bocca,  2022),  but it actively  plays  a role in shaping  \nand directing  the evolution  of technology  (Nelson  and Sampat,  2001;  Ostrom,  2009).  These  \ntransformations  can be observed  in various  fields,  from  labor  market  dynamics  due to \nautomation  (Autor,  2015)  and to changes  in communication  patterns  as a result  of social  media  \n(Van Dijck , 2013).  \nThe initial  decades  after  the implementation  of such  new  technological  systems  have  shown  a \nclear  difference  between  the economic  and social  aspects  of technological  change  (Perez,  2003).  \nFor example,  concerns  about  data  privacy  have  led to significant  changes  in how  personal  data  \nis managed  and regulated  (Zuboff,  2023).  The widespread  use of AI in decision -making  processes  \nraises  ethical  concerns  on privacy,  consent,  and accountability  of automated  systems  (Cath,  2018).  \nMoreover,  4IR shapes  social  interactions  and cultural  norms  for digital  connectivity  enhances  the \nboundaries  of communities  and changes  the way people  communicate  and interact  (Holm  et al., \n2023).  4IR points  out that  the introduction  and integration  of new  technologies  not only  bring  \nabout  economic  transitions,  but also significant  transformations  in social  structures  and functions  \n(Schwab, 2017).  With  its participation  in this dynamic  process,  society  influences  not only the  \ndirection  but also the pace  of technological  advancements  (Hughes  et al., 1987),  with  the \npossibility  of hindering  the adoption  of certain  technologies.  For instance,  the widespread  social  \ndemand  for sustainable  energy  solutions  has accelerated  progress  in renewable  energy  \ntechnologies  (Jacobsson  and Lauber,  2006),  while  resistance  from  society  can slow  down  the \ndevelopment  of technologies  like GMOs  as well  (Paarlberg,  2000).  \nThe fundamental  problem  concerning  media  management  derives  from  a deep  cultural  rift \nbetween  the world  of science  and the world  of news  and commentary.  History  has shown  that  \nwhen  scientists  run to the press  with  sensational  claims  that  haven’t  been  properly  checked,  the \noutcome  is very  damaging  to the credibility  of science  itself,  not to mention  the reputations  of \nthe scientists  involved.  Therefore,  the role of society  goes  beyond  a simple  neat  choice  of \naccepting  or rejecting  technological  innovations  -it actively  shapes  its trajectory  and impact  \n(Pinch  and Bijker,  1984).  Such  a mutual  relationship  between  society  and technology  suggests  \nthat  understanding  technological  progress  requires  a comprehensive  approach  that  not only  \nfocuses  on the economic  and technological  dimension  but also on social,  cultural,  and ethical  \ndimensions  (La- tour,  2007).  \nThe democratization  of digital  technologies  is a first example  of the way 4IR has made  advanced  \ntechnologies  more  accessible.  Though  these  technologies  may  be enough  expensive  to be \navailable  to a narrow  community  of institutions  and corporations  only,  the progressive  \nimprovements  in their  components  and architecture  allowed  for a sustained  decrease  in sale \nprice  across  time,  making  them  widely  available  to the majority  of the population  (Ceruzzi,  \n2012).  For instance,  smartphones,  which  have  advanced  computing  capabilities,  have  become  \nwidely  accessible  and have  had a significant  impact  on social  dynamics  (West,  2012).  The spread  \nof smartphones  has largely  increased  the access  to information,  allowing  people  from  different  \nsocioeconomic  backgrounds  to join the digital  world.  The economic  theory  about  the diffusion  of \ninnovation  contributes  to explaining  the shift  from  exclusivity  to ubiquity  suggesting  that  \ntechnological  advancements become more  accessible  and affordable over  time, reaching  a wider \naudience  (Rogers  et al., 1962).  Furthermore,  the rise of social  media  and digital  platforms  has \ncreated  new  forms  of social  engagement  and expression  but has also introduced  challenges  \nrelated  to misinformation  and digital  well -being  (Twenge,  2017).  Nevertheless,  we should  \nrecognise  that  the digital  divide  is still a challenge.  While  many  technologies  have  become  more  \naccessible  allowing  people  from  different  socioeconomic  backgrounds  to join the digital  world,  \ndisparities  in access  still exist,  influenced  by factors  such  as income,  geography,  and education  3  (Van Dijck,  2013).  In this context,  managing  the socio -economic  considerations  brought  about  by \n4IR is crucial  to ensure  that  it benefits  are widely  distributed  and that  potential  harms  are \nmitigated.  This requires  a collaborative  approach  involving  policymakers,  industry  leaders,  and \npublic  institutions  to develop  strategies  that  promote  inclusive  growth  and safeguard  ethical  \nstandards  (Brynjolfsson  and McAfe e, 2014;  Min et al., 2019).  \nSocial  networks  have  become  crucial  in shaping  public  opinion,  transforming  communication  and \ninformation  dissemination.  The extensive  use of platforms  like Facebook,  Twitter,  and Instagram  \nhas revolutionized  how  people  access  and engage  with  information,  creating  new  dynamics  in the \nformation  of public  opinion  (Allcott  and Gentzkow,  2017).  These  networks  enable  rapid  \ninformation  sharing,  allowing  news  and ideas  to spread  quickly  to large  and diverse  audiences.  \nConsequently,  they  have  become  influential  tools  in political  campaigns,  social  movements,  and \npublic  discourse  (Bakshy  et al., 2015).  For example,  the rise of hashtag  activism  and online  \ncommunities  exemplifies  how  social  media  can bring  attention  to societal  issues  and influence  \npublic  opinion  on a global  scale  (Jackson  et al., 2020).  \nIt is important  to underline  that  the content  algorithm  of these  platforms  plays  a significant  role \nin influencing  what  users  see and engage  with.  It can potentially  raise  echo  chambers  and filter  \nbubbles  that  reinforce  existing  beliefs  and viewpoints  (Pariser,  2011),  leading  polarisation  in \npublic  opinion.  In such  scenarios,  users  are less likely  to be exposed  to different  perspectives  and \nchallenging  viewpoints  (Sunstein,  2018).  \nHowever,  these  platforms  also face  challenges  such  as the  spread  of misinformation  and fake  news,  \nwhich  can significantly  distort  public  perceptions  and decision -making  (Lazer  et  al., 2018).   The \nease  with  which  misleading  information  can be spread  on social  networks  calls  for greater  \naccountability  and regulation.  This issue  is essential  to ensure  the integrity  of public  discourse  \nand to prevent the negative consequences of selective exposure.  While social networks have \ndemocratised  the means  of influencing  public  opinion,  their  impact  requires  careful  consideration  \nand management.  Effective  strategies  are needed  to ensure  the quality  and diversity  of public  \ndiscourse,  and to counter  the formation  of echo  chambers  and the spread  of misinformation  \n(Gille - spie,  2018).  \nCurrently, the advent of ChatGPT together with the enormous progress in the field of AI have  \nled researchers  to investigate  the economic  impacts  of AI-based  technologies  (Agrawal  et al., \n2019;  Furman  and Seamans,  2019;  Cockburn  et al., 2018),  and their  integration  in organizational  \nstructures  (Brynjolfsson  and McAfee,  2014).  The use of AI has led to significant  contributions  in \nseveral  disciplines  including  healthcare,  finance,  and the like.  \nHowever,  the way  in which  AI evolved  before  the advent  of COVID  and ChatGPT  is still a largely  \nunexplored  issue  in the literature.  Whilst  there  are several  papers  that  do explore  AI dimension  \nin literature  (Horowitz,  2016;  Awad  et al., 2018;  Brundage  et al., 2020;  Merenkov  et al., 2021;  \nKelley  et al., 2021;  Zhang  et al., 2021;  Liehner  et al., 2023)  they  deal  mostly  with  surveys  and \ndo not consider  the potential  of social  media  e.g.,  Twitter  to be a key factor  in the analysis  of \npublic  opinion  with  respect  to other  technologies.  Analysing  the influence  of the media  in shaping  \npublic  opinion  prior  to these  events  can reveal  the extent  to which  media  narratives  influence  \npublic  perceptions  of this technologies  (Maxwell  et al., 1972).  \nGiven  the complexity  of this narrative  surrounding  the 4IR, two research  questions  emerge  that  \nwarrant  further  investigation.  The first question  focuses  on the evolution  in time  of public  \nopinions  about  4IR. Specifically,  do people’s  attitudes  towards  technology  become  more  positive  or \nnegative  as they  are exposed  to the advances  and implications  of the 4IR?  The objective  is to \nquantify  and track  social  sentiment  towards  the transformative  potential  of digital  technologies.  \nAdditionally,  this works  aims  at examining  the extent  to which  the public  discourse  reflects  \noptimism  or concerns on the risks associated with 4IR. The second question what  is the nature  of \ninteractions  between  users  with  different  viewpoints  on 4IR?  Thus  we explores  whether  users  with  4  similar  viewpoints  tend  to form  polarized  communities  or engage  with  open  discourse  and debate  \nwith  those  holding  contrasting  beliefs.  \nThis study  contributes  to the ongoing debate  on aligning  technological  advances with societal  \nvalues  and needs,  emphasizing  the role of informed  public  opinion  in shaping  effective  policy.  \nAdditionally,  it presents  a first large -scale  study  of public  opinion  on 4IR technologies.  Answering  \nthese  questions  contributes  to better  policy -making  in several  ways.  Firstly,  by analysing  how  \npublic  opinions  about  4IR technologies  evolve  over  time,  policymakers  can identify  patterns  and \nshifts  in sentiment.  This insight  allows  for the anticipation  of public  concerns  and misconceptions  \nbefore  they  become  widespread.  Secondly,  during  periods  of rapid  technological  change  or crisis,  \nfor example  during  the introduction  of new  technology,  understanding  public  opinion  and \ninteraction  patterns  helps  in developing  clear  and effective  communication  plans  to quickly  \naddress  and correct  any misinformation.  Additionally,  the recognition  of unique  misinformation  \npatterns  associated  with  different  technology  types  allows  for the implementation  of more  \ntargeted  countermeasures.  \n \n2 Background  literature  \n2.1 Narratives  \nThe narratives  surrounding  AI and the technologies  of the Fourth  Industrial  Revolution  (4IR)  \nhave  a significant  impact  on society  perceptions  and understanding.  A number  of scholars  have  \nconducted  in-depth  research  into the representation  of AI in various  forms  of media,  including  \nscientific and popular publications, as well as in fictional contexts. Their findings indicate that  \nthis representation  tends  to oscillate  between  two extremes:  optimism  and pessimism.  This \noscillation  is believed  to reflect  deeply -rooted  beliefs,  hopes,  and fears  related  to technological  \nadvancements  (Fast and Horvitz,  2017;  Cave  and Dihal,  2019;  Cave  et al., 2020).  In addiction  \nCave  and Dihal  (2019)  have  identified  four  main  narratives  that  interpret  these  feelings  (Tab.1):  \n \n• Immortality -Dehumanization  explores  the medical  field,  in which  AI is used  in research,  \nsuggesting  a utopic  vision  of human  immortality,  contrasted  with  dystopic  concerns  of \ndehumanization  and the loss of human  values.  \n• Freedom -Obsolescence  in which  the former  symbolizes  the liberation  from  mundane  tasks,  \npromising  a future  free from  physical  and mental  strain,  while  the latter  is associated  with  \nthe risks  of job losses  caused  by abrupt  technological  shifts.  \n• Gratification -Alienation  celebrates  the potential  of AI to fulfill  any human  desire,  offering  \ngratification  in the several  dimensions  of life. However,  it is counterbalanced  by the risk of \nalienation,  in which  technology  threatens  human  interaction.  \n• Dominance -Uprising addresses the role of AI in military applications, oscillating between  \nthe need  of dominance  and security,  and the fear about  machine  uprising  and loss of human  \ncontrol.  \n \nThese  narratives  not only  reflect  but also shape  social  engagement  with  technology,  which  as a \npractice,  reveals  the dynamics  of production  and usage  (Suchman  et al., 2017).  Nevertheless,  these  \nnarratives  often  deviate  from  AI current  technical  capabilities  (Floridi  and Chiriatti,  2020;  Musa  \nGiuliano,  2020).  This discrepancy  is often  attributed  to the thought  capabilities  of AI (Neff  and \nNagy,  2018),  which  leads  to some  mismatch  in user  expectations,  e.g.,  the Tay chatbot  incident \n(Nagy  and Neff,  2015;  Zemˇc´ık, 2021).1 \nFurthermore,  human -like perceptions  of technology  fuelled  by the need  for social  interaction  and 5  the push  for technological  acceptance  in robot  research  (Katz  et al., 2015;  Salles  et al., 2020;  \nZemˇc´ık, 2021),  contribute  to the construction  of these  narrati ves.  These  factors  highlig ht that \ntechnology  extends  into the social  realm  through  interactions  and beliefs.  \nAlongside, narratives about the 4IR are intertwined with societal progress.  Fast and Horvitz  \n(2017)  argue  that  technological  advancements  under  4IR will fundamentally  shape  societal  \nevolution,  driven  by the promise  of intelligent  machines,  improvements  in healthcare,  and \nenhanced  well -being.  Yet, concerns  raised  by many  scholars  focus  on potential  threats,  including  \nOrwellian  surveillance, job displacement, and further ethical challenges (P erkowitz, 2007; Frey \nand Os borne, 2017; Obozintsev, 2018; Jobin et al., 2019).  Regarding other technologies, such \nas Virtual  Reality  (VR),  the narratives  often  focus  on the possibilities  of Enhanced  Experience  \nand the risks  of Escapism . VR provides  immersive  experiences  that  enhance  learning,  \nentertainment,  and social  interaction.  This process  fuels  an optimistic perspective  beyond  physical  \nlimitations  and enables  access  to further  experiences.  Social  isolation  and escapism  may  none  the \nless threaten  optimistic  scenarios  and calls  in the right  balance  between  virtual  and real-world  \ninteractions.  \nTable  1: AI narratives  \n \nField  Hopes  Fear  Debate  \n \nMan  conquering  immortality  while  on the \nHealth  Immortality  Dehumanization  other  side  humans  lose  their  essence,  ditching  \nvalues  and emotions.  \n \n \n \nEmployment  Freedom  Job replacement/Obsolescence  \n \n \n \n \nSociology  Gratification  Alienation  \n \n \n \n \nSurveillance  Security  Uprising  Humans  will be liberated  from  tedious  or  \ntiring  tasks,  be  they  physical  or  cognitive.  \nThe opposite  representation  is the risk linked  \nto this technical  turning  point.  \nAI and robots  fulfill  every  human  desire,  \nbut on the other  hand,  the opposite  scenario  \npredicts  that  individuals  will  only  interact  \nwith  technologies  rather  than  with  other  \npeople.  \nThe optimistic  scenario  predicts  that  new  \ntools  will enable  nations  and  communities  \nto ensure  security  for all, while  on the other  \nhand  there  is the iconic  narrative  of sci-fi \nwhere  AI will take  over  humans.  \n \n \n \nNotes:   Own  elaboration  based  on Cave  and Dihal  (2019)  \n \n \nFor what  concerns  to Blockchain,  the literature  highlights  the contrast  between  Decentralization  \nand Trust  and Complexity  and Misuse . Blockchain  technology  is emphasised  for its ability  to \ndecentralize  power  structures  and improve  transparency.  It enhances  trust  in transactions  \nwithout  the need  of central  authorities,  as observed  in sectors  like finance,  supply  chain,  and \ndigital  identity.  Despite  this potential,  the complexity  of the technology  and its association  with  \nillegal  activities,  as well  as concerns  about  energy  consumption,  presents  a counter -narrative  \n(Khan  and Salah,  2018).  Seemingly  the narrative  on the Internet  of Things  (IoT),  turns  around  \nConnectivity  and Efficiency  versus  Privacy  and Security  Risks . IoT and its interconnected  network  \nof devices  promise  to enhance  efficiency  and convenience  in daily  life (Atzori  et al., 2010).  \nHowever,  this increased  connectivity  also brings  significant  concerns  regarding  privacy  and data  \nsecurity  (Wein berg  et al., 2015).  \n \n1Tay chatbot was launched on Twitter in 2016 as an experiment in conversational understanding . However, it  \nwas quickly corrupted by users that filled it with racist and offensive remarks, leading the bot to ex inappropriate  6  and inflammatory  statements.  Therefore,  Microsoft  shut  it down  less than  24 hours  after  its launch.7   \n2.2 Echo  chambers,  polarization  and misinformation  \nThe advent  of the digital  era, characterized  by the rapid  expansion  of the internet  and social  \nmedia,  has fundamentally  altered  the landscape  of information  dissemination  and consumption.  \nDespite  offering  unparalleled  access  to diverse  perspectives,  this transformation  poses  significant  \nchallenges,  including  the creation  of echo  chambers,  the spread  of misinformation,  and increased  \npolarization.  These  challenges  threaten  the integrity  of public  discourse  and the cohesion  of \nsocial  fabric.  \nEcho  chambers  refer  to the situation  in which  individuals  are predominantly  exposed  to opinions  \nand information  that  reinforce  pre-existing  beliefs  (Del Vicario  et al., 2016;  Quattrociocchi  et al., \n2016).  On the one hand,  this selective  exposure,  often  exacerbated  by algorithmic  filtering,  \nfacilitates  the reinforcement  of existing  viewpoints.  On the other  hand,  polarisation  results  from  \nthe homogenization  of thought,  leading  to societal  attitudes  that  increasingly  diverge  towards  the \nideological  extremes.  The presence  of echo  chambers  contributes  to a social  divide  and intensifies  \nboth  polarization  and its deleterious  effects  on democratic  discourse.  Furthermore,  the circulation  \nof misinformation  within  these  isolated  communities  can deepen  public  polarization  and distort  \nthe collective  comprehension  of crucial  issues  (Lazer  et al., 2018).  \nThe phenomenon  of echo  chambers  has been  identified  as a significant  contributor  to social  \npolarization.  These  environments  are characterized  by the amplification  of existing  beliefs  and \nthe minimization  of exposure  to conflicting  viewpoints,  which  collectively  foster  a false  \nconsensus  (Sunstein,  2018).   The critical  examination  of digital -platforms  impact  on public  \nopinion  and discourse  is imperative,  given  the role of social  media  algorithms  in perpetuating  \nthese  echo  chambers  (Nyhan  and Reifler,  2010;  Pariser,  2011;  Lewandowsky  et al., 2017).  \nMisinformation  further  fuels  social  polarization  by skewing  the information  landscape  and \nreinforcing  pre-existing  biases  (Fig.1).  The propagation  of false  information  through  social  \nmedia  platforms  exacerbates  this issue  and undermines  the integrity  of public  discourse  and the \ndemocratic  process  (Allcott  and Gentzkow, 2017).  The swift  spread  of misinformation within echo  \nchambers  not only  fixes  biased  beliefs  but also diminishes  trust  in credible  information  sources  \n(Bakshy  et al., 2015;  Wineburg  and McGrew,  2017;  Lazer  et al., 2018;  Vosoughi  et al., 2018) . \nThe misinformation  exposure  is a complex  interplay  of technological,  social,  psychological,  and \neconomic  factors  that  contribute  to its proliferation.  Social  media  platforms,  with  their  vast  reach  \nand rapid  dissemination  capabilities,  act as catalysts  for the spread  of false  information,  driven  \nby algorithms  that  prioritize  engagement  over  accuracy  (Del Vicario  et al., 2016;  Wu et al., 2019).  \nCognitive  biases,  such  as the confirmation  bias,  play  a significant  role by leading  individuals  to \nfavor  information  that  confirms  their  pre-existing  beliefs,  thereby  intensifying  polarization  (Ecker  \net al., 2011;  Lewandowsky  et al., 2017).  8  Figure  1: Different  aspects  of public  opinion  dynamics  \n \n(a) Polarization  (b) Consensus  \n \n(c) Dissent  \n \nNotes : In panel  (a) population  is divided  into two  dominant  groups  with  opposing  views  on  a  specific  \nissue.  The peaks indicate the concentration of individuals within each opinion group,  while the trough  \nindicates a lack of moderate stances.  This highlights the clear divide and potential for increased social  \ntensions;  in panel (b) the “lock -in” effect in public opinion occurs when a single viewpoint has become  \noverwhelmingly predominant.  This marginalizes alternative perspectives and demonstrates the societal or  \ncultural  homogeneity  on a specific  issue; in  pane  (c) the dissent  shows  a spectrum  of views  where  the majority  \nholds a central opinion, while a range of dissenting views exists on either side. This indicates a diverse and  \nengaged  public  discourse  \n \n \n \n \n3 Data  and  methods  \nWe focused  on the analysis  of the discourse  surrounding  4IR across  six European  countries:  France,  \nGermany,  Italy,  Spain,  the Netherlands,  and United  Kingdom.  We adopt  a multi -step  approach  \nto gather  an original  dataset  (Fig.2).  \n9  Figure  2: Data  pipeline -time  period  considered  from  01/01/2006  to 31/12/2019  \n \n \n \n \n \n3.1 Data  sources  \nThe data  collection  process  begins  with  the identification  of the most  widely  circulated  \nnewspapers  in each  country  according  to the number  of copies  sold  (Tab .2). Afterwards,  we \ndetect  their  official  Twitter  profiles  and their  corresponding  tweets  which  contain  some  keywords  \nbelonging  to 4IR (T ab.2).  To guarantee  linguistic  precision  and cultural  appropriateness, we  perform  \ntranslations  of keywords.  For example,  in the case  of Italy,  we search  for both  Artificial  \nIntelligence  and  Intelligenza  Artificiale . \n10  Table  2: Country -specific  4IR keywords  and associated  newspapers  \n \nCountry  4IR Keywords  Newspaper  \nUK artificial  intelligence;  robot;  \nblockchain;  cloud  computing;  IoT; \nvirtual  reality  \n \nFrance  intelligence  artificielle;  robot;  \nblockchain; cloud computing; IoT;  \nvirtual  reality;  ralit  virtuelle;  \nInternet  des objets  \nSpain  inteligencia  artificial;  robot;  \nblockchain;  cloud  computing;  IoT; \nvirtual  reality;  realidad  virtual;  \nInternet  de las cosas  \nGermany  knstliche  Intelligenz;  robot;  \nblockchain; cloud computing; IoT;  \nvirtual reality; virtuelle realitt; \ninternet  der dinge  \nNetherlands   kunstmatige  intelligentie;  robot;  \nblockchain;  cloud  computing;  IoT; \nvirtual  reality;  virtuele  \nwerkelijkheid;  internet  der dingen  \nItaly  intelligenza  artificiale;  robot;  \nblockchain;  cloud  computing;  IoT; \nvirtual  reality;  realt  virtuale;  \ninternet  delle  cose  DailyMailUK;  guardiannews;  \nEveningStandard;  thetimes;  \nMetroUK;  MailOnline;  guardian;  \nTheSun;  DailyMirror  \nhumanite  fr; Mediapart;  LaCroix;  \nlibe;  lopinion  fr; le Parisien;  \nlemondefr;  Le Figaro;  LesEchos  \n \nElMundoEspan; elcorreo  com;  \nlavozdegalicia;  diariovasco;  \nelperiodico;  abc es; larazon  es; el \npas;  LaVanguardia  \nNdaktuell;  tazgezwitscher;  \nTagesspiegel;  BILD;  SZ; faznet;  \nwelt;  handelsblatt  \n \nDelimburger;  DeGelderlander;  \ntrouw;  De Stentor;  nrc; Telegraaf;  \nvolkskrant;  Adnl  \n \nIlgiornale;  LaVeritaWeb;  \nAvvenire  Nei; Libero  official;  \nLaStampa;  fattoquotidiano;  \nrepubblica;  Corriere;  Solo24ore  \n \n \n \n \nTo create  a sample  of users  who  show  interest  in AI and related  technologies,  we observe  \ninteractions – likes, retweets, and comments – with tweets from the selected newspapers.  We \nconsider  users  who  engage  with  them  as if they  have  a potential  personal  interest  in the technologies  \ngiven  their  interaction  with  the newspapers.  For each  user,  we collect  their  tweet  timeline  from  \nJanuary  2006  to December  2019  using  Twitter  API and twarc2. This time  frame  was selected  to \nmitigate  the potential  influence  of the COVID -19 pandemic  on the data.  Furthermore,  we collect  \ndata  on the followers  and followed  accounts  and apply  a similar  process  to gather  tweets  from  their  \ntimelines.  The final  dataset  includes  approximately  25,000  users  and 90,000  tweets  (Fig. 3). Each  \ntweet  is identified  by a unique  ID and includes  information  about  author,  text,  date,  as well  as \ndetails  about  the location,  number  of likes,  and retweets.  \n2Twarc is a command line tool and Python library for collecting and archiving Twitter JSON data via the  \nTwitter API. It handles Twitter API’s rate limits and can be used to collect tweets, users, trends, and hydrate  \ntweet  IDs. 11  Figure  3: Number  of news  and tweets  collected  per country  \n \n  \n \n \nFigure  4: Number  of tweets  retrieved  per keyword  \n \nNotes : Frequency  of specific  technology -related  keywords.  The data  reflects  the number  of mentions  for each  technology,  \nhighlighting  the interest  in various  technological  fields  among  Twitter  users.  \n12  Table  3: Share  of technology  terms  by country  \n \nKeyword  UK France  Italy  Spain  Germany  Netherlands  \nArtificial  Intelligence  14.49  27.38  25.25  19.14  13.84  19.94  \nVirtual  Reality  7.15  0.19  2.48  3.46  2.28  11.98  \nBlockchain  49.11  21.21  15.68  19.32  49.73  24.86  \nRobot  59.91  34.68  34.98  26.90  22.09  78.76  \nCloud  Computing  0.92  0.31  0.41  0.28  0.27  0.23  \nIoT 11.83  3.34  3.81  3.20  4.99  2.90  \n5G 6.57  3.70  5.40  4.61  5.99  7.06  \n \nBuilding  on the data  collection  framework  described  above,  we then  proceeded  to analyze  the \ncontents  of the gathered  tweets.  As first approach  we focused  on identifying  the occurrence  of \nthe key technology -related  terms  within  the tweets.  As illustrated  in Fig.4,  the prevalence  of \ndiscussions  on technologies  such  as Robots , Blockchain , and AI mirrors  the findings  of other  \nstudies,  which  highlight  the increasing  penetration  of these  technologies  in various  sectors  and \ntheir  perceived  impact  (Ford, 2015;  Swan,  2015).  The moderate  mentions  of cloud  computing  \nand virtual  reality  align with the  observations by  Greenhalgh  et al. (2017),  who suggest  that  while  \nthese  technologies  are well -established,  they  may  not provoke  the same  level  of continuous  public  \nintrigue  as more  disruptive  technologies.  On the other  hand,  the relatively  lower  frequency  for \nemerging  technologies  like IoT and 5G towards  the later  part  of the analyzed  period  can be \nunderstood  through  the lens of diffusion  of innovations  theory,  which  posits  that  newer  \ntechnologies  typically  undergo  a phase  of gradual  adoption  marked  by lesser  public  discourse  \ninitially  (Rogers  et al., 1962).  This trend  underscores  the necessity  to continuously  monitor  \ntechnological  discourse  over  time  to capture  shifting  public  and professional  interests  as new  \ntechnologies  mature  and penetrate  different  market  segments.  \nRegarding  intra -country  differences,  the results  in Tab.3  suggests  pattern  variances  in the \ndiscussion  frequency  of technological  terms  among  European  countries.  AI is more  debated  in \nFrance  and Italy  compared  to other  countries  such  as United  Kingdom  and Germany,  suggesting  a \ngreater  focus  or investment  in AI technologies  in these  countries.  The Netherlands  exhibits  \nincreased  discussion  rates  on topics  such  as VR and robotics,  which  may  indicate  stronger  \nindustrial  applications  or governmental  support  in these  fields.  Germany  and the UK both  exhibit  \na high  interest  \nin blockchain, which might reflect a robust engagement with cryptocurrency and blockchain \ntechnologies. On the other hand, cloud computing and IoT show low percentages across all \ncountries,  indicating  that  these  technologies  are still in the early  stages  of adoption  or discussion  \nsaturation.  \n \n3.2 Text  analysis  \nWe use sentiment  analysis  techniques  to understand  public  sentiment.  Specifically,  we employ  the \nXLM -T Roberta  model  (Barbieri  et al., 2021)  which  is available  on Hugging  Face  and represents  \na transformer  model  trained  on a dataset  including  over  15 million  tweets  in 10+ languages.3 \nSentiment  analysis,  also known  as opinion  mining,  is a key task in Natural  Language  Processing  \n3Hugging  Face  is a platform  for machine  learning  and data  science  that  simplifies  building,  deploying  and \ntraining  of machine  learning  models.  It is often  referred  to as the ’GitHub  of machine  learning’  due to its ability  to \nenable developers to share and discover machine learning models.  The platform offers infrastructures for deploying  \nand running  AI in live applications,  along  with  tools  to decrease  model  training  time,  resource  consumption,  and \nenvironmental  impact  of AI development.  13  (NLP)  that  involves  the identification  and categorisation  of sentiments  expressed  in text that  \nrelate  to specific  topics,  products,  or services.  By using  language  models,  it is possible  to \ndetermine  the type  of sentiment  within  the text,  which  can be classified  as positive,  negative,  or \nneutral.  \nFor instance,  a sentence  such  as “I love  you and I like you”  expresses  a positive  sentiment.  \nSentiment  analysis  is the process  of analysing  and interpreting  express  opinions,  allowing  for the \nextraction  of information  from  unstructured  textual  data.  It has a wide  range  of applications  \nacross  various  sectors  and functions.  In the business  sector,  it serves  as an important  \nmechanism  for gathering  business  intelligence,  helping  companies  capture  customer  feedback  on \ntheir  offerings  for product  development,  define  marketing  strategies,  and revise  customer  service  \noperations  (Liu et al., 2022).  Sentiment  analysis  is proving  to be crucial  to market  research,  \nenabling  companies  to gain  a deeper  understanding  of market  trends  and consumer  preferences  \nby analysing  social  media  posts,  reviews  and forums,  allowing  them  to tailor  services  and \nproducts  to consumer  needs  and market  dynamics,  and to manage  a brand  and its reputation  in \nreal time  (Pang et al., 2008).  The use of sentiment  analysis  is not limited  to commercial  \napplications.  It is also employed  in the political  sphere  to gauge  public  sentiment  towards  \npolicies,  debates,  and election  messages.  This provides  political  parties  and candidates  with  \nvaluable  insights  into their  campaign  strategy  (Tumasjan  et al., 2010).  \nTo determine  the presence  of echo  chambers  within  our dataset,  we analyzed  the sentiment  \ndistribution  of tweets  shared  by users  and their  followers  and followings.  The intensity  of each  \nsentiment  – negative,  neutral,  and positive  – was averaged  within  the followers  and followers  for \neach  user.  The application  of sentiment  analysis  to detect  echo  chambers  is based  on the premise  \nthat  echo chambers typically exhibit homogeneous sentiment expressions, as members reinforce  \neach  other’s  viewpoints  (Garimella  et al., 2018).  Using  sentiment  analysis  to examine  the tweets  \nof users  and their  followers/followings  allows  researchers  to detect  patterns  of agreement  or \ndisagreement, which are indicative of the presence or absence of echo chambers.  Averaging the \nsentiment scores  among a user’s  followers and followings  to assess consensus  and the \nreinforcement  of beliefs  is a methodological  choice  supported  by literature  on social  media  \ndynamics.  It helps  in understanding  the collective  sentiment  within  a user’s  network,  which  is \ncrucial  for identifying  echo  chambers  where  prevalent  sentiments  can suggest  a uniformity  in \nattitudes  and beliefs  (Sunstein,  2001;  Del Vicario  et al., 2016).  The assumption  here  is that  high  \naverage  sentiment  scores  (either  positive  or negative)  within  a network  signal  agreement  and \npotentially  an echo  chamber  environment.  We decided  to set as threshold  0.6 to balance  \nsignificant  sentiment  indicative  of agreement  and maintaining  robustness  across  different  topics.  \nThe decision  to set a threshold  of 0.6 for sentiment  scores  to classify  the presence  of an echo  \nchamber  is a critical  step  that  requires  justification.  This threshold  balance  sensitivity  (the ability  to \ndetect  actual  echo  chambers)  and specificity  (the  ability  to exclude  non-echo  chamber  cases).  The \nchoice  of 0.6 as a threshold  implies  a significant  skew  towards  a specific  sentiment.  This \napproach  aligns  with  the work  by Cinelli  et al. (2021),  who  suggest  that  clear  demarcations  in \nsentiment  can help  identify  highly  polarized  communities,  akin  to echo  chambers.  When  the \nsentiment  score  is above  0.6, it indicates  the likelihood  of a user  as part  of an echo  chamber,  \ncharacterized  by a high  level  of agreement  and reinforcement  of existing  beliefs.  The use of a \nsentiment  score  threshold  to infer  these  characteristics  is therefore  a rational  extension  of this \ndefinition,  aiming  to carry  out the detection  of such  environments  through  quantitative  measures  \nof sentiment  agreement.  \nFor the purpose  of the narrative  identification,  the DeBERTa  algorithm  was employed  on \nzeroshot  classification,  a machine  learning  technique  that  enables  a model  to accurately  classify  \ndata  into categories  that  were  not present  during  training.  DeBERTa  was selected  over  other  \nmodels  due to its disentangled  attention  mechanism,  which  distinguishes  between  the relative   14  Figure  5: Trends  in newspaper  tweet  sentiments  \n \n \n \n \n \nNotes:  The figure shows a decrease in neutral sentiment tweets and a gradual increase in both positive and \nnegative  sentiment  tweets,  indicating  a slightly  growing  polarization  in public  discourse  over  time.  \n \n \npositions  of words  from  their  absolute  positions  in a sentence,  thereby  enhancing  its ability  to \nunderstand  complex  language  patterns.  This capability  enables  the model  to apply  \ngeneralisation  effectively  from  observed  categories  to unobserved  categories  through  the \nutilisation  of semantic  relationships  between  categories  (Lampert  et al., 2009).  Moreover,  \nDeBERTa enhances  this  capability  with  a robust  pre-training  on a diverse  dataset,  which  \nprovides  it with  a broad  linguistic  understanding  necessary  for handling  the novel  and complex  \nsentence  structures  encountered  in differents  scenarios.  Additionally,  the performance  of \nDeBERTa  on various  NLP benchmarks  indicates  its capability  on feature  extraction  and  \ncontextual  understanding  capabilities.  Typically,  rich feature  representations,  such  as \nembeddings,  are employed  to capture  underlying  similarities  between  different  classes.  For \ninstance,  a model  trained  on images  about  animals  and their  corresponding  labels  could  correctly  \nclassify  an unobserved  image  of a “zebra”  if it has learned  the concept  of animals  and similar  \nfeatures  from  observed  categories  such  as “horse”.  \n4 Results  \nThe investigation  into public -opinion  dynamics  surrounding  4IR technologies,  conducted  prior  to \nthe widespread  adoption  of ChatGPT  and the onset  of the COVID -19 pandemic,  revealed  a set of \ninsights  into societal  perceptions  and discursive  patterns.  We analyzed  a comprehensive  dataset  \nof tweets  and news  articles  from  six European  countries  (Italy,  France,  Germany,  United  Kingdom,  \nNetherlands,  and Spain),  quantifying  public  sentiment  and identifying  prevalent  themes  and \nnarratives  that  shape  societal  engagement  with  4IR technologies.  We apply  the sentiment  analysis  \nboth  on the tweet  shared  by the newspaper  and the user,  discovering  a similar  pattern(Fig.5  and \n6). Over  time,  there  is a tendency  towards  an increased  revelance  of negative  and positive  \nsentiments  with  respect  to some  neutrality.  Moreover,  we compute  the sentiment  analysis  on the \nfollower  and the following  for each  user.  \n15  Figure  6: Trends  in user  tweet  sentiments  \n \n \n \n \n \nNotes:  The figure shows a decrease in neutral sentiment tweets and a gradual increase in both positive and \nnegative  sentiment  tweets,  indicating  a slightly  polarization  in public  discourse  over  time.  \n \nThe data  indicate  a decrease  in neutrality  in both  media  coverage  and user  responses.  Specifically,  \nthe number  of neutral  tweets  and articles  has decreased  over  time,  suggesting  that more  \nindividuals  and media  outlets  are taking  a stand  as discussions  around  4IR intensify.  This shift  \nsignifies  greater  public  awareness  and engagement  with  emerging  technologies,  reflecting  a more  \npolarized  and active  debate.  \nWith  applying  zero -shot  classification  using  DeBERTa  (Laurer  et al., 2023)  we categorise  tweets  \naccording  to key themes  partially  considering  Tab.1,  such  as employment  (14%),  environment  \n(20%),  privacy  (3%),  health  (7%),  and other  (56%)  partly  following  the narratives  in Tab.1.  \nFurthermore,  our analysis  revealed  a slight  slope  towards  positivity  in the discourse  about  new  \ntechnologies.  The data  show  an increase  in the frequency  of positive  tweets  and articles,  \nreflect ing an optimistic outlook on the potential benefits these technologies can bring. This \npositive  trend  is particularly  evident  in the fields  of health  and employment,  where  4IR \ntechnologies,  such  as AI and robotics,  are perceived  as tools  that  can improve  quality  of life and \ncreate  new  job opportunities.  We also conducted  specific  country  analysis,  which  reveals  distinct  \ntrends  in sentiment  toward  new  technologies  across  various  nations,  highlighting  the complex  \nlandscape  of public  opinion.  Figure  7 illustrates  that  while  there  is an overall  decrease  in neutral  \nsentiment  across  several countries like the UK, Germany, and the Netherlands, indicating a \npossibly cautious or  ambivalent  attitude  toward  new  technologies,  the trends  in positive  and \nnegative  sentiments  show  more variability. For instance, countries like Spain and the \nNetherlands exhibit a rising trend in  positive sentiment, aligning with a generally optimistic \nview on the potential of 4IR technolo gies.  On the other  hand,  the negative  sentiment  remains  \nrelatively  low and stable  across  most  countries,  suggesting  that  while  enthusiasm  varies,  there  is \nnot a significant  rise in skepticism  or opposition.  \nBuilding  on the results  of our sentiment  analysis,  Tab.4  further  deepens  our understanding  of \nthe specific  issues  that  dominate  discussions  about  new  technologies  in different  countries.  This  \n16  Figure  7: Trends  in user  tweets  sentiments  by country  \n \n \n \ntopic -categorisation  shows  a diversified  interest  that  varies  significantly  between  regions.  For \ninstance,  the share  of discussion  on employment , particularly  in country  such  as the Netherlands  \nand France,  could  suggests  a strong  interest  in how  new  technologies  are reshaping  labour  \nmarkets.  This reflects  the positive  sentiment  towards  4IR technologies  observed  in these  \ncountries,  indicating  optimism  about  the potential  for job creation  and economic  growth.  \nMoreover,  in countries  like France  and the Netherlands,  the importance  of this issue  is higher  \nthan  in Germany.  This may  reflect  the integration  of technology  issues  into public  health  \ndiscussions,  particularly  in the context  of recent  global  health  challenges.  The relatively  low \nengagement  in privacy  could  indicate  a need  for increased  awareness  and education  on privacy  \nissues  as technology  becomes  more  pervasive.  These  findings  complement  the sentiment  trends  \nby revealing  not only  the emotional  tone  of discussions,  but also the substantive  concerns  and \ninterests  of the public.  A comprehensive  analysis  of the trends  by country  for both  keywords  and \ntopics  is detailed  in the Appendix.  \n \n4.1 Echo  chamber  identification  \nOur findings  indicate  that  slightly  more  than  6% of users  may  be situated  within  an echo  \nchamber,  with  minimal  variation  observed  across  different  topics  (Tab.5).  This suggests  a \nmoderate  level  of topic -dependent  engagement  within  echo  chambers,  with  privacy  showing  the \nhighest  propensity  and health  the lowest.  \n17  Table  4: Share  of topic  per country  \n \nTopic  UK France  Italy  Spain  Germany  Netherlands  \nEmployment  10.26  14.80  13.98  13.43  10.35  16.60  \nEnvironment  17.44  14.43  13.13  15.15  15.72  14.94  \nHealth  5.67  7.96  7.83  5.09  3.16  7.06  \nOther  64.90  60.72  63.45  64.50  68.95  59.24  \nPrivacy  1.76  1.56  1.61  1.83  1.82  2.16  \n \nTable  5: Topic  analysis  with  sentiment  variance  and misinformation  mean  \n \nTopic  Sentiment  Variance  Misinformation  mean  Share  in echo  chamber  (%) \nEmployment  0.29  0.25  5.82  \nEnvironment  0.30  0.24  7.08  \nHealth  0.26  0.24  5.22  \nOther  0.26  0.25  6.14  \nPrivacy  0.30  0.27  7.20  \n \nIn addition,  the work  of Mosleh  and Rand  (2022)  here  was used  to associate  each  user  with  an \nelite  misinformation -exposure  score  based  on the elite  misinformation -exposure  score  that  users  \nfollow on  Twitter.  For instance,  by following individuals  such  as Trump,  who  are known to  \ndisseminate  false  information,  a user  is likely  to receive  a high  misinformation -exposure  score.4 \nThis score  is negatively  correlated  with  the quality  of the news  disseminated  and positively  \ncorrelated  with  conservative  ideology.  Although  misinformation  levels  are generally  low,  as \nindicated  by the results  in Tab.5  and Figure8  (Panel  C), privacy  has a higher  average  \nmisinformation  score,  suggesting  that  this topic  is more  affected  to misinformation  than  the \nothers.  In Fig.8  (Panel  B) is illustrate  how  the gradual  increase  in the average  misinformation  \nexposure  score  may  reflect  various  factors,  including  a greater  prevalence  of fake  news  on social  \nmedia  and greater  polarisation  in online  discussions.  The presence  of high  scores  in each  year  \nindicates  that  misinformation  is a persistent  problem,  but the moderate  growth  suggests  that  the \ndynamics  behind  its spread  may  be multiple.  \nOur analysis  highlighted  that  misinformation  and polarization  are significant  issues  in the public  \ndiscourse  on 4IR technologies.  The spread  of misinformation  is facilitated  by the presence  of echo  \nchambers,  where  false  information  can be easily  shared  and accepted  without  verification.  \nPolarization  is further  exacerbated  by this dynamic,  creating  a growing divide  between  groups with  \ndifferent  opinions.  The diversity  of opinions  is another  key element  that  emerged  from  our \nanalysis.  Despite  the trend  towards  increased  polarization,  there  remains  a significant  variety  of \nviewpoints  in public  discourse.  This plurality  of voices  supports  inclusive  and critical  debates  \nabout  the implications  of 4IR technologies,  highlighting  the  importance of  considering  all \nperspectives  in decision -making  processes.  \nAt the country -level  as shown  in Tab.6  reveals  marked  differences  in how  misinformation  and \necho  chambers  influence  public  opinion  across  various  nations.  For instance,  in countries  with  \nrobust  digital  literacy  programs  and stringent  media  regulations,  misinformation  spread  appears  \nto be more  contained,  and echo  chambers  less prevalent.  This contrasts  with  countries  where   \n4see https://misinfoexpose.com/  18  Figure  8: Misinformation  exposure  score  \n \n \n \nNotes: Panel A represents the histogram of the misinformation exposure score. Panel B the share of misinformation  \nexposure scores. This suggests that exposure to misinformation has gradually risen over this period, highlighting a  \ngrowing challenge in fighting misinformation in public discourse. Panel C illustrates the distribution of \nmisinformation  exposure  scores  across  five topics:  employment,  environment,  health,  other,  and privacy.  The \nmedian  scores  are similar  across  topics,  with  a moderate  spread  in the interquartile  ranges.  This  indicates  a \nconsistent  exposure  to misinformation  across  these  key areas,  with  no single  topic  showing  significantly  higher  or \nlower  levels  of misinformation  exposure  \n \n \ndigital  education  is lacking  and media  regulations  are lenient,  where  misinformation  tends  to \nflourish  and echo  chambers  solidify,  deepening  societal  divides.  \nThese  disparities  not only  reflect  the effectiveness  of national  policies  but also underscore  the \nvarying  cultural  attitudes  towards  technology  and information  consumption.  For example,  \ncountries  that  prioritize  education  in media  literacy  and critical  thinking  skills  show  a higher  \nresilience  to misinformation  and a more  diverse  and healthy  public  discourse.  This is evident  in \nnations  like Germany  and the Netherlands,  where  the public  debates  around  4IR technologies  are \ncharacterized  by a higher  degree  of skepticism  and critical  engagement,  despite  the challenges  of \npolarization  and echo  chambers.  \nFurthermore,  the degree  of technological  advancement  and the prevalence  of technology  in \neveryday  life also play  crucial  roles  in shaping  the discourse.  In technologically  advanced  \ncountries,  there  is a tendency  for more  nuanced  discussions  about  the benefits  and risks  of 4IR \ntechnologies.  Conversely,  in countries  where  technology  penetration  is lower,  discussions  are often  \nmore  polarized,  with  a pronounced  divide  between  pro-technology  advocates  and those  wary  of \nthe rapid  changes  brought  about  by 4IR technologies.  \n19  Figure  9: Trends  in echo  chamber  participation  \n \n \n \nNotes:  Panel A shows the share of echo chamber participation over time for various technology -related keywords  \nincluding AI, VR, Blockchain, Robots, Cloud Computing, IoT, and 5G. The sharp peak in 2014 suggests a significant  \nmoment  of concentrated  discussion,  possibly  linked  to pivotal  technological  developments  or debates.  Panel  B \nrepresents the fluctuation in echo chamber shares for discussions on key social issues such as employment, \nenvironment,  health, privacy, and others over time. The graph highlights a notable spike around 2014, indicating a \nyear of possibly   polarized  discussions  across  these  topics  \n \n5 Discussion  \nOur study  highlights  a complex  set of attitudes  towards  emerging  technologies  that  policymakers  \ncould  consider  as they  shape  the future  of 4IR technologies  regulations.  These  attitudes  reflect  \nthe intricate  interplay  between  technological  advancements  and societal  needs  and concerns.  \nThe observed  reduction  in neutrality  in both  media  coverage  and public  responses  indicates  a \ngrowing  polarization  in the discourse  surrounding  4IR technologies.  \nThe increased  polarization  can be leveraged  to engage  more  deeply  with  the public,  ensuring  that  \nthe deployment  of 4IR technologies  aligns  with  societal  values  and needs.  For instance,  \nunderstanding  the roots  of public  skepticism  can guide  the development  of targeted  educational  \ncampaigns  and transparent  information  sharing.  These  efforts  can foster  public  trust  and support  \nfor 4IR initiatives.  \nThe general  appreciation  for AI when  it is used  in ways  that  clearly  benefit  society,  such  as \nimproving  health  and science,  underscores  the positive  externalities  associated  with  technological  \ninnovation.  This positive  view aligns with findings  from  studies,  which  noted  strong  public  support  \nfor AI applications  that  enhance  societal  welfare  (Zhang  and Dafo e, 2020;  Birkstedt  et al., 2023).  \nThe recognition  of the AI potential  to drive  significant  improvements  in healthcare  and scientific  \nresearch  highlights  the importance  of innovation  policies  that  support  and promote  beneficial  \napplications.  Public  support  for AI in health  and science  suggests  a broad  recognition  of the \ntechnology’s  role in solving  complex  problems  and improving  quality  of life, which  is a key driver  \nof technological  adoption  and diffusion  as articulated  in the theory  of diffusion  of innovations  \n(Rogers  et al., 1962).  \nHowever,  significant  concerns  arise  when  AI systems  make  critical  decisions  affecting  individual  \nlives,  such  as determining  eligibility  for welfare  benefits.  These  concerns  echo  broader  issues  of \naccountability  and transparency  in automated  decision -making  processes  (Butcher  and Beridze,  \n20  Table  6: Topic  analysis  with  sentiment  variance,  misinformation  mean,  and echo  chamber  share  \nby country  \n \nCountry  Sentiment  variance  Misinformation  mean  Share  in echo  chamber  (%) \n  Employment   \nUK 0.31  0.30  6.61  \nFrance  0.26  0.20  4.23  \nItaly  0.29  0.26  4.99  \nSpain  0.28  0.20  5.89  \nGermany  0.28  0.24  9.30  \nNetherlands  0.37  0.31  6.50  \n  Environment   \nUK 0.31  0.27  8.20  \nFrance  0.27  0.20  4.59  \nItaly  0.25  0.24  6.60  \nSpain  0.29  0.16  5.04  \nGermany  0.33  0.24  9.41  \nNetherlands  0.35  0.26  8.89  \n  Health   \nUK 0.28  0.28  5.65  \nFrance  0.22  0.20  4.52  \nItaly  0.33  0.22  4.86  \nSpain  0.25  0.19  4.63  \nGermany  0.33  0.30  7.61  \nNetherlands  0.31  0.31  7.06  \n  Other   \nUK 0.28  0.29  7.33  \nFrance  0.23  0.21  3.89  \nItaly  0.23  0.26  6.45  \nSpain  0.25  0.20  5.14  \nGermany  0.27  0.27  6.54  \nNetherlands  0.28  0.24  6.48  \n  Privacy   \nUK 0.32  0.31  7.73  \nFrance  0.25  0.21  7.14  \nItaly  0.35  0.32  3.95  \nSpain  0.24  0.20  6.19  \nGermany  0.28  0.30  5.66  \nNetherlands  0.24  0.26  11.54  \n \n2019).  Public  wariness  of delegating  critical  decision -making  to automated  systems  without  \nhuman  oversight  reflects  the broader  economic  concern  of asymmetric  information  and the \npotential  for technology  to exacerbate  inequalities  if not properly  managed.  As AI systems  take  \non more  significant  roles  in governance  and administration,  the potential  for unintended  \nconsequences  increases,  necessitating  robust  safeguards  and accountability  measures.  The fear of \nautomated  decision -making  systems  potentially  mishandling  personal  data  or making  biased  \ndecisions  illustrates the need for transparency and explainability in AI, which are crucial for \nmaintaining public  trust  (Pasquale,  2015).  \nMoreover,  the strong  public  call to protect  basic  rights  like privacy  highlights  the need  for \nregulatory  frameworks  that  safeguard  individual  freedoms  while  promoting  technological  \ninnovation  (Brown  and Marsden,  2023).  Privacy  concerns  are paramount  in the digital  age,  \nwhere  data  is a critical  resource  driving  innovation.  The economic  trade -offs between  data  utility  \nand privacy  must  be carefully  managed  to ensure  that  advancements  in AI do not come  at the \ncost  of fundamental  rights  (Acquisti  et al., 2015).  Public  demand  for stringent  privacy  protections  \nunderscores  the importance  of developing  AI systems  that  are secure  and respect  user  \nconfidentiality,  aligning  with  the principles  of data  protection  regulations  such  as GDPR.  The \nnuances  in public  opinion  are evident.  People  support  AI that  simplifies  tasks  and enhances  21  accessibility,  recognizing  the potential  benefits  for the greater  good.  However,  they  also worry  \nabout  over -reliance  on technology  at the expense  of human  judgment,  especially  in areas  that  \nsignificantly  impact  personal  and professional  lives.  This dual  sentiment  underscores  the economic  \nprinciple  of balancing  efficiency  gains  from  technology  with  the maintenance  of human -centric  \nvalues  and the potential  costs  associated  with  technological  disruptions.  This concern  about  the \nbalance  between  technology  and human  interaction  is echoed  in the broader  discourse  on the \nsocial  impacts  of automation  and AI (Brynjolfsson  and McAfee,  2014).  Public  involvement  can take  \nvarious  forms,  such  as consultations,  surveys,  and participatory  governance  models.  These  \napproaches  help  bridge  the gap between  technological  experts  and the public,  fostering  a \ncollaborative  environment  where  diverse  perspectives  contribute  to more  robust  and socially  \nacceptable  technological  solutions.  \nRegarding  regulation,  the public  desires  rules  that  can address  the complex  issues  AI presents.  \nThere  is skepticism  about  leaving  AI regulation  solely  in the hands  of the private  sector,  with  a \npreference  for robust  oversight  to ensure  fairness  and transparency.  This perspective  is supported  \nby research  indicating  that  public  trust  in governance  is crucial  for the successful  implementation  \nof AI technologies  (Butcher  and Beridze,  2019).  Effective  regulation  can help  mitigate  the risks  \nof market  failures,  such  as monopolistic  practices  and the misuse  of AI, ensuring  that  \ntechnological  benefits  are widely  shared.  Regulatory  frameworks  need  to be adaptive  and \nforward -looking  to keep  pace  with  rapid  technological  changes,  ensuring  that  they  do not stifle  \ninnovation  while  protecting  public  interests  (Birkstedt  et al., 2023).  \nLastly,  there  is a strong  desire  for more  public  involvement  in AI decision -making.  People  want  \ntheir  voices  heard,  especially  on matters  that  directly  impact  their  daily  lives,  supporting  the \nadvocacy  for participatory  approaches  in tech  policy  (Fung,  2006).  This aligns  with  the economic  \ntheory  of democratic  governance  in innovation,  which  posits  that  inclusive  and participatory  policy -\nmaking  processes  can lead  to more  equitable  and effective  outcomes  (Papadopoulos  and Warin,  \n2007).  By involving  the public  in decision -making,  policymakers  can ensure  that  AI technologies  \nare developed  and deployed  in ways  that  reflect  societal  values  and priorities.  Participatory  \ngovernance  models  help  bridge  the gap between  technological  experts  and the public,  fostering  a \ncollaborative  environment  where  diverse  perspectives  contribute  to more  robust  and socially  \nacceptable  technological  solutions.  \nOur findings  suggest  that  data  governance  policies  must  align  with  societal  values  and needs  to \nearn  and maintain  public  trust.  This requires  a collaborative  approach  involving  policymakers,  \nindustry  leaders,  and public  institutions  to develop  strategies  that  promote  inclusive  growth  and \nuphold  ethical  standards.  There is  a strong  public  demand  for robust  and independent  regulations  \nto address  the complex  ethical  and social  issues  posed by  4IR  technologies.  Regulation  should  not \nbe left entirely  to the private  sector;  public  oversight  is necessary  to ensure  fairness  and \ntransparency.  Educating  the public  about  the potential  benefits  and risks  of emerging  \ntechnologies  is crucial  to mitigate  concerns  and increase  acceptance.  Raising  awareness  of the \nmechanisms  of misinformation  and echo  chambers  can help  reduce  polarization  and improve  the \nquality  of public  discourse.  It is important  to involve  the public  in decisions  regarding  the \nadoption  and regulation  of new  technologies,  ensuring  that  their  voices  are heard,  especially  on \nissues  directly  impacting  their  daily  lives.  Continuous  monitoring  of public  discourse  and social  \nperceptions  over  time  is essential  to adapt  policies  and strategies  in response  to changing  \nopinions  and concerns.  The dynamics  of public  discourse  on social  media  should  be carefully  \nexamined  to better  understand  how  they  influence  societal  perceptions  and behaviors.  \nOur research focuses on the time period before the worldwide release of ChatGPT in December  \n2022 (Marr, 2023).  This decision is based on the timing of our data acquisition, which occurred  \nbefore.  The exploitation  of the Twitter API  also  took  place prior  to Elon Musk’s acquisition  of 22  the platform  in October  2022.  This event  has significantly  altered  the conditions  of data  access  \nand the amount  of retrievable  information  (Conger  and Hirsch,  2022).  While  we acknowledge  \nthe importance  of considering  the perspectives  that  reflect  the post -ChatGPT  era in the analy - \nsis of public opinion, this study aims at establishing a baseline framework. Moreover, this \nbenchmark  aims  at suggesting  avenues  for further  research  on the period  that  follows  the \nintroduction  of ChatGPT.  \n \nReferences  \nAcquisti,  A., Brandimarte,  L., and Loewenstein,  G. (2015).  Privacy  and human  behavior  in the \nage of information.  Science , 347(6221):509 –514.  \nAgrawal,  A., Gans,  J. S., and Goldfarb,  A. (2019).  Exploring  the impact  of artificial  intelligence:  \nPrediction  versus  judgment.  Information  Economics  and Policy , 47:1 –6. \nAllcott,  H. and Gentzkow,  M. (2017).  Social  media  and fake  news  in the 2016  election.  Journal  \nof economic  perspectives , 31(2):211 –236.  \nAtzori,  L., Iera,  A., and Morabito,  G. (2010).  The internet  of things:  A survey.  Computer  \nnetworks , 54(15):2787 –2805.  \nAutor,  D. H. (2015).  Why  are there  still so many  jobs?  the history  and future  of workplace  \nautomation.  Journal  of economic  perspectives , 29(3):3 –30. \nAwad,  E., Dsouza,  S., Kim,  R., Schulz,  J., Henrich,  J., Shariff,  A., Bonnefon,  J.-F., and Rahwan,  \nI. (2018).  The moral  machine  experiment.  Nature , 563(7729):59 –64. \nBakshy,  E., Messing,  S., and Adamic,  L. A. (2015).  Exposure  to ideologically  diverse  news  and \nopinion  on facebook.  Science , 348(6239):1130 –1132.  \nBarbieri,  F., Anke,  L. E., and Camacho -Collados,  J. (2021).  Xlm-t: A multilingual  language  \nmodel  toolkit  for twitter.  arXiv  preprint  arXiv:2104.12250 . \nBirkstedt,  T., Minkkinen,  M., Tandon,  A., and M¨antym¨aki, M. (2023).    Ai governance:  themes, \nknowledge  gaps  and future  agendas.  Internet  Research , 33(7):133 –167.  \nBrown,  I. and Marsden,  C. T. (2023).  Regulating  code:  Good  governance  and better  regulation  in \nthe information  age. MIT Press.  \nBrundage, M., Avin, S., Wang, J., Belfield, H., Krueger, G., Hadfield, G., Khlaaf, H., Yang, J.,  \nToner,  H., Fong,  R., et al. (2020).  Toward  trustworthy  ai development:  mechanisms  for \nsupporting  verifiable  claims.  arXiv  preprint  arXiv:2004.07213 . \nBrynjolfsson,  E. and McAfee,  A. (2014).  The Second  Machine  Age:  Work,  Progress,  and \nProsperity  in a Time  of Brilliant  Technologies . W. W. Norton  & Company.  \nButcher,  J. and Beridze,  I. (2019).  What  is the state  of artificial  intelligence  governance  globally?  \nThe RUSI  Journal , 164(5 -6):88 –96. \nCath,  C. (2018).  Governing  artificial  intelligence:  ethical,  legal  and technical  opportunities  and \nchallenges.  Philosophical  Transactions  of the Royal  Society  A: Mathematical,  Physical  and \nEngineering  Sciences , 376(2133):20180080.  23  Cave,  S. and Dihal,  K. (2019).   Hopes  and fears  for intelligent  machines  in fiction  and reality.  \nNature  Machine  Intelligence , 1(2):74 –78. \nCave,  S., Dihal,  K., and Dillon,  S. (2020).  AI narratives:  A history  of imaginative  thinking  about  \nintelligent  machines . Oxford  University  Press.  \nCeruzzi,  P. E. (2012).  Computing:  a concise  history . MIT press.  \nCinelli,  M., De Francisci  Morales,  G., Galeazzi,  A., Quattrociocchi,  W., and Starnini,  M. (2021).  \nThe echo  chamber  effect  on social  media.  Proceedings  of the National  Academy  of Sciences , \n118(9):e2023301118.  \nCockburn, I. M., Henderson, R., and Stern, S. (2018).  The impact of artificial intelligence on  \ninnovation:  An exploratory  analysis.  In The economics  of artificial  intelligence:  An agenda , \npages  115–146.  University  of Chicago  Press.  \nConger, K. and Hirsch,  L. (2022).  Elon  musk  completes 44 billion  deal  to own  twitter.  The New  \nYork  Times . \nDel Vicario,  M., Bessi,  A., Zollo,  F., Petroni,  F., Scala,  A., Caldarelli,  G., Stanley,  H. E., and \nQuattrociocchi,  W. (2016).  The spreading  of misinformation  online.  Proceedings  of the national  \nacademy  of Sciences , 113(3):554 –559.  \nDouglas, D. G. (2012).  The Social  Construction  of Technologi', 'dilettaabbonato@gmail.com', 'Diletta Abbonato', '', '../pdf_files/67497ed51e95b-An unsolicited public opinion poll from Twitter.pdf', 2300712, 40, 10480, 78713, '2024-11-29 08:44:12', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(8, '7172972718', '6745cf4203d9a', 1, 15, 'FinML-Chain: A Blockchain-Integrated Dataset for Enhanced Financial Machine LearningFinML-Chain: A Blockchain-Integrated Dataset for Enhanced Financial Machine Learning', '2024-11-29 16:45:55.510862', '2024', 'Machine learning has become essential for innovation and efficiency in financial markets, offering predictive models and data-driven decision-making. However, challenges such as missing data, lack of transparency, I. INTRODUCTION Financial machine learning has emerged as a pivotal tool for driving innovation and enhancing efficiency in financial untimely updates, insecurity, and incompatible data sources hinder its effectiveness. These limitations reduce the accuracy and reliability of predictive models. Blockchain technology, with its transparency, immutability, and real-time updates, offers solutions to these challenges. In this paper, we introduce not just a dataset but a new framework for integrating high-frequency on-chain data with low-frequency off-chain data, providing a benchmark for addressing novel research questions in economic mechanism design. This framework enables the generation of modular, extensible datasets tailored to advancing the analysis of economic mechanisms such as the Transaction Fee Mechanism, facilitating multi-modal insights and fairness-driven evaluations. Through time series analysis using four machine learning techniques—linear regression, deep neural networks, XGBoost, and LSTM models—we demonstrate the framework’s capability to produce datasets that drive innovation in financial research and enhance the understanding of blockchain-driven economic systems. Our contributions are threefold: first, we propose a novel research scenario for the Transaction Fee Mechanism and demonstrate how our framework can address previously unexplored questions in economic mechanism design. Second, we provide a new benchmark for financial machine learning by open-sourcing both the sample dataset generated by our framework and the code for the pipeline, allowing future researchers to append new data and expand the datasets continuously. Third, by ensuring that the framework and its outputs are fully open-source, we promote reproducibility, transparency, and collaboration within the research commu nity. This initiative enables researchers to extend our work, tackle a broader range of economic challenges, and develop innovative financial machine-learning models. By offering this framework, sample datasets, and accompanying resources, we aim to establish a foundation for future advancements in interdisciplinary research at the intersection of machine learning, blockchain, and economics.', 'Blockchain Dataset,Machine Learning', 'FinML-Chain: A Blockchain-Integrated Dataset\nfor Enhanced Financial Machine Learning\nJingfeng Chen†, Wanlin Deng†, Dangxing Chen*, and Luyao Zhang*\nDuke Kunshan University\nSuzhou, China, 215316\nAbstract —Machine learning has become essential for\ninnovation and efficiency in financial markets, offering\npredictive models and data-driven decision-making. However,\nchallenges such as missing data, lack of transparency,\nuntimely updates, insecurity, and incompatible data sources\nhinder its effectiveness. These limitations reduce the accuracy\nand reliability of predictive models. Blockchain technology,\nwith its transparency, immutability, and real-time updates,\noffers solutions to these challenges. In this paper, we introduce\nnot just a dataset but a new framework for integrating\nhigh-frequency on-chain data with low-frequency off-chain\ndata, providing a benchmark for addressing novel research\nquestions in economic mechanism design. This framework\nenables the generation of modular, extensible datasets tailored\nto advancing the analysis of economic mechanisms such as the\nTransaction Fee Mechanism, facilitating multi-modal insights\nand fairness-driven evaluations. Through time series analysis\nusing four machine learning techniques—linear regression,\ndeep neural networks, XGBoost, and LSTM models—we\ndemonstrate the framework’s capability to produce datasets\nthat drive innovation in financial research and enhance the\nunderstanding of blockchain-driven economic systems.\nOur contributions are threefold: first, we propose a novel\nresearch scenario for the Transaction Fee Mechanism and\ndemonstrate how our framework can address previously\nunexplored questions in economic mechanism design. Second,\nwe provide a new benchmark for financial machine learning\nby open-sourcing both the sample dataset generated by our\nframework and the code for the pipeline, allowing future\nresearchers to append new data and expand the datasets\ncontinuously. Third, by ensuring that the framework and its\noutputs are fully open-source, we promote reproducibility,\ntransparency, and collaboration within the research commu-\nnity. This initiative enables researchers to extend our work,\ntackle a broader range of economic challenges, and develop\ninnovative financial machine-learning models. By offering this\nframework, sample datasets, and accompanying resources,\nwe aim to establish a foundation for future advancements\nin interdisciplinary research at the intersection of machine\nlearning, blockchain, and economics.\nIndex Terms —Blockchain Dataset, Machine Learning, EIP-\n1559\n†Joint First Authors.\n*Corresponding Authors: Luyao Zhang (lz183@duke.edu), Data Sci-\nence Research Center and Social Science Division; Dangxing Chen (dan-\ngxing.chen@dukekunshan.edu.cn), Zu Chongzhi Center for Mathematics\nand Computational Sciences.\nAddress: Duke Kunshan University, Duke Avenue No.8, Kunshan,\nSuzhou, Jiangsu, China, 215316.I. I NTRODUCTION\nFinancial machine learning has emerged as a pivotal tool\nfor driving innovation and enhancing efficiency in financial\nmarkets. By enabling sophisticated predictive models\nand data-driven decision-making, it offers the potential\nto significantly improve market outcomes. However, the\napplication of machine learning is fraught with challenges,\nincluding missing data, lack of transparency, untimely up-\ndates, data insecurity, and the diversity and incompatibility\nof data sources [1]–[3]. These issues collectively impair\nthe accuracy and reliability of predictive models, posing\nsubstantial barriers to progress in the field. Blockchain tech-\nnology presents a novel solution to these challenges. As a\ndistributed database, blockchain offers unique attributes of\ntransparency, immutability, and real-time updates, making\nit an ideal candidate for addressing the data issues plaguing\nfinancial machine learning. Blockchain’s decentralized\nnature ensures that data is transparently recorded and\nverified by multiple parties, enhancing data reliability and\ntrustworthiness [4], [5]. The immutability of blockchain\nrecords prevents data tampering and fraud, providing a\nsecure foundation for financial analysis. Real-time updates\nfacilitated by blockchain technology ensure that data is\nconsistently current, enabling timely and accurate model\npredictions.\nIn our research, we developed a comprehensive dataset\nthat integrates high-frequency on-chain transaction data\nwith low-frequency off-chain discussion data. The on-chain\ndata ensures traceability, transparency, and security, while\nthe inclusion of off-chain data supports the compatibility\nand corroboration of different data sources. To assess the\npotential applicability of this dataset in real-world finan-\ncial market analysis, we propose the following research\nquestions:\nRQ: Can this dataset be used to apply different ma-\nchine learning models for researching innovative financial\nproblems?\nWe provide all data and code in the following link:\nhttps://huggingface.co/datasets/StevenJingfeng/FinML.\nThe dataset is 80.4MB for the discord data and 4.92 MB,\n13.4MB for two of the on-chain data. Under the property\nof Blockchain, the data can be continuously updated, and\nnew datasets can be generated at any time. The workflow\ndoesn’t specify the size because anyone can extend it.arXiv:2411.16277v1  [econ.GN]  25 Nov 2024A. Innovative Mechanism-designed Related Question\nTo test the potential of this datatset, we apply it to\nresearch how to adavance the latest transaction mechanism\nimplemented in Ethereum. Transaction fee mechanism\n(TFM) is an essential component of a blockchain protocol\nto help allocate the limited blockchain computing resources\n[6]. People will consume Ethereum gas and pay for their\ngas usage if they want to execute transactions in Ethereum.\nThe introduction of EIP-1559 in 2021 restructured user fees\ninto two components: the base fee and the priority fee [6].\nThe base fee reflects the cost of executing the transactions\nand will be removed from circulation, which is constantly\nadjusted based on network congestion, aiming to keep block\nsizes within a target range. The base fee is determined\nthrough a Markov process, which involves calculations\nbased on the base fee and gas usage of the previous block.\nHowever, due to the calculation formula for the base fee\nof the next block involving the actual gas consumption\nof the previous block, EIP-1559 is limited to adjusting its\nstrategy based on events that have already occurred. In\nother words, the current mechanism of EIP-1559 adjusts\nthe gas price after transactions have taken place. Such\na mechanism is passive and cannot proactively predict\nand strategically adjust the base fee based on upcoming\ntransactions to achieve the mechanism’s goal to control the\ngas used of each block to half of the maximum amount\nit can be consumed. Zhang [7] emphasizes the urgent\nneed for AI’s fluid adaptability. If we can apply machine\nlearning methods to realize the precise prediction of the\ngas price for the upcoming transaction and adjust the base\nfee based on these predictions, we can alter the TFM from\nex-post adjustment to proactive adjustment, thus improving\nthe flexibility and efficiency of the transaction fee. Also,\nthe increasing fluid adaptability will contribute to better\ncatering to changes in network traffic and user demands.\nThe Ethereum EIP-1559 TFM provides an effective\nscenario for testing our dataset. We aim to test if we can\nleverage the information within this dataset to achieve\nreliable future gas demand predictions, which can help\nfacilitate the transition of EIP-1559 from a reactive to a\nproactive mechanism.\nB. Our Approach and Contributions\n1) Dataset Validation through Machine Learning Mod-\nels: We employed this dataset to train several machine\nlearning models, including linear regression, deep neural\nnetworks (DNN), XGBoost, and Long-Short Term Memory\n(LSTM) models, to assess the feasibility of predicting\ngas usage in the next block. This approach validated the\ndataset’s effectiveness in supporting gas usage prediction.\n2) Exploration of Multi-Task Capabilities: Furthermore,\nwe explored the potential of integrating monotonicity\nconstraints and the BERT model to evaluate the dataset’s\ncapability for handling multiple tasks. These methodologies\nassess the dataset’s compatibility and scalability, ensuring\nits robustness and applicability in various financial predic-\ntion tasks.3) Our Contributions:\n•Introduction of a Novel Framework and Bench-\nmark Dataset : We developed a new framework that\nintegrates high-frequency on-chain data with low-\nfrequency off-chain data, providing a benchmark\nfor addressing novel research questions in economic\nmechanism design. This framework generates modular\nand extensible datasets tailored to financial machine\nlearning, overcoming the challenges of transparency,\nreliability, and timeliness faced in traditional datasets.\n•Innovative Research Scenario : We proposed a novel\nresearch scenario: leveraging machine learning to op-\ntimize blockchain-based transaction fee mechanisms,\nsuch as Ethereum’s Transaction Fee Mechanism,\nmoving beyond reactive approaches to proactive\ndesign. This scenario highlights the practical potential\nof the framework in advancing mechanism design and\nother economic applications.\n•Open-Sourcing Data and Pipeline : To ensure re-\nproducibility and foster collaboration, we openly\nrelease not only a sample dataset generated by the\nframework but also the full pipeline code. This enables\nresearchers to continuously expand the dataset, adapt\nit to new contexts, and explore a broader range of\nfinancial and blockchain-related challenges.\nAdditionally, our framework supports machine learning\npredictions for demand and supply forecasting, trading\nmechanism design, and other financial applications. By\nestablishing a benchmark for financial machine learning, it\ndrives innovation and enhances the accuracy and reliability\nof financial models in the blockchain context.\nIt is important to note that our contribution is not merely\nincremental but a qualitative leap. The framework enables\nthe creation of high-frequency, verifiable, and extensible\ndatasets, fundamentally differing from existing benchmarks.\nTraditional comparisons with existing datasets are thus not\napplicable in this case.\nII. R ELATED WORK\nA. The Potential of Blockchain Data\nBlockchain’s diverse application scenarios provide a\nrobust foundation for addressing challenges in financial\nmachine learning by ensuring data integrity, security, and\nreliability. Its distributed, transparent, and immutable nature\naligns well with the requirements of financial machine-\nlearning models. Leading companies like Deloitte and\nAccenture have adopted blockchain to store and manage\nhealthcare and medical data, demonstrating its secure\ndata handling capabilities [8]. Additionally, blockchain\ntechnology has been extended to the gaming industry,\nwhere it secures in-game assets by recording them in\na distributed ledger, thereby preventing falsification [9].\nMa et al. proposed BlockBDM [10], a decentralized trust\nmanagement and secure usage model for IoT big data\nbased on public blockchain, highlighting blockchain’s\ncapability to securely handle large-scale data. Similarly,\nLiang et al. introduced CoopEdge, a blockchain-based\ndecentralized platform designed to support cooperativeFig. 1. Accuracy at token airdrop period\nedge computing, addressing trust issues inherent in edge\ncomputing environments [11]. Furthermore, the application\nof blockchain in the smart grid cyber layer enhances cyber-\nsecurity across various aspects, including measurement and\ncontrol, data aggregation, data management, and system\noperation [12]. These examples collectively underscore the\nsecurity, transparency, and reliability of blockchain data,\nestablishing it as an ideal solution for ensuring the integrity\nand trustworthiness of financial datasets used in machine\nlearning models.\nB. Gas Price Prediction and Innovation\nPresently, there exists a plethora of scholarly endeavors\ndedicated to the prediction of gas prices using machinelearning models. Mars et.al.’s research has shown that the\nmodels implementing Long-Short Term Memory (LSTM)\nand Gated Recurrent Unit (GRU) outperform the Prophet\nmodel and the gas price oracle Geth [13]. Butler and\nCrane conduct research comparing and combining different\nmachine learning models (Direct-Recursive Hybrid LSTM,\nCNN-LSTM, and Attention-LSTM) to estimate the gas\nprice in the next 5 minutes [14]. Chuang and Lee proposed\nthat the Gaussian process model has a better gas price pre-\ndiction when experiencing great fluctuation in transaction\nvolumes, recommending a hybrid model consisting of both\nthe Gaussian process and GasStation-Express [15]. Lan et\nal. propose a model combining both LSTM and XGBoost\nto predict the Ethereum gas price based on the data inMempool under the EIP-1995 mechanism [16].\nIn addition, a multitude of factors are identified as\nexerting substantial influence on gas prices. Liu et al.\nutilized a regression-based gas price predicting approach\n(MLR) to predict the transaction fee in the next block and\nproposed five significant factors regarding prediction (i.e.,\ndifficulty, block gas limit, transaction gas limit, ether price,\nand miner reward) [17]. Muminov et al. implemented the\nDeepAR model to predict Ethereum gas price and identified\ndirect factors (e.g., seasonal variations, transaction volumes,\ntransaction values, the number of token transactions, price,\nand the amount of gas used per block) as well as indirect\nfactors (e.g., market trends, regulatory developments, and\ninvestor sentiment) [18].\nThese studies have predominantly focused on post-\nadjustment analysis, offering practical insights for guiding\nusers’ future transaction decisions. However, a significant\ngap exists in the research concerning the precise prediction\nof gas usage in subsequent blocks. As a result, there is\ncurrently no established benchmark for proactive EIP-1559-\nbased fee adjustments. To address this gap, our research\naims to develop an predictive model benchmark for gas\nusage in the next block. By establishing this benchmark,\nwe create a foundation for proactive gas usage prediction,\nthereby facilitating future exploration and contributing\nto the optimization of the EIP-1559 framework. This\nadvancement will shift the focus from post-adjustment to\npre-adjustment strategies, enhancing the overall efficiency\nand effectiveness of dynamic transaction fee mechanisms.\nC. Other Blockchain-related Dataset\nThe papers previously accepted by ICDE primarily\nfocus on distributed ledgers and blockchains, with an\nemphasis on data privacy and security. For example, Ni et\nal. address the anonymity-aware output decomposition (AA-\nOD) problem by proposing an approximation algorithm,\nBoggart, to minimize the number of decomposed outputs\nwhile preserving transaction privacy in blockchain mixing\nservices [27]. Similarly, Chen et al. introduce BlockOPE,\nan efficient order-preserving encryption scheme for per-\nmissioned blockchains, enhancing query functionality and\nperformance while maintaining security through parallel\nprocessing and an adaptive lightweight client cache [28].\nWang et al. present vChain+, a searchable blockchain\nsystem that improves query performance and public key\nmanagement by utilizing sliding window accumulators\nand tree-based indexes [29]. However, these studies do\nnot explicitly explore or utilize the financial attributes\nof blockchain-related datasets. In contrast, our research\nis particularly novel, as it focuses on the application of\nblockchain datasets in the financial sector.\nThere are some blockchain-based datasets being pro-\nposed to solve some financial problems. Wang et al.\nintroduce EX-Graph, a dataset that authentically links\nEthereum and Twitter [30]. However, the blockchain part\nthey integrated only included OpenSea transaction data.\nOpenSea is just one application on Ethereum, and the NFT-\nrelated transactions it covers represent only a small portionof the overall transactions on Ethereum. Our data is sourced\nfrom Ethereum Layer 1, and the scale of our dataset is\nsignificantly larger. Shamsi et al. also tried to provide a\nblockchain-based dataset, but they focused on the network\nbetween accounts [31], which is quite different from our\nstudy on supply and demand prediction and mechanism\ndesigns in financial markets. Thus, even though it seems\nthat similar datasets have been proposed previously, the\nscale and the usage scope of our dataset are totally different\nand more comprehensive.\nIII. D ATA\nAs mentioned before, we propose a dataset that incor-\nporate the on-chain data and off-chain data.\nFor the on-chain data, we include Ethereum’s blockchain\ndata, which includes details such as timestamps, block\nnumbers, hashes, parent hashes, transactions, etc., which\nis extracted from Ethereum using Google BigQuery. For\nthe purpose of predicting gas usage in forthcoming blocks,\nwe retain only the pertinent features: timestamp, gas limit,\ngas used, and base fee. We exclude other variables such as\ntransaction numbers, despite their high correlation with gas\nusage, based on our specific research focus. Furthermore,\nour study acknowledges the impact of token airdrops on\ntransaction engagement levels for both recipients and non-\nrecipients. According to Guo [32], token airdrops can\nsignificantly influence engagement, resulting in pronounced\ngas usage volatility and subsequent base fee fluctuations.\nConsequently, our analysis is bifurcated into two distinct\nperiods. The first period examines the ARB token airdrop,\nthe most substantial airdrop event in 2023, which occurred\nfrom March 21 to April 1 and comprised 78,290 blocks.\nThe second period, devoid of significant fungible token\nairdrop activities, extends from June 1, 2023, to July\n1, 2023, encompassing 213,244 blocks. This temporal\ndelineation allows for a comprehensive analysis of the\neffects of major airdrop events on Ethereum’s gas fee\ndynamics.\nFor the off-chain data, we include users’ discussion text\nfrom Discord. Discord hosts vibrant crypto discussions\nranging from market analysis to technical debates, yet\nremains underexplored for sentiment analysis, unlike\nplatforms like Twitter and Reddit, where extensive studies\nin cryptocurrency sentiment research exist (e.g., Kraaijeveld\n& De Smedt, 2020 [33]; Mohapatra et al., 2019 [34]; Khan,\n2022 [35]). Another reason we chose to use Discord data\nis its accessibility: Twitter has closed its API, limiting\nour ability to obtain large-scale discussion data from that\nplatform. Moreover, Discord serves as a community hub for\nmany crypto communities, attracting both professionals and\nenthusiasts interested in cryptocurrency. Consequently, the\ninformation on Discord is more targeted and relevant than\ndiscussions on other social media platforms. Specifically,\nwe query the discussion text from the Binance, Uniswap,\nand Ethereum Dev communities in Discord. These com-\nmunities are at the forefront of decentralized finance and\nblockchain development, offering a wealth of information\nthat can reveal emerging trends, sentiments, and technicalConference\nAbbreviationPaper Title Research Focus\nCA V SolCMC: Solidity Compiler’s Model Checker [19] Smart Contract Verification\nICDCS(CCF-B) A Graph Diffusion Scheme for Decentralized Content\nSearch based on Personalized PageRank [20]Blockchain Application\nICDCS(CCF-B) Distributed Runtime Verification of Metric Temporal\nProperties for Cross-Chain Protocols [21]Blockchain Analysis\nICDCS(CCF-B) Monitoring Data Requests in Decentralized Data Storage\nSystems: A Case Study of IPFS [22]Blockchain Analysis\nINFOCOM Blockchain Based Non-repudiable IoT Data Trading:\nSimpler, Faster, and Cheaper [23]Blockchain Performance\nOptimization\nINFOCOM BrokerChain: A Cross-Shard Blockchain Protocol for\nAccount/Balance-based State Sharding [24]Blockchain Performance\nOptimization\nINFOCOM Payment Channel Networks: Single-Hop Scheduling for\nThroughput Maximization [25]Blockchain Performance\nOptimization\nNSDI DispersedLedger: High-Throughput Byzantine Consensus\non Variable Bandwidth Networks [26]Consensus Protocol\nICDE Boggart: An Approximation Algorithm for\nAnonymity-Aware Output Decomposition in Blockchain\nMixing Services [27]Blockchain Privacy Protection\nICDE BlockOPE: Efficient Order-Preserving Encryption for\nPermissioned Blockchains [28]Blockchain Data Security &\nPerformance Optimization\nICDE vChain+: A Searchable Blockchain System with\nImproved Query Performance and Public Key\nManagement [29]Blockchain Query\nPerformance Enhancement\nOthers EX-Graph: A Dataset Authentically Linking Ethereum\nand Twitter [30]Blockchain Data for Social\nNetwork Research\nOthers Chartalist: Blockchain Network Dataset for Account\nRelationship Analysis [31]Blockchain Account Network\nTABLE I\nSUMMARY OF BLOCKCHAIN -RELATED RESEARCH PAPERS\nadvancements. The discussion texts are queries from\nDiscord using the DiscordChatExporter, which is an open-\nsource tool provided on GitHub.\nIV. V ALIDATION METHOD ’SDETAILS\nA. Variables\n1) On Chain Variables: Gas limit and gas target are\ntwo significant indicators in TFM. Specifically, the gas\nlimit refers to the maximum amount of gas that can be\nconsumed when executing smart contracts or transactions\non each block. Gas target refers to the gas amount people\nwant to achieve in one block. To ensure the efficiency of\ntransactions, the gas target should equal half of the gas\nlimit [6].\nour approach is to predict the normalized gas used\n(denoted as y), which is calculated by the formula:\ny=gas used −gas target\ngas target(1)\nThis formula will shift the y within a range of [-1,1]. Or,\nin simple terms, this formula compares the actual gas used\nto the target gas limit, allowing us to assess how far off the\ngas usage is from the intended target. The Xis the variable\nused as features, containing αandβ. The corresponding\nαandβare calculated by the following formulas:\nα=x1\nx2, β=base fee (2)\nwhere x1denotes the feature gas-used and x2denotes the\nfeature gas-limit. αandβare applied as the informationof each block, and the length of previous data points used\nis denoted as k, which varies among the values of 1,2 and\n3. Variation in kaims to evaluate the performance model\nover different historical data lengths.\n2) Off Chain Variables: As mentioned in the Data\nsection, we also incorporate an additional off-chain data\nsource, specifically the discussion text from Discord. To\nanalyze this data, we use a large language model to process\nEnglish sentences or words, estimating the probability of\neach sentence being classified as positive, negative, or\nneutral, ensuring that the total probability sums to 1. After\nobtaining sentiment information, we organize the corpus\nsequentially and compute average sentiment scores over\nboth hourly and daily intervals. This sentiment information\nis denoted as γ. We then synchronize the on-chain data\nwith the off-chain sentiment using corresponding block\ndata from the previous time chunk, ensuring that only\npreceding sentiment information is included in the training\ndata.\nB. Use of Models\n1) Neural Additive Model: The Neural Additive Model\n(NAM), proposed by Agarwal et al. in 2021 [36], offers a\ntransparent framework for utilizing Deep Neural Networks\n(DNNs) to model individual or combined features. In this\narchitecture, the outputs from all DNNs are aggregated\nat the final hidden layer, resulting in a unified model.\nOur research omits interactions between unrelated features,\nenabling the imposition of weak monotonicity constraints\non each feature.This model’s relative transparency stems from the\nminimal interaction between variables, allowing for easy\nisolation of specific parts of the model to understand the\nrelationships between the output and individual features.\nConsequently, even during periods of high fluctuation in\ngas usage, the model’s specific outputs can be readily\ninterpreted and justified.\n2) Monotonicity: One of the primary concerns with\nusing neural networks to predict gas usage in blockchain\nsystems is the ‘black-box’ nature of the models. When\nEthereum adopts a DNN-based approach for proactive EIP-\n1559, stakeholders must understand how predictions are\ngenerated to mitigate potential risks. If users depend on\noverly optimistic predictions without comprehending the\nmodel’s limitations, it can lead to substantial issues. Thus,\nensuring the model’s explainability and transparency, along\nwith a clear understanding of the prediction procedures, is\ncrucial.\nTo address these concerns, we can employ various\nstrategies to enhance the interpretability of DNNs and\nincorporate well-established methods for time-series data\nmanipulation. One commonly applied method for high-\nfrequency time-series data, such as blockchain data, is the\nExponential Moving Average (EMA) [37]. EMA assigns\ngreater weight to more recent data points, thereby providing\na smoothed representation of the underlying trends in the\ndata. The formula of EMA [38], [39] is denoted as\nEMA = (C(P_c−P_p)) +P_c (3)\nWhere C is a constant, P_candP_pare the current\nprice and previous prices. Through iterative processes, the\ntraditional EMA method often results in the forgetting of\nprior information, thereby forcing a high attention on the\nmost recent data values. However, this approach can lead\nto a distortion of the original value distribution. A more\nrefined solution is to address the increasing importance of\ndata from earlier to more recent blocks, without entirely\ndiscarding historical information.\nIn this context, we propose a novel method for predicting\ngas usage in blockchain transactions, inspired by the\nconcept of pairwise monotonicity as detailed by Chen [40].\nUnlike traditional methods like EMA, which emphasizes\nthe forgetting of older information, our approach employs\na monotonicity representation to attribute varying levels\nof importance to data over time. Monotonicity has demon-\nstrated its interdisciplinary applicability, as evidenced by\nworks such as Liu et al. [41] and Milani [42], which\nfocused on individual monotonicity for single variables.\nour method is inspired by Chen’s work [40] for introducing\npairwise monotonicity in the financial domain. For instance,\nin credit scoring, past due amounts over a longer period\nshould more significantly impact the scoring of new debt\nrisk. Similarly, in blockchain transactions, older data points\nare less influential, whereas recent data points are more\ncritical for prediction.\nWe apply monotonicity to the αfeature, where changes\ninαfor recent blocks result in greater variance in prediction\ncompared to changes in distant previous data points. Inthe case of k= 2, where the prediction uses data from\nthe two previous blocks, the αvalues are α1andα2with\nvalues (α1=a, α 2=a). Given the higher importance\nassigned to α2, increasing or decreasing α2by a certain\namount tcompared with altering α1by the same amount\nwill lead to a higher variation of results. The mathematical\nequation can be denoted as\n|f(α1=a, α 2=a)−f(α1=a+t, α 2=a)| ≤\n|f(α1=a, α 2=a)−f(α1=a, α 2=a+t)|(4)\nThe formal definition of pairwise monotonicity is modified\nfrom Chen’s work [40] where the individual monotonicity\ncontrols the positive sign of the addition. In other words,\nthe model’s output increases as the input variable increases.\nHence, given fas the model, he concludes that fis weakly\nmonotonic with respect to xβoverxγif\nf(xβ, xγ+c,x¬)≤f(xβ+c, xγ,x¬),\n∀xβ, xγs.t.xβ=xγ,∀x¬,∀c∈R+.(5)\nThis indicates that when given any value of xβand\nxγ, adding a certain amount c, the cadding on xβwill\nresult in a higher value. Since in our case, no individual\nmonotonicity is imposed on the model, the changing of\nthe output can both be positively correlated and negatively\ncorrelated with variables. Thereby, we varied the definition\ncan propose a modified one, given f, the model, we\nconclude fis weakly monotonic concerning xβoverxγif\n|f(xβ, xγ+c,x¬)−f(xβ, xγ,x¬)|\n≤ |f(xβ+c, xγ,x¬)−f(xβ, xγ,x¬)|\n∀xβ, xγsuch that xβ=xγ,∀x¬,∀c∈R.(6)\nUnder this weak monotonicity definition, we ensure\nmore information is addressed on the nearer data point,\nenhancing its transparency and explainability.\n3) FinBert Model: The extraction of sentiment from\nthe data is conducted using FinBert, a model proposed\nby Dogu and Araci in 2019 [43]. FinBert is a BERT-\nbased architecture specifically trained on financial data\nsets, including the Financial PhraseBank, TRC2-financial,\nand FiQA Sentiment. This training enables FinBert to\nachieve state-of-the-art performance in FiQA sentiment\nscoring. In our research, we leverage FinBert to predict\nsentiment in our text data, ensuring accurate sentiment\nanalysis aligned with financial contexts.\nV. R ESULTS\nA. Experiments with General Models\nTo validate the applicability of our dataset for innovative\nfinancial research, we initially evaluated four machine\nlearning algorithms—linear regression, DNN, XGBoost,\nand LSTM—during two distinct periods: the ARB token\nairdrop and a standard non-airdrop period. The ARB\nairdrop period, comprising 78,290 data points, allowed\nus to test the dataset’s robustness across diverse prediction\ntechniques.Each algorithm demonstrated substantial predictive accu-\nracy, with the DNN model achieving superior performance\nin 23 out of 24 trials. The highest accuracy was attained\nwhen using a 10-timestep lookback, incorporating both α\nandβfeatures as regressors, indicating the DNN’s capacity\nto capture complex temporal relationships effectively.\n(a) Loss at token airdrop period\n(b) Variance at token airdrop period\nFig. 2. Comparison of methods at Token airdrop period\nA similar experimental setup was used for the normal,\nnon-airdrop period to assess the dataset’s performance\nin stable conditions. The predictive accuracy decreased\nslightly across models during this extended timeframe,\nwith DNN again showing resilience to performance drops.\nWhile Linear Regression, XGBoost, and LSTM exhibited\nincreased errors and variance, DNN maintained only a\nmarginal reduction, reinforcing its suitability for handling\nextended prediction intervals in volatile block data.\nThe following Plot 3(a) and Plot 3(b) visualize each\nmethod’s average mean square error and variance. The\nresults indicate that DNN consistently performs well\nwith low error and variance. Thereby, we continue the\nsubsequent experiment on a structure based on the DNN\nstructure.\nThe consistent performance of the DNN model across\nboth periods led to its selection as the basis for further\nexperiments, underscoring this dataset’s potential for sup-\nporting advanced financial prediction models under varying\nmarket conditions.\nB. Experiments with Monotonicity\nTo demonstrate the scablity of this dataset, we employ\nvarious DNN structures, specifically the Neural Additive\nModel (NAM) proposed by Agarwal et al. (2021) [36]. We\nutilized the NAM model due to its inherent transparency\ncharacteristic as well as the ability to isolate variables,\n(a) Loss at normal period\n(b) Variance at normal period\nFig. 3. Comparison of methods at normal period\nfacilitating the imposition of monotonicity constraints on\nspecific features. The model is trained on data from two\ndistinct periods, achieving weak pairwise monotonicity\nover the αfeature. In the first step, standard training is\nconducted to enable the model to learn from the data. In the\nsecond step, we impose monotonic constraints. Specifically,\ndiscretizing the αfeature into fractions ranging from 0\nto 1 with fine intervals. Using the function described in\nEquation 6, we add a small value cto generate a pair of\ninputs that must satisfy a strict inequality. The violation\namount of that input, combined with the Mean Squared\nError (MSE), forms a new loss function. The objective is\nto ensure the loss caused by the monotonicity violations\nbecomes zero.\nWe only impose the monotonicity to the αvariable since\nthe base fee βis generated by the Markov process from\ntheα. After training, we observe that with a maximum\nvalue of k= 3, which includes three previous data points,\nthe monotonicity constraints are satisfied without adversely\naffecting the loss. However, when k= 4 or more, it\nbecomes challenging to satisfy all monotonic constraints.\nThereby, once the block number is within a constraint, we\ncan ensure that the monotonic relationship persists and the\nmodel remains transparent. While applying monotonicity\ndoes not affect the model’s loss, it enhances the model’s\nexplainability and ensures it meets the transparency require-\nments set by the finance director. The two-step training\nloss is in Plot 4. A comparison between the model with\nand without the monotonicity is shown in Figures 5 and 6.0 2 4 6 8 10\nEpoch0.110.120.130.140.150.16Training Loss\nTraining Loss over Epochs for 2-Step Training\nStep 1 Training Loss\nStep 2 Training LossFig. 4. The two-step training loss\n0 20 40 60 80 100\n0-100 datapoint1.00\n0.75\n0.50\n0.25\n0.000.250.500.751.00Gas usedPrediction\npred gas used\ntrue gas used Fig. 5. Prediction without monotonicity\n0 20 40 60 80 100\n0-100 datapoint1.00\n0.75\n0.50\n0.25\n0.000.250.500.751.00Gas usedPrediction\npred gas used\ntrue gas used Fig. 6. Prediction with monotonicity\nFig. 7. The NAM model with monotonicity, training and comparison\nC. Experiments with Sentiment Information\nWe further explore the NAM model at k=1,2 and 3.\nGiven the availability of both on-chain and off-chain\nvariables, we conducted tests to determine whether the\ninclusion of off-chain variables, specifically sentiment anal-\nysis, enhances the model’s predictability. We restricted the\nkvalue to 1, 2, and 3, based on previous empirical analyses\nindicating that increasing kbeyond 3 does not significantly\nimprove the model’s performance. Additionally, since the\nminimum interval of the sentiment result is by an hour\nand the block interval is 12 seconds, indicating that the\nsentiment results are the same over the adjacent blocks.\nHence, for all k=1,2 or 3, we only include 1 sentiment\ndatapoint for each data. We design the experiment with 4\nvariable settings:\n•Utilizing both hour-averaged sentiment, day-averaged\nsentiment, and on-chain variables.\n•Utilizing day-averaged sentiment and on-chain vari-\nables.\n•Utilizing hour-averaged sentiment and on-chain vari-\nables.\n•The base case, incorporates only on-chain variables.\nThe prediction on the test set with 40 and 100 data points\nis demonstrated in Figure 8(a) and 8(b). The sentiment\nanalysis can marginally improve the accuracy of the model.\nAdditionally, Adding timesteps enhances predictability\nwhen only on-chain data is used. However, when sentiment\ndata is included, the number of needed timesteps decreases.\nThe results, summarized in Table II, show that sentiment\naddition had a minor effect on overall predictive accuracy,\nwith slight improvements during high-activity periods, such\nas the ARB airdrop. The dataset’s design enabled analysis\nacross different configurations, demonstrating flexibility in\nsupporting diverse data types and hybrid prediction models.\nNonetheless, sentiment data in its averaged form displayed\nlimited impact, likely due to unrelated information within\nthe corpus that reduced its relevance to gas usage patterns.\nHowever, this can be addressed by further refining the\nfiltering methods for text data.\nIn summary, our findings validate the versatility and\nrobustness of this dataset for implementing diverse machine\nlearning techniques and financial prediction models. The\nexperiments substantiate that the dataset not only supportsvarious prediction methods but is also equipped to handle\ncomplex, hybrid data types, reinforcing its suitability for\nexploring novel financial models and enhancing blockchain\ntransaction predictability.\nVI. C ONCLUSION AND FUTURE STUDY\nIn conclusion, we present a novel dataset that integrates\nboth on-chain and off-chain data, specifically designed\nto address key financial challenges, such as mechanism\ndesign, through advanced machine learning techniques.\nThis dataset addresses the critical need for robust, data-\ndriven decision-making in both blockchain and financial\nsystems. One of the primary research questions we explore\nusing this dataset is how to accurately predict gas usage\nin upcoming blocks and dynamically adjust transaction\nfees based on specific financial objectives, such as cost\noptimization or efficiency improvements. To evaluate the\nadaptability and effectiveness of this dataset, we applied\nfour widely-used machine learning algorithms—Linear\nRegression, LSTM, Deep Neural Networks (DNNs), and\nXGBoost—demonstrating its flexibility for various analyti-\ncal approaches. Additionally, we incorporated monotonicity\nand sentiment analysis to validate the dataset’s ability to\nsupport multi-modular research, crucial for understand-\ning both quantitative patterns and qualitative insights in\nfinancial markets.\nOur research underscores the limitations of current\nblockchain data usage frameworks, particularly in their\nadaptability to financial applications, and highlights the\nneed for systems capable of seamlessly integrating diverse\ndata sources while supporting sophisticated machine learn-\ning techniques. Looking forward, this dataset sets a new\ndirection for future research in blockchain-based financial\ndata management. This dataset demonstrates its potential\nof leveraging machine learning for predictive analytics in\nblockchain systems, offering a foundation for enhancing\ntransaction mechanisms and financial modeling in finance,\nespecially in decentralized finance (DeFi). By making this\ndataset openly available, we aim to support the broader\nresearch community and drive further exploration into the\nintersection of blockchain data and machine learning to\nfoster innovation in the financial sector.TABLE II\nMODEL PERFORMANCE OVER TWOPERIODS\n+OC,+DS,+HS +OC,+DS,-HS +OC,-DS,+HS +OC,-DS,-HS\nPeriod 1: 03/21/2023 - 04/01/2023 (ARB-airdrop)\n3 Timesteps 0.10022 0.10150 0.10164 0.10201\n2 Timesteps 0.10056 0.10249 0.10213 0.10265\n1 Timestep 0.10169 0.10190 0.10204 0.10290\nPeriod 2: 06/01/2023 - 07/01/2023 (Normal)\n3 Timesteps 0.13341 0.15657 0.16142 0.16089\n2 Timesteps 0.13477 0.15381 0.15806 0.16456\n1 Timestep 0.13593 0.15321 0.15459 0.18428\nTABLE III\nTHE NOTATION \"OC\" REFERS TO ON-CHAIN VARIABLES ,WHILE \"HS\" AND \"DS\" DENOTE HOURLY AVERAGED SENTIMENT AND DAILY\nAVERAGED SENTIMENT ,RESPECTIVELY . ‘+’ SYMBOL INDICATES THE INCLUSION OF A VARIABLE IN THE MODEL ,WHEREAS ‘-’SYMBOL\nDENOTES ITS EXCLUSION . THE NUMERICAL VALUES REPRESENT THE MEAN SQUARE ERROR (MSE) OF THE MODEL ON THE TEST DATASET .\n0510152025303540\n40 datapoint1.00\n0.75\n0.50\n0.25\n0.000.250.500.751.00Gas usedPrediction\npred gas used with sentiment\npred gas used without sentiment\ntrue gas used\n(a) 40 datapoints\n0 20 40 60 80 100\n0-100 datapoint1.00\n0.75\n0.50\n0.25\n0.000.250.500.751.00Gas usedPrediction\npred gas used with sentiment\npred gas used without sentiment\ntrue gas used (b) 100 datapoints\nFig. 8. Comparitive prediction results of model with and without sentiments\nACKNOWLEDGMENT\nLuyao Zhang is supported by the National Science\nFoundation of China (NSFC) for the project titled “Trust\nMechanism Design on Blockchain: An Interdisciplinary\nApproach of Game Theory, Reinforcement Learning, and\nHuman-AI Interactions” (Grant No. 12201266). Jingfeng\nChen and Wanlin Deng are supported by the Office of\nAcademic Services and the DKU Summer Research Scholar\nProgram, under the supervision of Prof. Dangxing Chen\nand Prof. Luyao Zhang, respectively.\nREFERENCES\n[1]A. G. F. Hoepner, D. McMillan, A. Vivian, and C. Wese Simen,\n“Significance, relevance and explainability in the machine learning\nage: an econometrics and financial data science perspective,” The\nEuropean Journal of Finance , vol. 27, no. 1–2, pp. 1–7, 2020.\n[2]Q. Liu, P. Li, W. Zhao, W. Cai, S. Yu, and V . C. M. Leung, “A survey\non security threats and defensive techniques of machine learning:\nA data driven view,” IEEE Access , vol. 6, pp. 12 103–12 117, 2018.\n[3]M. Xue, C. Yuan, H. Wu, Y . Zhang, and W. Liu, “Machine learning\nsecurity: Threats, countermeasures, and evaluations,” IEEE Access ,\nvol. 8, pp. 74 720–74 742, 2020.\n[4]M. Andoni, V . Robu, D. Flynn, S. Abram, D. Geach, D. Jenkins,\nP. McCallum, and A. Peacock, “Blockchain technology in\nthe energy sector: A systematic review of challenges and\nopportunities,” Renewable and Sustainable Energy Reviews ,\nvol. 100, pp. 143–174, 2019. [Online]. Available: https:\n//www.sciencedirect.com/science/article/pii/S1364032118307184\n[5]S. Lawrenz, P. Sharma, and A. Rausch, “Blockchain technology as\nan approach for data marketplaces,” ser. ICBCT ’19. New York,\nNY , USA: Association for Computing Machinery, 2019, p. 55–59.\n[Online]. Available: https://doi.org/10.1145/3320154.3320165[6]Y . Liu, Y . Lu, K. Nayak, F. Zhang, L. Zhang, and Y . Zhao,\n“Empirical analysis of eip-1559: Transaction fees, waiting\ntimes, and consensus security,” in Proceedings of the 2022\nACM SIGSAC Conference on Computer and Communications\nSecurity , ser. CCS ’22. New York, NY , USA: Association for\nComputing Machinery, 2022, p. 2099–2113. [Online]. Available:\nhttps://doi.org/10.1145/3548606.3559341\n[7]L. Zhang, “Machine learning for blockchain: Literature review and\nopen research questions,” OSF Preprints , November 2023.\n[8]T.-T. Kuo, H.-E. Kim, and L. Ohno-Machado, “Blockchain\ndistributed ledger technologies for biomedical and health care\napplications,” Journal of the American Medical Informatics\nAssociation , vol. 24, no. 6, pp. 1211–1220, 09 2017. [Online].\nAvailable: https://doi.org/10.1093/jamia/ocx068\n[9]O. J. Scholten, N. G. J. Hughes, S. Deterding, A. Drachen,\nJ. A. Walker, and D. Zendle, “Ethereum crypto-games: Mechanics,\nprevalence, and gambling similarities,” in Proceedings of the\nAnnual Symposium on Computer-Human Interaction in Play ,\nser. CHI PLAY ’19. New York, NY , USA: Association for\nComputing Machinery, 2019, p. 379–389. [Online]. Available:\nhttps://doi-org.proxy.lib.duke.edu/10.1145/3311350.3347178\n[10] M. Zhaofeng, W. Lingyun, W. Xiaochang, W. Zhen, and Z. Weizhe,\n“Blockchain-enabled decentralized trust management and secure\nusage control of iot big data,” IEEE Internet of Things Journal ,\nvol. 7, no. 5, pp. 4000–4015, 2020.\n[11] L. Yuan, Q. He, S. Tan, B. Li, J. Yu, F. Chen, H. Jin, and\nY . Yang, “Coopedge: A decentralized blockchain-based platform for\ncooperative edge computing,” in Proceedings of the Web Conference\n2021 , ser. WWW ’21. New York, NY , USA: Association for\nComputing Machinery, 2021, p. 2245–2257. [Online]. Available:\nhttps://doi-org.proxy.lib.duke.edu/10.1145/3442381.3449994\n[12] P. Zhuang, T. Zamir, and H. Liang, “Blockchain for cybersecurity\nin smart grid: A comprehensive survey,” IEEE Transactions on\nIndustrial Informatics , vol. 17, no. 1, pp. 3–19, 2021.\n[13] R. Mars, A. Abid, S. Cheikhrouhou, and S. Kallel, “A machinelearning approach for gas price prediction in ethereum blockchain,”\nin2021 IEEE 45th Annual Computers, Software, and Applications\nConference (COMPSAC) , 2021, pp. 156–165.\n[14] C. Butler and M. Crane, “Blockchain transaction fee forecasting:\nA comparison of machine learning methods,” Mathematics , vol. 11,\nno. 9, 2023. [Online]. Available: https://www.mdpi.com/2227-7390/\n11/9/2212\n[15] C.-Y . Chuang and T.-F. Lee, Eds., The International Conference on\nDeep Learning, Big Data and Blockchain (Deep-BDB 2021) , vol.\n309, 2022.\n[16] D. Lan, H. Wang, C. Yin, L. Zhou, C. Ge, and X. Lu, “Gas price\nprediction based on machine learning combined with ethereum\nmempool,” in 2022 IEEE 19th International Conference on Mobile\nAd Hoc and Smart Systems (MASS) , 2022, pp. 346–354.\n[17] F. Liu, X. Wang, Z. Li, J. Xu, and Y . Gao, “Effective gasprice\nprediction for carrying out economical ethereum transaction,” in\n2019 6th International Conference on Dependable Systems and\nTheir Applications (DSA) , 2020, pp. 329–334.\n[18] A. Muminov, O. Sattarov, and D. Na, “Enhanced bitcoin price\ndirection forecasting with dqn,” IEEE Access , vol. 12, pp. 29 093–\n29 112, 2024.\n[19] L. Alt, M. Blicha, A. E. J. Hyvärinen, and N. Sharygina,\n“Solcmc: Solidity compiler’s model checker,” in Computer\nAided Verification: 34th International Conference, CAV 2022,\nHaifa, Israel, August 7–10, 2022, Proceedings, Part I . Berlin,\nHeidelberg: Springer-Verlag, 2022, p. 325–338. [Online]. Available:\nhttps://doi.org/10.1007/978-3-031-13185-1_16\n[20] N. Giatsoglou, E. Krasanakis, S. Papadopoulos, and I. Kompatsiaris,\n“A graph diffusion scheme for decentralized content search based\non personalized pagerank,” in 2022 IEEE 42nd International Con-\nference on Distributed Computing Systems Workshops (ICDCSW) ,\n2022, pp. 53–59.\n[21] R. Ganguly, Y . Xue, A. Jonckheere, P. Ljung, B. Schornstein,\nB. Bonakdarpour, and M. Herlihy, “Distributed runtime verification\nof metric temporal properties for cross-chain protocols,” 2022.\n[Online]. Available: https://arxiv.org/abs/2204.09796\n[22] L. Balduf, S. Henningsen, M. Florian, S. Rust, and B. Scheuermann,\n“Monitoring data requests in decentralized data storage systems:\nA case study of ipfs,” 2022. [Online]. Available: https:\n//arxiv.org/abs/2104.09202\n[23] F. Chen, J. Wang, C. Jiang, T. Xiang, and Y . Yang, “Blockchain\nbased non-repudiable iot data trading: Simpler, faster, and cheaper,”\ninIEEE INFOCOM 2022 - IEEE Conference on Computer\nCommunications , 2022, pp. 1958–1967.\n[24] H. Huang, X. Peng, J. Zhan, S. Zhang, Y . Lin, Z. Zheng, and S. Guo,\n“Brokerchain: A cross-shard blockchain protocol for account/balance-\nbased state sharding,” in IEEE INFOCOM 2022 - IEEE Conference\non Computer Communications , 2022, pp. 1968–1977.\n[25] N. Papadis and L. Tassiulas, “Payment channel networks: Single-\nhop scheduling for throughput maximization,” in IEEE INFOCOM\n2022 - IEEE Conference on Computer Communications , 2022, pp.\n900–909.\n[26] L. Yang, S. J. Park, M. Alizadeh, S. Kannan, and D. Tse,\n“DispersedLedger: High-Throughput byzantine consensus on\nvariable bandwidth networks,” in 19th USENIX Symposium on\nNetworked Systems Design and Implementation (NSDI 22) . Renton,\nWA: USENIX Association, Apr. 2022, pp. 493–512. [Online].\nAvailable: https://www.usenix.org/conference/nsdi22/presentation/\nyang\n[27] W. Ni, P. Cheng, and L. Chen, “Mixing transactions with arbitrary\nvalues on blockchains,” in 2022 IEEE 38th International Conference\non Data Engineering (ICDE) , 2022, pp. 2602–2614.\n[28] Z. Chen, Q. Li, X. Qi, Z. Zhang, C. Jin, and A. Zhou, “Blockope:\nEfficient order-preserving encryption for permissioned blockchain,”\nin2022 IEEE 38th International Conference on Data Engineering\n(ICDE) , 2022, pp. 1245–1258.\n[29] H. Wang, C. Xu, C. Zhang, J. Xu, Z. Peng, and J. Pei, “vchain+:\nOptimizing verifiable blockchain boolean range queries,” in 2022\nIEEE 38th International Conference on Data Engineering (ICDE) ,\n2022, pp. 1927–1940.\n[30] Q. Wang, Z. Zhang, Z. Liu, S. Lu, B. Luo, and B. He, “EX-graph:\nA pioneering dataset bridging ethereum and x,” in The Twelfth\nInternational Conference on Learning Representations , 2024.\n[Online]. Available: https://openreview.net/forum?id=juE0rWGCJW\n[31] K. Shamsi, F. Victor, M. Kantarcioglu, and C. Akcora, “Char-\ntalist: Labeled graph datasets for utxo and account-basedblockchains,” OpenReview , 2024, retrieved September 16, 2024\nfrom https://openreview.net/pdf?id=10iA3OowA V3.\n[32] D. Guo, L. Wang, and Y . Li, “Spillover effects of airdrops:\nEvidence from tokenization platforms,” in ICIS 2023 Proceedings ,\nDecember 11 2023. [Online]. Available: https://aisel.aisnet.org/\nicis2023/user_behav/user_behav/7/\n[33] O. Kraaijeveld and J. De Smedt, “The predictive power of public\ntwitter sentiment for forecasting cryptocurrency prices,” Journal of\nInternational Financial Markets, Institutions and Money , vol. 65, p.\n101188, 2020.\n[34] S. Mohapatra, N. Ahmed, and P. Alencar, “Kryptooracle: a real-time\ncryptocurrency price prediction platform using twitter sentiments,”\nin2019 IEEE international conference on big data (Big Data) .\nIEEE, 2019, pp. 5544–5551.\n[35] S. Khan, “Business intelligence aspect for emotions and sentiments\nanalysis,” in 2022 First International Conference on Electrical, Elec-\ntronics, Information and Communication Technologies (ICEEICT) .\nIEEE, 2022, pp. 1–5.\n[36] R. Agarwal, L. Melnick, N. Frosst, X. Zhang, B. Lengerich,\nR. Caruana, and G. E. Hinton, “Neural additive models: Interpretable\nmachine learning with neural nets,” Advances in Neural Information\nProcessing Systems , vol. 34, 2021.\n[37] A. Raudys, V . Len ˇciauskas, and E. Mal ˇcius, “Moving averages for\nfinancial data smoothing,” in Information and Software Technologies ,\nT. Skersys, R. Butleris, and R. Butkiene, Eds. Berlin, Heidelberg:\nSpringer Berlin Heidelberg, 2013, pp. 34–45.\n[38] F. Klinker, “Exponential moving average versus moving exponential\naverage,” Mathematische Semesterberichte , vol. 58, pp. 97–107,\n2011.\n[39] “Exponential moving average (ema).” [Online]. Avail-\nable: https://www.fidelity.com/learning-center/trading-investing/\ntechnical-analysis/technical-indicator-guide/ema\n[40] D. Chen and W. Ye, “How to address monotonicity for model risk\nmanagement?” in Proceedings of the 40th International Conference\non Machine Learning , ser. Proceedings of Machine Learning\nResearch, vol. 202. PMLR, 23–29 Jul 2023, pp. 5282–5295.\n[41] X. Liu, X. Han, N. Zhang, and Q. Liu, “Certified monotonic neural\nnetworks,” Advances in Neural Information Processing Systems ,\nvol. 33, pp. 15 427–15 438, 2020.\n[42] M. Milani Fard, K. Canini, A. Cotter, J. Pfeifer, and M. Gupta,\n“Fast and flexible monotonic functions with ensembles of lattices,”\nAdvances in neural information processing systems , vol. 29, 2016.\n[43] D. Araci, “Finbert: Financial sentiment analysis with pre-trained\nlanguage models,” arXiv preprint arXiv:1908.10063 , 2019.', 'jingfengchen@gmail.com', 'Jingfeng Chen, Wanlin Deng, Dangxing Chen, and Luyao Zhang', '', '../pdf_files/67497f433aa58-FinML-Chain - A Blockchain-Integrated Dataset.pdf', 1561981, 10, 7082, 49700, '2024-11-29 08:45:55', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(9, '2460559462', '6745cf4203d9a', 1, 2, 'Can an increase in productivity cause a decrease in production? Insights from a model economy with AI automation', '2024-11-29 16:49:16.982397', '2024', 'It is widely assumed that increases in economic productivity necessarily lead to economic growth. In this paper, it is shown that this is not always the case. An idealized model of an economy is presented in which a new technology allows capital to be utilized autonomously without labor input. This is motivated by the possibility that advances in artificial intelligence (AI) will give rise to AI agents that act autonomously in the economy. The economic model involves a single profit-maximizing firm which is a monopolist in the product market and a monopsonist in the labor market. The new automation technology causes the firm to replace labor with capital in such a way that its profit increases while total production decreases. The model is not intended to capture the structure of a real economy, but rather to illustrate how basic economic mechanisms can give rise to counterintuitive and undesirable outcomes.', 'Machine Learning,AI,Automation,Economic Production', 'Can an increase in productivity cause a decrease in production?\nInsights from a model economy with AI automation\nExecutive Summary\nOverview: This work investigates an undesirable and counterintuitive economic scenario that\ncould result from AI automation. It is shown that, for a certain economic structure, an increase\nin the productivity of automation technology will decrease total production (GDP). This pro-\nvides a counterexample to the widespread assumption that productivity increases necessarily\nincrease economic production. Although the economic model in this work does not capture the\nfull structure of a real economy, the model illustrates how basic economic mechanisms can give\nrise to unexpected adverse outcomes. I argue that quantitative economic modeling should play\na larger role in analyses of AI risks. Such models also serve as testbeds to explore the effects of\nproposed government policies.\nQuestioning a common assumption: It is widely assumed that productivity increases due\nto AI will increase GDP. This assumption underlies redistributive policy proposals like Univer-\nsal Basic Income (UBI), where it is assumed that redistribution will allow everyone to benefit\nfrom AI. While this assumption is supported by economic models with perfectly competitive\nmarkets, it is likely that a small number of AI companies will dominate the market for automa-\ntion technology, undermining competition. Noncompetitive markets typically lead to adverse\noutcomes, and very little is known about how automation technology affects economies with\nimperfect competition.\nCould AI decrease economic production? This work shows that the answer is yesfor a\ncertain economic structure. This is shown using a model economy with no competition in either\nproduct or labor markets, as illustrated schematically below. The firm chooses labor employ-\nment and production in order to maximize profit. When AI productivity surpasses a critical\nProductivity	of	AI	Automation(increases	with	time)%	Change	in	Production\nFirm\nHouseholdsLabor	MarketProduct	MarketLabor	supplyLabor	demand\nProduct	supplyProduct	demandDrop	in	GDPDeclining	production	with	increasing	productivityDrop	in	production	with	rise	in	productivity\nthreshold, the firm replaces its labor force with AI,\ncausing an increase in its profits but a decrease in\ntotal production, as shown in the figure.\nModels vs. Reality: Most of the literature on the\nmacroeconomics of automation uses models with\nperfectly competitive markets, whereas my model\nassumes zero competition. Reality is somewhere\nin between, and models of more realistic market\nstructures are needed. There are other assumptions\nwidely-used in macroeconomic models that I argue\nare not well suited for modeling AI impacts, includ-\ning inelastic labor supply and representative agents.\nOutlook: AI Safety needs quantitative eco-\nnomic scenario modeling . Most economic re-\nsearch today is empirical, using historical data to\nunderstand the mechanisms that will shape the fu-\nture. Yet, there is no data on the unprecedented\nchanges that AI is likely to bring. This work il-\nlustrates how quantitative models can be used to\nexplore scenarios for which no data exists, filling\nthis gap.\n1Author: Casey O. BarkanarXiv:2411.15718v1  [econ.GN]  24 Nov 2024Can an increase in productivity cause a decrease in production?\nInsights from a model economy with AI automation∗\nCasey O. Barkan†\nWorking Paper. November 22, 2024.\nAbstract\nIt is widely assumed that increases in economic productivity necessarily lead to economic\ngrowth. In this paper, it is shown that this is not always the case. An idealized model of an\neconomy is presented in which a new technology allows capital to be utilized autonomously\nwithout labor input. This is motivated by the possibility that advances in artificial intelligence\n(AI) will give rise to AI agents that act autonomously in the economy. The economic model\ninvolves a single profit-maximizing firm which is a monopolist in the product market and a\nmonopsonist in the labor market. The new automation technology causes the firm to replace\nlabor with capital in such a way that its profit increases while total production decreases. The\nmodel is not intended to capture the structure of a real economy, but rather to illustrate how\nbasic economic mechanisms can give rise to counterintuitive and undesirable outcomes.\n1 Introduction\nRecent advances in artificial intelligence (AI) have inspired a growing public conversation on the\nextent to which AI will automate human labor, and on the economic impacts of automation. Nobel\nLaureate and AI pioneer Geoffrey Hinton has predicted that artificial general intelligence (AGI)\nwill likely be developed by 20441, and a recent survey of AI experts found that a majority expect AI\nto automate all human labor within the next 100 years (Grace et al., 2024). These advances have\nled to a flurry of research modeling the impacts of automation technology on economic growth,\nwages, and inequality (Aghion et al., 2017; Korinek and Stiglitz, 2018; Acemoglu and Restrepo,\n2018; Brynjolfsson and Unger, 2023; Acemoglu, 2024; Korinek and Suh, 2024; Steigum, 2011).\nThese studies include models that extend well-established macroeconomic models to incorporate\nautomation technology. In doing so, they adopt many of the same assumptions used in these\nwell-established models, notably, perfectly competitive markets and constant labor employment\n(equivalently, inelastic labor supply). Yet, AI will likely bring unprecedented changes to the econ-\nomy, so assumptions that have been valid in the past may become invalid in the near future. In\nparticular, AI may lead to a concentration of wealth in the hands of a few companies or individuals,\nwhich could undermine market competition.\nIn this paper, I use a simple model economy to demonstrate an undesirable and counterintuitive\nimpact of automation that could occur if markets lack competition. Within the model, an increase\nin the productivity of automation technology (this productivity is the output produced per unit of\nautomation technology employed) causes a decrease in production (total output, or GDP) when\nthe economy has a certain structure. This result stands in contrast to the findings of prior models\nwith competitive markets, which find the more intuitive result that increased productivity increases\n∗©Casey O. Barkan, 2024. All rights reserved.\n†Department of Physics & Astronomy, University of California, Los Angeles. Email: barkanc@ucla.edu\n1Hinton gave an interview in April 2024 at University College Dublin in which he said “my guess is we’ll get [AI]\nsmarter than us, with a probability of about 0.5, in between 5 and 20 years.” (Hinton, 2024).\n1production. My model involves two markets, a product market and labor market, with a single\nfirm which faces no competition in either market. The firm chooses the amount of human labor\nand capital2to employ in order to maximize profit. The firm has access to two technologies, an old\ntechnology which requires both labor and capital input, and a new automation technology which\nrequires only capital input. I assume that the productivity of the automation technology starts\nfrom zero and increases, and I examine how production, wages, labor employment, and the firm’s\nprofit change as this productivity increases. When the productivity of the automation technology\nsurpasses a threshold, the firm replaces its human labor force with automation technology. This\nreplacement increases the firm’s profit, but substantially decreases the firm’s output. However, if\nthe productivity of automation continues to rise beyond this threshold, total production will grow\nand eventually surpass its original level.\nThe model in this work is too simple to quantitatively describe a real economy, and one must\nask, what is the value of such a simple model? I argue that the value is twofold. First, highly\nsimplified models play a central role in economics, forming the foundations upon which more so-\nphisticated models are built. For example, the Ramsey model of economic growth (Ramsey, 1928),\nwhich involves only two markets, a representative firm, and a representative agent, serves as the\nfoundation for a large portion of modern macroeconomic models (Ljungqvist and Sargent, 2018).\nTypically, the key insights from the simplified models generalize to the more sophisticated mod-\nels. With regard to the model presented here, extensions of this model to more realistic economic\nstructures with imperfectly competitive markets may clarify whether the phenomenon of decreasing\nproduction with increasing productivity could occur in the real economy. Second, this work shows\nacounterexample to a prevailing assumption, namely, that productivity increases necessarily lead\nto production increases. Counterexamples are crucial for motivating a re-examination of assump-\ntions, for refining intuitions and conceptual understandings, and ultimately for guiding improved\nmodels and theories.\nIn AI safety and governance research, threat modeling and scenario modeling are important\ntools for exploring the range of harmful and beneficial impacts that AI may bring. The trajectory\nof AI’s capabilities, dangers, and societal influence are highly uncertain, so models that explore a\nwide range of scenarios are needed. I would argue there is a similar need for economic scenario\nmodeling. AI’s future impacts on the economy are highly uncertain, but the impacts are likely\nto be profound. Hence, there is a need for economic models that deviate from standard modeling\nparadigms and that explore less common economic structures and counterintuitive mechanisms.\nThe model in this work is meant to be a first step toward such economic scenario modeling.\n2 Model\nConsider a model economy with two markets: a product market and a labor market, as illustrated\nschematically in Fig. 1A. Labor is assumed to be undifferentiated and all laborers receive the same\nwage. There is a single firm which is a monopolist in the product market and a monopsonist in\nthe labor market3. The firm’s ability to produce is described by a production function (defined\nbelow), which specifies the amount of product that the firm can produce as a function of labor and\ncapital input. The production function depends upon the scientific development of AI automation\ntechnology; specifically, a parameter Aautospecifies the productivity of automation technology,\nwhich is assumed to increase with time as scientific progress in AI is made4. The households\nthat supply labor choose their consumption and labor supply by maximizing a utility function,\nand all households are assumed to have the same utility function. Lastly, it is assumed that the\n2Capital refers to the physical machinery used in production, which includes compute resources used by AI.\n3This means that they are the only firm operating in either market, facing no competitors.\n4To be concrete, Aautocaptures advances in AI architectures as well as advances in performance (i.e. improved\nmodel weights) for given architectures.\n2Figure 1: Model structure, labor supply, and profit maximization (A) Schematic of the\nstructure of the economy. (B) Labor supply with c0>0 (blue), and an inelastic labor supply\n(c0= 0) for comparison (dashed grey). (C) Firm’s profit function Π( L) for increasing values of\nthe productivity Aauto. As Aautoincreases beyond a value of 1, the profit-maximizing labor L∗\n(indicated by dots) jumps from L∗≈20 down to 0. Model parameters used to generate plots are\nlisted in section 2.3.\nhouseholds that supply labor do not own capital or equity in the firm, so that wages are their only\nsource of income. The general equilibrium is computed as a function of Aautoto determine how\nthe economy’s production (GDP), labor employment, and wages, depend upon the productivity of\nautomation technology.\nThe total capital stock in the economy is assumed to be fixed at a constant value ¯K. This\nis a valid approximation when technological change occurs rapidly relative to the rate of capital\naccumulation. Whether this approximation is valid for AI automation technology remains to be\nseen, though the model can be extended to include capital accumulation. In fact, dynamic growth\nmodels of economies with competitive markets and automation technology have been developed\npreviously, and they predict that automation produces unbounded endogenous growth (Steigum,\n2011; Aghion et al., 2017; Prettner and Bloom, 2020). It is an interesting open question how this\nprediction would change for an economy with noncompetitive markets.\n2.1 The firm’s production decision\nThe firm chooses its production f, labor employment L, capital employment K, and wage wso\nas to maximize profit. The firm has access to two technologies for production, the old technology\nand the automation technology, and the firm chooses how to allocate capital between the two\ntechnologies to maximize profit. Each technology has a production function of the Cobb-Douglas\nform (Barro and Sala-i Martin, 2004). The old technology has production function fold(K, L) =\nAoldKαL1−αwith 0 < α < 1. The automation technology has production function fauto(K) =\nAautoK, which is a Cobb-Douglas function with exponent equal to 1. These production functions\nhave the following key properties: with the old technology, capital requires labor input to be\nproductively utilized, whereas, with the automation technology, capital is productive without labor\ninput. Aautorepresents the productivity of the automation technology, and I assume that Aauto= 0\ninitially, then study how the economy changes as Aautoincreases.\nThe firm’s total production function, f(K, L), is determined by allocating capital between the\ntwo technologies so as to maximize output. Mathematically,\nf(K, L) = max\nKold∈[0,K]\0\nfold(Kold, L) +fauto(K−Kold)\n(1)\nTheKoldthat solves this maximization problem can be found by differentiating the expression\nbeing maximized with respect to Kold, setting the result to zero, and solving for Kold. This yields\n3the optimal capital allocation K∗\nold(K, L), given by\nK∗\nold(K, L) = min(\nLα Aold\nAauto 1\n(1−α)\n, K)\n(2)\nThe minimum operation in Eq. 2 ensures that the constraint Kold∈[0, K] is satisfied. The\nproduction function can now be rewritten as\nf(K, L) =AoldK∗\nold(K, L)αL1−α+Aauto(K−K∗\nold(K, L)) (3)\nTo express the firm’s profit as a function of KandL, we use the price of product as the\nnumeraire5(meaning units are set so the price of product equals 1), so profit Π is given by\nΠ(K, L) =f(K, L)−w(L)L−r(K)K (4)\nwhere w(L) is the wage that the firm must offer to procure labor quantity Lin the labor market\n(w(L) is the labor supply curve ), and r(K) is the rental rate of capital. The firm chooses, f,L,\nandKin order to maximize Π( K, L).\nLastly, I assume that it is profit maximizing for the firm to utilize the entire capital stock6.\nThis is valid if the maximum rental rate ¯ r≡r(¯K) is lower than the marginal product of capital\nat the profit-maximizing point. This simplifies the profit function to a function of only L,\nΠ(L) =f(¯K, L)−w(L)L−¯r¯K (5)\nand the firm chooses Lto solve max LΠ(L). To solve this profit maximization problem, we need to\nknow the labor supply w(L). In the section below, the households’ utility maximization problem\nis solved to derive the supply curve,\nw(L) =wmin\n1−L/(γLmax)(6)\nwhere γis a parameter in the utility function, as described below. This labor supply curve is\nshown in Fig. 1B.\nThe problem max LΠ(L) can now be solved to obtain the equilibrium labor L∗, production\nf∗=F(¯K, L∗), and profit Π∗= Π( L∗). In equilibrium, the firm allocates an amount of capital\nK∗\nold(¯K, L∗) to the old technology, and the remainder of the capital stock is allocated to the\nautomation technology.\nFig. 1C shows the profit function Π( L) and the profit maximizing point (indicated by a dot)\nfor four values of AAuto. As shown, the profit maximizing labor L∗remains fixed until AAuto>1,\nthen it quickly drops and reaches zero when AAuto≳1.2, indicating that the labor force is replaced\nby AI automation.\n2.2 Households’ labor and consumption decision\nNearly all prior studies on the impacts of automation assume inelastic labor supply, which implies\nconstant labor employment7. Yet, displacement of labor is one of the primary concerns regarding\n5Thenumeraire in an economic model is the unit according to which all prices are measured, and it is standard\nto use the price of the representative product as the numeraire (Barro and Sala-i Martin, 2004). This means that,\nfor example, if wage w= 2, then two units of product can be purchased with the wage earnings from one unit of\nlabor.\n6This is a very minor assumption for the following reason: The only case in which this assumption would fail\nto hold is if the operating cost of capital is so high that some capital is left unused. We would not expect this to\noccur, because such capital would not have been manufactured if it were too expensive to be profitably used.\n7I am aware of only one exception to this: (Prettner and Strulik, 2017)\n4the economic impacts of AI. In this model, I do not assume inelastic labor supply; rather, I\nmodel labor supply by assuming that households select their labor and consumption quantities to\nmaximize a utility function U(c, ℓ), where c≡wLis consumption (equal to labor income) and\nℓ≡Lmax−Lis leisure, where Lis the labor supplied by households and Lmaxis the maximum\namount of labor that households can provide. Assume that U(c, ℓ) takes the form\nU(c, ℓ) = (c+c0)γℓ1−γ(7)\nwhere γis a parameter that specifies households’ preference for consumption over leisure, and\n0< γ < 1. The parameter c0captures an essential aspect of the labor supply, namely, that there\nexists a minimal wage wminbelow which households do not supply labor. wminis not a legally-\nimposed minimum wage, rather, it reflects the fact that if wages are too low, households will choose\nnot offer labor or will be incapable of offering labor due to the wage not providing subsistence-level\nconsumption. If c0= 0 then this utility function produces an inelastic labor supply curve. However,\nifc0>0 orc0<0, then the resulting labor supply is not perfectly inelastic, and there will be a\nminimal wage wmin, as derived below. There are multiple ways to interpret c0. It could be merely\nan intrinsic parameter that characterizes households preferences. Or, if c0>0, it could correspond\nto an exogenous source of consumption, perhaps due to a welfare policy like universal basic income.\nc0<0 could describe a scenario where households require a minimal consumption level to subsist,\nso marginal utility approaches infinity in the limit that cdrops to c0, and households cease to\nprovide labor for c≤c0because starvation occurs.\nWe will solve the households’ utility maximization problem for an arbitrary c0̸= 0. The\nmaximization problem is\nmax\nc,ℓU(c, ℓ) subject to c=w(Lmax−ℓ)\nand c≥0, c > −c0, ℓ > 0(8)\nSolving this using a Lagrange multiplier and setting ℓ=Lmax−Lyields the labor supply w(L),\nwhich is the wage that induces households to offer Lunits of labor. The result is\nw(L) =(1−γ)c0\nγLmax−L(9)\nThis can be written in a more intuitive form in terms of wmin, as follows:\n•Forc0>0,wmin=1−γ\nγc0\nLmaxand\nw(L) =wmin\n1−L/(γLmax)(10)\nThis labor supply curve is shown in Fig. 1B.\n•Forc0<0,wmin=−c0/Lmaxand\nw(L) =1−γ\nγwmin\n1−L/(γLmax)(11)\nThis labor supply curve is downward sloping forw > w min. For w≤wmin, the household\ncannot meet the subsistence level of consumption c0; in other words, starvation occurs,\nso labor supplied drops to 0. Despite the grim interpretation of this scenario, the model’s\npredictions of production, labor employment, profit, and capital allocation are nearly identical\nto the predictions for c0>0.\nOne might wonder why we have not computed a demand curve for the product. In fact, the\n5Figure 2: Equilibrium quantities versus the productivity of automation technology\nAauto.(A) Production ( f∗) vs. Aauto. (B) Percent capital allocation vs. Aauto. Blue and red\ncurves show, respectively, percent of capital allocated to the old and automation technologies. (C)\nFirm’s profit (Π∗) vs. Aauto. (D) Labor employment ( L∗) vs. Aauto.\nproduct demand is implicitly defined by Eq. 9 and by our choice to use the product price as the\nnumeraire. We could solve the problem differently, by setting the wage as the numeraire, in which\ncase solving Eq. 8 would yield a product demand curve instead of a labor supply curve.\n2.3 Computing the equilibrium\nDue to the monopolist-monopsonist structure of the economy, the equilibrium is determined by the\nfirm’s profit maximization problem, i.e. by maximizing Eq. 5. The labor market clearing condition\nisw=w(L) and product market clearing condition is f=wL+rK−Π, and both of these\nconditions are satisfied by maximizing Eq. 5. To generate Figures 1 and 2, I used the following\nparameters: α= 0.5,γ= 0.5,wmin= 2, ¯K= 50, and Lmax= 500. Aoldis set so that the marginal\nproduct of capital equals 1 when Aauto= 0, which yields Aold≈3.01. The maximization of Eq. 5\nis done numerically and code is provided8.\n3 Results\nSuppose that the productivity of automation technology, Aauto, equals 0 initially, and Aautoin-\ncreases as automation technology develops. When Aautois low, it is most profitable for the firm\nto only utilize the old technology. But, once Aautosurpasses the marginal productivity of capital\nof the old technology, the firm begins to reallocate capital from the old technology to the new\nautomation technology9. This transition is illustrated in Fig. 2, where the transition occurs at\nAauto= 1.\nFig. 2 panels A, B, C, and D show, respectively, how production, capital allocation, profit, and\nlabor employment, change as Aautoincreases. As capital is reallocated from the old technology to\nthe new, a reduction in labor employment causes a decrease in production fbut a larger decrease\nin labor costs wL. Because profit Π = f−wL−rK, it is profitable for the firm to decrease fif,\nin doing so, it decreases wLby a greater amount. This is exactly what the firm does: it decreases\nits labor employment to zero, decreasing production while drastically decreasing costs, leading to\nan increase in profit despite less total product being produced in the economy.\n8Python code is available at https://github.com/cbarkan1/socioeconomic-impacts-of-AI\n9The initial marginal productivity of capital of the old technology is MPk0≡∂Kfold(¯K, L∗)|Aauto=0, and model\nparameters are chosen so that MPk0= 1. Hence, once Aautosurpasses 1, the transition begins, as shown in Fig. 2.\n6The abruptness of this transition is concerning from a policy perspective. As AI automation\ntechnology develops, the model predicts no change in the economy until a massive and abrupt\ntransition occurs. In other words, AI technology can become quite advanced with no societal\nimpact, until the technology reaches a critical level, at which point a profound restructuring of the\neconomy occurs.\nAfter the transition to the automation technology occurs, production begins to rise with Aauto,\neventually surpassing its pre-transition level. If Aautocontinues to grow to be arbitrarily large,\nproduction fwill become arbitrarily large as well (in fact fandAautoare linearly related after the\ntransition). Although all labor has been displaced in this post-transition scenario, a redistributive\npolicy like universal basic income would let everyone benefit from the transition once Aautobecomes\nsufficiently large. However, even if the drop in production is transient and a redistributive policy\nis enacted, the transient drop could have severe and lasting consequences (for instance, people\nmay starve when labor is displaced). Moreover, if a large drop in production were to occur, it\nwould likely induce a financial crisis which could hinder the technological developments that lead\nto continued growth of Aauto. In this case, the economy may become stuck in the regime of reduced\nproduction.\nWith the model parameters used in Fig. 2, an approximately 40% drop in production occurs.\nThis is substantially larger than the drop in GDP during the Great Depression, which, in the\nUnited States, was 30%. However, the magnitude of the drop depends on the model parameters,\nand there are certain parameter values for which no drop in production occurs. Ideally, one could\nestimate model parameters from data, but the model in this work is too simplistic to be fit to\nreal-world data.\n4 Comparison with other models\nThe model in this work has several differences from recently published macroeconomic models that\nincorporate automation. Some of these differences give this model a unique perspective, but others\nare limitations that can be improved upon in future work.\n•Competition. The lack of competitive markets in this model is the key feature that makes it\nunique from other macroeconomic models of automation. There is only one other published\nmodel that studies automation in imperfectly competitive markets (Acemoglu and Restrepo,\n2024). Their model involves labor markets where certain workers are paid above opportu-\nnity cost. The implications of their model are interesting but completely distinct from the\nimplications of the model in this work.\n•Investment and Capital Accumulation. The accumulation of capital via investment\nis a central feature of models of economic growth. Capital accumulation is omitted from\nthe model in this work for simplicity, but the model can be extended to include capital\naccumulation in a straightforward way. When capital accumulation of automation technology\noccurs, economies can achieve unbounded growth (Steigum, 2011; Prettner and Strulik, 2017;\nAghion et al., 2017).\n•Labor Supply. The model in this work involves an elastic labor supply curve, and the\nlabor supply captures the fact that workers will not supply labor when the wage is below a\nminimal value. This is essential for modeling labor displacement. This contrasts from nearly\nall other macroeconomic models of automation, where constant labor employment (inelastic\nlabor supply) is assumed. I am aware of one other work that incorporates elastic labor supply\nto model labor displacement due to automation (Prettner and Strulik, 2017).\n7•Approach to modeling automation technology. There are multiple ways in which\nautomation can be incorporated into macroeconomic models. For the model in this work,\nI assume that there is an existing capital stock which can be repurposed for automation,\nand the productivity of capital utilized for automation is described by a parameter Aauto\nwhich increases with time. To explicitly relate this to real AI, capital would refer to compute\nresources and Aautowould include trained model weights which improve as better AI models\nare trained. Of course, compute resources are not the only form of capital in the economy, so\nthis approach is an oversimplification. A different approach, taken in (Prettner and Bloom,\n2020), is to assume automation capital is an entirely distinct form of capital, and existing\ncapital cannot be repurposed for automation. In this approach, the automation capital stock\nbegins at zero and accumulates over time via savings. This approach is also an oversimpli-\nfication, because in the real world, new AI models do not require new compute resources,\nrather new AI models are run on existing hardware. An improved model could take the best\nof both of these approaches, by treating compute resources as its own category of capital\nwhich must accumulate (as in the model in (Prettner and Strulik, 2017)) and which can be\nreallocated between AI models with time varying productivities (as in my model).\nThere is a more fine-grained approach to modeling automation used in (Acemoglu and Re-\nstrepo, 2018; Acemoglu, 2024; Korinek and Suh, 2024). In these works, the production\nfunction is expressed in terms of a continuum of tasks, and tasks are completed either by\nhuman labor or by capital. This approach allows the model to capture the fact that certain\ntasks are easier to automate than others, yet it also does not differentiate between different\nforms of capital.\n5 Discussion\nAn essential question is, who benefits and who is harmed by the transition to automation in this\nmodel? The owners of the firm and the owners of capital benefit, as their profits increase through\nthe transition to automation despite declining production. Laborers, whose employment drops\nto zero during the transition, are harmed. In the absence of redistributive policy, the displaced\nlaborers must either subsist through non-market activities or starve. Redistributive policies like\nuniversal basic income (UBI) are widely proposed as a means to support displaced laborers. Yet,\nif AI automation leads to a decrease in GDP, redistributive policies cannot remedy the fact that\nthere is less total wealth to be distributed.\nModels like the one in this work provide a setting in which to explore the effects of government\npolicies. As an example, a redistributive policy coupled with a tax policy could be incorporated\ninto the model in the following way. Consider a policy in which the firm is obligated to make direct\nwelfare payments to unemployed workers; this is not a fixed tax rate, but a dynamic tax that varies\nas unemployment varies. With such a policy, the firm is disincentivized from replacing labor with\nautomation. Incorporating such a policy into the model is left for future work, but I hypothesize\nthat the firm will not replace its human labor force with automation until the productivity of\nautomation is sufficiently high that no drop in production occurs when the transition is made. In\ngeneral, policies can be incorporated into the mathematical framework of economic models, so that\nthe models can make predictions about the policies’ effects.\nExtensions of the model to more realistic contexts are needed to make predictions about the\nreal economy. Some features to include in subsequent models are:\n•Imperfectly competitive markets, which describe a middle-ground between perfect competi-\ntion and zero competition.\n•Differentiated capital (i.e. different categories of capital). In particular, compute resources\n8should be treated as distinct from other forms of capital. Advances in AI technology would\ncorrespond to an increase in the productivity of compute, but may not affect the productiv-\nities of other forms of capital.\n•Capital accumulation and dynamic growth, describing the accumulation of compute resources\nthrough time.\n•Heterogeneity among agents. In real economies, people differ in their capital ownership\nand labor skillset, and these differences can be described with heterogeneous agent models\n(Guvenen, 2011). Heterogeneous agent models also allow for modeling of financial markets\nin which different agents have different investment behaviors. In a world with diminishing\nlabor income, returns on financial investments may become a larger source of income for a\ngrowing portion of the population, so such models may be especially relevant. Heterogeneous\nagent models can also describe the dynamics of the distribution of wealth in the economy,\nwhich will likely become increasingly concentrated as AI develops.\nStepping back to look at economic research broadly, most research today uses empirical data\nto investigate economic mechanisms and to forecast the future. This empirical data reflects the\nstructure of our current society, yet its relevance for a future reshaped by AI is limited. As an\nalternative, theoretical models provide a way to explore scenarios for which no empirical data\nexists. For this reason, economic models incorporating AI automation are essential.\nReferences\nDaron Acemoglu. The simple macroeconomics of ai. Technical report, National Bureau of Economic\nResearch, 2024.\nDaron Acemoglu and Pascual Restrepo. The race between man and machine: Implications of\ntechnology for growth, factor shares, and employment. American economic review , 108(6):1488–\n1542, 2018.\nDaron Acemoglu and Pascual Restrepo. Automation and rent dissipation: Implications for wages,\ninequality, and productivity. Technical report, National Bureau of Economic Research, 2024.\nPhilippe Aghion, Benjamin F Jones, and Charles I Jones. Artificial intelligence and economic\ngrowth , volume 23928. National Bureau of Economic Research Cambridge, MA, 2017.\nRobert Barro and Xavier Sala-i Martin. Economic Growth . The MIT Press, 2nd edition edition,\n2004.\nErik Brynjolfsson and Gabriel Unger. The macroeconomics of artificial intelligence. Finance &\nDevelopment Magazine , 2023.\nKatja Grace, Harlan Stewart, Julia Fabienne Sandk¨ uhler, Stephen Thomas, Ben Weinstein-Raun,\nand Jan Brauner. Thousands of ai authors on the future of ai. arXiv preprint arXiv:2401.02843 ,\n2024.\nFatih Guvenen. Macroeconomics with heterogeneity: A practical guide. Technical report, National\nBureau of Economic Research, 2011.\nGeoffrey Hinton. University college dublin, presentation of the ulysses medal. University Col-\nlege Dublin Department of Computer Science, 2024. Video available at https://youtu.be/\nIIl2DbLvBtE?t=2630 .\n9Anton Korinek and Joseph E Stiglitz. Artificial intelligence and its implications for income dis-\ntribution and unemployment. In The economics of artificial intelligence: An agenda , pages\n349–390. University of Chicago Press, 2018.\nAnton Korinek and Donghyun Suh. Scenarios for the transition to agi. Technical report, National\nBureau of Economic Research, 2024.\nLars Ljungqvist and Thomas J Sargent. Recursive macroeconomic theory . MIT press, 2018.\nKlaus Prettner and David E Bloom. Automation and its macroeconomic consequences: theory,\nevidence, and social impacts . Academic Press, 2020.\nKlaus Prettner and Holger Strulik. The lost race against the machine: automation, education, and\ninequality in an r&d-based growth model. Education, and Inequality in an R&D-Based Growth\nModel (December 1, 2017). cege Discussion Papers , (329), 2017.\nFrank Plumpton Ramsey. A mathematical theory of saving. The economic journal , 38(152):\n543–559, 1928.\nErling Steigum. Robotics and growth. In Economic Growth and Development , volume 11, pages\n543–555. Emerald Group Publishing Limited, 2011.\n10', 'caseybarkan@gmail.com', 'Casey O. Barkan', '', '../pdf_files/6749800ca8d6a-Insights from a model economy with AI automation.pdf', 775232, 11, 5281, 34131, '2024-11-29 08:49:17', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(10, '8231706827', '6745cf4203d9a', 1, 15, 'Expectation Formation in a Simple New Keynesian DSGE Framework: A Comparative Analysis of Behavioral and Rational Expectations in the Indian', '2024-11-29 16:50:16.754529', '2024', 'The Dynamic Stochastic General Equilibrium (DSGE) model has become a cor nerstone of macroeconomic analysis, yet research in emerging economies like India remains limited. This study makes a significant contribution by introducing be havioral expectation formation into a New Keynesian DSGE model of the Indian economy, a novel approach absent in existing literature. While previous studies have exclusively employed rational expectations, this research comparatively exam ines behavioral and rational expectation frameworks. Using the output gap and the inflation rate, we find nuanced differences in model performance: behavioral expectations more effectively capture the constructed output gap characteristics, while rational expectations capture the inflation dynamics better. These findings have critical implications for future macroeconomic modeling and policy design, suggesting context-specific expectation formation strategies.', 'Behavioral Macroeconomics,Indian economy,DSGE models', 'arXiv:2411.17165v1  [econ.GN]  26 Nov 2024Expectation Formation in a Simple New Keynesian\nDSGE Framework: A Comparative Analysis of\nBehavioral and Rational Expectations in the Indian\nContext\nArpan Chakraborty∗\nNovember 27, 2024\nAbstract\nThe Dynamic Stochastic General Equilibrium (DSGE) model ha s become a cor-\nnerstone of macroeconomic analysis, yet research in emergi ng economies like India\nremains limited. This study makes a signiﬁcant contributio n by introducing be-\nhavioral expectation formation into a New Keynesian DSGE mo del of the Indian\neconomy, a novel approach absent in existing literature. Wh ile previous studies\nhave exclusively employed rational expectations, this res earch comparatively exam-\nines behavioral and rational expectation frameworks. Usin g the output gap and\nthe inﬂation rate, we ﬁnd nuanced diﬀerences in model perform ance: behavioral\nexpectations more eﬀectively capture the constructed outpu t gap characteristics,\nwhile rational expectations capture the inﬂation dynamics better. These ﬁndings\nhave critical implications for future macroeconomic model ing and policy design,\nsuggesting context-speciﬁc expectation formation strate gies.\nKeywords: Behavioral Macroeconomics, Indian economy, DSGE models\nJEL Classiﬁcation: E12, E70, E71\n∗Corresponding author. PhD Scholar, Indian Institute of Technolo gy Kharagpur, Department of Hu-\nmanities and Social Sciences, Kharagpur, West Bengal, India, arpa n.ms97@kgpian.iitkgp.ac.in, ORCID\n- 0000-0002-7777-56431 Introduction\nThe Dynamic Stochastic general equilibrium model (DSGE model) is the workhorse\nof modern macroeconomics. However, the DSGE literature has ext ensively focused on\nexplaining business cycles in developed economies, while studies on eme rging economies\n(such as India) remain sparse due to the unique frictions and distor tions these economies\nface. In the Indian context, DSGE research is even more limited. Ea rly contributions in-\nclude Peiris, Saxegaard, and Anand (2010), who estimated a small o pen economy DSGE\nmodel with macro-ﬁnance linkages for India, incorporating a ﬁnanc ial accelerator and\ndual-currency borrowing. Using Bayesian estimation on data from 1 996 to 2008, they ex-\nplored macro-ﬁnance interactions. Gabriel et al. (2011) enhance d the model by including\nthe informal sector and credit-constrained consumers, demons trating improved model ﬁt\nwith these additions.\nSubsequent studies aimed to address speciﬁc objectives. Banerj ee, Basu, and Ghate\n(2020) analyzed the weak aggregate demand channel in India’s mon etary policy transmis-\nsion using a New Keynesian DSGE model, highlighting the informal secto r as a hindrance\nto eﬀective monetary policy transmission. Sarkar (2020, 2022) ex plored the interplay\nbetween the stock market and economic growth, as well as the eco nomic impacts of the\nCOVID-19 pandemic, incorporating migration disruptions, supply sh ocks, and demand\nconstraints. His results underscored the importance of monetar y transfers in mitigating\nunemployment and boosting output. Shah and Garg (2023) evaluat ed post-pandemic\npolicy responses, ﬁnding expansionary monetary policy eﬀective on both demand and\nsupply sides, whereas ﬁscal policy impacts were demand-centric. S harma and Behera\n(2022) demonstrated the superiority of DSGE models over traditio nal HP ﬁlters for an-\nalyzing the output gap in post-pandemic recovery. Kumar (2023) a nalyzed the eﬀects of\nproductivity and monetary policy shocks in India, showing that a pos itive productivity\nshock enhances economic activity, while an expansionary monetary policy shock has only\nshort-term eﬀects on output.\nTo the best of the authors’ knowledge, no prior work has implement ed New Keynesian\nDSGE modeling in the Indian context using behavioral expectation fo rmation. All previ-\nous contributions, including the works mentioned above, have exclu sively utilized rational\nexpectations, which assume that agents are omniscient. While this f ramework has been\ninsightful, it may not adequately capture the frictions of developing economies like India.\nThis paper makes a novel contribution by being the ﬁrst to conduct a comparative\nstudy of behavioral and rational expectations in the context of t he Indian economy. Fol-\nlowing the earlier works of literature on behavioral macroeconomics by De Grauwe (2012),\n2De Grauwe and Ji (2019), and De Grauwe and Foresti (2023), this paper incorporates be-\nhavioral expectation formationinasimple NK model toidentify which e xpectation forma-\ntioncanbetterﬁtthedata1. Theanalysisreveals thatbehavioralexpectations capturethe\nconstructed output gap data characteristics more eﬀectively, w hile rational expectations\nbetter explain inﬂation dynamics. This distinction implies that future r esearch focusing\noninﬂationtargetingandmonetarypolicyshouldprioritizerationale xpectations, whereas\nstudies aiming to minimize output volatility should adopt behavioral exp ectations.\nThe rest of the paper is organized as follows: Section 2 describes th e data, Section\n3 introduces the simple NK model, Section 4 depicts the results, and ﬁ nally, Section 5\nconcludes.\n2 Data\nThe primary challenge faced by this paper lies in data collection, partic ularly for the\noutput gap of the Indian economy. Unlike developed economies, rea l output gap data\nfor India is not directly available and is typically estimated using various techniques.\nHowever, this paper adopts a simpliﬁed approach to address this limit ation. Quarterly\nreal GDP data for the Indian economy was sourced from FRED2. Using this dataset3, the\noutput gap was approximated by calculating ln( Yt/¯Y), where ¯Yrepresents the average\nrealGDPovertheentiretimespan. Whilethisconstructedmeasure doesnotrepresent the\ntrue output gap—since it relies on the average real GDP rather tha n potential GDP—it\nprovides a straightforward perspective on the output gap’s dyna mics.\nFor inﬂation, the dataset was obtained from the Reserve Bank of I ndia (RBI) and cov-\ners the period from January 2014 to April 2024. Quarterly observ ations of the combined\ninﬂation rate for the Indian economy were used to align with the analy sis.\nNote that the moments of the output gap data are compared with t he simulated\ndata spanning the 1000th to 1077th observations of the simulated output gap. Similarly,\nthe inﬂation rate is compared against the simulated data from the 10 00th to 1041th\nobservations, corresponding to the 42 quarters of available inﬂat ion rate data.\n1Note that, this paper uses the behavioral expectation as it can ma tch the higher order moments of\nthe output gap and the inﬂation rate of the US economy.\n2https://fred.stlouisfed.org/series/NGDPRNSAXDCINQ\n3The output gap data ranges from 1st quarter 2004 to the 3rd qua rter 2023.\n33 The Model\nAs described in the introduction, this paper employs the behavioral New Keynesian\n(NK) macroeconomic framework developed by De Grauwe and Ji (20 19) in the context\nof the Indian economy. The Aggregate Demand (AD) equation is as f ollows:\nyt=/tildewideEt(yt+1)−1\nσ(it−/tildewideEt(πt+1))+εt;t= 1,2,3,... (1)\nwhere,ytdenotes the output gap, itis the short-term nominal interest rate, and\nεt=ρεεt−1+ǫε,t (2)\nwhereǫε,t∼N(0,0.5) follows a normal distribution with mean zero and variance 0.5, and\nρεrepresents the autoregressive parameter of the AD shock (See ; Kumar (2023)). The\nexpectations in this model are non-rational.\nThe Phillips curve/AS equation, derived under monopolistic competitio n and Calvo\npricing (Calvo, 1983), is expressed as:\nπt=β/tildewideEt(πt+1)+κyt+ηt (3)\nwhere, 0 ≤κ≤1 measures the sensitivity of inﬂation to the output gap, βmeasures the\ndiscount rate, and πtis the inﬂation rate. Also, similar to the AD shock, I introduce,\nηt=ρηηt−1+ǫη,t (4)\nwhereǫη,t∼N(0,0.5) follows a normal distribution with mean zero and variance 0.5, and\nρηrepresents the autoregressive parameter of the AS shock. Follo wing De Grauwe and Ji\n(2020), the parameter κcan be expressed as:\nκ=(1−θ)(1−βθ)\nθσ(1−ς)+χ+ς\n1−ς+ς´e\nwhere 1−θreﬂects the expected price of the Calvo lottery ticket, χdenotes the inverse\nFrisch elasticity of labor supply in the household utility function, ςrepresents the labor\nelasticity inthemonopolistically competitive labor-augmented produc tionfunction, [ Yi\nt=\nAtL1−ς,i\nt], and ´eis the price elasticity of demand, which determines the markup price, M,\nfor monopolistically competitive ﬁrms, [ M=´e\n´e−1] (see Gali, 2008).\nA fraction θof ﬁrms cannot adjust prices in each period. For θ= 1,b2equals zero,\nindicating highly rigid prices, while for θ= 0,b2approaches inﬁnity.\n4The short-term nominal interest rate ( it) is set according to the Taylor rule (Taylor,\n1993; Blattner and Margaritov, 2010):\nit= (1−c3)(c1πt+c2yt)+c3it−1+ut (5)\nwhere the Taylor rule shock, ut, follows the process:\nut=ρuut−1+ǫu,t (6)\nwithǫu,t∼N(0,0.5) being a normally distributed error term with mean zero and\nvariance 0.5, ρurepresenting the autoregressive parameter of the shock, and c1>1,\n0< c2<1 are the coeﬃcients governing inﬂation and output gap responses , respectively.\nNote that, the term c3captures interest rate smoothing.\n3.1 Behavioral Expectation Formation\nFollowing De Grauwe and Ji (2019), the behavioral expectations mo del includes fun-\ndamentalist and extrapolator agents. Expectations for a variable (it can be output gap\nor inﬂation rate) xtare given by:\n/tildewideEt(xt+1) =αx\nf,t/tildewideEf\nt(xt+1)+αx\ne,t/tildewideEe\nt(xt+1)\nwherefundamentalistsexpect /tildewideEf\nt(xt+1) =xss,4andextrapolatorsuse /tildewideEe\nt(xt+1) =xt−1.\nThe proportions αx\nf,tandαx\ne,tare determined based on the relative forecast perfor-\nmance, which is evaluated using their mean square forecast errors :\nUf,t=−∞/summationdisplay\nk=0̺k/bracketleftBig\nxt−k−1−/tildewideEf,t−k−2(xt−k−1)/bracketrightBig2\nUe,t=−∞/summationdisplay\nk=0̺k/bracketleftBig\nxt−k−1−/tildewideEe,t−k−2(xt−k−1)/bracketrightBig2\nwhere̺k= (1−ρ)ρk, with 0< ρ <1 as the memory parameter. The proportion of\nfundamentalists is given by:\nαx\nf,t=exp(γUf,t)\nexp(γUf,t)+exp(γUe,t), αx\ne,t= 1−αx\nf,t\nwhereγis the willingness to learn/intensity of choice parameter.\n4which is normalized to be zero.\n53.2 Simulation Parameters\nTable 1 lists the simulation parameters, aligned with the papers descr ibed below:\nTable 1: Simulation Parameters for the Indian Economy\nParameter Description and Source\nκ= 0.065 Output gap coeﬃcient in AS (Calculated using the formula )\nβ= 0.98 Discount factor (Gabriel et al., 2012)\n´e= 7.01 Price elasticity of demand (Gabriel et al., 2012)\nσ= 1.5 CRRA of household consumption (Das and Nath, 2019; Gabriel et al.,\n2012)\nς= 0.7 Share of labor in production function (Banerjee, Basu, and Ghate,\n2020)\nχ= 2.7 Inverse of Frisch elasticity of labor supply (Anand and Pra sad, 2010;\nSharma and Behera, 2022)\nθ= 0.75 Calvo price rigidity (Kumar, 2023)\nc1= 1.2 Interest rate sensitivity of inﬂation (Gabriel et al., 201 2)\nc2= 0.5 Interest rate sensitivity of output (Banerjee, Basu, and G hate, 2020)\nc3= 0.8 Interest rate smoothing parameter (Banerjee, Basu, and Gh ate, 2020)\nγ= 2 Learning intensity (De Grauwe and Ji, 2019)\nρ= 0.5 Memory parameter (De Grauwe and Ji, 2019)\nT= 2000 Simulation length\nρε= 0.95 Autoregressive parameter for AD shock (Kumar, 2023)\nρη= 0.95 Autoregressive parameter for AS shock\nρu= 0.95 Autoregressive parameter for Taylor rule shock (Kumar, 2 023)\nIt is important to note that this study does not have the calibrated values for the\nmemory parameter and the willingness-to-learn parameter speciﬁc to the Indian econ-\nomy. Therefore, this paper uses the parameters given by De Grau we and Ji (2019).\nAdditionally, unlike Kumar (2023), this paper incorporates aggrega te supply (AS) shocks\ninto the analysis.\n4 Results\nFollowing De Grauwe and Ji (2019, 2020), Table 2 shows that the Beh avioral NK\nmodel is more adept at capturing the output gap data of the Indian economy. The\nrational expectations model, which assumes agents are omniscient , fails to account for\nthe complexities in the observed data, particularly in skewness and k urtosis. Hence, we\ncan say,\n6Table 2: Statistical Comparison of various Expectations: Output g ap\nMeasure Behavioral Expectation Rational Expectation Actu al Data\nKurtosis 1.52 2.89 1.91\nSkewness -0.20 0.50 -0.27\nAutocorrelation 0.99 0.92 0.98\n1.Kurtosis : The kurtosis for behavioral expectations (1.52) is closer to the a ctual\ndata (1.91) compared to rational expectations (2.89). This sugge sts that behav-\nioral expectations better capture the actual data’s tail behavio r and distributional\ncharacteristics.\n2.Skewness : Theskewness ofbehavioral expectations(-0.20)alignsmoreclos elywith\nthe actual data (-0.27) than rational expectations (0.50), indica ting that behavioral\nexpectations better represent the asymmetry observed in real- world data.\n3.Autocorrelation : Behavioral expectations (0.99) and rational expectations (0.92 )\nboth closely approximate the autocorrelation of the actual data ( 0.98). However,\nbehavioral expectations demonstrate equal performance in this regard.\nNotethat,boththemodelsaresimulatedusingtheidenticalshocks tructureandnumerical\nmethods5.\nTable 3: Statistical Comparison of various Expectations: Inﬂation Rate\nMeasure Behavioral Expectation Rational Expectation Actu al Data\nKurtosis 2.95 1.74 2.33\nSkewness -1.16 -0.34 0.30\nAutocorrelation 0.99 0.93 0.63\nBased on the statistical evidence in Table 3, the following inferences can be drawn:\n1.Rational expectations outperform behavioral expectation sin approximat-\ning the moments of the actual inﬂation data. This is particularly evide nt in the\nmeasures of skewness and autocorrelation, where rational expe ctations align more\nclosely with the observed data than behavioral expectations6.\n5Following De Grauwe (2012), the Binder and Pesaran (2000) method is employed to generate the\nresults. For further details on the comparison of rational and beh avioral expectations for the US, please\nrefer to the MATLAB code provided by De Grauwe (2012).\n6The analysis compares this data with quarterly observations, as th ese models are typically calibrated\nusing quarterly data. For a similar calibration applied to the US econom y, see De Grauwe and Ji (2019).\n72.Behavioral expectations capture extreme events better. Thehigher kurtosis\nunder behavioralexpectations reﬂects astronger abilitytomode l fattailsorextreme\nﬂuctuations, which may be signiﬁcant in certain contexts with a large r inﬂation rate\ndataset.\nIt is important to note that, unlike the U.S. economy, the actual ou tput gap, inﬂation\nrate, and the simulated output gap and inﬂation rate—obtained by im plementing the\nsimple New Keynesian model under both behavioral and rational exp ectations—exhibit\nnormality at the 99% level of signiﬁcance, as veriﬁed by the Jarque- Bera (JB) test.\n5 Conclusion\nThis study demonstrates that the Behavioral New Keynesian (NK) model performs\nremarkably well in capturing the statistical properties of macroec onomic variables for\nthe Indian economy, aligning with ﬁndings from studies on the U.S. eco nomy (e.g., De\nGrauwe and Ji, 2019, 2020). In particular, the behavioral expect ation framework eﬀec-\ntively replicates the distributional characteristics of the output g ap and inﬂation rate,\nshowing its potential to outperform the Rational Expectations (R E) model in key areas\nsuch as kurtosis and skewness.\nWhile the Rational Expectations model aligns more closely with the obs erved data\nregarding skewness and autocorrelation for inﬂation, the Behavio ral Expectations model’s\nsuperior performance in capturing extreme events (fat tails) high lights its robustness in\ndynamic macroeconomic modeling. These ﬁndings suggest that futu re research should\nprioritize further exploration and reﬁnement of Behavioral Expec tations frameworks for\npolicy modeling, especially in the context of emerging economies like Ind ia.\n5.1 Limitations and Future Directions\nThis analysis is subject to several limitations. First, the absence of actual output\ngap data for the Indian economy necessitated the construction o f a proxy measure us-\ning quarterly real GDP data obtained from FRED. Future research should utilize more\ncomprehensive and accurate output gap data for India to enhanc e the robustness of the\nresults.\nSecond, the limited availability of combined inﬂation rate data for India (42 quarterly\nobservations) constrainstheanalysis. Expanding thedataset to include moreobservations\nwill improve the generalization of the ﬁndings.\n8References\n[1] Anand, R., and Prasad, E. (2010), Optimal price indices for targ et-\ning inﬂation under incomplete markets, IMF Working Papers , 10(200), 1.\nhttps://doi.org/10.5089/9781455205301.001.\n[2] Banerjee, S., Basu, P., and Ghate, C. (2020), A monetary busin ess cycle model for\nIndia,Economic Inquiry , 58(3), 1362–1386. https://doi.org/10.1111/ecin.12855.\n[3] Binder, M., and Pesaran, H. (2000), Solution of ﬁnite-horizon mu ltivariate linear ra-\ntional expectations models and sparse linear systems, Journal of Economic Dynamics\nand Control , 24(3), 325–346. https://doi.org/10.1016/S0165-1889(99)00 008-1.\n[4] Blattner, T. S., and Margaritov, E. (2010), Towards a robust m onetary policy rule for\nthe euro area, SSRN Electronic Journal . https://doi.org/10.2139/ssrn.1617252\n[5] Calvo, G. A. (1983), Staggered prices in a utility-maximizing frame work,Journal of\nMonetary Economics , 12:383–398.\n[6] Das, R., and Nath, S. (2019), Capital misallocation and its implicatio ns for In-\ndia’s potential GDP: Evidence from India KLEMS, Indian Economic Review , 54(2).\nhttps://doi.org/10.1007/s41775-019-00055-4.\n[7] De Grauwe, P. (2012), Lectures on behavioral macroeconomics , Princeton Univer-\nsity Press. https://press.princeton.edu/books/hardcover/97 80691147390/lectures-on-\nbehavioral-macroeconomics\n[8] De Grauwe, P., and Ji, Y. (2019), Behavioural Macroeconomics: Theory and Policy ,\nOxford University Press, UK.\n[9] De Grauwe, P., and Ji, Y. (2020), Structural reforms, animal\nspirits, and monetary policies, European Economic Review , 124,\nhttps://doi.org/10.1016/j.euroecorev.2020.103395\n[10] DeGrauwe, P., andForesti, P. (2023), Interactions ofﬁscal andmonetary policies un-\nder waves of optimism and pessimism, Journal of Economic Behavior & Organization ,\n212, 466–481. https://doi.org/10.1016/j.jebo.2023.05.024\n[11] Gabriel, V., Levine, P., Pearlman, J., & Yang, B. (2012), An estima ted\ndsge model of the indian economy, In: C. Ghate (Ed.), The Oxford Hand-\n9book of the Indian Economy , 1st ed., 835–890. Oxford University Press.\nhttps://doi.org/10.1093/oxfordhb/9780199734580.013.0029\n[12] Gal´ ı, J. (2008), Monetary policy, inﬂation, and the business cycle: An intro duction\nto the new Keynesian framework , Princeton University Press.\n[13] Kumar, A. (2023), A basic two-sector new keynesian dsge mod el of the indian\neconomy, Theoretical and Practical Research in the Economic Fields , 14(1), 36.\nhttps://doi.org/10.14505/tpref.v14.1(27).04\n[14] Peiris, S., Saxegaard, M., and Anand, R. (2010), An estimated m odel\nwith macroﬁnancial linkages for India, IMF Working Paper , 10(21), 1.\nhttps://doi.org/10.5089/9781451962321.001\n[15] Sarkar, A. (2020), Understanding the short-run relationsh ip between stock mar-\nket and growth in emerging economies, Journal of Quantitative Economics , 18(2).\nhttps://doi.org/10.1007/s40953-019-00183-x.\n[16] Sarkar, A. (2022), Understanding the COVID economic crisis: A short-run general\nequilibrium framework, South Asian Journal of Macroeconomics and Public Finance ,\n11(2), 217–245. https://doi.org/10.1177/22779787221097787 .\n[17] Shah, S. A., and Garg, B. (2023), Testing policy eﬀectiveness d uring\nCOVID-19: An NK-DSGE analysis, Journal of Asian Economics , 84, 101577.\nhttps://doi.org/10.1016/j.asieco.2022.101577.\n[18] Sharma, S., and Behera, H. (2022), A dissection of Indian grow th\nusing a DSGE ﬁlter, Journal of Asian Economics , 80, 101480.\nhttps://doi.org/10.1016/j.asieco.2022.101480.\n[19] Taylor, J. B. (1993), Discretion versus policy rules in practice, Carnegie-Rochester\nConference Series on Public Policy , 39, 195–214. https://doi.org/10.1016/0167-\n2231(93)90009-L\n10', 'arpanchakraborty@gmail.com', 'Arpan Chakraborty', '', '../pdf_files/6749804886e97-Expectation Formation in a Simple New Keynesian.pdf', 120180, 10, 2840, 20079, '2024-11-29 08:50:16', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(11, '3147117426', '6745cf4203d9a', 11, 18, 'Causal Inference in Finance: An Expertise-Driven Model for Instrument Variables Identification and Interpretation', '2024-11-29 16:53:23.924143', '2024', '—Instrumental Variable (IV) provides a source of treatment randomization that is conditionally independent of the outcomes, responding to the challenges of counterfactual and confounding biases. In finance, IV construction typically relies on pre-designed synthetic IVs, with effectiveness measured by specific algorithms. This classic paradigm cannot be generalized to address broader issues that require more and specific IVs. Therefore, we propose an expertise-driven model (ETE-FinCa) to optimize the source of expertise, instantiate IVs by the expertise concept, and interpret the cause-effect relationship by integrating concept with real economic data. The results show that the feature selection based on causal knowledge graphs improves the classification performance than others, with up to a 11.7% increase in accuracy and a 23.0% increase in F1 score. Furthermore, the high-quality IVs we defined can identify causal relationships between the treatment and outcome variables in the Two-Stage Least Squares Regression model with statistical significance.', 'Finance,Expertise-Driven,Algorithms', 'Causal Inference in Finance: An Expertise-Driven\nModel for Instrument Variables Identification and\nInterpretation\n1stYing Chen\nTokyo Institute of\nTechnology\nTokyo, Japan\nchen.y.cc3c@m.isct.ac.jp2ndZiwei Xu\nNational Institute of Advanced\nIndustrial Science and Technology\nTokyo, Japan\nxu.ziwei@aist.go.jp3rdKotaro Inoue\nTokyo Institute of\nTechnology\nTokyo, Japan\ninoue.k.aq@m.titech.ac.jp4thRyutaro Ichise\nTokyo Institute of\nTechnology\nTokyo, Japan\nichise@iee.e.titech.ac.jp\nAbstract —Instrumental Variable (IV) provides a source of\ntreatment randomization that is conditionally independent of the\noutcomes, responding to the challenges of counterfactual and\nconfounding biases. In finance, IV construction typically relies\non pre-designed synthetic IVs, with effectiveness measured by\nspecific algorithms. This classic paradigm cannot be generalized\nto address broader issues that require more and specific IVs.\nTherefore, we propose an expertise-driven model (ETE-FinCa)\nto optimize the source of expertise, instantiate IVs by the\nexpertise concept, and interpret the cause-effect relationship by\nintegrating concept with real economic data. The results show\nthat the feature selection based on causal knowledge graphs\nimproves the classification performance than others, with up\nto a 11.7% increase in accuracy and a 23.0% increase in F1-\nscore. Furthermore, the high-quality IVs we defined can identify\ncausal relationships between the treatment and outcome variables\nin the Two-Stage Least Squares Regression model with statistical\nsignificance.\nIndex Terms —Instrument Variables; Causal Inference; Causal\nKnowledge Graph; Finance; Interpretability\nI. I NTRODUCTION\nThe instrumental variable (IV) approach provides a source\nof treatment randomization that is conditionally independent\nof the outcome to estimate the counterfactual effect using\nobservational data. In Figure 1, we take the airline ticket de-\nmand scenario to explain the relationships among instrumental\nvariable (Z),treatment (A),outcome (B) and other observed/\nunobserved variables (µn). Typically, lower ticket prices lead\nto higher sales, yet high sales can also occur during holidays\n(µ1) despite high ticket prices. The arrow from A to B\nindicates that price causes sales, with observed holiday ( µ1)\naffecting both. Other unobserved variables like conferences\n(µ2) also impact A and B, adding complexity to their direct\ncausality. However, by including an IV (Z) that solely impacts\nA but not B directly, we can clarify the causality between\nA and B. This aligns with the principle that fuel costs (Z)\naffect ticket prices (A), which then influences sales (B). This\nclear causal pathway, enabled by including the IV , excludes\nthe possibility of other variables directly affecting outcomes,\nproviding valuable insights for financial experts conducting\nquantitative research.\nFig. 1. The causal graphs with instrument variable (Z) specification.\nIn finance, IVs construction typically relies on pre-designed\nsynthetic IVs, with effectiveness measured by specific al-\ngorithms. This classic paradigm cannot be generalized to\naddress broader issues that require more and specific IVs. For\ninstance, in the traditional Two-Stage Least Squares (2SLS)\nmethod, which is widely accepted in empirical economic\nresearch, their coefficients can be simply interpreted under\nstrict theoretical assumptions as follows: ceteris paribus, a\none-unit increase in treatment (Ai) will literally cause a βi\nchange in the outcome (Bi). In practical applications, the\nstrict assumptions of correct specification and exogeneity can\nonly be relaxed with the knowledge of economists. Therefore,\nwe propose to identify IVs directly from textual expertise,\ninstantiate IVs by their expertise concept, and interpret the\ncause-effect relationship by the significant IVs calculated from\nreal economic data with 2SLS regression model. We abbreviate\nour method, ExperTise-driven mod El for Financial Causal\nvariables identification and interpretation asETE-FinCa ,\nwhich will be used throughout the following sections.\nFurthermore, ETE-FinCa has shown significant effective-\nness in two key tasks:\n(1) Which dataset possesses adequate expertise for IV\nidentification tasks? We introduce various corpus sources to\nretrieve important features. Using the predefined IV classifica-\ntion task, we assess the classification models on these features\nto identify the corpus with optimal expertise. The results showarXiv:2411.17542v1  [econ.GN]  26 Nov 2024that the feature selection based on our approach improves the\nclassification performance than others, with up to a 11.7%\nincrease in accuracy and a 23.0% increase in F1-score.\n(2) How are IVs interpreted for causal prediction? The\ncausal relationships that appear in all subgraphs are considered\ncommon sense. We design a task to focus on those causal\nvariables that are only mentioned in certain graphs due to\ndivergent standpoint. These insufficiently studied standpoint-\nbased causality may face more complex confounding biases.\nWe develop an interpretation module to curate 19,678 causal\nstructures that are consistent with the IV pattern from the\ncausal knowledge graph, identify high-quality IVs that exclu-\nsively exist in certain subgraphs and interpret the directional\ncausal relationships extracted from different standpoints with\nreal economic data through 2SLS Regression. We generalize\nthe standpoint-based causality and demonstrate the research\npotential of these specific expertise in financial domain.\nII. R ELATED WORK\nA. Causal Inference and Instrument Variables (IV)\nRecent work aim to understand the impact of confounders\nthrough observational data without performing randomized\nexperiments. This framework includes the potential outcome\nframework [2] and the structural causal model (SCM) [4].\nThe former is also known as the Rubin Causal Model, which\naims to estimate potential outcomes and subsequently calculate\nthe treatment effect. Meanwhile, SCM approach describes the\ncausal mechanisms of a system where variables and their\ncausal relationships are modeled using a set of simultaneous\nstructural equations or causal graphs. Confounders lead to\nincorrect causal relationships when estimating the Average\nTreatment Effect (ATE) of interventions. Thus, mitigating\nconfounding bias is critical in causal inference. Prior research\nhas proposed several methods to mitigate selection bias and\nsimulate the true distribution of the target group, such as sam-\nple reweighting [5], stratification [1], matching [11], tree-based\nmethods [15], representation [16], and multitask methods [12].\nAnother effective approach is to train a foundational estimator\nof potential outcomes using observational data and then correct\nfor estimation bias caused by selection bias [17]. Similar to\nETE-FinCa , previous approaches apply intervention effects\nconditioned on confounders and perform weighted averaging\nbased on their distribution [9].\nInstrument variable Zonly influences outcomes Bvia\nvariables A, which allows for the identification of directional\ncausal relationships even in the presence of confounding\nbiases. The classic 2SLS regression requires the researcher\nto have a strong prior understanding, and this method is\nconstrained by computational complexity. Advanced machine\nlearning methods have demonstrated the power of learning\npotential representations of complex feature spaces. Recent\nremarkable works include Deep-IV [6], Kernel-IV [13], and\nAuto-IV [7]. DeepIV trains a network to estimate the condi-\ntional distribution of treatment variable given the instruments\nand covariance, integrating this into a causal inference net-\nwork to estimate causal effects. Kernel-IV relaxes linearityassumptions by modeling IV patterns with nonlinear functions\nin Reproducing Kernel Hilbert Spaces (RKHS). AutoIV gen-\nerates confounder representations from observational data and\ninputs these IV candidates into an adversarial game network\nwith mutual information maximization and minimization con-\nstraints until the IV candidates meet relevance and exclusion\nconditions. The lack of interpretability limits the practical\napplication of these methods.\nB. Interpretable Approaches and Causal Knowledge Graph\nTo address these issues, recent work focus on applying the\ninvariant causal relationships from observable data to establish\nmodels that provide stable and interpretable predictions. These\nmethods typically adhere to the unconfoundedness assumption,\ne.g., propensity score [21], covariate balance [19], back-\ndoor criteria [4], and representation learning [20]. However,\nconfounding bias is inevitable in practical problem settings. It\nis necessary to find a method to comprehensively display the\ninterconnected effect of all potential and observable variables.\nETE-FinCa maps the causal relationships between financial\nconcepts and extracts causal chains that fit the IV pattern,\nenabling researchers or decision-makers to utilize the frame-\nwork to understand the useful instrumental variables and their\nconnections with other observed variables, thereby enhancing\nthe interpretability. Causal relations have been explored in\nmany open source knowledge bases, such as WikiData [3]\nand ConceptNet [14]. Recently, causality-dedicated knowl-\nedge graphs have been generated by many works, including\nCausalNet [22], Cause Effect Graph [23], CauseNet [18], and\nATOMIC [8]. The entire logic of thinking, including potential\nconfounding factors, treatment, and outcomes, is crucial in\ncausal inference. However, the causal relationships within\nthese graphs lack interconnections between tuples, making it\ndifficult to identify IV representations. FinCaKG [10] provides\na causal knowledge graph based on cause-effect textual spans.\nThe construction of this graph allows ETE-FinCa to use an\nend-to-end visualization framework for instrumental variable\nmining. Specifically, this method presents causal relationships\nthrough intuitive logical chains, simplifying the identification\nof instrumental variables, significantly enhancing the inter-\npretability, and making the application of IV extracted from\nETE-FinCa in economic empirical research possible.\nIII. M ETHODOLOGY\nIn this section, we outline the procedures from expertise\nselection to causal variables identification and interpretation\nof the ETE-FinCa model. As shown in Figure 2, our method\nconsists of three modules: Preparation Module, Evaluation\nModule, and Interpretation Module.\nA. Preparation Module\nThe corpus and labeled training sets are placed in the\npreparation module. we process financial vocabulary obtained\nfrom Investopedia1that provides expertise related to finance,\n1https://www.investopedia.com/financial-term-dictionary-4769738, access\ndate:2024/03/28Fig. 2. The workflow of ETE-FinCa model for causal vairables identification and interpretation.\nAlgorithm 1: IV identification based on DFS\nInput: Graph G, all NPs unique (V),\ntuple nodes sameid\nOutput: Set of (Z, A, B) triples K\nDefine R(x, y): the distance between x and y in Graph\nis less than or equal to 3 hops;\nInitialize empty result set K;\nforeach z in V do\nAz={a∈V|R(z, a)};\nforeach a in Azdo\nBtemp ={b∈V|R(a, b)} \\a;\nforeach b in Btemp do\nC={c∈V|R(b, c)};\nifz∈Cthen\nRemove bfrom Btemp;\nBz={b∈Btemp|¬R(z, b)};\nAdd triple (z, a, b) to result set K;\nreturn K\ninvesting, and economic concepts. Regarding the first corpus,\nnamely the cosine similarity-based corpus Csim(see Picture\n(1) in Figure 2.), which involved computing cosine similarity\nby pipeline of spaCy between each concept in the vocab-\nulary list and ‘shareholder’. The second corpus CFinCaKG\n(see Picture(2) in Figure 2) is based on a financial causal\nknowledge graph. We extract the terms from causal chains\nthat span multiple hops to describe a logical pathway. The\nlabelled annual reports from companies that claim to be\neither “stakeholder-maximizing” or “shareholder-maximizing”\nare compiled into a dataset, split into 80% for the training set\nand 20% for the validation set.B. Evaluation Module\nWe classify two datasets, CsimandCFinCaKG , beginning\nwith feature retrieval. Suppose we have set of documents: D=\n{d1, d2, ..., d n}, for each document dk∈D, we remove the\nsymbols and stopwords and obtain d′\nk. For each document d′\nk\nand each term tifrom CsimorCFinCaKG , we have features:\nxi,k=tf(ti, d′\nk)·weight (wi) (1)\nwhere tf(ti, d′\nk)represents the term frequency of tiin the\ndocument d′\nk,weight (wi)is the cosine similarity in Csim\nand the edge weight of the relationship between two nodes\ninCFinCaKG . Then we get xi,k={x1, x2, ..., x i}the feature\nmatrix for d′\nk. The resulting feature matrix Xhas dimensions\nX∈Rn×m, where nis the number of nodes in each selected\ncorpus and mis the size of the corpus. The term frequency-\nbased feature matrix is considered to be sparse. We also apply\nthe transformer-based embedding method (RoBERTa) to learn\nthe text representation because it handles long text efficiently\nand effectively without information loss. To conserve informa-\ntion as much as possible, we apply a length-weighted average,\nmax pooling, direct concatenation, and a simple attention\nmechanism in the process of document embedding by using\nRoBERTa .\nIn the process of model evaluation, Random Forest and\nXGBoost are both popular choices for classification tasks\nin machine learning due to interpretability and robustness\nto overfitting. All model results are provided in terms of\nAccuracy (%), Precision, Recall, and F1-score for evaluation.\nC. Interpretation Module\nIn the interpretation module, we separate CFinCaKG\nto two subgraphs, “shareholder-oriented standpoint”\n(CSH−FinCaKG ) and “stakeholder-oriented standpoint”TABLE I\nCLASSIFICATION RESULTS\nCorpus selection Feature Style Classifier Model Num. of Feature Accuracy Precision Recall F1-score\nCsimTerm FrequencyRandom Forest 166 0.726 0.707 0.426 0.524\nXGBoost 166 0.680 0.795 0.157 0.263\nDocument Embedding (RoBERTa) Random Forest (max length,1024) 0.713 0.752 0.336 0.464\nCFinCaKG (unweighted)Term FrequencyRandom Forest 602 0.84 0.872 0.655 0.748\nXGBoost 602 0.744 0.779 0.411 0.538\nDocument Embedding (RoBERTa) Random Forest (max length,1024) 0.712 0.730 0.372 0.493\nCFinCaKG (weighted)Term Frequency +WeightRandom Forest 236 0.843 0.878 0.660 0.754\nXGBoost 236 0.737 0.846 0.335 0.480\nDocument Embedding (RoBERTa) Random Forest (max length,1024) 0.718 0.733 0.379 0.500\nAttention : the first 1-3 rows are the baseline results. We mark the best-performing model with bold markdowns and the second-best model with underlines .\n(CST−FinCaKG ) and analyze the similarities and differences\nbetween them.\nMost causal chains lose causal meaning after three hops\n[24]; thus, we define associations within 3-hop as effective log-\nical connections. Therefore, this task is defined as “finding a Z\nwithin a 3-hop causal chain associated to A and not included in\nthe causal chains associated to B within 3-hop.” We execute\na Depth-First Search (DFS) algorithm (see Algorithm 1) to\nfind patterns that meet the conditions of “ A⊥B|Z”\nin FinCaKG. We first define a function Rto search for all\nneighbor nodes within three hops of start node n. We assume\neach node can potentially become an instrumental variable for\nother “ treatment-outcome ” pairs. Therefore, we loop through\nall nodes as z, useR(z, a)to find set Azrelated to z, then loop\nthrough the elements of set Aand use “ R(a, b)and¬R(z, b)\n” to define set B. Finally, we output the triple {z, a, b}to\nvisualize the IVs.\nIn terms of IV evaluation, we categorize extracted IVs as\n“high-quality (3 points) ”, “middle-quality (1-2 points) ”, and\n“low-quality (0 point) ” from ETE-FinCa , according to the\nfollowing scoring conditions:\n•Z is an edge node (+1 point);\n•The weight between ZandA:wz,a≥5.0(+1 point).\n•The weight between AandB:wa,b≥5.0(+1 point).\nFurthermore, we aim to identify high-quality IVs that exist\nonly in certain subgraphs and run 2SLS regression model to\ninterprets the directional effects and significance of “ treatment-\noutcome ” variables and finally generalizes the specific exper-\ntise. The statistical results of 2SLS are calculated to interpret\nthe validation of causality.\nIV. E XPERIMENTS AND RESULTS\nThis section is dedicated to testing our proposed ETE-\nFinCa with diverse experimental configurations for classifica-\ntion and IV-identification tasks. Also, we apply an acceptable\n2SLS regression model for the case study to provide insights\nfor statistical supports in the financial domain.A. Data Preparation\nIn the experiment, we collect 3,000 samples from glob-\nally listed companies that provided complete financial data\nfor five consecutive years. The stock price, crude oil, and\nforeign exchange data were obtained from Bloomberg. The\n2SLS regression model includes 14,099 observations. We also\ncontrol for firm size and Tobin’s Q as observed confounding\nvariables to correct for sample bias. We set a threshold of 0.55\nforCsim. A total of 2,436 financial concepts are included in\nthe overall FinCaKG graph, with 1,890 nodes included in the\nST-FinCaKG, and 1,566 nodes included in the SH-FinCaKG.\nB. Results\n1) Classification: Table I gives an overview of the results\nof our experiments using Csim,CFinCaKG (unweighted and\nweighted) to select the corpus for feature retrieval. CFinCaKG\n(unweighted) captures the most features (602) and significantly\nimproves baseline performance. The feature matrix based on\nCFinCaKG (weighted) achieves best-performance compared\nto the baseline (see row 1 in Csim), resulting in a 11.7%\nincrease in accuracy, a 17.1% increase in precision, a 23.4%\nincrease in recall and a 23.0% increase in F1 score (see row 1\ninCFinCaKG (weighted)). In knowledge graphs, important\ninformation tends to be connected to multiple nodes and\nthus leads to higher edge weights. Compared to CFinCaKG\n(unweighted), CFinCaKG (weighted) improves the attention\nof model to 236 crucial expertise. Furthermore, the term\nfrequency based on CFinCaKG (weighted) outperforms the\ndocument embedding approach (see row 3 in the Csim) with\nan accuracy improvement of 13%, a precision improvement\nof 12.6%, a recall improvement of 32.4%, and an F1 score\nimprovement of 29%.\n2) DFS Result: Table II presents the results of mining IV\nfrom FinCaKG using a DFS (Algorithm 1). “All-FinCaKG”\nis the entire graph containing knowledge from all samples,\nwhile “ST-FinCaKG” and “SH-FinCaKG” are subgraphs that\ninclude knowledge from only the “stakeholder-oriented” or\n“shareholder-oriented” standpoints, respectively. Due to the\nassumption that “each entity can potentially serve as an IV forTABLE II\nDFS R ESULTS\nDataset Chain Pattern Min. Avg.± std. Max. Total\nAll-FinCaKGZ 2,436\nZ→A 0 5±6 28 7,498\nZ→A→B 0 13±19 89 19,678\nST-FinCaKGZ 1,890\nZ→A 0 4±5 33 5,217\nZ→A→B 0 11±18 91 13,533\nSH-FinCaKGZ 1,566\nZ→A 0 4±3 18 3,896\nZ→A→B 0 9±8 52 8,932\nTABLE III\nRESULTS OF IVSQUALITY AND EDGE NODES\nDatasetNum. of Chain Patterns\nIV is\nedge nodeslow-\nqualitymiddle-\nqualityhigh-\nquality\nAll-FinCaKG 446 9,973 9,618 87\nSH-FinCaKG 294 3,260 5,577 95\nST-FinCaKG 345 7,811 5,701 21\nother causal pairs ( A→B)”, the number of Z equals the total\nnumber of entities in the knowledge graph. The table shows\nthat the All-FinCaKG comprises 2,436 IVs, and ST-FinCaKG\nand SH-FinCaKG subgraphs contain 1,890 and 1,566 IVs,\nrespectively. This indicates that different standpoints may lead\nto varying causal explanations for business operations.\nZ→A→Bindicates that Z can only influence B through\nA. Figure 3 is an instance of DFS, which illustrates the search\nprocess when node id “368” is selected as an IV . According\nto the definition, Z is related to A but is not related to B.\nThe association set of 368 consists of 1402 and 1308. Among\nthese, 1402 is related to {2000,322}, and 1308 is related to\n{2000,322,2179,1630}. However, since the C set related to\n2179 contains 368 (Z), this indicates that B is related to Z;\nconsequently, 2179 is removed from the B set. Finally, we\ncan conclude that 368 can serve as an instrumental variable\nfor 5 causal pairs: {(1402 →2000) ,(1402 →322),(1308 →\n2000) ,(1308 →322),(1308 →1630)}.\nOn average, each financial entity can serve as an IV for 13\ncausal pairs. In the entire knowledge graph, 19,678 patterns\nmeeting the conditions of IV are discovered. In the ST-\nFinCaKG subgraph, 13,533 qualifying patterns are found; in\nthe SH-FinCaKG subgraph, 8,932 patterns are identified. The\nnumber of patterns in the entire graph (19,678) is less than\nthe sum of patterns in the ST-FinCaKG and SH-FinCaKG\nsubgraphs (22,465), indicating some overlaps; i.e., several\ncertain patterns may appear in both subgraphs. This also\nsuggests that each subgraph may have its unique patterns.\n3) IVs Quality Classification Results: Table III shows the\nnumber of low-quality, middle-quality, and high-quality “ IV-\ntreatment-outcome ” causality in FinCaKG and subgraphs. SH-\nFinCaKG identifies the most high-quality IVs and corre-\nsponding explainable causal relationships exclusively (95).\nFig. 3. An instance of causal variables identification in DFS algorithm. The\ndashed arrows indicate a hop in a causal chain. The gray highlight signifies\nthat the node has been removed from the graph (invalid node).\nST-FinCaKG includes more IVs (1,890) than SH-FinCaKG\n(1,566) (see Table II) However, only 21 causal relationships\ncan be identified using high-quality IVs. Despite ST-FinCaKG\ncapturing more expertise, many of its causal relationships\nare confounded. SH-FinCaKG provides a clearer and more\npersuasive explanation for the “shareholder value maximiza-\ntion” standpoint compared to ST-FinCaKG. Here is another\npotential explanation: though ST-FinCaKG has more edge\nnodes (345), the connections between the variables are not\nas close as those in SH-FinCaKG (weights are too small.)\nIn other words, the expertise in SH-FinCaKG might be more\nstandpoint-concentrated.\nWe also compare the IV patterns identified from different\nsubgraphs. There are 870 IVs that appear exclusively in the\nST-FinCaKG, 546 specific IVs in the SH-FinCaKG, and 1020\nIVs included in both subgraphs. It indicates that most of the\nexpertise are common sense in FincaKG. The question arises:\nAre the causal relationships observed exclusively in certain\nsubgraphs attributable to standpoint bias of experts, or do they\nreflect logical patterns specific to certain types of companies?\nWe further discuss this issue using real financial data in the\nnext section.\n4) Empirical Study of Standpoint Causality: We validate\ntwo standpoint-based causal relationships in ST-FinCaKG\n(economic →EBITDA →governance ) and SH-FinCaKG\n(oil→profit →securities ) using high-quality IVs in\nthe overall sample. Table IV presents the results of 2SLS\nregression model with industry-fixed effects and year-fixed\neffects. we represent ‘ economic exposure ’ and ‘ crude oil ’\nwith foreign exchange exposure and oil price exposure, which\nare calculated based on the industry’s sensitivity to foreign\nexchange and oil price fluctuations. The ratio of independent\ndirectors is used as a proxy variable for corporate governance.\nThis result demonstrates that these specific causal relationships\nare also significant in the overall sample. The foreign exchange\nexposure clarifies the positive effect of EBITDA on corporate\ngovernance with a coefficient of 26.1 (p <0.01), and the oil\nprice exposure identifies the positive effect of operating profit\non market securities with a coefficient of 0.34 (p <0.01). The\nAnderson canon. statistics are significant(p <0.01) and the\nCD statistics are greater than 10, suggesting that Z as an\ninstrumental variable satisfies the assumptions of relevance\n(Cov (Z, A )̸= 0) and exogeneity (Cov (Z, ε 2) = 0) . In thisTABLE IV\nSTANDPOINT -BASED CAUSALITY SELECTION EMPIRICAL ANALYSIS RESULTS\nChain Selection Node Selection2SLS\n- 1st /2nd stage2SLS\n- coefficientt-valueAnderson canon.\ncorr. LM statisticCragg-Donald(CD)\nWald F statistic\nST-FinCaKGZ: economic exposure1st: Z→A -0.645*** -4.9224.96*** 12.49 A: ebitda\nB: corporate governance 2nd: A →B 26.100*** 3.84\nSH-FinCaKGZ: crude oil1st: Z→A -1.102*** -3.0611.43*** 11.41 A: operating profit\nB: marketable securities 2nd : A →B 0.340*** 2.55\nFootnote: Robust t-statistics in parentheses. *** p <0.01, ** p <0.05, * p <0.1\nexample, the causal relationships observed exclusively in the\nsubgraphs are more likely to reflect standpoint-based biases\nsince they are significantly validated across the overall real-\nworld sample.\nV. C ONCLUSION AND FUTURE WORK\nCausal inference is an expanding field with a significant\nimpact on both academic research and industrial applications.\nOur results show that the expertise-driven model provides op-\ntimal expertise for financial causal variables identification and\ninterpretation. Additionally, we separate the causal knowledge\ngraph into two subgraphs according to divergent standpoints.\nWe concentrate on those specific causal relationships that are\nincluded exclusively in the subgraph. Different from well-\nresearched consensus expertise, these standpoint-based causal\nrelationships are confounded and insufficiently studied. They\nhave the potential to be generalized, thus showing more\nresearch opportunities. We interpret the directional causality\nof two specific expertise by introducing high-quality IVs and\ndemonstrate the significance and applicability of these causal\nvariables in general cases by running the 2SLS regression\nmodel. In future practical applications, ETE-FinCa can as-\nsist economists in identifying under-explored financial causal\nrelationships and the IV candidates for validation.\nVI. ACKNOWLEDGMENT\nThis paper is partially supported by the New Energy and\nIndustrial Technology Development Organization (NEDO).\nREFERENCES\n[1] C. E. Frangakis and D. B. Rubin, “Principal stratification in causal\ninference,” Biometrics , vol. 58, no. 1, pp. 21–29, 2002.\n[2] D. B. Rubin, “Estimating causal effects of treatments in randomized\nand nonrandomized studies,” Journal of Educational Psychology , vol.\n66, no. 5, pp. 688–701, 1974.\n[3] D. Vrande ˇci´c and M. Kr ¨otzsch, “Wikidata: a free collaborative knowl-\nedgebase,” Communications of the ACM , vol. 57, no. 10, pp. 78–85,\n2014.\n[4] J. Pearl, “Causality,” Cambridge: Cambridge University Press , 2009.\n[5] J. M. Robins, A. Rotnitzky, and L. P. Zhao, “Estimation of regression\ncoefficients when some regressors are not always observed,” Journal\nof the American Statistical Association , vol. 89, no. 427, pp. 846–866,\n1994.\n[6] J. Hartford, G. Lewis, K. Leyton-Brown, and M. Taddy, “Deep IV: A\nflexible approach for counterfactual prediction,” in Proc. 34th Interna-\ntional Conference on Machine Learning , 2017, pp. 1414–1423.\n[7] J. Yuan et al., “Auto IV: Counterfactual prediction via automatic instru-\nmental variable decomposition,” ACM Trans. Knowl. Discov. Data , vol.\n16, no. 4, pp. 1–20, Aug. 2022.[8] J. D. Hwang et al., “(COMET-) ATOMIC 2020: On symbolic and neural\ncommonsense knowledge graphs,” in Proc. 35th AAAI Conference on\nArtificial Intelligence , 2021, vol. 35, no. 7, pp. 6384–6392.\n[9] K. Kuang, P. Cui, B. Li, M. Jiang, S. Yang, and F. Wang, “Treatment\neffect estimation with data-driven variable decomposition,” in Proc. 31st\nAAAI Conference on Artificial Intelligence , 2017.\n[10] N. Kertkeidkachorn, R. Nararatwong, Z. Xu, and R. Ichise, “FinKG:\nA core financial knowledge graph for financial analysis,” in Proc. IEEE\n17th International Conference on Semantic Computing , 2023, pp. 90–93.\n[11] P. R. Rosenbaum and D. B. Rubin, “Constructing a control group using\nmultivariate matched sampling methods that incorporate the propensity\nscore,” The American Statistician , vol. 39, no. 1, pp. 33–38, 1985.\n[12] P. Schwab, L. Linhardt, S. Bauer, J. M. Buhmann, and W. Karlen,\n“Learning counterfactual representations for estimating individual dose-\nresponse curves,” in Proc. 34th AAAI Conference on Artificial Intelli-\ngence , 2020, pp. 5612–5619.\n[13] R. Singh, M. Sahani, and A. Gretton, “Kernel instrumental variable re-\ngression,” in Proc. Advances in Neural Information Processing Systems ,\n2019.\n[14] R. Speer, J. Chin, and C. Havasi, “Conceptnet 5.5: An open multilingual\ngraph of general knowledge,” in Proc. 31st Conference on Artificial\nIntelligence , 2017, pp. 4444–4451.\n[15] S. Athey and G. Imbens, “Recursive partitioning for heterogeneous\ncausal effects,” in Proc. the National Academy of Sciences , vol. 113,\nno. 27, pp. 7353–7360, 2016.\n[16] S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira, “Analysis of\nrepresentations for domain adaptation,” in Proc. Advances in Neural\nInformation Processing Systems , 2007, pp. 137–144.\n[17] S. R. K ¨unzel, J. S. Sekhon, P. J. Bickel, and B. Yu, “Metalearners for\nestimating heterogeneous treatment effects using machine learning,” in\nProc. the National Academy of Sciences , vol. 116, no. 10, pp. 4156–\n4165, 2019.\n[18] S. Heindorf, Y . Scholten, H. Wachsmuth, A.-C. Ngonga Ngomo, and\nM. Potthast, “Causenet: Towards a causality graph extracted from the\nweb,” in Proc. 29th ACM International Conference on Information &\nKnowledge Management , 2020, pp. 3023–3030.\n[19] S. Athey, G. W. Imbens, and S. Wager, “Approximate residual balancing:\ndebiased inference of average treatment effects in high dimensions,”\nJournal of the Royal Statistical Society: Series B (Statistical Methodol-\nogy), vol. 80, no. 4, pp. 597–623, 2018.\n[20] U. Shalit, F. D. Johansson, and D. Sontag, “Estimating individual\ntreatment effect: generalization bounds and algorithms,” in Proc. 34th\nInternational Conference on Machine Learning , 2017, pp. 3076–3085.\n[21] X. Wang, R. Zhang, Y . Sun, and J. Qi, “Doubly robust joint learning\nfor recommendation on data missing not at random,” in Proc. 36th\nInternational Conference on Machine Learning , 2019, pp. 6638–6647.\n[22] Z. Luo, Y . Sha, K. Zhu, S.-W. Hwang, and Z. Wang, “Commonsense\ncausal reasoning between short texts,” in Proc. 15th International\nConference on Principles of Knowledge Representation and Reasoning ,\n2016.\n[23] Z. Li, X. Ding, T. Liu, J. E. Hu, and B. Van Durme, “Guided generation\nof cause and effect,” in Proc. 29th International Joint Conference on\nArtificial Intelligence , 2020, pp. 3629–3636.\n[24] Z. Xu and R. Ichise, “Exploring causal chain identification: Compre-\nhensive insights from text and knowledge graphs,” 26th International\nConference in Big Data Analytics and Knowledge Discovery, Springer ,\n2024, in press.', 'ziweixu@gmail.com', 'Ying Chen, Ziwei Xu, Kotaro Inoue, and Ryutaro Ichise', '', '../pdf_files/67498103baad9-Causal Inference in Finance - An Expertise-Driven.pdf', 4313651, 6, 4457, 30361, '2024-12-01 10:53:33', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(12, '9522515718', '6745cf4203d9a', 5, 19, 'Belief patterns with information processing', '2024-11-29 16:54:21.952638', '2024', 'This paper presents a model of costly information acquisition where decision-makers can choose whether to elaborate information superficially or precisely. The former action is costless, while the latter entails a processing cost. Within this framework, decision-makers’ beliefs may polarize even after they have access to the same evidence. From the perspective of a Bayesian observer who neglects information processing constraints, the decision-makers’ optimal behavior and belief updating may appear consistent with biases such as disconfirmation, underreaction to information, and confirmation bias. However, these phenomena emerge naturally within the model and are fully compatible with standard Bayesian inference and rational decision-making when accounting for the costs of information acquisition', 'information processing,beliefs,polarization,confirmation,acquisition', 'Belief patterns with information processing∗\nFederico Vaccari†\nAbstract\nThis paper presents a model of costly information acquisition where decision-makers\ncan choose whether to elaborate information superficially or precisely. The former\naction is costless, while the latter entails a processing cost. Within this framework,\ndecision-makers’beliefsmaypolarizeevenaftertheyhaveaccesstothesameevidence.\nFrom the perspective of a Bayesian observer who neglects information processing\nconstraints, the decision-makers’ optimal behavior and belief updating may appear\nconsistent with biases such as disconfirmation, underreaction to information, and\nconfirmationbias. However, thesephenomenaemergenaturallywithinthemodeland\nare fully compatible with standard Bayesian inference and rational decision-making\nwhen accounting for the costs of information acquisition.\nJEL codes: D81, D80, D83, D91\nKeywords: information processing, beliefs, polarization, confirmation, acquisition\n∗I thank Ennio Bilancini, Santiago Oliveros, Ludovic Renou, and Katharine Rockett for helpful\ncomments and suggestions on a much earlier draft. All errors are mine.\n†Department of Economics, University of Bergamo, e-mail:vaccari.econ@gmail.com .arXiv:2411.17597v1  [econ.GN]  26 Nov 2024Contents\n1 Introduction 3\n1.1 An introductory example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2 The model 7\n2.1 Set-up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2 Discussion of the model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n3 Incentives for information processing 9\n3.1 Prior categorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3.2 Willingness to pay for additional information . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.3 Prior beliefs and information processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n4 Analysis of belief patterns 14\n4.1 Additional definitions and intermediate results . . . . . . . . . . . . . . . . . . . . . . . . 14\n4.2 Belief polarization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.3 Confirmatory belief patterns and reaction to information . . . . . . . . . . . . . . . . . . . 20\n5 Concluding remarks 24\nA Appendix 25\nA.1 Bayesian updating . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nA.2 Prior categorization and proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . 26\nA.2.1 Cases 1 to 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\nA.2.2 Cases 5 to 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\nA.3 Proof of Proposition 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\nA.3.1 Proof of Corollary 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nA.4 Belief polarization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\nA.4.1 Proof of Proposition 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nA.4.2 Proof of Proposition 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nA.4.3 Proof of Corollary 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\nA.5 Confirmatory belief patterns and reaction to information . . . . . . . . . . . . . . . . . . . 43\nA.5.1 Proof of Proposition 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\nA.5.2 Proof of Proposition 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\nA.5.3 Proof of Proposition 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n21 Introduction\nIndividuals with access to the same information can arrive at increasingly divergent\nbeliefs or update their opinions in ways that fail to reflect the available evidence. This\nobservation is consistent with a substantial body of literature in economics and psychology\nthat documents systematic biases in how information is processed. Understanding how\nindividuals incorporate new information is vital, as belief polarization can drive financial\nfrenzies, escalate conflicts, and deepen economic, political, and cultural divisions. This\npaper employs a fully rational Bayesian framework to examine decision-makers’ incentives\nfor information acquisition and their implications on belief updating.\nThere are three key observations that define the approach taken here. First, having\naccess to information does not necessarily mean fully incorporating its content—just as\nowning an encyclopedia does not equate to knowing all of its entries. Second, scrutinizing\nevidence with greater precision is possible but comes at a cost. Third, individuals with\ndifferent beliefs have different incentives for examining information. This is because the\nvalue of information lies in its potential to influence optimal decision-making. For example,\nstaunch supporters of a political party may have little interest in carefully analyzing the\nplatforms or debates of opposing parties, as their choice is already decided. By contrast,\nundecided voters are more motivated to seek political information that helps them make\nan informed decision when casting their ballot.\nThis paper examines a parsimonious model of information acquisition where rational\nand Bayesian decision-makers must determine which of two states is true. They have\naccess to an imperfect signal that provides information about the true state, and they can\nchoose to scrutinize it either superficially or with greater precision. Superficial scrutiny\ncomes at no cost, while precise acquisition requires decision-makers to incur a processing\ncost. Their trade-off is between making a less informed decision for free or incurring a\ncost to make a better-informed choice.\nProcessing costs take the form of a disutility required to obtain additional information,\nencapsulating concepts developed in both economics and psychology. In their simplest\nform, they may represent a direct economic cost, such as a fee to consult an expert or\nthe price of accessing a database. More broadly, they encompass the resources needed to\nprocess larger volumes of information, including time, opportunity costs, and cognitive\neffort. This approach is also consistent with the theory of rational inattention, which\nposits that “agents cannot process all available information, but they can choose which\nexact pieces of information to attend to” (Maćkowiak, Matějka, & Wiederholt, 2023).\nThe first part of the paper examines the incentives driving information acquisition.\nDecision-makers with different prior beliefs may exhibit different willingness to pay for a\n3precise scrutiny, with some entirely unwilling to incur any cost for additional information.\nTheshapeofthewillingness-to-payfunctionisdeterminedbythespecificsoftheunderlying\ndecision problem and by the information received through a superficial scrutiny.\nAnalyzing the belief patterns that emerge after optimal information acquisition is the\nfocus of the paper’s second part. The analysis begins by examining the relative belief\npatterns of two decision-makers, with a particular emphasis on belief polarization. The\nmain proposition in this section establishes the necessary and sufficient conditions for\npolarization and derives the ex-ante probability of its occurrence. The analysis then shifts\nto the information acquisition choices and belief patterns of individual decision-makers.\nThis part identifies the necessary and sufficient conditions for various phenomena, including\ndisconfirmation, confirmatory belief patterns, and underreaction to information.\nThese results remark the importance of considering decision-makers’ incentives for\ninformation acquisition when evaluating their responses to information. Beliefs can natu-\nrally polarize under common evidence because decision-makers with different priors make\ndifferent information acquisition decisions. Ignoring these incentives may lead to choices\nand belief patterns that, from the perspective of an informed Bayesian observer, appear\nsimilar to well-documented biases in information processing, such as confirmation bias.\nThese findings also offer several testable implications regarding beliefs and information\nacquisition choices, providing a foundation for empirical exploration.\nThis work is related to the literature on information acquisition and processing, and\nspecifically to those papers which focus on patterns such as belief polarization and\nconfirmation bias. Calvert (1985) uses a rational choice model to show how Bayesian\ndecision-makers optimally select biased and imperfect advice based on their prior beliefs.\nIn Suen (2004), decision-makers acquire information through “experts” who coarsen\ncontinuous data into discrete recommendations. This process leads rational Bayesian\nindividuals to gather information confirming their priors. Decision-makers with different\nprior beliefs may choose different experts, selecting those who coarsen information in ways\nthat resonate with their priors. This behavior can foster the polarization of beliefs.\nNimark and Sundaresan (2019) examine the persistence of disagreement over ob-\njective truths. They develop a model in which rational Bayesian agents learn about\na state through noisy signals, and identify two key mechanisms driving disagreement:\nthe confirmation effect, where agents select signal structures that reinforce their prior\nbeliefs, and the complacency effect, where agents with more precise prior beliefs opt for\nless informative signals. When priors are sufficiently precise, agents may even choose\ncompletely uninformative signals. Together, these effects can lead to clustering of beliefs\ninto opposing groups over time, despite agents being ex ante identical. Differently from\nthe aforementioned work, this paper keeps the information structure fixed and focuses on\n4decision-makers’ optimal acquisition choices and belief patterns.\nBörgers, Hernando-Veciana, and Krähmer (2013) study the conditions under which two\nsignals are substitutes or complements in the spirit of Blackwell and Dubins (1962). They\nshow that the complementarity of signals is closely tied to the phenomenon where two\nagents, starting with differing prior beliefs, may become even more polarized after receiving\nadditional public evidence. Kondor (2012) and Andreoni and Mylovanov (2012) describe\ninformation structures in which increased polarization following the public disclosure of\nevidence is consistent with Bayesian updating. Polarization arises because agents disagree\non how to interpret the public signal, implying that signals are complements according to\nBörgers et al. (2013).\nThe seminal paper by Rabin and Schrag (1999) models confirmation bias as an\nexogenous probability that a decision-maker misinterprets signals contradicting her prior\nhypothesis. Specifically, the decision-maker unwittingly misinterprets only contrasting\ninformation, creating a distinction between the information she receivesand what she\nperceives . Key implications of this bias in their model include overconfidence, belief\npolarization, and potential wrongness. The latter occurs when a Bayesian observer, aware\nof the agent’s confirmation bias, concludes that she supports an incorrect hypothesis.\nSimilarly, this paper introduces a distinction between the information a decision-maker\nreceives and the information she chooses to observe due to costly acquisition. A fully\ninformed Bayesian observer, disregarding the cost constraints, may interpret the decision-\nmaker’s behavior as irrational, despite its optimality within the model.\nThere is a tight connection between costly information acquisition and cognitive\nlimitations (Dewatripont & Tirole, 2005). This connection resonates with psychological\ntheories, such as the dual-process theory, which distinguish between two distinct modes\nof information processing. In this framework, individuals either rely on automatic,\nintuitive judgments or engage in more deliberate, reasoning-based processing (Kahneman,\n2003). The role of processing costs fits with these theories, as cognitive limitations can\nconstrain the ability to engage in deliberate yet straining processing. Furthermore, this\nidea connects to the Elaboration Likelihood Model (Petty and Cacioppo, 1986) and the\nHeuristic-Systematic Model (Chaiken, Liberman, and Eagly, 1989), which also propose\nthat individuals process information through either heuristic shortcuts or more systematic,\neffortful strategies, depending on the cost and motivation to process information.1\n1TheElaborationLikelihoodModelandtheHeuristic-SystematicModelbothemphasizehowindividuals\nprocess persuasive messages either through a superficial, heuristic approach or through more effortful,\nsystematic thinking. These models are foundational in understanding how information is processed under\nvarying levels of motivation and cognitive resources.\n51.1 An introductory example\nThere are two possible states of the world, AandB. Two decision-makers are uncertain\nabout which state is true and must bet on it. Each decision-maker makes her independent\nguess and receives her payoff independently of the other decision-maker’s choice. If they\nguess correctly, they receive a payoff of 1; otherwise, they receive 0. Decision-maker High\n(H) initially considers state Amore likely to be true, with prior belief pH(A) = 0.7. In\ncontrast, decision-maker Low(L) initially believes state Bis more likely, with pL(A) = 0.3.\nA bi-dimensional signal σ= (σ1,σ2)is then publicly disclosed, consisting of two mutually\nindependent components. Each dimension of σcan take one of two possible values, αand\nβ, whereαsupportsAas the true state of the world, and βfavorsB.\nDecision-makers can choose whether to scrutinize σsuperficially or precisely. A\nsuperficial acquisition is free of charge but reveals only the realization of the first dimension,\nσ1. By contrast, a full and precise acquisition entails the payment of a processing cost\nc>0, which reveals the realizations of both dimensions of σ. The processing cost can be\ninterpreted as additional time, effort, or simply a monetary amount required to acquire σ\nin its entirety. I make the following assumptions regarding the informative content of the\nsignals:\nP(σ1=α|A) =P(σ1=β|B) =θ1=3/5,\nP(σ2=α|A) =P(σ2=β|B) =θ2=4/5.\nSuppose that the processing cost is c=1\n10and the signal is σ= (α,β). Both decision-\nmakers acquire the first, free component σ1=α, resulting in Bayesian posteriors of\npH\nα(A)≈0.78forHandpL\nα(A)≈0.39forL. Compared to their prior beliefs, both\nagents have increased their support for state A. Furthermore, we observe convergence , as\npH\nα−pL\nα<pH−pL. The decision-makers have different willingness to pay for observing\nσ2. Specifically, His willing to pay at most cH≈0.02, whileLis willing to pay at most\ncL≈0.19. Given that c=1\n10, onlyLopts for a precise acquisition of σ. After observing\nσ2=β, her posterior is pL\nαβ≈0.14.\nThe decision-makers’ posterior beliefs now lie further apart compared to their priors,\nresulting in belief divergence . Moreover, while Hhas increased her support for A,Lhas\ndecreased it. This pattern is reminiscent of what is known as belief polarization , as the\ndecision-makers’ beliefs diverge and move further apart even though they were endowed\nwith the same signal. Despite the signal overall supports state Bbecause its second\ncomponent is more informative than the first, decision-maker Hnonetheless increases\nher confidence in state A. Compared to the signal’s informative content, she updates\nher beliefs in a way that confirms her previously held hypothesis about the state. This\npattern is resembles what is known as confirmation bias .\n6Suppose now that the signal gives σ1=β. In this case, the decision-makers would\nswitch their willingness to pay for σ2, withcH≈0.19andcL≈0.02. Only decision-maker\nHchooses to incur the processing cost to observe σ2. This example highlights how\ndecision-makers are more willing to scrutinize with greater accuracy information that\ncontradicts their prior beliefs. This behavior recalls other biases in information selection\nand acquisition.2Finally, suppose instead that σ= (α,α). We have seen before that, after\nobservingσ1=α, decision-maker Hdecides not to incur the processing cost to observe\nσ2, and thus her posterior is pH\nα(A)≈0.78. However, if she instead observes σ2=α, her\nposterior would be pH\nαα(A)≈0.93. This belief pattern, compared to the signal’s whole\ninformational content, is reminiscent of under-reaction to information, as 0.78<0.93.\n2 The model\n2.1 Set-up\nThere is a state of the world represented as a random variable, ˜ω, with realization\nω∈Ω ={A,B}. A decision-maker (DM, she) must take an action s∈Ω, which is\ninterpreted as a literal guess of the realized state. The decision-maker believes that the\nstateω=Arealizes with prior probability p=Pr(ω=A)∈[0,1].\nBefore choosing an action s∈Ω, the decision-maker is endowed with a two-dimensional\nsignal,σ. The signal is a random variable ˜σ=(˜σ1,˜σ2)with realization σ= (σ1,σ2)∈Θ2,\nwhere Θ ={α,β}. I indicate the conditional and unconditional probability distribution of\nσbyP. Each component σj,j∈{1,2}, is itself an informative signal about the state,\nandσ1andσ2are mutually independent. The information structure is\nθ1:=P(˜σ1=α|˜ω=A) =P(˜σ1=β|˜ω=B)>1/2,\nθ2:=P(˜σ2=α|˜ω=A) =P(˜σ2=β|˜ω=B)>1/2.\nI will sometimes use αjandβjto denoteσj=αandσj=β, respectively.\nThesignal’sfirstcomponent, σ1, isfreelyobservable. Bycontrast, itssecondcomponent,\nσ2, can be scrutinized only by incurring a processing cost c>0. After receiving σ, but\nbefore choosing s∈Ω, the decision-maker chooses whether to observe only the signal’s\nfirst component for free, or to acquire also its second component at a cost. Formally,\nthis choice is represented by action a∈Π ={ρ,¬ρ}, whereρindicates the decision of\npayingcto observe both σ1andσ2, and¬ρthe decision of acquiring only σ1. Actionais\n2From Lord, Ross, and Lepper (1979, p. 2099): “The biased assimilation processes underlying this effect\nmay include a propensity to [...] accept confirming evidence at face value while scrutinizing disconfirming\nevidence hypercritically.”\n7σ, ω a∈Π p(σ) s∈Ω u(·)\nThe state and\nthe signal are\nrealizedThe DM\nobserves σ1and\nchooses a∈ΠIfa∗=ρ, then\nthe DM\nobserves σ2The DM\nchooses s∈ΩPayoffs are\nrealizedFigure 1: Timing structure\nselected after observing σ1but before choosing s, thusa(p,c,σ 1) : [0,1]×R+×Θ→Π.\nConversely, s(p,σ 1) : [0,1]×Θ→Ωifa=¬ρ, ands(p,σ 1,σ2) : [0,1]×Θ2→Ωotherwise.\nThe decision-maker obtains a utility of v(s=ω,ω) =Uwhen she selects an action\nsthat matches with the state’s realization ω, and obtains v(s̸=ω,ω) =Uotherwise. I\ndenote ∆U:=U−U, and assume that ∆U > 0. The decision-maker’s utility when the\nstate isω∈Ωand her actions are a∈Πands∈Ωisu(a,s,ω ), where3\nu(a,s,ω ) =\n\nv(s,ω)ifa=¬ρ,\nv(s,ω)−cotherwise.\nThe decision-maker updates information according to Bayes’ rule. Her posterior beliefs\nafter receiving σis denoted by pσ1whena=¬ρ, and by either pσ1σ2orpσotherwise.\nThe decision-maker selects actions a∈Πands∈Ωto maximize her expected utility. I\nindicate her optimal decisions given beliefs by a∗∈Πands∗∈Ω. When choosing a∈Π,\nher beliefs are necessarily pσ1. Denote by p(σ)the decision-maker’s posterior beliefs at\nthe time of choosing s∈Ω, and conditional on optimal information acquisition choice, a∗.\nWe have that p(σ) =pσ1ifa∗=¬ρ, andp(σ) =pσotherwise. Therefore,\na∗:= argmax\na∈ΠEpσ1[u(a,s∗,ω)|σ],ands∗:= argmax\ns∈ΩEp(σ)[u(a∗,s,ω)|σ].\nPart of the analysis will consider two decision-makers, say iandj, that differ in\ntheir prior beliefs only. In those cases, I indicate their prior beliefs with piandpj, and\ntheir posterior beliefs with pk\nσ1,pk\nσ1σ2, andpk(σ)fork∈{i,j}. Similarly, I will use ak,\na∗\nk,skands∗\nkfor their actions, and will always imply that i̸=j. From the perspective\nof decision-maker k, with prior pk, the conditional distribution of the signal’s second\ncomponent is Pk(σ2|σ1), and the unconditional distributions are Pk(σj).\nThe model’s timeline, as depicted by Figure 1, is as follows: (i) The state, ω∈Ω, and\nthe signal, σ∈Θ2, are realized but not observed; (ii) The decision-maker observes σ1\nfor free, and then chooses a∈Π; (iii) Ifa=ρ, then the decision-maker observes σ2and\nincurs a cost c; (iv) The decision-maker selects s∈Ω; (v) Finally, her payoff realizes.\n3Formally,a(p,c,σ 1)\n82.2 Discussion of the model\nIn this model, the decision-maker faces a problem of costly information acquisition. The\navailable signal consists of two components: the first is free, while the second is costly\nto access. The analysis initially focuses on the decision-makers’ incentives for acquiring\ninformation. Then, it shifts to studying the relative beliefs of decision-makers who have\ndifferent prior beliefs but are otherwise identical. Decision-makers always scrutinize the\nfirst signal because it is free. Whether they choose to acquire the second, costly component\ndepends crucially—but not solely—on their prior beliefs.\nSome findings could be derived from a simpler model, where there is a single, one-\ndimensional signal that is costly to acquire. However, such a simplified framework would\nnot capture the variety of results and belief patterns that the current two-dimensional\nmodelprovides. Amodelwithmorethantwodimensionswouldaddadditionalcomplexities\nwithout providing more insights, as a rich variety of belief patterns is addressed by the\ncurrent two-dimensional setting. Moreover, the signals are assumed to be symmetric.\nWhile asymmetric signals may offer additional benefits to decision-makers (Calvert, 1985),\nremoving symmetry would complicate the analysis without yielding significant insights.\nIn the analysis, decision-makers differ only in their prior beliefs, while remaining\nidentical in all other respects. This assumption serves three purposes. First, it mirrors the\ntypical setup of controlled laboratory experiments, where subjects face the same payment\nscheme. Second, it isolates the role of prior beliefs in shaping incentives for information\nacquisition and the resulting belief patterns. Finally, it simplifies the analysis without\nsignificant loss of generality. Decision-makers with different utility functions could, of\ncourse, make different decisions even with the same prior beliefs, but this possibility is\nexcluded in the current setting.\n3 Incentives for information processing\nThis section examines the incentives for information acquisition faced by a decision-maker.\nThe first part (Section 3.1) categorizes a decision-maker’s problem into eight qualitatively\ndistinct cases based on her prior beliefs. This categorization is instrumental for the\nsubsequent analysis and establishes a link between the decision-maker’s prior beliefs and\ntheir willingness to pay for additional information. The section illustrates how to calculate\nthe willingness to pay for decision-makers belonging to the first case, while the remainder\nof the analysis is presented in the appendix. The second part (Section 3.2) investigates the\nfunction that describes such a willingness to pay, conditional on the decision-maker’s prior\nbeliefs, signal received, and information structure. This analysis clarifies the relationship\nbetween prior beliefs and the value of additional information.\n90 0.14 0.4 0.73 1#4 #3 #2 #1σ1=α\n0 0.27 0.6 0.86 1#5 #6 #7 #8σ1=βFigure 2: Partition of the conditional posterior belief spaces induced by an information\nstructure where θ1=3/5andθ2=4/5, categorized according to Table 1. The case numbers\nare labeled at the top of each corresponding partition.\n3.1 Prior categorization\nA decision-maker’s incentive to scrutinize ˜σ2depends on her interim beliefs ( pσ1), the\npayoff structure ( ∆U), the processing cost ( c), and the information structure of the signal’s\nsecond component ( θ2). Given the informative content of each dimension of ˜σ, every prior\npinduces posteriors with implications on the DM’s optimal behavior that are crucial in\ndetermining her willingness to pay for additional information.\nConsider, for example, a decision-maker with prior belief p, such that, after observing\nσ1=α, her posterior belief is greater than1/2independently of whether she observes ˜σ2\nand its possible realizations. As a result, she will choose action Aregardless of σ2. I will\nrefer to this situation as “case 1,” where pα,pαα, andpαβare all greater than or equal to\n1/2. Although the costly signal ˜σ2is informative about the true state of the world ˜ω, the\nDM’s choice is independent of its realization. In this case, the DM cannot benefit from\nacquiring the signal’s second component, and her willingness to pay for observing σ2is\nzero.\nIntuitively, decision-makers whose prior falls into case 1are relatively extreme in the\nsense that they place a very high (prior) probability on the state being ω=A. Decision-\nmakers with more moderate prior beliefs may have different incentives for information\nacquisition. To aid the analysis that follows, it is useful to partition the decision-maker’s\nbelief space in a way that links each partition to a qualitatively different optimal behavior.\nRecall that the decision-maker optimally selects action s=Aif her posterior beliefs exceed\n1/2, and selects action s=Botherwise. Table 1 groups all posterior beliefs that lead\nto qualitatively different choices over s∈Ωconditional on all possible observed signals’\nrealizations. Each group of posteriors induces a convex set of prior beliefs, and constitutes\na different case. This procedure partitions the belief space into eight cases.\nFigure 2 illustrates, for a given information structure, an example of partition induced\nby the categorization as in Table 1. The next section illustrates the connection between\ncases and decision-makers’ willingness to pay for observing the signal’s second component.\n10Posterior beliefs and optimal behavior\nCase # ˜σ1Posteriors’properties Prior’s interval\n1α1pα≥1\n2,pαα≥1\n2,pαβ≥1\n2/bracketleftigθ2(1−θ1)\nθ1+θ2−2θ1θ2,1/bracketrightig\n2α1pα≥1\n2,pαα≥1\n2,pαβ≤1\n2/bracketleftig\n1−θ1,θ2(1−θ1)\nθ1+θ2−2θ1θ2/bracketrightig\n3α1pα≤1\n2,pαα≥1\n2,pαβ≤1\n2/bracketleftig\n1−θ1θ2\n1−θ1−θ2+2θ1θ2,1−θ1/bracketrightig\n4α1pα≤1\n2,pαα≤1\n2,pαβ≤1\n2/bracketleftig\n0,1−θ1θ2\n1−θ1−θ2+2θ1θ2/bracketrightig\n5β1pβ≤1\n2,pβα≤1\n2,pββ≤1\n2/bracketleftig\n0,θ1(1−θ2)\nθ1+θ2−2θ1θ2/bracketrightig\n6β1pβ≤1\n2,pβα≥1\n2,pββ≤1\n2/bracketleftigθ1(1−θ2)\nθ1+θ2−2θ1θ2,θ1/bracketrightig\n7β1pβ≥1\n2,pβα≥1\n2,pββ≤1\n2/bracketleftig\nθ1,θ1θ2\n1−θ1−θ2+2θ1θ2/bracketrightig\n8β1pβ≥1\n2,pβα≥1\n2,pββ≥1\n2/bracketleftig\nθ1θ2\n1−θ1−θ2+2θ1θ2,1/bracketrightig\nTable 1: Categorization of prior beliefs in eight cases yielding different optimal behavior\nconditional on observed information.\nWillingness to pay for additional information\nCase # ˜σ1Prior’s interval WTP cσ1(p)\n1α1/bracketleftigθ2(1−θ1)\nθ1+θ2−2θ1θ2,1/bracketrightig\n0\n2α1/bracketleftig\n1−θ1,θ2(1−θ1)\nθ1+θ2−2θ1θ2/bracketrightig\n∆U·/bracketleftigθ2(1−p)−θ1p−θ1θ2(1−2p)\nθ1p+(1−θ1)(1−p)/bracketrightig\n3α1/bracketleftig\n1−θ1θ2\n1−θ1−θ2+2θ1θ2,1−θ1/bracketrightig\n∆U·/bracketleftigθ1θ2p−(1−θ1)(1−θ2)(1−p)\nθ1p+(1−θ1)(1−p)/bracketrightig\n4α1/bracketleftig\n0,1−θ1θ2\n1−θ1−θ2+2θ1θ2/bracketrightig\n0\n5β1/bracketleftig\n0,θ1(1−θ2)\nθ1+θ2−2θ1θ2/bracketrightig\n0\n6β1/bracketleftigθ1(1−θ2)\nθ1+θ2−2θ1θ2,θ1/bracketrightig\n∆U·/bracketleftig(1−θ1)θ2p−θ1(1−θ2)(1−p)\n(1−θ1)p+θ1(1−p)/bracketrightig\n7β1/bracketleftig\nθ1,θ1θ2\n1−θ1−θ2+2θ1θ2/bracketrightig\n∆U·/bracketleftigθ1θ2(1−p)−(1−θ1)(1−θ2)p\n(1−θ1)p+θ1(1−p)/bracketrightig\n8β1/bracketleftig\nθ1θ2\n1−θ1−θ2+2θ1θ2,1/bracketrightig\n0\nTable 2: The DM’s willingness to pay for observing σ2given prior beliefs pand signal\nrealization σ1.\n113.2 Willingness to pay for additional information\nThe previous section categorized decision-makers by cases. Each case is characterized\nby the the pair (p,σ 1), which induces the interim posterior pσ1. This section describes\nand analyzes the cost function characterizing the decision-makers’ willingness to pay for\nobserving the signal’s second component, σ2. As we shall see, the shape and the properties\nof this function vary across cases. The proofs of Propositions 1 and 2, which are outlined\nin this section, are in Appendix A.2 and A.3, respectively.\nThe decision-maker’s interim posterior beliefs, pσ1, determine her willingness to pay\nfor observing σ2. Given a fixed payoff and information structure, I hereafter refer to such\na willingness to pay by cσ1(p), and say that a processing cost is admissible when it is\nsmaller than cσ1(p). Table 2 associates each case to the decision-maker’s willingness to\npay for observing σ2, that is,cσ1(p).\nDefinition 1. The function cσ1(p) : [0,1]×Θ1∝⇕⊣√∫⊔≀→R+\n0represents the highest processing\ncost that a decision-maker with prior beliefs pis willing to incur after observing σ1. A\nprocessing cost, c, is “admissible” if c≤cσ1(p). The setCσ1(p) := [0,cσ1(p)]contains all\nadmissible processing costs given prior beliefs pand signal realization σ1.\nThe function cσ1(p), as in Definition 1, is piecewise with discontinuities between\ndifferent cases, and is characterized by the following proposition. I denote by cn\nσ1(p)the\ncost function for a decision-maker that belongs to case n.4\nProposition 1. Given an information structure (θ1,θ2), the decision-maker’s willingness\nto pay for observing σ2is determined by the cost function cσ1(p), where\ncα(p) =\n\nc4\nα(p) = 0 ifp∈/bracketleftig\n0,1−θ1θ2\n1−θ1−θ2+2θ1θ2/bracketrightig\n,\nc3\nα(p) = ∆U·/bracketleftigθ1θ2p−(1−θ1)(1−θ2)(1−p)\nθ1p+(1−θ1)(1−p)/bracketrightig\nifp∈/bracketleftig\n1−θ1θ2\n1−θ1−θ2+2θ1θ2,1−θ1/bracketrightig\n,\nc2\nα(p) = ∆U·/bracketleftigθ2(1−p)−θ1p−θ1θ2(1−2p)\nθ1p+(1−θ1)(1−p)/bracketrightig\nifp∈/bracketleftig\n1−θ1,θ2(1−θ1)\nθ1+θ2−2θ1θ2/bracketrightig\n,\nc1\nα(p) = 0 ifp∈/bracketleftigθ2(1−θ1)\nθ1+θ2−2θ1θ2,1/bracketrightig\n,\ncβ(p) =\n\nc5\nβ(p) = 0 ifp∈/bracketleftig\n0,θ1(1−θ2)\nθ1+θ2−2θ1θ2/bracketrightig\n,\nc6\nβ(p) = ∆U·/bracketleftig(1−θ1)θ2p−θ1(1−θ2)(1−p)\n(1−θ1)p+θ1(1−p)/bracketrightig\nifp∈/bracketleftigθ1(1−θ2)\nθ1+θ2−2θ1θ2,θ1/bracketrightig\n,\nc7\nβ(p) = ∆U·/bracketleftigθ1θ2(1−p)−(1−θ1)(1−θ2)p\n(1−θ1)p+θ1(1−p)/bracketrightig\nifp∈/bracketleftig\nθ1,θ1θ2\n1−θ1−θ2+2θ1θ2/bracketrightig\n,\nc8\nβ(p) = 0 ifp∈/bracketleftig\nθ1θ2\n1−θ1−θ2+2θ1θ2,1/bracketrightig\n.\nProposition 2. The cost function cσ1(p),\n4The notation for the cost function cn\nσ1(p)is redundant, as each case number is already associated\nwithσ1. However, σ1is retained for clarity and conformity with Definition 1.\n121\n21−θ1 θ1\nPriorp∆U[θ2−θ1]∆U[θ2−0.5]Cost functions, cσ1, as a function of the prior p\ncα(p)\ncβ(p)Figure 3: The cost function for different prior beliefs: the blue line represents cα(p), and\nthe yellow line represents cβ(p). The shaded areas indicate the respective sets of admissible\ncosts, i.e.,Cα(p)andCβ(p).\n•is continuous in p, and satisfies cα(p) =cβ(1−p)for allp∈[0,1];\n•c3\nα(p)is strictly increasing and concave, while c2\nα(p)is strictly decreasing and convex;\n•c6\nβ(p)is strictly increasing and convex, while c7\nβ(p)is strictly decreasing and concave;\n•cα(p)has a global maximum at p= 1−θ1, whilecβ(p)has a global maximum at\np=θ1, wherecα(1−θ1) =cβ(θ1) = ∆U/bracketleftig\nθ2−1\n2/bracketrightig\n.\nFigure 3 illustrates the decision-maker’s willingness to pay for observing the signal’s\nsecond component, ˜σ2, conditional on their prior beliefs and on the realization of the\nsignal’s first component, σ1.\n3.3 Prior beliefs and information processing\nWhich prior beliefs would induce decision-makers to incur the cost for processing additional\ninformation? The cost function characterization from the previous section allows us to\nanswer this question. First, Proposition 2 shows that no decision-maker is willing to\nacquireσ2when the processing cost exceeds ∆U/bracketleftig\nθ2−1\n2/bracketrightig\n. For more reasonable costs,\n0< c < ∆U/bracketleftig\nθ2−1\n2/bracketrightig\n, Propositions 1 and 2, along with a visual inspection of Figure 3,\nsuggest that only decision-makers with prior beliefs in convex and strict subsets of the\nbelief space would pay the processing cost to observe ˜σ2. Moreover, these sets must depend\nonσ1, as the decision to acquire ˜σ2hinges on the interim posterior, pσ1.\nDefinition 2. The set of prior beliefs for which a decision-maker, after observing σ1, is\n13willing to incur a given processing cost to observe σ2is defined as\nHσ1(c):={p∈[0,1]|cσ1(p)>c}.\nThe following result confirms the intuition that only decision-makers with relatively\nmoderate prior beliefs are willing to acquire additional information at a cost, while those\nwith extreme beliefs—closer to zero or one—do not find it beneficial. However, this\nintuition holds only if the signal’s second component is more informative than the first.\nOtherwise, even decision-makers with prior beliefs near1\n2may not benefit from observing\nthe signal’s second component. Furthermore, some “extreme” decision-makers may remain\nunwilling to scrutinize additional information, even as the processing cost approaches zero.\nCorollary 1. Given a processing cost c, we have that\nHσ1(c) =\n\n∅ ifc>∆U/bracketleftig\nθ2−1\n2/bracketrightig\n,/parenleftig\nqσ1(c),qσ1(c)/parenrightig\nifc∈/parenleftig\n0,∆U/bracketleftig\nθ2−1\n2/bracketrightig/parenrightig\n,\nwhere 0< qα(c)< qβ(c)andqα(c)<qβ(c)<1. Moreover, qβ(c)≤qα(c)if and only if\nθ2≥θ1.\nThe corollary above additionally shows that the sets Hσ1(c)are convex, withHα(c)\nshifted relatively to the left with respect to Hβ(c). The boundaries of Hσ1(c)are derived\nby inverting the decision-makers’ cost function. Explicit closed-form formulas for qσ1(c)\nandqσ1(c)are provided in Appendix A.3.1.\n4 Analysis of belief patterns\nThis section examines the relative belief patterns exhibited by either one or two decision-\nmakers. Section 4.1 introduces additional definitions and partial results to support the\nanalysis that follows. Section 4.2 focuses the relative belief patterns of two decision-makers,\niandj, with prior beliefs piandpj. In that section, the only potential difference between\nthe decision-makers lies in their beliefs, while both share the same signal realization. By\ncontrast, Section 4.3 analyzes the belief patterns of a single decision-maker.\n4.1 Additional definitions and intermediate results\nThis section introduces definitions and intermediate results that are essential for the\nupcoming analysis. Four main concepts are defined: diverging attitudes ,inverse updating ,\nextreme, andreciprocal beliefs. Two decision-makers exhibit diverging attitudes (DA)\n14when the distance between their posteriors exceeds the distance between their priors.\nThey exhibit inverse updating (IU) when one decision-maker increases her belief in one\nstate of the world, while the other decreases hers.5\nMore formally, consider the Euclidean distance between the decision-makers’ prior\nbeliefs and that between their posterior beliefs, that is, respectively, |pi−pj|, and\n|pi(σ)−pj(σ)|. Thedivergence function , defined as\nD(σ):=|pi−pj|−|pi(σ)−pj(σ)|, (1)\nindicates whether the decision-makers’ posterior beliefs are closer or farther from each\nother compared to their priors when the signal realization is σ. A positive (resp. negative)\ndivergence function indi that their beliefs became closer (resp. farther) after receiving σ.\nTheinversion function , defined as\nI(σ):= [pi−pi(σ)]·[pj−pj(σ)], (2)\nindicates whether the decision-makers update their posterior beliefs in the same direction\nwhen the signal is σ. A positive (resp. negative) inversion function means that decision-\nmakers update their prior in the same (resp. opposite) direction.\nDefinition 3. Diverging attitudes occur when D(σ)<0; inverse updating when I(σ)<0.\nA necessary condition for diverging attitudes and inverse updating is that one decision-\nmaker incurs the processing cost to scrutinize σas a whole, whereas the other does not\nand observes σ1only. Formally, a∗\ni(σ1)̸=a∗\nj(σ1). Otherwise, their beliefs would converge\nand move in the same direction. This implies that it is necessary for the occurrence of\nDA and IU that decision-makers have different prior beliefs, as otherwise they would have\nexactly the same incentives for information processing (see Section 3). As we shall see,\nthe necessary conditions for DA and IU are stronger than just pi̸=pj.\nIn Section 3, we observed that decision-makers with prior beliefs sufficiently close to\neither zero or one do not find it profitable to incur the processing cost which is required to\nobserve the signal’s second component. Intuitively, these decision-makers are so confident\nabout the realized state that they are unwilling to pay any cost for new information,\nregardless of how small the cost is. In this sense, they hold extreme beliefs . The next\ndefinition formalizes the sets containing extreme and non-extreme beliefs.\n5In Jern, Chang, and Kemp (2014), this concept is referred to as “contrary updating.” As they\npoint out, inverse updating can lead to both divergence and convergence of beliefs, but not to “parallel\nupdating.”\n15Definition 4. The set of non-extreme beliefs is\n¬E:= lim\nc→0Hα(c)∪Hβ(c),\nwhile the set of extreme beliefs is E:= [0,1]\\¬E. The sets of non-extreme and extreme\nbeliefs conditional on observing σ1are, respectively,\n¬Eσ1:= lim\nc→0Hσ1(c)andEσ1:= [0,1]\\¬Eσ1.\nThe sets of extreme and non-extreme beliefs are intimately related with the catego-\nrization outlined in Table 1. Using the results from Section 3, we can find a closed-form\nsolution for these sets. Specifically, we have ¬E=¬Eα∪¬Eβ, where\n¬Eα≜(qα(0),qα(0)) =/parenleftigg(θ1−1)(θ2−1)\n1−θ1−θ2+ 2θ1θ2,(1−θ1)θ2\nθ1+θ2−2θ1θ2/parenrightigg\n,\n¬Eβ≜/parenleftig\nqβ(0),qβ(0)/parenrightig\n=/parenleftiggθ1(1−θ2)\nθ1+θ2−2θ1θ2,θ1θ2\n1−θ1−θ2+ 2θ1θ2/parenrightigg\n.\nThe set¬Eis convex if and only if the signal’s second component is more informative\nthan the first one (i.e., θ2≥θ1). Otherwise,¬Ewould have a gap in the middle where\nbeliefs are considered “extreme” despite being relatively moderate. Decision-makers with\nextreme beliefs belong to either cases 4 and 5, or cases 1 and 8 when θ2≥θ1. They can\nbelong to both cases 1 and 5 when θ2<θ 1. In the latter scenario, the second signal is\nnot sufficiently informative to alter the best course of action for decision-makers with\nrelatively central prior beliefs after observing the first signal’s realization.\nFrom Section 3, we have the straightforward result that two decision-makers sharing\nthe same prior beliefs also share identical incentives for information acquisition. Either\nboth opt to pay for observing the signal’s second component, or both abstain from doing\nso. They face the same set of admissible costs. However, sharing the same prior beliefs\nis not a necessary condition for aligned incentives in information acquisition. There are\ndecision-makers who, despite having different prior beliefs, end up with the same set\nof admissible costs after observing ˜σ1. This is trivially true for decision-makers with\nextreme beliefs who do not benefit from additional information, but it is also true for\npairs of decision-makers who do not hold extreme beliefs. I refer to such decision-makers\nasreciprocal with respect to σ1. The next definition provides the implicit relationship\nbetween posterior beliefs characterizing reciprocal decision-makers.\nDefinition 5. Two decision-makers, iandj, withpi<pj, are said to be “reciprocal” for\nσ1if, after observing ˜σ1=σ1, (i) both have prior beliefs that belong to the non-extreme\n16set¬Eσ1, and (ii) their posterior beliefs are related as follows,\npi\nσ1α=1\n2+Pj(β2|σ1)\nPi(α2|σ1)/parenleftbigg1\n2−pj\nσ1β/parenrightbigg\n. (3)\nEquation (3)outlines a specific relationship between posterior beliefs that implicitly\ndefines a condition on prior beliefs. Importantly, such a condition is conditional on the\nrealization of the signal’s first component. The next result shows that decision-makers\nthat are reciprocal for a signal realization σ′\n1must share the same set of admissible cost\nconditional on σ′\n1. At the same time, they cannot be reciprocal for the other realization\nσ′′\n1, on which they have different willingness to pay for acquiring the signal’s second\ncomponent.\nLemma 1. Two decision-makers that are reciprocal for σ1share the same set of admissible\ncosts,Cσ1(pi) =Cσ1(pj). If they are reciprocal for signal realization σ′\n1, then they are not\nreciprocal for σ′′\n1, whereσ′\n1̸=σ′′\n1.\nProof.For the first part of the proof, rewrite equation (3)asPi(α2|σ1)/bracketleftig\npi\nσ1α−1\n2/bracketrightig\n=\nPj(β2|σ1)/bracketleftig\n1\n2−pj\nσ1β/bracketrightig\n. Multiplying both sides by ∆Uwe get,\n∆U·Pi(α2|σ1)·/bracketleftig\n2pi\nσ1α−1/bracketrightig\n= ∆U·Pj(β2|σ1)·/bracketleftig\n1−2pj\nσ1β/bracketrightig\n.\nDepending on the realization of ˜σ1, the left-hand side is DM i’s cost function for cases 3\nand 6. The right-hand side is DM j’s cost function for cases 2 and 7. It follows that iand\njshare the same cost threshold and thus the set of admissible cost conditional on σ1.\nThe second part of the proof begins with the observation that the only prior for which\ncα(p) =cβ(p)isp=1/2. Reciprocal DMs have different prior beliefs, and thus at least one\nof them must have different cost thresholds for different realizations of ˜σ1. Their prior\nbeliefs must belong to different cases (see Table 1) because of the strict monotonicity\nof the cost function, cσ1(p), in the domain of non-extreme sets, ¬Eσ1. Otherwise, they\ncould not share the same set of admissible costs. From the cost function’s shape (see\nSection 3) we have that, on their shared domain, c3\nα(·)>c6\nβ(·), andc2\nα(·)<c7\nβ(·). Hence,\nifcσ′\n1(pi)=cσ′\n1(pj), thencσ′′\n1(pi)̸=cσ′′\n1(pj)forpi̸=pjandσ′\n1̸=σ′′\n1. The DMs do not\nshare the same set of admissible costs, and thus they are not reciprocal for σ′′\n1.\nOnly pairs of decision-makers who have the same prior beliefs (and thus cannot be\nreciprocal) share the same set of admissible costs regardless of σ1, with the exception\nof the pathological case where pi= 0andpj= 1. From Definition 5 and Lemma 1, we\nobtain that ihas a higher willingness to pay for information than j(i.e.,cσ1(pi)>cσ1(pj))\nif and only if pi\nσ1α<1\n2+Pj(β2|σ1)\nPi(α2|σ1)/bracketleftig\n1\n2−pj\nσ1β/bracketrightig\n. Given signal realization σ1, and two different\n17but non-reciprocal decision-makers, if at least one of them belongs to the non-extreme\nset (¬Eσ1), then one decision-maker must be willing to pay a higher processing cost than\nthe other. In these cases, there are processing costs for which only one decision-maker\nwould pay to observe ˜σ2. Such a set would be empty for decision-makers who are either\nreciprocal or have identical priors. As we shall see, conditions under which only one\ndecision-maker acquires additional information are key for the analysis that follows. The\nnext definition formally defines the sets containing all pairs of prior beliefs for which,\nconditional on σ1, decision-makers have different incentives for information acquisition.\nDefinition 6. Consider two decision-makers, kandl. Given a processing cost c, the\nset of all pairs of prior beliefs such that, after observing σ1, decision-maker kchooses to\nobserveσ2while decision-maker ldoes not is\nBkl\nσ1(c) :=/braceleftig/parenleftig\npi,pj/parenrightig\n|pk∈Hσ1(c)andpl/∈Hσ1(c)for somek,l∈{i,j}/bracerightig\n.\nThe set of prior beliefs for which decision-maker kobservesσ2while decision-maker ldoes\nnot, after observing σ1and for some processing cost, is\nVkl\nσ1:=/uniondisplay\nc>0Bkl\nσ1(c).\nTo clarify intuitions, it is useful to explore the connection between the set Vkl\nσ1and\nthe decision-makers’ willingness to pay to observe the signal’s second component, ˜σ2.\nFrom Definition 6, we see that Vkl\nσ1contains all pairs of prior beliefs for which, at some\nprocessing cost, only decision-maker k(optimally) observes σ2. This occurs only when\nkandl, given their prior beliefs and σ1, have different willingness to pay for additional\ninformation. By definition, we can express Vkl\nσ1alternatively as\nVkl\nσ1≜/braceleftig/parenleftig\npk,pl/parenrightig/vextendsingle/vextendsingle/vextendsinglecσ1/parenleftig\npk/parenrightig\n>cσ1/parenleftig\npl/parenrightig/bracerightig\n.\nIf two decision-makers’ prior beliefs belong to Vkl\nσ1, at least one must hold non-extreme\nbeliefs, and they must not be reciprocal for σ1. As we shall see, the sets Vkl\nσ1andBkl\nσ1(c)\nplay an important role in the analysis of belief polarization. Moreover, there is a tight\nconnection between the sets Vkl\nσ1andBkl\nσ1(c). By definition, (pi,pj)∈Bkl\nσ1(c)if and only if\n(pi,pj)∈Vkl\nσ1andc∈Cσ1(pk)\\Cσ1(pl).\n4.2 Belief polarization\nPolarization of beliefs occurs when two or more individuals, despite having access to the\nsame information, interpret it in ways that drive their beliefs further apart. Moreover,\ninstead of converging toward a common understanding, decision-makers update their\n18prior beliefs in opposite directions, leading to posteriors that are more distant from each\nother than before. This phenomenon is particularly striking because it suggests that even\nshared evidence may reinforce pre-existing disagreement, deepening divisions rather than\nfostering consensus. This section provides a formal definition of polarized beliefs within\nthe framework under scrutiny. It then outlines the necessary and sufficient conditions\nunder which beliefs polarize according to this definition.\nThere are two defining characteristics of polarized beliefs that we can formalize by\nusing concepts introduced in Section 4.1. First, decision-makers’ beliefs grow further\napart. Second, their beliefs move in opposite directions. The former is captured by the\ndivergence function described by equation (1), and the latter by the inversion function\ndescribed by equation (2). Following Definition 3, this paper defines polarization of beliefs\nas the simultaneous occurrence of diverging attitudes and inverse updating.6\nDefinition 7. Polarization of beliefs (PB) occurs when I(σ)<0andD(σ)<0.\nThe next proposition shows necessary and sufficient conditions for belief polarization\nbased on the decision-makers’ prior beliefs and the signal’s structure. Specifically, it shows\nthat polarization requires decision-makers, while receiving the same signal, σ, to scrutinize\nit differently: one must observe only its first component, while the other must observe\nit in its entirety. This requires at least one decision-maker to be willing, in principle, to\nincur some processing cost to observe the signal as a whole. A failure of any of these\nconditions implies that the decision-makers update their priors in the same direction. In\nsuch cases, their beliefs may diverge, but they cannot polarize.7\nProposition 3. Consider two decision-makers, iandj, such that pi<pj. Polarization\nof beliefs between decision-makers iandjoccurs with positive ex-ante probability and for\nsome processing cost if and only if,\ni)(pi,pj)∈Vij\nα∪Vji\nβ;\nii)θ2>θ 1.\nGiven a processing cost c>0, polarization of beliefs occurs with positive ex-ante probability\nif and only if\n6The notion of polarization here is more general than that used by, e.g., Jern et al. (2014). In Jern\net al. (2014, p. 3), belief divergence refers to “cases in which the person with the stronger belief in a\nhypothesis increases the strength of his or her belief, and the person with the weaker belief decreases the\nstrength of his or her belief.” Their definition excludes cases where beliefs change order. In contrast, the\nnotion of belief divergence employed here (see Definition 3) admits cases where beliefs swap order in the\nsense that if pi>pj, thenpi(σ)<pj(σ). Lemma 4 shows that polarization cannot happen via beliefs\nswap.\n7Two decision-makers with identical prior beliefs share the same incentives and thus make the same\ninformation acquisition decisions. Consequently, polarization of beliefs cannot occur between them.\nHowever, in a variation of the model, polarization between decision-makers with identical priors could\nstill occur if they have different payoff structures.\n19ii)θ2>θ 1;\niii)c<max{cσ1(pi),cσ1(pj)};\niv)(pi,pj)∈Bij\nα(c)∪Bji\nβ(c).\nProposition 3 establishes the necessary and sufficient conditions for belief polarization\nto occur with some positive ex-ante probability. However, it does not specify the events\nthat trigger polarization or quantify its likelihood. The next proposition addresses this\ngap, demonstrating that polarization arises when the signal’s components differ, i.e.,\nσ1̸=σ2. In other words, a superficial reading of ˜σmust support a different state than its\nmore precise scrutiny. The proposition also provides the probability of this event, showing\nthat it occurs less than half the time. Thus, polarization is inherently less likely to occur\nthan to not occur.\nProposition 4. When conditions i) to iv) in Proposition 3 are satisfied, and given a\nsubjective probability that the state is s=Aequal top, polarization of beliefs occurs with\nan ex-ante probability given by Pr(PB), where\nPr(PB) =Pr(˜σ1=α)·Pr(˜σ2=β)·1/braceleftig\n(pi,pj)∈Bij\nα(c)/bracerightig\n+Pr(˜σ1=β)·Pr(˜σ2=α)·1/braceleftig\n(pi,pj)∈Bji\nβ(c)/bracerightig\n.(4)\nWhen any of the conditions i)toiv)is not satisfied, then Pr(PB) = 0. Polarization of\nbeliefs occurs with an ex-ante probability that can be up to but no larger than1/2.\nProposition 4 shows that the ex-ante probability of polarization depends on the\nsubjective prior beliefs, which remain indeterminate due to the model’s allowance for\ndifferent beliefs about the state. Consequently, decision-makers and external observers\nwith different priors would also disagree on the likelihood of polarization. The next\ncorollary establishes that, provided the signal’s second component is more informative\nthan the first, (almost) no decision-maker is immune to polarization.\nCorollary 2. For any decision-maker iwith priorpi∈(0,1), and given some processing\ncostc∈/parenleftig\n0,∆U/bracketleftig\nθ2−1\n2/bracketrightig/parenrightig\n, there exists a non-empty set of priors, T ⊂ [0,1], such that,\ngiven any decision-maker jwith priorpj∈T, the condition θ2>θ 1is sufficient for belief\npolarization to occur between iandjwith positive ex-ante probability.\n4.3 Confirmatory belief patterns and reaction to information\nThis section examines the belief patterns of a single decision-maker. The model is grounded\nin standard Bayesian inference and rational choice, making it inappropriate to denote\nthe decision-maker’s optimal behavior or belief updating as biased. However, an external\n200.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0(a)Bij\nα(c)andBji\nβ(c)\n0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0 (b)Vij\nαandVji\nβ\nFigure 4: In both panels, the decision-makers’ prior beliefs are represented on the axes.\nThe left panel displays the sets Bij\nα(c)andBji\nβ(c), while the right panel illustrates the sets\nVij\nαandVji\nβ. Cases where σ1=αare shown in green, and cases where σ1=βare in blue.\nIn the left panel, a darker shade denotes a higher processing cost, with c∈{0,0.1,0.2}.\nThe dashed 45-degree line indicates pi=pj. Parameters are set to θ1=3/5,θ2=4/5, and\n∆U= 1.\nobserver might perceive them as “ as if” biased when assuming that the decision-maker\nfully knows and processes σ, thus neglecting the potential lack of incentives for information\nacquisition. Under this inaccurate lens, the decision-maker may make decisions and have\nbeliefs that are reminiscent of several well-know biases in information processing, while\nadhering to the model’s rational framework.\nThe next definition provides a formalization for attitudes that are akin to what some\nauthors refer to as disconfirmation bias . This bias is roughly described as “a propensity\nto [...] accept confirming evidence at face value while scrutinizing disconfirming evidence\nhypercritically” (Lord et al., 1979, p. 2099) or when “arguments incompatible with prior\nbeliefs are scrutinized longer, subjected to more extensive refutational analyses” (Edwards\n& Smith, 1996). Definition 8 introduces the concept of disconfirmation , which pertains\nnot to belief patterns but to the incentives for and choices of information acquisition.\nDefinition 8. A decision-maker with prior p>1/2has a tendency for disconfirmation\nwhencβ(p)> cα(p), and exhibits disconfirmation when a∗(β1) =ρ̸=a∗(α1) =¬ρ. A\ndecision-maker with prior p<1/2has a tendency for disconfirmation when cα(p)>cβ(p),\nand exhibits disconfirmation when a∗(α1) =ρ̸=a∗(β1) =¬ρ.\nDecision-makers with non-extreme beliefs always exhibit a tendency for disconfirmation.\nAs shown in Proposition 2, their willingness to pay for additional information is generally\nhigher after encountering evidence that contradicts their prior beliefs. For example, if\np>1/2andp∈¬Eβ– indicating that the decision-maker’s prior is non-extreme and favors\n21s=A– thencβ(p)> cα(p). This implies that the decision-maker’s willingness to pay\nfor observing σ2is higher after receiving evidence supporting the state s=Bthan after\nreceiving a signal supporting s=A. Likewise, if p<1/2andp∈¬Eα, thencα(p)>cβ(p).\nThe propensity to scrutinize information that contradicts one’s preconceptions is a direct\nimplication of Bayesian updating and rational decision-making.8Whether a decision-\nmaker exhibits disconfirmation depends on the processing cost, which must fall within an\nintermediate range. The next proposition formalizes these results.\nProposition 5. A decision-maker with prior phas a tendency for disconfirmation if\nand only if p∈¬E\\/braceleftig\n1\n2/bracerightig\n. A decision-maker with prior p >1/2(resp.p <1/2) exhibits\ndisconfirmation if and only if the processing cost is such that cβ(p)> c > cα(p)(resp.\ncα(p)>c>cβ(p)). This is possible only if p∈¬Eβ(resp.p∈¬Eα).\nThe following definition formalizes belief patterns that resemble what some authors\ndescribe as confirmation bias. Broadly, confirmation bias refers to the tendency to process\ninformation in a manner that reinforces one’s existing beliefs or hypotheses. As Nickerson\n(1998) describes, it involves “interpreting evidence in ways that are partial to existing\nbeliefs.” Definition 9 introduces the concepts of confirmatory anddisproving belief patterns.\nWhile confirmatory patterns may resemble attitudes associated with confirmation bias,\ndisproving patterns are introduced to complement the analysis.\nDefinition 9. A decision-maker with prior beliefs p >1/2(resp.p <1/2) exhibits\nconfirmatory belief patterns (CB) when pσ<p<p (σ)(resp.p(σ)<p<pσ), and exhibits\ndisproving belief patterns (DB) when p(σ)<p<pσ(resp.pσ<p<p (σ)).\nWhen the cost of processing additional information, c, is prohibitively high, the\ndecision-maker never observes the signal’s second component. In this scenario, both\nconfirmatory and disproving belief patterns can arise. Conversely, when cis very low,\nthe decision-maker always scrutinizes the second component, leaving no room for either\npattern to occur. However, within a moderate range of c, the decision-maker observes\nthe second component selectively—only when the first component presents contradictory\nevidence. In this range, confirmatory belief patterns can emerge, while disproving patterns\ncannot. Interestingly, this is also the range where the decision-maker has a tendency for\ndisconfirmation.\nWhen confirmatory evidence discourages further scrutiny, the decision-maker remains\nunaware of the second component’s realization. If the second component, when unobserved,\nis both contradictory and more informative, the decision-maker exhibits confirmatory\nbelief patterns. This outcome underscores an intriguing connection: confirmatory belief\n8The decision-maker’s willingness to pay for additional information at p=1/2iscα(1/2) =cβ(1/2) =\nmax{0,∆U[θ2−θ1]}, which is positive if and only if θ2>θ 1.\n22patterns often coexist with a tendency for disconfirmation. The next proposition provides\nnecessary and sufficient conditions for confirmatory and disproving belief patterns.\nProposition 6. Necessary and sufficient conditions for confirmatory and disproving belief\npatterns in a decision-maker with prior p, are\n•a relatively more informative second component of the signal, i.e., θ2>θ 1;\n•a sufficiently high processing cost, i.e., p /∈Hσ1(c)or, equivalently, c>cσ1(p);\n•for CB: ifp>1/2, thenσ= (α,β); ifp<1/2, thenσ= (β,α);\n•for DB: ifp>1/2, thenσ= (β,α); ifp<1/2, thenσ= (α,β).\nThe next definition introduces belief patterns describing individuals’ reactions to\ninformation, as seen in how they update beliefs based on new evidence. Underreaction\noccurs when an individual adjusts their beliefs less than expected given the evidence.\nOverreaction, happens when beliefs shift more than warranted by the evidence. “The\nexperimental evidence on inference taken as a whole suggests that [...] people generally\nunderinfer rather than overinfer” (Benjamin, 2019).\nIn this rational Bayesian model, decision-makers cannot inherently under- or overreact\nwhen processing all available information, as their belief updates follow Bayes’ rule.\nHowever, underreaction or overreaction can arise relative to the full information set if\ndecision-makers only acquire part of the available information—specifically, when they\nobserve only the first component of the signal, σ1, but not the second, σ2. This partial\ninformation processing leads to deviations in belief updating compared to the scenario\nwhere the complete signal σ= (σ1,σ2)is observed. The following definition formalizes\nthe notions of overreaction and underreaction with respect to σ.\nDefinition 10. A decision-maker underreacts to σ(UR) if either p < p (σ)< pσor\npσ<p(σ)<p; she overreacts to σ(OR) if either p<pσ<p(σ)orp(σ)<pσ<p.\nA decision-maker can under- or overreact to σonly if they choose not to observe the\nsignal’s second component. This outcome requires the processing cost to be sufficiently\nhigh to discourage the acquisition and processing of additional information. In such cases,\nthe direction of the reaction depends on whether the components of the signal support the\nsame state or not. Furthermore, overreaction to σis possible only if the second component\nof the signal is less informative than the first. The following proposition formalizes these\nresults, and concludes the analysis of belief patterns.\nProposition 7. A decision-maker underreacts to σif and only if σ1=σ2andc>cσ1(p).\nA decision-maker overreacts to σif and only if σ1̸=σ2,c>cσ1(p), andθ2<θ 1.\n235 Concluding remarks\nThis paper presents a model of costly information acquisition that explores how decision-\nmakers process and act on information under rational Bayesian principles. By introducing\na framework where individuals can choose between superficial and precise scrutiny of\nevidence, the analysis highlights how belief patterns such as polarization, confirmation\nbias, and underreaction to information may seem to emerge, even among rational agents.\nThese patterns are not indicative of cognitive biases but are instead driven by differing\nincentives for information acquisition. When these incentives are neglected, the decision-\nmakers’ optimal behavior is reminiscent of several biases in judgment and decision-making\ninvestigated in both psychology and economics. The findings suggest that phenomena\noften attributed to biases in human information processing may not stem from flaws in\nthe decision-makers themselves but rather from observers neglecting to account for the\nrole of incentives in information acquisition.\nIn this framework, belief polarization arises when individuals with different prior\nbeliefs make distinct choices about acquiring additional information. While some choose\nto scrutinize evidence fully, others opt for partial processing due to cost constraints. These\ndiffering courses of action, combined with the structure of the signal, may lead to diverging\nbeliefs, even when individuals share access to the same evidence. Importantly, polarization\nis shown to occur only under specific conditions, such as when one decision-maker observes\nonly part of the signal and when the signal’s components provide conflicting indications.\nA theoretical bound is provided: within this model, belief polarization should not be\nexpected to occur more often than not.\nBeyond polarization, the model also sheds light on individual belief patterns. Decision-\nmakers may exhibit behaviors reminiscent of confirmation bias or underreaction to in-\nformation when they process evidence selectively. However, these outcomes are fully\nconsistent with rational decision-making in the presence of processing costs. This rational\nframework provides a nuanced perspective, suggesting that behaviors often attributed to\ncognitive biases can result from optimal responses to constraints.\nThese results have significant implications for understanding information processing\nand belief formation in economics and psychology. The model offers testable predictions\nabout how belief patterns vary with prior beliefs, the informativeness of signals, and the\ncost of processing information. Future research can build on these insights to further\ninvestigate the interplay between incentives, information structures, and belief dynamics in\nvarious decision-making contexts. An empirical investigation may prove fruitful in testing\nthese implications and assessing the extent to which individuals deviate from a benchmark\nthat explicitly accounts for decision-makers’ incentives in information processing.\n24A Appendix\nA.1 Bayesian updating\nConsider a DM with prior p∈[0,1]. The posterior beliefs after observing σ1=αare\npα=P(A|α1) =θ1p\nθ1p+ (1−θ1)(1−p).\nConversely, the posterior beliefs after observing σ1=βare\npβ=P(A|β1) =(1−θ1)p\n(1−θ1)p+θ1(1−p).\nSuppose that the DM observes also the realization of ˜σ2. The posterior beliefs after\nobservingσ= (σ1,σ2)are\npαα=P(A|α1,α2) =θ1θ2p\nθ1θ2p+ (1−θ1)(1−θ2)(1−p),\npαβ=P(A|α1,β2) =θ1(1−θ2)p\nθ1(1−θ2)p+ (1−θ1)θ2(1−p),\npββ=P(A|β1,β2) =(1−θ1)(1−θ2)p\n(1−θ1)(1−θ2)p+θ1θ2(1−p),\npβα=P(A|β1,α2) =(1−θ1)θ2p\n(1−θ1)θ2p+θ1(1−θ2)(1−p).\nThe prior can also be represented as a function of the posteriors, and similarly, the\nposteriors after observing σ1(i.e.,pσ1) can be expressed as a function of the posteriors\nafter observing σ2(i.e.,pσ). This is because the prior is a convex combination of the\nposteriors. Within this alternative representation, we have\np=pαP(σ1=α) +pβP(σ1=β)\n=pα[P(α1|A)P(A) +P(α1|B)P(B)]\n+pβ[P(β1|A)P(A) +P(β1|B)P(B)].\nLikewise, the interim posteriors pαandpβcan be represented as convex combinations of\nposteriorspσ,\npα=pααP(α2|α1) +pαβP(β2|α1), (5)\npβ=pβαP(α2|β1) +pββP(β2|β1). (6)\n25The unconditional signal probability distributions P(α1)andP(β1)are\nP(α1) =pθ1+ (1−p)(1−θ1),\nP(β1) =p(1−θ1) + (1−p)θ1,\nwhereas the conditional signal probability distributions are\nP(α2|σ1) =pσ1θ2+ (1−pσ1)(1−θ2), (7)\nP(β2|σ1) =pσ1(1−θ2) + (1−pσ1)θ2. (8)\nA.2 Prior categorization and proof of Proposition 1\nThis section offers a rationale for the categorization outlined in Section 3.1 and provides a\nproof of Proposition 1, which formally defines the cost function.\nA.2.1 Cases 1 to 4\nCase 1:pα≥1\n2,pαα≥1\n2,pαβ≥1\n2\nThe condition pαβ≥1/2is necessary for a decision-maker who has observed σ', 'federicovaccari@gmail.com', ' Federico Vaccari', '', '../pdf_files/6749813c494f4-Belief patterns with information processing.pdf', 1070002, 45, 14150, 99267, '2024-11-29 08:54:22', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(13, '2644922873', '6745cf4203d9a', 1, 16, 'Coping with the Dunkelflaute: Power system implications of variable renewable energy droughts in Europe', '2024-11-29 16:55:50.725123', '2024', 'Coping with prolonged periods of low availability of wind and solar power, also referred to as “Dunkelflaute”, emerges as a key challenge for realizing a decarbonized European energy system fully based on renew able energy sources. Here, we investigate the role of long-duration electricity storage and geographical balancing in dealing with such variable renewable energy droughts. To this end, we combine renewable availability time series analysis and power sector modeling, using 36 historic weather years. We find that extreme drought events define long-duration storage operation and investment. The most extreme event in Europe occurred in the winter of 1996/97. Assuming policy-relevant interconnection, long-duration storage of 351 TWh or 7% of yearly electricity demand would be required to deal with this event. As it affects many countries simultaneously, a storage capacity of 159 TWh or 3% of yearly electricity de mand remains required even in the extreme case of unconstrained geographical balancing. Before and during Dunkelflaute events, we find complex interactions of long-duration storage with other flexibility options. Sensitivity analyses illustrate that firm zero-emission generation technologies would only moder ately reduce long-duration storage needs. Thus, policymakers and system planners should prepare for a rapid expansion of long-duration storage capacity to safeguard the renewable energy transition in Europe. We further argue that including multiple weather years is required for weather-resilient energy system modeling, particularly those with pronounced renewable energy droughts', 'variable renewable energy,variable renewable energy droughts,long-duration storage,power sector modeling', 'Coping with the Dunkelflaute: Power system implications of variable\nrenewable energy droughts in Europe\nMartin Kittela,b,∗, Alexander Rotha, Wolf-Peter Schilla\naDIW Berlin, Department of Energy, Transportation, Environment, Mohrenstraße 58, 10117 Berlin, Germany\nbTechnical University Berlin, Digital Transformation in Energy Systems, Einsteinufer 25 (TA 8), 10587 Berlin, Germany\nAbstract\nCoping with prolonged periods of low availability of wind and solar power, also referred to as “Dunkelflaute”,\nemerges as a key challenge for realizing a decarbonized European energy system fully based on renew-\nable energy sources. Here, we investigate the role of long-duration electricity storage and geographical\nbalancing in dealing with such variable renewable energy droughts. To this end, we combine renewable\navailability time series analysis and power sector modeling, using 36 historic weather years. We find that\nextreme drought events define long-duration storage operation and investment. The most extreme event\nin Europe occurred in the winter of 1996/97. Assuming policy-relevant interconnection, long-duration\nstorage of 351 TWh or 7% of yearly electricity demand would be required to deal with this event. As\nit affects many countries simultaneously, a storage capacity of 159 TWh or 3% of yearly electricity de-\nmand remains required even in the extreme case of unconstrained geographical balancing. Before and\nduring Dunkelflaute events, we find complex interactions of long-duration storage with other flexibility\noptions. Sensitivity analyses illustrate that firm zero-emission generation technologies would only moder-\nately reduce long-duration storage needs. Thus, policymakers and system planners should prepare for a\nrapid expansion of long-duration storage capacity to safeguard the renewable energy transition in Europe.\nWe further argue that including multiple weather years is required for weather-resilient energy system\nmodeling, particularly those with pronounced renewable energy droughts.\nKeywords: variable renewable energy, variable renewable energy droughts, long-duration storage, power\nsector modeling\n1. Introduction\nTo mitigate climate change and to meet international commitments, the European Union aims to achieve\nnet zero emissions of greenhouse gases by 2050. The electricity sector will play a central role in a decar-\nbonized economy. Massively expanding renewable energy sources would not only allow for rapid decar-\nbonization of the power sector but also for substituting the use of fossil fuels in other sectors, such as\n∗Corresponding author\nEmail addresses: mkittel@diw.de (Martin Kittel), aroth@diw.de (Alexander Roth), wschill@diw.de (Wolf-Peter\nSchill)\nPreprint submitted to arXiv November 27, 2024arXiv:2411.17683v1  [econ.GN]  26 Nov 2024industry, transport, and heat, via electrification, also referred to as “sector coupling” [1–5].\nThe potentials of firm renewable energy sources, such as hydroelectric or bioenergy, are limited in most\nEuropean countries. In contrast, wind and solar power offer vast expansion potentials and promise declin-\ning costs [6, 7]. Therefore, variable wind and solar power will likely form the backbone of the transition\nto net zero in most European countries [1, 8].\nWith a rising share of variable renewable energy (VRE), the European power system becomes increasingly\nexposed to weather variability [9, 10]. This has spurred a debate in the energy policy domains about\nthe security of supply [11–20]. Of particular concern are long-lasting periods also referred to as “VRE\ndroughts” or the German term “Dunkelflaute”, which are characterized by a very low availability of VRE\nsources [21, 22].\nPrevious research has shown that growing shares of VRE sources require an increasing amount of flexibility\nin the power sector. This can be provided by different types of electricity storage, demand response, or\ncross-border transmission [23–27]. While a wide range of flexibility technologies can help to cope with\nVRE droughtse is a central option for this as it can shift VRE surplus energy to periods of low wind and\nsolar availability across long time scales [28–30]. Reconversion of hydrogen or hydrogen-based derivatives\nto electrical energy, which are produced with renewable electricity, appears as the most promising option\nfor storing renewable energy over long periods [29, 31, 32].\nSpatial flexibility, facilitated by the interconnection between different countries, allows balancing of re-\ngional variations in demand and variable renewable supply [33, 34]. In Europe, cross-border interconnec-\ntion can mitigate energy storage needs, particularly by balancing differences in wind power availability\nacross countries [35]. Yet, it is unclear to what extent this storage-mitigating effect of geographical balanc-\ning via transmission remains feasible in extreme pan-European VRE droughts of synoptic scale, affecting\nmany countries simultaneously [30].\nIn this paper, we analyze the impact of VRE droughts on long-duration storage operation and sizing in\na fully renewable European electricity system. We further investigate how varying levels of geographical\nbalancing via interconnection affect these long-duration storage needs. We also examine power sector\noperation in extreme VRE droughts.\nWhile the research interest in VRE droughts and their electricity system implications is growing, respec-\ntive analyses vary regarding the research subject and temporal and spatial scope [22]. One strand of the\nliterature focuses on VRE droughts characterization based on time series wind speeds, solar irradiation,\nor normalized renewable availability factors. This includes analyses of historic or future wind droughts\nfor Germany [36], the North Sea [37], Ireland [38], or the U.K. [39–42]. These studies typically focus\non frequency-duration distributions, return periods, or spatio-temporal correlations. Wind droughts have\nbeen studied as VRE anomalies, i.e., cumulative deviations from climatological means or other reference\nprofiles, on a global scale [43] or for the Netherlands, including wind and solar droughts [44]. Combin-\ning wind and solar power in renewable technology portfolios can mitigate drought characteristics within\n2regions. This portfolio effect has been studied for Europe [21, 30, 45–48], the U.S. [49], or individual coun-\ntries, such as Germany [50, 51], Hungary [52], India [53], and Japan [54]. In addition, the complementary\nof wind and solar across regions further reduces extreme drought severity. This balancing effect has been\nshown for Europe [30, 47, 48, 50] and the U.S. [49].\nAnother literature strand explores positive residual load events, which relate to periods where VRE\ngeneration falls short of electrical demand and may occur during peak load and/or VRE drought periods\n[22]. These periods indicate the need for system flexibility, particularly for long-duration storage assuming\nlimited potential for geographical balancing via transmission. Positive residual load events have been\nstudied for Europe [21, 55–58], Norway, France, Italy, Spain and Sweden [59], Germany [60], Northern\nItaly [61], Africa [62], or the U.S. [63].\nVRE droughts that cause electricity system stress events can be detected through extreme electricity\nprices, shadow prices reflecting the value of the stored energy or transmission grid capacity, or emission\npatterns, as shown for Europe [64] or the U.S. [65–67]. Abstracting from cross-border electricity exchange\nand using historic renewable availability, Ruhnau and Qvist [60] find 55 TWh long-duration electricity\nstorage is required in a renewable German power system for dealing with the most extreme positive\nresidual load event, which occurred in winter 1996/97. Another model-based study by Kondziella et al.\n[68] finds that 67 TWh hydrogen storage is needed to deal with a stylized 2-week Dunkelflaute in Germany,\nfeaturing low wind and solar generation and high electricity demand. The long-duration storage capacity\nrequired to cope with renewable energy droughts corresponds to around 10% [60] or 9% [68] of the assumed\nyearly electricity demand in these two studies on Germany.\nEnergy system models increasingly include multiple sectors and energy carriers to explore future scenarios\nof sector-coupled energy systems [69, 70]. Due to increasing complexity and computational burden,\nthese models are often solved for only a single or a limited number of weather years. However, optimal\nenergy model outcomes vary substantially across years. These variations include optimal dispatch and\ninvestment decisions for electricity generation based on fossil fuels or renewable sources, electricity storage,\nor transmission grid capacities, as well as electricity demand, prices, levelized costs of electricity, or\nemissions. This is well-documented for single countries such as the UK [9, 71–74] or Ireland [74], Europe\n[10, 75–78], or the U.S. [29, 79, 80]. A general finding is that energy systems modeling based on only\none or a few weather years identifies energy system configurations that may lead to suboptimal capacity\nchoices or operational inadequacies. Extreme renewable drought events, which vary substantially across\nyears and regions, are likely to contribute significantly to these inter-annual variations in energy system\nmodeling [30].\nWhile there is growing interest in the meteorology and energy systems analysis domains on the impact of\nweather variability on renewable energy systems [81], the literature lacks a distinct analysis of the impact\nof extreme renewable drought events on energy storage needs, and how spatial system flexibility alleviates\nthese.\n3In this paper, we combine two open-source methods to investigate how VRE droughts impact the need for\nlong-duration storage in a fully decarbonized European power sector: renewable time series analysis and\na capacity expansion model of the power sector. We further quantify how much long-duration storage can\nbe avoided with different degrees of electricity and hydrogen exchange between countries. We determine\nthe long-duration storage need for dealing with extreme renewable droughts considering policy-oriented\nEuropean interconnection levels, what “no-regret” long-duration storage capacity remains for a scenario\nwith unconstrained geographical balancing of such events, and how much these results vary across years.\nIn doing so, we also shed light on appropriate weather year selection for modeling weather-resilient energy\nsystem scenarios in Europe and illustrate how different types of flexibility options interact while coping\nwith extreme renewable droughts.\n2. Methods\nIn this study, we combine two methods: a VRE drought analysis based on availability time series of wind\nand solar power, and a cost-minimizing capacity expansion model of the European power system.\n2.1. Variable renewable energy droughts identification method and data\nWe use the open-source tool Variable Renewable Energy Drought Analyzer (VREDA) to identify and\nevaluate VRE drought patterns based on availability time series. VREDA has been designed to implement\ngood practices of multi-threshold drought identification as outlined by Kittel and Schill [22] and has\nbeen applied before to characterize drought patterns in Europe [30]. It employs the varibale-duration\nMean-Below-Threshold (VMBT) method for drought identification, which varies the permissible drought\nduration between two full calendar years and one hour. This method searches for periods where renewable\navailability has a moving average below a specific drought qualification threshold by iteratively decreasing\nthe drought duration. In each iteration, the algorithm sets the averaging interval to the respective event\nduration. Initially, it searches for drought events that last two full years and iteratively decreases the\naveraging interval to identify shorter events. A time series section with a moving average below the\ndrought threshold identifies a drought event. It is then excluded from subsequent iterations, in which the\naveraging interval decreases further and additional (shorter) events are identified.\nThe iterative procedure of VMBT overcomes shortcomings of previous research [22]. The method al-\nlows for pooling of adjacent periods that independently may not qualify as VRE drought to capture\nlonger-lasting events, i.e., intermediate periods with a renewable availability above the drought thresh-\nold. It further identifies unique events, avoids double counting as well as overlaps with adjacent events,\nand captures the full temporal extent of drought periods (“event” definition). The code and input\ndata of the drought analysis tool are publicly available on GitLab at https://gitlab .com/diw-evu/\nvariable renewable energy droughts analyzer .\nWe use country-level VRE availability time series provided by the Pan-European Climate Database,\nincluding 36 weather years from 1982 to 2016 for on- and offshore wind and solar photovoltaics (PV) [82].\n4For comparability across regions, drought thresholds are determined as a fraction of country-specific long-\nrun mean availability factors for the period 1982 to 2016 [22]. These fractions range from 10 to 100% of\nmean availability, reflecting different levels of drought severity, increasing in 5% increments. Periods that\nqualify as drought events based on lower thresholds are likely brief and severe with very low availability.\nIn contrast, events identified by higher thresholds may last substantially longer, i.e., up to several weeks\nor months [30].\nWe analyze drought patterns for renewable technology portfolios, comprising on- and offshore wind as\nwell as solar PV, for two cases that differ regarding the assumed electricity transmission between coun-\ntries [22]: completely isolated countries (“energy islands”) or perfect interconnection across all countries\n(pan-European “copperplate”). For the energy islands scenario, we combine all technology-specific time\nseries into a portfolio time series using capacity-weighted averages. The respective weights are based\non policy-relevant assumptions on renewable capacity mixes from the Ten Year Network Development\nPlan (TYNDP) 2022 (scenario “Distributed Energy”) [83]. We update these assumptions for Germany\naccording to the latest government targets [84]. For the copperplate scenario, we combine all country-\nlevel portfolio time series into a single pan-European composite time series, using weights according to\nthe TYNDP 2022 (scenario Distributed Energy).\nWe use the “drought mass” metric devised by Kittel and Schill [30] to identify extreme drought events\nby aggregating the drought patterns of numerous single-threshold analyses, ranging in 5%-increments\nfrom the 10% to 75% threshold. To compute the drought mass score, we first modify these patterns by\nassigning the value 1 to drought hours and the value 0 to those hours that do not qualify as drought for\neach threshold. Next, we equally weigh the resulting drought patterns across all thresholds. We then\naccumulate the hourly scores up to the cut-off threshold 75%, excluding the drought patterns based on\nhigher thresholds. This approach determines the multi-threshold event duration according to the 75%-\nanalysis, while the event drought mass aggregates the drought patterns identified by included thresholds.\nThe highest cumulative score identifies the most extreme event per summer-to-summer planning horizon.\nWind droughts are more frequent and severe in summer than in winter [30, 36, 39]. In countries with\nhigh wind shares in their capacity portfolio, the most extreme renewable portfolio drought events may\nthus also occur in summer. Since peak electricity demand periods usually occur in winter in Central and\nNorthern European countries, summer droughts generally matter less than winter droughts. To account for\nthis, we compute a yearly drought mass score for droughts occurring throughout the summer-to-summer\nplanning horizon and a winter drought mass score for drought events between October and March. When\nillustrating the relation of drought patterns and long-duration storage operation, we display both the\nmost extreme summer and winter droughts if the highest drought mass score relates to summer drought\n(compare gray and teal boxes in Figure 1). Conversely, we mark only one event if the highest yearly\ndrought mass score refers to a winter drought (compare gray boxes only in Figure 1).\n52.2. Power sector model\nIn this paper, we use the open-source dispatch and capacity expansion model of the European power sector\nDispatch and Investment Evaluation Tool with Endogenous Renewables (DIETER) [24, 85, 86] to analyze\nthe interaction between VRE droughts and long-duration storage needs in a fully renewable European\npower system. The model features a simple transport model for exchanging electricity across countries,\nabstracting from grid constraints within countries. It has previously been applied to study various aspects\nof VRE integration and their interaction with flexibility options or sector coupling technologies [35, 86–95].\nDIETER is a linear program that determines least-cost capacity and dispatch decisions, optimizing over\nall contiguous hours of a full year under perfect foresight.\nExogenous model inputs entail techno-economic parameters such as investment and variable costs, avail-\nability time series of wind and solar PV, as well as price-inelastic demand time series for electricity and\nhydrogen. Model results can be interpreted as the outcomes of a perfect, frictionless European electricity\nmarket, where all power generators maximize their profits. Costs are minimized for the overall system, de-\npending on interconnection assumptions. In the energy islands case, costs are optimized for every country\nin isolation.\nWhile the general model formulation of DIETER has been described extensively in the papers mentioned\nabove, we use a version that features an improved representation of hydrogen technologies in this study.\nThe model includes the generation, storage, and transport of renewable hydrogen technologies as well as\nits re-conversion to electricity. The hydrogen-based long-duration storage energy capacity denotes the\nlower heating value of the storage working gas. A formal definition of the novel equations is available in\nthe Supplementary information SI.1.\nFor transparency and reproducibility, we provide the model code, the input data, and a manual in public\nrepositories under permissive licenses available on GitLab at https://gitlab .com/diw-evu/projects/\npower-sector-droughts/ .\n2.3. Scenarios\nOur analysis comprises 33 European countries (EU27, the UK, Norway, Switzerland, and the Western\nBalkans). We analyze and compare the impact of VRE droughts on long-duration storage needs for four\ndifferent interconnection states: (1) all countries operate as energy islands without exchange of electricity\nor hydrogen between countries; (2) cross-border exchange of electricity in line with the assumptions on\nthe European transmission grid in 2050 projected by the TYNDP 2022 [83] (scenario Distributed Energy),\nwhile hydrogen exchange remains disabled; (3) cross-border electricity and hydrogen exchange according to\nthe TYNDP 2022 (scenario Distributed Energy); and (4) unlimited exchange of electricity and hydrogen,\ni.e, all countries are perfectly integrated as pan-European copperplate. Note that VRE drought analysis\nbased on renewable availability time series can only be carried out for the two extreme interconnection\nsettings energy islands and copperplate (compare Section 2.1).\n6These varying degrees of interconnection allow distinguishing several effects. First, scenario (1) identi-\nfies maximal long-duration storage needs across European countries, excluding geographical balancing of\nVRE droughts between countries [30]. Second, comparing scenarios (2) and (3) disentangles the effects\nof policy-oriented electricity and hydrogen interconnection levels on long-duration storage needs. Finally,\nthe copperplate scenario (4) identifies minimal long-duration storage needs, including unconstrained geo-\ngraphical balancing of VRE droughts, which can be interpreted as unavoidable or “no-regret” investments\nin a fully renewable European energy system. We abstract from grid investment costs but impose losses\non hydrogen exchange related to compression for long-distance transport via pipeline.\nOur objective is to assess the role of system flexibility and the impact of inter-annual variability in the\ncontext of VRE droughts. Besides varying interconnection levels, we therefore investigate a large number\nof weather years that differ in renewable availabilities and demand patterns. These weather years range\nfrom 1982 to 2016. Extreme VRE droughts often occur in European winter, may last up to several weeks,\nand span across the turn of years [30]. Hence, we use a summer-to-summer planning horizon [60, 64],\ncomprising 8760 consecutive hours. Note that we independently optimize the capacity mix for every year.\n2.4. Input data, technology portfolio, and capacity bounds\nTo quantify the maximum impact of VRE droughts on long-duration storage, we model fully renewable\nsupply scenarios, excluding carbon capture and storage (CCS) and fossil fuel-based dispatchable generation\ntechnologies. This is not enforced by binding renewable or carbon emission targets [90] but rather by\nlimiting the available generation technology portfolio to zero-emission technology options. These options\ninclude solar PV, on- and offshore wind power, bioenergy, and different types of hydroelectric power\n(run-of-river, reservoir, pumped-hydro). In a sensitivity analysis, we add a firm zero-emission generation\ntechnology.\nFor policy relevance, we allow generation capacity expansion within lower and upper potentials of the\nTYNDP 2024 [96]. Additionally, we assume an annual generation limit for bioenergy in line with the\nTYNDP 2022 [18]. Installed power and energy capacities of the available hydro technologies are fixed to\nvalues provided in European Resource Adequacy Assessment (ERAA) 2021 [97].\nWe include underground hydrogen storage as a long-duration storage option. Underground cavern and\nporous storage energy potentials vary substantially across countries, including newly built and retrofitted\nstorage facilities from natural gas infrastructure [98, 99]. We constrain the expansion of long-duration\nstorage energy capacities accordingly. For simplicity, we abstract from any differentiation between under-\nground storage types and aggregate their potentials for each modeled country.\nIn our analysis, we attempt to illustrate the impact of persistent VRE droughts lasting longer than a few\ndays on the power sector, notably regarding long-duration electricity storage. We thus abstract from an\nexplicit representation of sector coupling options as well as seasonal heat storage. To this end, we use\nnear-term demand profiles, retrieved from ERAA 2021 [97] (representative for the year 2025). The profiles\n7are scaled to the annual demand levels of the TYNDP (scenario Distributed Energy for 2050) and are\nreduced by the electrical energy amount required for the generation of the exogenous hydrogen demand.\nWe use the Pan-European Climate Database for renewable availability factors of on- and offshore wind\nand solar PV [82], as well as the hydro inflow, retrieved from the ERAA 2021 [97].\n3. Results\n3.1. Extreme renewable energy droughts coincide with major discharging periods of long-duration storage\nTo analyze the impact of VRE droughts on long-duration storage, we first provide an intuition on how\nthe long-duration storage operation is affected by such events. Figure 1 illustrates drought patterns of\nthe renewable technology portfolios and long-duration storage operation for the weather year 1996/97,\nwhich comprises the most extreme pan-European drought we find in the data (Figure SI.2), affecting many\nEuropean countries simultaneously [30]. For each region, it shows the events with the highest drought\nmass score, which comprise sequences of shorter but more severe droughts within contiguous periods of\nwell-below-average renewable availability that may last up to several months and span across the turn of\nyears.\nNotes: For each region, the figure illustrates identified drought patterns lasting longer than 12 hours across all color-coded thresholds\n(upper panel) and the most extreme drought events occurring in winter (teal boxes). For the UK, where the most extreme drought\nthroughout the year occurs in summer, this event is additionally shown (gray box). The lower panels show exogenous demand\nprofiles, which have been smoothed to highlight demand seasonality. They further display optimized storage state-of-charge levels\nfor isolated countries modeled within the interconnection scenario (1) and for the pan-European copperplate (CP) of scenario (4).\nFigure 1: Drought events, electricity demand, and state-of-charge of long-duration storage in winter 1996/97.\nDuring these long-lasting events, average renewable availability is well below its long-run mean, but still\nremains above zero. This means that long-duration storage is not necessarily required to continuously\n8discharge during the entire identified drought event. However, these events comprise periods with signif-\nicantly lower availability, lasting multiple days or even two to three weeks. In these periods, storage is\ndischarged at capacity and the storage state-of-charge accordingly declines, particularly when co-occurring\nwith peak-demand periods.\nExtreme events typically occur in winter, leading to significant long-duration discharge periods. Countries\nthat heavily rely on wind power, such as the UK, may face the most extreme renewable technology portfolio\nevents also in summer, driven by wind droughts that are generally more pronounced in summer in Europe\n[30, 36, 39]. Yet, the UK’s electricity demand is much higher in winter than in summer, similar to other\ncentral and northern European countries. As this seasonal demand effect by far outweighs the differences\nbetween summer and winter droughts, UK’s major storage discharging period still coincides with the\nwinter drought. In contrast, the slightly larger summer drought hardly affects the storage state-of-charge.\n3.2. Droughts drive long-duration storage energy capacity\nThe most severe drought events define not only major long-duration storage discharge. For each modeled\nweather year, there is also a clear positive correlation between the most extreme renewable droughts in a\ngiven country and that country’s long-duration storage energy need (Figure 2a). We find that this applies\nto nearly all European countries modeled as energy islands and also to the pan-European copperplate\nscenario.\n0 10k 20k00.020.040.060.080.10.120.14\nDE\nES\nFR\nNL\nPL\nRO\nUK\nCP\ndrought massnormaliz ed long-dur ation stor age energydata / regression:\n(a) Long-duration storage only.\n0 10k 20k00.020.040.060.080.10.120.14\nDE\nES\nFR\nNL\nPL\nRO\nUK\nCP\ndrought massnormaliz ed mid- and long-dur ation stor age energydata / regression: (b) Mid- and long-duration storage.\nNotes: For comparison, we normalized the optimal storage energy by annual demand for electricity (including electrified heating) and\nhydrogen. For illustration, we exclude countries with optimal storage energy below 5 TWh or investment at potential. Figure SI.3\nshows the unfiltered regression results and emphasizes the substitutability of mid- and long-duration storage needs.\nFigure 2: Correlation of the drought mass of most extreme winter drought events and normalized storage energy capacity.\nThe correlation between the most extreme winter drought events and storage needs differs between coun-\ntries. In Central European countries such as France or the UK, storage capacity increases substantially in\nyears with more severe droughts, illustrated by the steep gradient of the fitted regression lines in Figure 2.\nThis is because electricity demand has a pronounced winter peak in these countries (Figure 3). In contrast,\nmore severe droughts hardly increase storage needs in other countries, particularly in Romania or Spain,\n9driven by a less seasonal or even summer-peaking electricity demand in such countries. Complementary\nGermany-only analysis using flat electricity demand profiles exemplarily disentangles the storage-defining\neffect of renewable droughts from the storage-driving effect of demand seasonality for the German power\nsector (compare blue and orange lines in Figure 4). The incline of the regression gradient decreases when\nflattening electricity demand profiles, i.e., the storage-defining effect of droughts is less pronounced.\nThere is also a combined level and gradient effect. Normalized long-duration storage energy needs are\ngenerally much lower in Spain or the pan-European Copperplate than those in Central or Northern\nEuropean countries. One driving factor for this are significant hydro reservoir and pumped-hydro storage\ncapacities in Spain or Europe, which substitute long-duration storage needs for dealing with extreme\ndroughts to some extent. This leads to a lower sensitivity of long-duration storage needs to increasingly\nsevere droughts, visible as lower regression line intercepts and, in the case of Spain, a low regression\ncoefficient. Considering both hydro and long-duration storage capacities for the regression eliminates this\neffect (Figure 2b).\nIn the pan-European copperplate scenario, droughts are notably less severe than in individual countries\n(lower drought mass), resulting in significantly reduced normalized storage needs. This is due to a geo-\ngraphical balancing effect, which spatially smooths renewable generation and demand patterns, thereby\nmitigating extreme droughts [30, 35].\nThe scatter plot indicates that the correlation between the most extreme winter drought event and the\noptimal long-duration storage size for the same year is not perfect. Several factors explain this. First,\ncountry-specific factors such as varying portfolios of variable or firm renewable generation capacity or\nflexibility options, e.g., high shares of reservoir power plants in the Spanish capacity mix, may cause\nthe imperfect fit. Second, demand peaks vary substantially between weather years in terms of level and\ntemporal variation, especially in winter (compare France in Figure 3). This means that similar droughts\ncan trigger different storage needs, depending on the load situation. Third, our measurement of drought\nevents is, by design, purely based on renewable availability time series and does not consider pre- or\nsucceeding periods of very high availability or the seasonality of electricity demand. In contrast, the power\nsystem optimization factors in these aspects. In addition, the drought mass metric based on the VMBT\nmethod relies on the choice of a cut-off threshold and is solely an approximation of the cumulative energy\ndeficit of drought events [22], which is relevant for long-duration storage needs. Due to the averaging\nmechanism of the VMBT method, this metric tends to underestimate solar PV contributions within\nextreme droughts, particularly in countries with a less pronounced solar seasonality. These contributions\ngenerally lead to higher deployment of short-duration system flexibility and lower long-duration storage\nneeds. Finally, VRE portfolios differ to some extent between the drought analysis and the power system\nmodel. While these portfolios are fixed in the former, they are optimized in the latter, yielding slightly\ndifferent capacity mixes between weather years. Yet, the overall fit between the indicators appears to be\nreasonable, which can also be confirmed by a complementary Germany-only analysis (compare dark and\nbright lines in Figure 4).\n106008001000\n100150\n3040506070\n50100\n203040\n20304050\n1015\nJul Aug Sep Oct Nov Dec Jan Feb Mar Apr May Jun6080100120demand [GW] demand [GW] demand [GW] demand [GW] demand [GW] demand [GW] demand [GW] demand [GW]CP (21%)\nDE (17%)\nES (21%)\nFR (41%)\nNL (15%)\nPL (24%)\nRO (20%)\nUK (31%)Notes: The figure shows climatological mean demand as a bold line over all years using a moving average over a window of 168h\n(resulting in the blank first week) as a line, the standard deviation range as an area ( mean ±std dev , dark green), the difference\nbetween the climatological minimum and maximum as an area using a moving average over a window of 24h (light green), and\nthe regional difference between the minimum and maximum climatological mean normalized by the maximum in parenthesis. Each\nvertical axis is scaled to show its range if demand seasonality in this region was as pronounced as in France.\nFigure 3: Demand seasonality across countries, which is particularly pronounced in France both in terms of level but also\nvariance within winter months due to high shares of electrified heat.\n115k 10k 15k00.010.020.030.040.050.060.07\nyearly load profiles with endogoneous VRE capacities\nyearly load profiles with fix ed VRE capacities\nflat load profiles with endogoneous VRE capacities\nflat load profiles with fix ed VRE capacitiesdrought massstorage energy normaliz ed by annual demand\ndata / regression:Notes: For comparison, we normalized the optimal storage energy by annual demand for electricity (including electrified heating)\nand hydrogen. The renewable portfolio assumptions of the scenarios with fixed VRE capacities align with those used for the time\nseries-based VRE drought analysis. In contrast, the scenarios with endogenous VRE capacities are optimized by our power sector\nmodel.\nFigure 4: Correlation of the drought mass of most extreme winter drought events and normalized storage energy capacity\nin Germany.\n3.3. Long-duration storage needs decrease with geographical balancing\nInterconnection provides spatial power system flexibility to cope with VRE droughts, which affects long-\nduration storage needs. Figure 5 illustrates how interconnection mitigates the need for long-duration\nstorage. Scenario (1) shows the results if every country was an energy island, excluding the possibility of\nexchanging electricity or hydrogen with its neighbors to mitigate extreme renewable droughts. Here, an\naggregated median (maximum) long-duration storage energy capacity of 232 (378) TWh is required across\nall modeled countries. This corresponds to around 4.7 (7.6)% of the yearly European electricity demand.\nScenario (2) allows for policy-oriented TYNDP cross-border exchange of electricity, which reduces the\nmedian (maximum) long-duration storage energy to 206 (385) TWh, or 4.2 (7.8)%. The slight increase\nin the maximum requirements is mainly driven by an increase in offshore wind generation in Belgium,\nwhich is transmitted to and stored in additional long-duration storage in the Netherlands, while long-\nduration storage energy capacity remains at expansion potential in Belgium. When additionally including\nhydrogen exchange within policy-oriented limits (scenario (3)) decreases the median long-duration storage\nenergy even more to 170 (351) TWh, or 3.4 (7.1)%. Finally, scenario (4) allows for the unconstrained\nexchange of electricity and hydrogen, leading to the lowest storage needs with a median value of 91\n(159) TWh, corresponding to 1.8 (3.2)% of yearly electricity demand. The decreasing storage energy\nwith increasing interconnection capacity is due to geographical balancing, which smooths storage-defining\nrenewable droughts [30].\nStorage results show a substantial degree of inter-annual variation. This is driven by differences in renew-\nable energy droughts and demand patterns across years (compare Figure 3). The inter-annual variation\nincreases in scenarios (2) and (3), which allow for policy-oriented geographical balancing compared to the\n12Notes: Each dot refers to one modeled weather year, which is modeled independently of other weather years. The year with the\nhighest long-duration storage need is 1996/97 (red). The year that benefits most from rising interconnection capacity in terms of\ndecreasing long-duration storage needs is 1988/89 (green). The year that benefits the least from increasing interconnection is 1987/88\n(orange). Figure SI.6 illustrates the impact of interconnection on the ranking of weather years in terms of optimal long-duration\nstorage energy.\nFigure 5: Optimal long-duration storage energy capacity aggregated across all countries for all modeled weather years and\ninterconnection scenarios.\nisland setting. This is because the correlation of storage-defining drought events in individual countries\nvaries across space and time across weather years [30]. When drought events do not occur simultaneously\nacross countries, a more pronounced geographical balancing can reduce long-duration storage needs, ex-\npanding the lower bound of the storage energy capacity range. The effect is even more pronounced when\nincluding cross-border exchange hydrogen (scenario (3)). We find the lowest weather year variation in the\ncopperplate scenario, in which all drought events are balanced to the fullest extent possible.\nThe year 1996/97 marks the period with the highest long-duration storage investments across all inter-\nconnection scenarios, which is in line with the most extreme drought in Europe that we find in renewable\navailability data (Figure SI.2). The reducing effect of geographical balancing via policy-oriented inter-\nconnection on total storage needs is limited. This is because storage-defining drought events in winter\n1996/97 are strongly correlated and co-occurring (see teal boxes in Figure 6) and largely coincide with win-\nter demand peaks. In contrast, the unconstrained balancing in the copperplate scenario (4) substantially\nmitigates overall storage needs. In other years, the effects of interconnection may play out differently. For\ninstance, geographical balancing has a particularly strong storage-mitigating effect in the year 1988/89,\nas the largest droughts in major countries hardly overlap and co-occur with high demand periods only to\na limited extent (Figure SI.4). In contrast, the period 1987/88 seems less affected by interconnection. Its\nrelative position in the ranking of years even slightly increases with increasing interconnection. This can\nbe explained by a large temporal overlap of droughts in individual countries (Figure SI.5). Figure SI.6\nadditionally illustrates the change of weather year ranking as interconnection levels increase.\nFigure 5 shows Europe’s minimum need for long-duration storage capacity. This can be inferred from\n13Notes: For each region, the figure illustrates identified drought patterns lasting longer than 12 hours across all color-coded thresholds\n(upper panel) and the most extreme drought events occurring in winter (teal boxes). For the UK, where the most extreme drought\nthroughout the year occurs in summer, this event is additionally shown (gray box). The lower panels show exogenous demand\nprofiles, which have been smoothed to highlight demand seasonality. They further display optimized storage state-of-charge levels\nfor isolated countries modeled within the interconnection scenario (1), for policy-oriented interconnection levels in scenario (3), and\nthe pan-European copperplate (CP) in scenario (4).\nFigure 6: Drought events, electricity demand, and state-of-charge of long-duration storage in winter 1996/97 in countries\nwith highest long-duration storage energy capacities.\n14scenario (4), which allows for unlimited exchange of electricity and hydrogen between countries. The\nresults suggest that this “no-regret” level of storage investments ranges amount to 159 TWh or 3.2% of\nthe yearly European electricity demand. This amount of long-duration storage is needed to balance the\nremaining energy deficit of the most extreme VRE drought in the data after unconstrained geographical\nbalancing and cannot be further compensated by additional interconnection. Given policy-oriented inter-\nconnection levels in scenario (3), our analysis suggests that the need for long-duration storage capacities\nranges between 67 and 351 TWh, equivalent to 1.4-7.1% of the yearly European electricity demand. If\nthe envisaged interconnection levels cannot be realized but remain at the current level, then long-duration\nstorage needs will likely be higher and range between the outcomes of scenarios (1) and (3).\nlicable here). See Grochowitdifferentp.org/article/10.108 for coping with extreme droughts8/1748-9326/ad374a)\nFigure 7 illustrates the power sector operation for exemplary weeks in Germany and Spain for the weather\nyear 1996/97. These optimized dispatch patterns reveal complex interactions between short-duration\nflexibility options such as batteries or pumped hydro storage and longer-duration flexibility options. The\nlatter include hydrogen-based electricity storage, hydro reservoirs, and dispatchable bioenergy. These\nflexibility options differ in their cost structures. Short-duration power capacity costs are relatively low\ncompared to high energy capacity costs. As storage duration rises, this relation increasingly inverts.\nElectrolysis and gas turbines, used for long-duration storage charging and discharging, incur high power\ncapacity costs, while long-duration energy capacity costs are substantially lower. When combining these\nflexibility options, we observe five effects in dispatch patterns that enable coping with extreme VRE\ndroughts at the lowest possible cost.\nFirst, electrolysis for long-duration storage charging typically occurs before but also within major re-\nnewable energy droughts (Figure 7a). In certain situations, short-duration battery storage cycles, i.e., it\ncharges and subsequently discharges, while electrolyzers are continuously running. Similarly, bioenergy\ngeneration or hydro reservoirs may generate electricity in such long-duration charging periods. This\nspecific operation leverages the lower-cost power capacity of different flexibility options to increase elec-\ntrolyzer full-load hours not only in negative but also in positive residual load situations, which minimizes\nelectrolysis capacity needs. Without this interaction, additional electrolysis capacity would be required\nto run in renewable surplus situations where electrolysis is at capacity.\nSecond, battery cycling may conversely also occur in periods of uninterrupted discharging of long-duration\nstorage, i.e., while hydrogen gas turbines generate electricity (e.g., on December 12 in Figure 7b). Charging\nbatteries with electricity that is discharged from hydrogen-based storage may appear counter-intuitive as\nit incurs additional energy losses from conversion. Yet, this combined use of different flexibility options\nminimizes the hydrogen gas turbine capacity required during peak residual load events. The battery\ncapacities do not incur additional investment costs here, as they are anyway required for diurnal balancing\nin other periods of the year. In other words, long-duration storage may provide all the energy capacity\nneeded to cope with a renewable drought but not necessarily all the power capacity. Similarly, shorter-\n15(a) Long-duration charging period in Germany before an extreme drought.\n(b) Long-duration discharge period in Germany within an extreme drought.\n(c) Long-duration discharge period in Spain within an extreme drought.\n(d) Long-duration storage follows diurnal solar PV pattern in Germany during summer.\nFigure 7: Optimized power sector operation in Germany and Spain for the weather year 1996/97. The positive part of the\nleft y-axis relates to generation and storage discharge, and its negative part to electricity demand and storage charge. The\nright y-axis refers to the long-duration storage state-of-charge. For illustration, we focus on scenarios excluding cross-border\nexchange of electricity or hydrogen.\n16duration storage temporally shifts renewable surplus to avoid additional hydrogen gas turbine capacity\ninvestments (e.g., battery and pumped hydro charge on December 16 and discharge on December 17 and\n18 in Figure 7b).\nThird, short-duration flexibility options are used to balance brief events of renewable surplus generation\nwithin longer drought events. In such cases, the discharging of long-duration storage is interrupted,\nand batteries and pumped hydro storage are used instead for short-duration balancing (e.g., visible on\nDecember 16, 22, 25, or 26 in Figure 7b). The model favors shorter-duration storage over hydrogen-based\nstorage because of lower roundtrip energy losses, which could be interpreted as a “merit order” of storage\ntechnologies.\nFourth, in countries with less pronounced solar seasonality in winter and significant reservoir capacity, such\nas Spain, optimal battery discharge capacity is relatively large compared to hydrogen gas turbine capacity.\nDuring extreme drought periods, long-duration storage discharge enables battery charging before and after\nPV peaks, even in positive residual load periods (e.g., visible on January 24 in Figure 7c). Although this\noperation incurs high conversion losses, it leverages lower-cost power capacity of short-duration flexibility\noptions that is anyway required to balance diurnal PV variations, which minimizes higher-cost long-\nduration storage discharge capacity.\nFinally, long-duration storage may not only be used in periods of extended renewable energy droughts\nbut also for diurnal cycling in summer Figure 7d). Hydrogen-based storage integrates solar PV surplus\nenergy, which reduces the need for short-duration battery capacity that otherwise would be required\nfor this purpose. Importantly, optimal long-duration storage capacity is not defined by these diurnal\nvariability patterns in summer, but rather by balancing needs for major renewable winter droughts. In\nother words, the long-duration storage capacity required to cope with winter droughts has repercussions on\nthe optimal capacity and dispatch decisions that allow for dealing with summer-time solar PV variability.\n3.4. Sensitivity analyses\nSo far, we only allowed for firm and variable renewable technologies. However, some European countries\nconsider nuclear power a valid decarbonization option. To reflect country-specific energy policy strategies,\nwe thus include nuclear power in Finland, France, Romania, Slovakia, and the UK in a sensitivity run,\ntotaling 24 GW based on the assumptions of the TYNDP 2022 [83]. This firm generation capacity can\ncontinuously provide power during extreme renewable drought events. Yet, this reduces the need for\nlong-duration storage energy capacity across all investigated interconnection scenarios only to a minor\nextent (Figure 8). Without geographical balancing in scenario (1), nuclear power reduces the aggregated\nmedian (maximum) long-duration storage energy capacity by 4.4 (5.9)%. With policy-oriented cross-\nborder exchange of electricity in scenario (2) or electricity and hydrogen in scenario (3), the mitigating\neffect on the aggregated median (maximum) storage energy capacity is slightly larger with 6.4 (6.8)%\nor 8.1 (6.7)%, respectively. This is because the additional firm generation mitigates renewable droughts\nboth domestically and in other countries. This mitigating effect is less pronounced under the assumption\n17of unconstrained geographical balancing in scenario (4), with a reduction of the mean by 2.7%, and\nmaximum storage energy even slightly increases by 0.5%. In this case, nuclear power disproportionally\ndisplaces bioenergy, i.e., one gigawatt of nuclear power substitutes more than one gigawatt of bioenergy.\nElectricity generation from bioenergy, which serves as a renewable baseload technology in the previous\nscenarios, is therefore only partially replaced by nuclear power during renewable droughts, which in turn\ncan necessitate a slightly higher long-duration storage energy capacity for coping with these events. Long-\nduration storage further remains necessary to continuously meet the flat hydrogen demand from coupled\nsectors (see Supplementary Information SI.1).\n50100150200250300350400\ndefault setting sensitivity: nuclear power sensitivity: fixed demand profilesstorage ener gy [TWh]\n(1) electricity: island\nhydrogen: island(2) electricity: TYNDP\nhydrogen: island(3) electricity: TYNDP\nhydrogen: TYNDP(4) electricity: copperplate\nhydrogen: copperplate\nFigure 8: Optimal long-duration storage energy capacity aggregated across all countries for all modeled weather years and\ninterconnection scenarios.\nWhile limited in near-term scalability [7], other firm zero-emission generation technologies potentially\nbecome viable in the longer run, such as advanced nuclear fission or fusion or advanced geothermal power\ngeneration. Such technologies are expected to have very high capital costs but low operational costs,\nwhich implies that they would optimally operate at very high full-load hours. Based on the weather\nyear 1996/97, which includes a very pronounced renewable drought in many European countries, we\nanalyze the impact of a generic dispatchable zero-emission technology on long-duration storage for the\nillustrative example of Germany, modeled as an energy island. In a series of 51 scenarios, we iteratively\nincrease the exogenous generation capacity of the zero-emission capacity by 1 GW increments as dispatch\nand investment decisions of all other generation and storage technologies remain endogenous. The firm\nzero-emission technology can continuously generate electricity not only during extreme droughts but also\nthroughout the entire modeled weather year. This reduces the reliance on variable wind and solar power,\nwhich decreases the need for system flexibility. Figure 9 illustrates these substitution effects. In addition\nto disproportionally displacing VRE capacity due to higher full-load hours, the increasing zero-emission\ngeneration capacity also reduces the need for battery storage, hydrogen gas turbines, and long-duration\nstorage energy capacity. Yet, long-duration storage remains required as long as variable renewables are\n18still part of the energy mix.\n0 5 10 15 20 25 30 35 40 45 500100200300400500600700800\n01020304050607080hydrogen storage\noffshore wind\nonshore wind\nsolar PV\nlithium-ion batteries\nhydrogen gas turbine\nzero-emission capacity\nbioener gy\npumped hydro with inflow\npumped hydro\nreservoir hydro\nrun-of-river\nzero-emission generation capacity [GW]capacity [GW]\nstorage ener gy [TWh]\nNotes: We limit the expansion of solar PV as well as on- and offshore wind according to the upper bounds of the TYNDP 2024,\nwhile we remove the lower expansion bounds. Section SI.5 elaborates on the non-steady decline in long-duration storage energy.\nFigure 9: Sensitivity of optimal wind and solar capacity as well as short- and long-duration flexibility options to an increasing\nzero-emission generation capacity.\nIn additional sensitivity analyses, we investigate the impact of the inter-annual variability of electricity\ndemand on long-duration storage needs. This is of interest because model-based energy system studies\noften use demand data for only a limited number of years or even a single year. To isolate this effect, we\nmodel the entire set of weather years as above but do not use the demand profiles of the respective weather\nyears, but always the one from 2009/2010, leaning on the TYNDP 2022 methodology. Comparing the\ncorrelation between winter droughts and long-duration storage needs from the original runs with annually\nvarying demand profiles (Figure 10a) and the sensitivity runs with fixed demand profiles (Figure 10b)\nreveals only minor differences in regression coefficients and intercepts. This indicates that inter-annual\ndemand variations have a negligible impact on the storage-defining effect of extreme renewable droughts.\n4. Discussion\n4.1. Summary and conclusions\nThis paper analyzes the impact of renewable energy droughts on investment and operational decisions of\nstorage and generation technologies, particularly on long-duration energy storage, in a future renewable\nEuropean power system. To this end, we combine a renewable time series analysis for VRE drought\nidentification with power sector modeling to analyze scenarios with different interconnection levels across\nEuropean countries for 36 weather years.\nOur analysis yields several key insights and conclusions. Extreme renewable energy droughts, which may\nlast several weeks or even months, define operational and investment needs for long-duration storage in\n190 10k 20k00.020.040.060.080.10.120.14\nDE\nES\nFR\nNL\nPL\nRO\nUK\nCP\ndrought massnormaliz ed long-dur ation stor age energydata / regression:(a) Yearly electricity demand profiles.\n0 10k 20k00.020.040.060.080.10.120.14\nDE\nES\nFR\nNL\nPL\nRO\nUK\nCP\ndrought massnormaliz ed long-dur ation stor age energydata / regression: (b) Fixed electricity demand profile from 2009.\nNotes: For comparison, we normalized the optimal storage energy by annual demand for electricity (including electrified heating)\nand hydrogen. For illustration, countries with storage energy below 5 TWh or storage energy at potential are excluded.\nFigure 10: Correlation of winter drought mass and optimal long-duration storage energy normalized by annual demand for\nelectricity and hydrogen across years.\na European power sector with high shares of wind and solar power. Major discharge periods of long-\nduration storage coincide with the most pronounced drought periods identified in the data. Further, our\nresults reveal a positive correlation between extreme drought events and optimal storage energy capacity\ninvestments for many European countries and weather years. Firm renewable energy sources such as hydro\nreservoirs or bioenergy mitigate long-duration storage needs for dealing with extreme droughts while co-\noccurring high-demand periods exacerbate them. The most pronounced pan-European renewable drought\nidentified in the VRE drought analysis leads to the highest long-duration storage need. These findings\nhighlight that long-duration storage is an indispensable technology for coping with extreme droughts in\nfully renewable energy systems.\nInterconnection among European countries significantly reduces the requirement for long-duration energy\nstorage. Extending previous literature [35], we show that this general finding also holds in settings with\nextreme renewable energy droughts. Yet, the storage-mitigating effect of interconnection for dealing with\nvery pronounced renewable droughts is limited. As inferred from our copperplate scenario, the storage\ncapacity required for coping with the most extreme events in the data (particularly in winter 1996/97)\ncould only be substantially reduced in scenarios with interconnection levels far beyond envisaged grid\nexpansion plans. In contrast, interconnection levels, as foreseen in the TYNDP scenarios, mitigate the\nstorage needs for extreme drought events only to a limited extent. Yet, additional cross-border exchange\nof renewable hydrogen, as planned in the European Union, contributes to reducing long-duration storage\nneeds.\nThus, a sizeable need for long-duration electricity storage remains in a fully renewable European power\nsector, irrespective of the extent of interconnection. Even under the assumption of a perfectly inter-\nconnected Europe, coping with the most pronounced drought in the data would require 159 TWh of\n20long-duration storage, corresponding to around 3% of yearly electric load. This storage capacity can be\ninterpreted as a lower boundary of what a fully renewable European energy system requires and could\nserve as a “no-regret” target for system planning. In more policy-relevant TYNDP interconnection sce-\nnarios between European countries, long-duration storage needs substantially increase to 351 TWh, or\nmore than 7% of yearly European electricity demand. Our results extend previous analyses that focused\non droughts in single countries, such as Germany, where long-duration storage capacities of 9% [68] or 10%\n[60] of annual electricity demand are required for dealing with extreme drought events. Even taking into\naccount hydrogen’s lower volumetric energy density compared to methane, realizing such energy capacity\nlevels appears feasible, considering that around 1700 TWh of natural gas storage is currently installed in\nEurope [100]. Yet, there is very limited experience with converting existing gas storage to hydrogen or\nbuilding new underground hydrogen storage [99]. The same applies to hydrogen grids as well as hydrogen\ngeneration and re-conversion infrastructure.\nImportantly, large-scale adoption of hydrogen-based long-duration storage, comprising electrolyzers, cav-\nerns, and hydrogen turbines for reconversion, will likely have long lead times because of supply chain and\npermitting bottlenecks [101, 102]. Consequently, system planners and policy-makers should consider early\naction to enable rapid scaling to realize the ambitious hydrogen storage investments determined here. Fur-\nther, the maximum long-duration storage need in Europe, driven by the most extreme renewable drought\nin the winter of 1996/97, exceeds the next highest storage need found for the weather year 1984/85 by\n42%. Market actors are unlikely to invest in such rarely utilized long-duration storage capacity without\nadditional deployment incentives. Accordingly, targeted support or capacity mechanisms may be required\nto ensure sufficient storage capacity for coping with the most extreme droughts.\nWe also observe complex interactions of long-duration storage with short-duration batteries and other\nflexibility options. The latter can mitigate long-duration charging and discharging capacities to some ex-\ntent. We also show that long-duration storage does not continuously discharge during prolonged drought\nperiods, and instead, shorter-duration flexibility options are used. Further, hydrogen storage needed for\ncoping with winter droughts can complement batteries in balancing diurnal PV variability in summer.\nDetailed numerical power sector modeling with an adequate representation of different flexibility tech-\nnologies and a high temporal resolution appears indispensable for analyzing such interactions. System\nplanners should consider these potential interactions of a wide range of complementary flexibility options\nfor realizing least-cost renewable energy systems.\nNext, the selection of weather years has a notable impact on long-duration storage use in energy system\nmodels, which confirms previous research [29, 74, 103]. Different weather years result in widely varying\noptimal long-duration storage investments, particularly in scenarios with constrained interconnection.\nThese inter-annual variations emphasize the significance of accounting for extreme renewable droughts\nwhen planning renewable energy systems.\nHowever, due to computational limitations, many policy-relevant studies rely on only one or a limited set\n21of weather years. For instance, the TYNDP 2022 [18], a strategic decarbonization report for the European\npower sector, draws on three weather years (1995, 2008, and 2009) for its long-term scenarios for 2050.\nOur analysis shows that the optimal long-duration storage capacity considering TYNDP interconnection\nlevels in the corresponding weather years (1994/95, 1995/96, 2007/08, 2008/09, and 2009/10) ranges from\n103 to 239 TWh. Notably, the storage capacity required to balance the most extreme drought in winter\n1996/97 is 47% higher than this range’s upper bound. This underscores the importance of considering\nmultiple weather years for identifying weather-resilient system configurations, particularly those with the\nmost pronounced drought events.\nTo select such years, we propose using VRE drought analysis based on renewable availability time series\nand multi-threshold indicators such as the drought mass metric. Importantly, respective time series\nanalyses should rely on multiple drought thresholds and account for sequences of contiguous droughts\nwith varying severity to adequately capture the most extreme events [22, 30].\nFor Europe, the power sector impacts of VRE droughts are most pronounced in winter, particularly in the\nwinter of 1996/97 [30]. Consequently, a summer-to-summer or multi-annual planning horizon for energy\nsystem modeling is more suitable to capture storage-defining drought events compared to using single\ncalendar years.\nSensitivity analyses confirm the robustness of our findings in case moderate levels of firm generation\ncapacity are present. Moderate, policy-oriented levels of nuclear power in the capacity mix of five European\ncountries mitigate long-duration storage needs across Europe, but only to a minimal extent, particularly\nfor weather years with very severe renewable droughts. This leads to the conclusion that moderate\nlevels of nuclear power would hardly reduce the need for flexibility options for coping with extreme\ndrought events. However, its role in a net-zero European energy system remains contentious due to\nscalability challenges, exceptionally long construction times, high uncertainty in final investment costs,\nas evident in ongoing expansion projects in Europe and globally, and the economic, environmental, and\nsocietal challenges of nuclear waste management. Abstracting from these implementation barriers, and\nconceptually going beyond nuclear power, our sensitivity analysis for a Germany-only scenario illustrates\nthat higher capacities of firm low- or zero-emission generation technologies could reduce long-duration\nstorage requirements to a larger extent. Still, long-duration energy capacities remain substantial, even in\nhypothetical scenarios with firm zero-emission capacity that by far exceed the nuclear generation capacity\never realized in Germany.\nFinally, there is no consensus on the definition of variable renewable energy droughts [22]. In the energy\npolicy debate, events lasting from just a few hours to one or two weeks have been labeled as Dunkelflaute\n[13, 19, 20, 104]. Based on our analysis, we propose refining the Dunkelflaute notion to focus on events\nwith the most significant implications for long-duration power sector flexibility: extended (winter) periods\nwhere renewable energy falls short of electricity demand, which ultimately define the energy capacity and\nthe operation of long-duration storage. We suggest not using the term Dunkelflaute for very short periods\n22of low wind and solar availability, especially not for a few hours within a day. While such shorter events\nwill become more frequent as VRE penetration increases [30], dealing with them particularly requires\nshort-duration flexibility options that rather focus on power and not on energy, such as battery storage.\nYet, such short-duration technologies are likely to be inherently necessary for systems with high shares of\nwind and solar to balance regular diurnal demand and solar variations.\n4.2. Limitations\nOur analysis has several limitations. We briefly discuss their qualitative effects on our main results in\nthe following. First, space heating will likely be electrified to a substantial extent in future European\nenergy scenarios [105]. This will not only increase annual electricity demand but also lead to a more\npronounced demand seasonality due to substantially higher (peak) demand in winter. While we account\nfor the additional electricity demand, our demand time series only have a moderately seasonal profile as\nexpected for 2025 (see Section 2.4). Complementary model runs indicate that demand profiles with more\npronounced seasonality lead to significantly higher long-duration electricity storage needs. These, in turn,\ncould be mitigated by long-duration thermal energy storage on district or even building levels. However,\ninteractions of different types of thermal storage, heating technologies, and building renovation with the\npower sector are complex [95, 106] and beyond the scope of this paper.\nNext, our analysis excludes industrial and commercial load shifting, load shedding as well as optimized grid\ninteractions of battery-electric vehicles. While these flexibility options would generally enhance system\nflexibility, their impact on long-duration energy needs is likely limited because of their limited duration.\nWe further abstract from conventional backup generation such as gas or oil turbines, which may provide\na cost-efficient measure to avoid unmet electricity demand at limited emissions while decreasing long-\nduration storage needs [107]. Similarly, we do not consider other long-duration storage technologies\nthan hydrogen caverns in combination with electrolyzers and hydrogen turbines. For example, methanol-\nbased long-duration storage in combination with Allam cycle turbines has recently been discussed as a\npotential alternative [103]. This technology does not depend on highly localized underground sites but\nallows for aboveground storage that can generally be placed anywhere [98, 99], which could lead to spatial\nredistribution of optimal storage capacity. Further, if this alternative storage technology came with higher\nroundtrip losses or with lower costs than assumed here for hydrogen-based long-duration storage, optimal\nstorage capacities aggregated across all countries are likely to increase compared to our results.\n4.3. Future research\nSome of these limitations merit future research. In particular, future work could explore the effects of\nadditional electricity demand in winter, driven by more pronounced electrification of space heating. In\nsuch a setting, low temperatures compound', 'wolf-peter@gmail.com', 'Martin Kittel, Alexander Roth, Wolf-Peter Schill', '', '../pdf_files/6749819449101-Power system implications of variable renewable energy droughts in Europe.pdf', 5969493, 41, 14865, 106726, '2024-11-29 08:55:50', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(14, '3628018459', '6745cf4203d9a', 1, 16, 'The Impact of Banking Competition on Interest Rates for Household Consumption Loans in the Euro Area', '2024-11-29 16:57:06.645419', '2024', 'This paper investigates the impact of banking competition on interest rates for household consumption loans in the Euro Area from 2014 to 2020. Utilizing a panel data regression approach, we analyze how various factors, including local banking competition, influence the interest rates set by banks across 13 Euro-area countries. Our key independent variable, local banking competition, is measured by the number of commercial bank branches per 100,000 adults. Control variables include the ECB interest rate, euro exchange rate, real GDP growth rate, inflation rate, unemployment rate, bank business volumes, and country risk. We address potential endogeneity and heterogeneity biases and employ both Fixed Effects and Hausman-Taylor models to ensure robust results. Our findings indicate that higher local banking competition is associated with a slight increase in interest rates for household loans. Additionally, factors such as ECB interest rate, country risk, and euro appreciation significantly affect interest rates. The results offer insights into how competitive dynamics in the banking sector influence borrowing costs for households, providing valuable implications for policymakers and financial institutions in the Euro Area', 'Banking Competition', '1\nTheImpactofBankingCompetitiononInterestRatesforHousehold\nConsumptionLoansintheEuroArea\nAlexanderRom\nUniversityofSanFrancisco\nMay17,20242\nAbstract:\nThispaperinvestigatestheimpactofbankingcompetitiononinterestratesforhousehold\nconsumptionloansintheEuroAreafrom2014to2020.Utilizingapaneldataregression\napproach,weanalyzehowvariousfactors,includinglocalbankingcompetition,inﬂuencethe\ninterestratessetbybanksacross13Euro-areacountries.Ourkeyindependentvariable,local\nbankingcompetition,ismeasuredbythenumberofcommercialbankbranchesper100,000\nadults.ControlvariablesincludetheECBinterestrate,euroexchangerate,realGDPgrowthrate,\ninﬂationrate,unemploymentrate,bankbusinessvolumes,andcountryrisk.Weaddresspotential\nendogeneityandheterogeneitybiasesandemploybothFixedEﬀectsandHausman-Taylor\nmodelstoensurerobustresults.Ourﬁndingsindicatethathigherlocalbankingcompetitionis\nassociatedwithaslightincreaseininterestratesforhouseholdloans.Additionally,factorssuch\nasECBinterestrate,countryrisk,andeuroappreciationsigniﬁcantlyaﬀectinterestrates.The\nresultsoﬀerinsightsintohowcompetitivedynamicsinthebankingsectorinﬂuenceborrowing\ncostsforhouseholds,providingvaluableimplicationsforpolicymakersandﬁnancialinstitutions\nintheEuroArea.\nKeywords:\nBankingCompetition:Therivalryamongbanksinthemarket,inﬂuencingthepricingand\navailabilityofﬁnancialproducts.\nJELClassiﬁcationsNumbers:E43,G213\n1Introduction\nIfwelookatthediﬀerencesininterestratesforanybankloanbetweenEuro-areacountriesinanygivenyearwewillnoticesigniﬁcantdiﬀerencesbetweenthemfromcountrytocountry.Forexample,inMarchof2024(image1.1),theEuro-areaaveragewas7.82%forhouseholdloansforconsumption.Whilesomecountries,suchasMalta,hadinterestratesofaround4.23%,others,likeEstonia,wereexperiencingratesashighas12.93%.Thispaperattemptstoinvestigatewhatfactorsplayaroleinsuchalargevariationinratesacrosscountriesbyaddressingtwokeyquotations.\n●WhatfactorsinﬂuencetheinterestratesonbankloansforhouseholdsinEuro-areacountries?\n●Isthereanyrelationshipbetweeninterestratesandbankingcompetitionineachcountry?\nUnderstandinganswerstothesequotationsaboutinterestratesiscrucialforbothpolicymakersandﬁnancialinstitutions,astheseratesdirectlyaﬀectconsumerborrowingcostsandoveralleconomicactivity.Weemploypaneldataregressiontechniques,andusebothFixedEﬀectsandHausman-Taylormodels,toaddresspotentialendogeneityandheterogeneitybiasesintheanalysistoﬁndthemostaccurateestimationsfortheeﬀects.Ourﬁndingsrevealanuancedrelationshipbetweenbankingcompetitionandinterestrates,withhighercompetitionassociatedwithslightincreasesininterestratesforhouseholdloans.Additionally,thestudyhighlightsthesigniﬁcantimpactofothermacroeconomicfactorsoninterestrates,providingacomprehensiveunderstandingofthedeterminantsofborrowingcostsintheEuroArea.\n(1.1)\n4\n2DataDescription\nThisstudyusesabalancedpaneldataset,overtheperiodfrom2011to2023,resultinginatimedimension(t)of13yearsandcovering13Euro-areacountries(i):Austria,Belgium,Finland,France,Germany,Greece,Ireland,Italy,Lithuania,Luxembourg,Portugal,Slovenia,\nSpain\n \n.Nextarelistedallvariablesusedinthemodel.Outcomevariable:IR(it)=bankinterestrateforhouseholdconsumptionloans(%)Treatmentvariable:BComp(it)=commercialbankbranches(per100,000adults)Controlvariables:ECB_rate(t)=ECBinterestrate;EXCH_rate(t)=EuroexchangerateasRealBroadEﬀectiveExchangeRateforEuroArea;GDP(it)=RealGDPgrowthrate;INFL(it)=HICP-inﬂationrate;U(it)=Unemploymentrate;ALM(it)=Bankbusinessvolumes-loanstohouseholdsforconsumption(newbusiness)CR(it)=CountryriskasDiﬀerencebetween10-yeargovernmentbond(i)andthe10-yearrateforEurobondLITH_2014=dummyvariableforLithuaniain2014equaling1INFL_sq(it)=squaredINFL,thereisnon-liberrelationbetweenIRandINFLsotransfrontionisneeded,aftertestingsquaredtransformationprefremedthebestBComp_trend(t)=componentofBCompthatisexplainedbythelineartimetrend,holdingcountry-speciﬁceﬀectsconstantCovid_2020=dummyvariableforCOVID-19,assignedavalueof1foreachcountryintheyear2020\n(2.1)\n5\nFromthedescriptivestatisticstable(2.1),wecanseethatwehave91observationsavailableforourmodels,astheCRvariabledoesnotincludedataforEstoniaandCyprus.However,othervariablesdohaveobservationsfromthesecountries,bringingthetotalnumberofobservationsto105.Additionally,weseealargevariationinminimumtomaximumvaluesformostofthevariables.Ifwelookatthescatterplot(2.2)withBComponthex-axisandIRonthey-axiswewillseethattherevisuallynegativerelationship(corr(BComp,IR=-0.4273).Italsomightseemthatthereisanon-linearrelationship,however,themodelswithsquaredorlaggedBCompvariableshadlowersigniﬁcancesothedecisionwasmadetonotdoanytrasfrontions.Also,wecansee(2.3)anoveralldecreasingtrendforallcountriesinBComp(overalldecreaseinBCompfrom35.54to26.23,totalchange9.31acrossallcountries)suggestingthatwithtimeaccessibilitytotraditionalbankingisfalling.\n(2.2)\n6\n(2.3)\n3EmpiricalModelandIdentiﬁcation\nWecanassumetohaveseveralidentiﬁcationissuesasweareworkingwithpaneldata,\nMostlikelyendogeneitybiasispresentasCOV(CR(it);u(it))≠0,sameforGDP(it)andU(it).\nWeknowfromtheorythatthesevariablesarelikelytobesubjecttorandomshocksthatwecan\nnottakeintoaccountsuchaswarornaturaldisastersthathavesigniﬁcanteﬀecton\nmacroeconomicindicators.Also,heterogeneitybiasislikelytobeanissuewithourmodel\nsuggestingthatCOV(BComp(it);a(i))≠0),andthesameforGDP(it)&CR(it).Timeinvariant\nerrorwillcorrelatewithbankingcompetitionasweknowthatfactorslikebankingculturethat\nwasestablishedbycenturiesordecadesplayaroleindeterminingbankingcompetition.\nAdditionally,wehavementionedbeforetheissueofmissingobservationforcountryriskthat\nreducesthenumberofobservationsinourmodelandcausesittobelessaccurate.Atlast,our\ndatadoesnotcoverthefulleconomiccycle,fromonerecessiontoanothersowecannothavea\nfullunderstandingofhowthesevariablesperformindiﬀerenttimeconditions.Image(3.1)shows\nthatinthetimeperiodcoveredbyourdatafrom2014to2020Euro-areacountriesexperienceda\ntimeofeconomicgrowthanddecreasinginterestratesbythecentralbank,onlyin2020wehad\nnegativegrowthwhichwascausedbythepandemicandlockdownoftheeconomy.\n7\n(3.1)\nMovingtotheempiricalmodel,weuseasimpleOLSregressionincorporatingallourvariables.\nBasedonthelinearregressionmodelresults,wecandrawseveralconclusionsregardingthesigniﬁcantvariablesaﬀectinginterestratesforhouseholdconsumptionloans.Bankingcompetition(BComp),hasahighsigniﬁcancewithap-valueof0.000.Suggestingthatan\n8\nincreaseinbankingcompetitionisassociatedwithadecreaseininterestrates,withaone-unitincreaseincompetitionleadingtoa0.05%decreaseininterestrates,whileholdingothervariablesconstant.Theunemploymentrate(U)isanothersigniﬁcantvariable,withap-valueof0.002.Higherunemploymentratesareassociatedwithhigherinterestratesforhouseholdconsumptionloans,asaonepercentagepointincreaseinunemploymentleadstoa0.221%increaseininterestrates,holdingothervariablesconstant.Additionally,thevariablerepresentingLithuania\'sadoptionoftheeuroin2015(LITH_2014)ishighlysigniﬁcantwithap-valueof0.000,suggestingthatthiseventresultedinasubstantialincreaseininterestrates,speciﬁcallyan8.191%rise,holdingothervariablesconstant.Finally,ourlastsigniﬁcantvariableINFL_sqshowssigniﬁcancewithap-valueof0.042,indicatinganonlinearrelationshipwhereinterestratesriseatanincreasingrateasinﬂationincreases.Ifwelookattheoveralleﬀectofinﬂation,\nThecalculationshowsthattheeﬀectofinﬂationoninterestratesstartstobecomepositive(asopposedtonegativewithlowinﬂation)whentheinﬂationrateexceedsapproximately1.559%,holdingothervariablesconstant.\n4Results\nA.Fixed-Eﬀects&Random-EﬀectsForbothﬁxed-eﬀects(FE)andrandom-eﬀects,weapplyrobuststandarderrorsthataredesignedtobevalidevenwhenheteroskedasticityispresent.Additionally,thisapproachhelpedtoincreasethesigniﬁcanceofallofthevariablesinthemodel.\n9\nRE(Robust)\nThemodelexplainsabout54.24%ofthevariationininterestrateswithincountriesandabout16.41%overall.TheWaldchi-squaredstatisticishighlysigniﬁcant,indicatingthatthemodelasawholeisstatisticallysigniﬁcant.Wewillfocusonafewkeyvariablestolearnhowtheychangeacrossmodels.Thecoeﬃcientforbankingcompetition(BComp)is-0.005128withap-valueof0.863,indicatingthatthevariableisnotstatisticallysigniﬁcant.However,theresultisconsistentwithourOLSmodelssuggestingthathigherBCompvalueshaveanegativeeﬀectontheIR.Incontrast,countryrisk(CR)whichwasnotsigniﬁcantinourOLSmodelnowshowsahighlysigniﬁcanteﬀectoninterestrates,withacoeﬃcientof-2.55976andap-valueof0.000.Thisnegativerelationshipimpliesthathighercountryriskisassociatedwithlowerinterestratesforhouseholdloans.Speciﬁcally,aone-unitincreaseincountryriskleadstoadecreaseininterestratesby2.56%,holdingothervariablesconstant.Thisresultiscounter-intuitiveandgoesagainstthetheory,butitwillbediscussedinfullintheconclusion.Finally,theadoptionoftheeurobyLithuaniain2015(LITH_2014)isfoundtohaveasigniﬁcantpositiveimpactoninterestratesasinourOLS.ThecoeﬃcientforLITH_2014is3.670642withap-valueof0.000,indicatingthatthiseventledtoasubstantialincreaseininterestratesbyabout3.67%,howeverwasnotasbigaswehadintheOLSmodelwherethecoeﬃcientwasmorethandoublethissize.\n10\nFE(robust)\nThemodelexplainsabout59.06%ofthevariationininterestrateswithincountriesandabout5.87%overall.Thisindicatesthattheﬁxedeﬀectsmodelcapturesasubstantialportionofthevariationwithincountriesbutnotasmuchoverall.CoefcintsforoursigniﬁcantvariablesLITH_2014andCRstayedalmostthesamesowewillnotdiscussthemoncemore.However,forBCompweseeasigniﬁcantchangeinthecoeﬃcient.TheFEregressionmodelindicatesthatbankingcompetition(BComp)hasasigniﬁcantpositiveimpactoninterestratesforhouseholdconsumptionloansintheEuroArea.Withacoeﬃcientof0.0548417(oppositecoeﬃcientcomparedtoourREmodel)andap-valueof0.048,theresultsshowthataone-unitincreaseinBCompisassociatedwitha0.0548%increaseininterestrates,holdingothervariablesconstant.\nHausmanTestWeusetheHausmantesttocomparethecoeﬃcientsfromtheFEmodelandtheREmodeltodeterminewhichmodelisappropriate.Thenullhypothesis(H0)isthatthediﬀerenceincoeﬃcientsisnotsystematic,implyingthattheREmodelispreferred.Thealternativehypothesis(Ha)isthatthediﬀerenceissystematic,suggestingthattheFEmodelismoreappropriate.\n11\nSincethep-valueis0.001,whichisbelow0.05,werejectthenullhypothesis.MeaningthatthereisasigniﬁcantdiﬀerencebetweenthecoeﬃcientsoftheFEandREmodels,andthusFEmodelisappropriate.\nB.Hausman-TaylormodelForourHausman-Taylormodel,wegetahighlysigniﬁcantWaldchi-squaredstatistic(equaling96.14)andp-value=0.000whichindicatesthatthemodelasawholeisstatisticallysigniﬁcant.\nTheresultsofthismodelareverysimilartotheFEmodeloutcomeasthesamecoeﬃcientsstayedsigniﬁcantandthedirectionoftheireﬀectstayedthesame.Bankingcompetition(BComp)isstatisticallysigniﬁcantwithacoeﬃcientof0.0468804andap-valueof0.045.Countryrisk(CR)alsoshowsasigniﬁcantnegativeimpactoninterestrates,withacoeﬃcientof-0.2364144andap-valueof0.015.AndLithuania\'seuroadoptionin2015(LITH_2014)ishighlysigniﬁcantwithacoeﬃcientof3.666819andap-valueof0.000.Inmoredetail,theoutcomesofthecoeﬃcientwillbediscussedintheconclusionsection.\n12\n5Conclusion\nThisstudyinvestigatestheimpactofbankingcompetition,andothermacroeconomic\nindicatorsoninterestratesforhouseholdconsumptionloansintheEuroAreafrom2014to2020,\nemployingpaneldataregressiontechniquesincludingﬁxedeﬀects,randomeﬀects,andthe\nHausman-Taylormodel.TheresultsfromtheHausman-Taylormodelproviderobustinsightsinto\nthedeterminantsofinterestratesandspeciﬁcallyhowourkeyvariableofbankingcompetitionis\nrelatedtointerestrates.\nCountryrisk(CR)isacriticalfactorinﬂuencinginterestrates.TheHausman-Taylor\nmodelindicatesasigniﬁcantnegativerelationshipbetweencountryriskandinterestrates,\nimplyingthathighereconomicandpoliticalinstabilityleadstolowerinterestrates.Unxepetcd\nnegativerelationcanbeexplainedbypossiblereductionsinborrowingcosts,asbankslowerrates\ntoattractmoresecureloansinriskierenvironments.Additionally,inresponsetoincreased\ncountryrisk,whichmightincludeeconomicinstability,politicaluncertainty,orﬁnancialcrises,a\ncentralbankmightlowerbenchmarkinterestratestostimulateeconomicactivity.\nTheadoptionoftheeurobyLithuaniain2015(LITH_2014)alsoshowsasigniﬁcant\nimpactoninterestrates,withthemodelindicatingasubstantialincreasefollowingtheadoption.\nThisresulthighlightsthesigniﬁcanteconomicadjustmentsassociatedwithmajormonetary\npolicychangesandtheeﬀectsofadoptingamorewidelyusedcurrency.\nAdditionally,theHausman-Taylormodelsuggests(withlowsigniﬁcanceforthese\ncoeﬃcients)thatwhenEuro(EXCH_rate)appreciationby1unit(mean98.94)causesinterest\nratestodecreaseby0.043%.Wealsocanassumethata1%increaseintheECBrate(ECB_rate)\ncausesa4.72%increaseininterestratesforconsumerloansinEuro-areacountries.Covid_2020:\nTheCOVID-19pandemic(covid_2020)variableindicatesanegativeimpactoninterestrates,\nwiththemodelshowingadecreaseofapproximately0.39%.Alltheseoutcomesaretheoretically\nsoundandcanbeexplainedbymonetaryeconomics.\nAtlast,theanalysisofthemodelrevealsthatbankingcompetition(BComp)hasa\nstatisticallysigniﬁcantpositiveimpactoninterestrates.Speciﬁcally,anincreaseinthenumberof\ncommercialbankbranchesper100,000adultsisassociatedwithariseininterestratesfor\nhouseholdloansbyapproximately0.0469%.Thisﬁndingmightsuggestthathighercompetition\namongbanksmayleadtoincreasedoperationalcostsandthushigherinterestratesforconsumer\nloans.Thereasonourresultforthisvariablemaynotalignwiththeoreticalexpectationscouldbe\nthatourBCompvariableisnotthemostaccuratemeasureofbankingcompetition.Thenumber\nofcommercialbankbranchesper100,000adultsmeasuresaccessibilitytotraditionalbanking\nservices,suchasthephysicallocationofbanks.However,itispossiblethatallthesebranchesare\nownedbyasinglebank,whichmeansourvariablemayfailtoaccuratelycapturetruebanking13\ncompetition.Thus,forfuturestudiesonbankingcompetition,itwouldbemoreaccuratetoﬁnd\norcreatevariablesthatbettercapturebankingcompetition,suchasthenumberoflicensed\nbankinginstitutionsper100,000people.\nEventhoughthisprojectfailstodeterminetheexactrelationshipbetweeninterestrates\nandbankingcompetitionineachcountry,wearestillabletoestablishsomefactorsthatinﬂuence\ntheseconsumerloanrates.Overall,thisstudyprovidesvaluableinsightsintothedeterminantsof\ninterestratesforhouseholdconsumptionloansintheEuroArea14\n6References\nEuropeanCentralBank.(n.d.).Bankinterestratesonloans.Retrievedfromhttps://data.ecb.europa.eu/main-ﬁgures/bank-interest-rates/loans\nEurostat.(n.d.).Grossdomesticproduct(GDP)atmarketprices.Retrievedfromhttps://ec.europa.eu/eurostat/databrowser/view/tec00115__custom_10585427/def ault/table?lang=en\nEurostat.(n.d.).Harmonisedindicesofconsumerprices(HICP).Retrievedfromhttps://ec.europa.eu/eurostat/databrowser/view/tec00118/default/table?lang=en\nWorldBank.(n.d.).Commercialbankbranches(per100,000adults).Retrievedfromhttps://data.worldbank.org/indicator/FB.CBK.BRCH.P5?most_recent_value_desc=false\nEuropeanCentralBank.(n.d.).Businessvolumesofloans.Retrievedfromhttps://data.ecb.europa.eu/data/data-categories/ﬁnancial-markets-and-interest-rates/bank-interest-rates/business-volumes/loans?searchTerm=&ﬁlterSequence=&sort=relevance&ﬁlterType=basic&showDatasetModal=false&ﬁltersReset=false&resetAll=false&reference_area_name%5B%5D=Austria&reference_area_name%5B%5D=Netherlands\nEurostat.(n.d.).Unemploymentrate.Retrievedfromhttps://ec.europa.eu/eurostat/databrowser/view/tipsun20__custom_10585547/def ault/table?lang=en\nFederalReserveBankofSt.Louis.(n.d.).Long-termgovernmentbondyields:10-year:Main(includingbenchmark)fortheEuroArea.Retrievedfromhttps://fred.stlouisfed.org/series/IRLTLT01EZM156N#0\nOECD.(n.d.).Financialmarketstatistics.Retrievedfromhttps://data-explorer.oecd.org/vis?lc=en&pg=0&fs[0]=Topic%2C1%7CEconomy%23ECO%23%7CShort-term%20economic%20statistics%23ECO_STS%23&fc=Topic&bp=true&snb=21&vw=tb&df[ds]=dsDisseminateFinalDMZ&df[id]=DSD_STES%40DF_FINMARK&df[ag]=OECD.SDD.STES&df[vs]=4.0&pd=2014%2C2020&dq=ESP%2BSVN%15\n2BPRT%2BLUX%2BLTU%2BITA%2BIRL%2BGRC%2BDEU%2BFRA%2BFIN%2BEST%2BBEL%2BAUT.A..PA.....&ly[rw]=MEASURE&ly[cl]=TIME_PERIOD&to[TIME_PERIOD]=false\nFederalReserveBankofSt.Louis.(n.d.).EuropeanCentralBank:Mainreﬁnancingoperationsminimumbidrate.Retrievedfromhttps://fred.stlouisfed.org/series/ECBMRRFR\nFederalReserveBankofSt.Louis.(n.d.).3-Monthor90-dayratesandyields:InterbankratesfortheEuroArea.Retrievedfromhttps://fred.stlouisfed.org/series/RBXMBIS\n7Appendix\n//convertmontlytoannualdata\ngenyear_num=real(substr(timeperiod,1,4))\negenannual_mean_bank_comp=mean(bank_comp),by(year_numcountry_name)\nbysortyear_numcountry_name:keepif_n==1//doropduplicate\nmerge1:mcountryyearusing\"/Users/alexanderrom/Desktop/EUR/orgcopy/GDP.dta\"\nmerge1:mcountryyearusing\"/Users/alexanderrom/Desktop/EUR/orgcopy/inﬂation.dta\"\nmerge1:mcountryyearusing\"/Users/alexanderrom/Desktop/EUR/orgcopy/loan_amount.dta\"\nmerge1:mcountryyearusing\"/Users/alexanderrom/Desktop/EUR/orgcopy/unemployment.dta\"\nmerge1:mcountryyearusing\"/Users/alexanderrom/Desktop/EUR/orgcopy/loan_rates.dta\"\nreplaceRate=subinstr(Rate,\",\",\".\",.)\ndestringRate,replace\nreplaceEU_bond_rate=round(EU_bond_rate,0.001)\n//////////////////////////////////////////////////////////////////////////////////\n//Generatecountry_id:\negencountry_id=group(country_name),label\n//GEntimeid16\nsummarizeyear,meanonly\nlocalmin_year=r(min)\ngentime_id=year-`min_year`\n//////////////////////////////////////////////////////////////////////////////////\n//bankcompthroughtiem\nregressBCompyear\ngeneratetrend=_b[_cons]+_b[year]*year\n//Country-speciﬁcTrends\nxtsetcountry_idyear\nxtregBCompyear,fe\npredicttrend_country,xb\ntwoway(lineBCompyearifcountry_id==1,sort)(linetrend_countryyearifcountry_id==1,\nsort)\n//includeaseparateinterceptforeachcountry,eﬀectivelycontrollingforalltime-invariant\ndiﬀerencesacrosscountries.Thismeansanyunobservedvariablethatdoesnotchangeovertime\nwithineachcountrybutvariesbetweencountrieswillnotbiastheestimatedeﬀectoftime.\ngenBComp_LITH2014=BComp*LITH_2014\n//graphs\nscatterIRBComp||lowessIRBComp\n//////////////////////////////////////////////////////////////////////////////////\n//Generatingtheyearlyaverageofbank_comp\ncollapse(mean)BComp,by(year)\n//Sortingthedatabyyeartoensuretheplotfollowschronologicalorder\nsortyear\n//Findingthemaximumvalueofbank_comptosetthey-axisscaledynamically\nsummarizeBComp,detail\nlocalmax_BComp=r(max)\n*Creatingalineplotoftheaveragebank_compovertheyearswithay-axisrangingfrom0to\nmaxvalue\ntwoway(linebank_compyear),title(\"YearlyTrendofBankingCompetition(bank_comp)\nAcrossCountries\")\\\nxtitle(\"Year\")ytitle(\"AverageBankingCompetition\")yscale(range(0`max_bank_comp`))\nlegend(oﬀ)graphregion(color(white)lcolor(black))17\n//////////////////////////////////////////////////////////////////////////////////\n//OLSmodel\nregIRBCompGDPINFLINFL_sqALMUEXCH_rateECB_rateCRLITH_2014covid_2020\n//IVmodel\ngenBComp_lag1=L.BComp\nivregress2slsIR(BComp=BComp_trend)GDPINFLINFL_sqALMUEXCH_rateECB_rate\nCRLITH_2014covid_2020\n//2SLSREandFE\nxtivregIR(BComp=BComp_trend)GDPINFLINFL_sqALMUEXCH_rateECB_rateCR\nLITH_2014covid_2020,revce(robust)\nxtivregIR(BComp=BComp_trend)GDPINFLINFL_sqALMUEXCH_rateECB_rate\nLITH_2014covid_2020,fevce(robust)\n//REandFE\nxtregIRBCompBComp_trendGDPINFLINFL_sqALMUCREXCH_rateECB_rate\nLITH_2014covid_2020,ferobust\nxtregIRBCompBComp_trendGDPINFLINFL_sqALMUCREXCH_rateECB_rate\nLITH_2014covid_2020,rerobust\n//Hausmantest\nxtregIRBCompBComp_trendGDPINFLINFL_sqALMUCREXCH_rateECB_rate\nLITH_2014covid_2020,fe\nestimatesstorefe_model\nxtregIRBCompBComp_trendGDPINFLINFL_sqALMUCREXCH_rateECB_rate\nLITH_2014covid_2020,re\nestimatesstorere_model\nhausmanfe_modelre_model,sigmamore\n//HousmanTaylor\nxthtaylorIRBCompBComp_trendGDPINFLINFL_sqALMUEXCH_rateECB_rateCR\nLITH_2014covid_2020country_id,endog(GDPCRINFLINFL_sqEXCH_rateUBComp)', 'alexanderrom@gmail.com', 'Alexander Rom', '', '../pdf_files/674981e1f2def-The Impact of Banking Competition on Interest Rates for Household.pdf', 868602, 17, 213, 19342, '2024-11-29 08:57:06', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(15, '8522477441', '6745cf4203d9a', 1, 2, 'Scale Economies and Aggregate Productivity', '2024-11-29 16:58:32.551612', '2024', 'We develop a theoretical framework to investigate the link between rising scale economies and stagnating productivity. Our model features heterogeneous firms, im perfect competition, and firm selection. We demonstrate that scale economies gener ated by fixedcosts have distinct impacts on aggregate productivity compared to those driven by returns to scale. Using UK data, we estimate long-run increases in both f ixed costs and returns to scale. Our model implies that this should increase aggre gate productivity through improved firm selection and resource allocation. However, increasing markups can offset the productivity gain. Higher markups cushion low productivity firms’ revenues, allowing them to survive, and constrain firm output, which limits exploitation of scale economies', 'Returns to Scale,Scale Economies,Productivity,Market Structures,Firm Dynamics,Fixed Costs,Marginal Costs.', 'Scale Economies and Aggregate Productivity\nJoel Kariel∗Anthony Savagar†\n19 March 2024\nAbstract\nWe develop a theoretical framework to investigate the link between rising scale\neconomies and stagnating productivity. Our model features heterogeneous firms, im-\nperfect competition, and firm selection. We demonstrate that scale economies gener-\nated by fixed costs have distinct impacts on aggregate productivity compared to those\ndriven by returns to scale. Using UK data, we estimate long-run increases in both\nfixed costs and returns to scale. Our model implies that this should increase aggre-\ngate productivity through improved firm selection and resource allocation. However,\nincreasing markups can o ffset the productivity gain. Higher markups cushion low-\nproductivity firms’ revenues, allowing them to survive, and constrain firm output,\nwhich limits exploitation of scale economies.\nJEL: E32, E23, D21, D43, L13.\nKeywords : Returns to Scale, Scale Economies, Productivity, Market Structures, Firm\nDynamics, Fixed Costs, Marginal Costs.\n∗Competition and Markets Authority and University of Kent, joel.kariel@cma.gov.uk\n†University of Kent, a.savagar@kent.ac.uk.\nThis research is funded under ESRC project reference ES/V003364/1.\nDisclaimer: This work was produced using statistical data from ONS. The use of the ONS statistical data in this\nwork does not imply the endorsement of the ONS in relation to the interpretation or analysis of the statistical data.\nThis work uses research datasets which may not exactly reproduce National Statistics aggregates.\nWe thank seminar participants at UAB, Danish Nationalbank, Cardi ff, CompNet, Nottingham, York,\nDurham Macro workshop, EUI, Bank of Italy, MWM Clemson, University of Washington, RES 2023, EMF\nBern 2023, Birmingham, St Louis Fed, Lancaster, King’s, Bath, IFN Stockholm, EEA-ESEM 2022, IAAE\n2022, CEF 2022, RES 2022, SNDE 2022, AMEF 2022, SES 2022, MMF 2022, Kent Firm Dynamics Work-\nshop 2021, Exeter Macro Workshop 2022 and Bristol for their helpful comments. We thank the following\npeople for feedback: Matthias Kehrig, Jan de Loecker, Jan Eeckhout, Mark Bils, Alex Monge, Max Gillman,\nMark Wright, Omar Licandro, Julian Neira, Tom Schmitz, Petr Sedl ´aˇcek, Danial Lashkari, John Morrow,\nAnthony Priolo, Riccardo Silvestrini and Kunal Sangani.arXiv:2411.18461v1  [econ.GN]  27 Nov 2024Recent technological advances, such as cloud computing, can raise scale economies\nallowing firms to expand at lower cost. But, as these technologies have emerged in\neconomies such as the US and UK, productivity has stagnated. In this paper, we develop\na theory to relate firm-level scale economies to aggregate productivity. We show that\nincreases in scale economies should have increased aggregate productivity significantly.\nHowever, rising markups can o ffset the productivity gains.\nWe make three contributions: first, we document rising scale economies from two de-\nterminants: higher returns to scale and higher fixed costs. Second, we develop a tractable\nmodel to link these determinants of scale economies to aggregate productivity. Third,\nwe conduct a quantitative exercise to replicate growing scale economies but stagnating\nproductivity in the UK economy.\nWe develop a heterogeneous firm model with monopolistic competition, fixed costs,\nreturns to scale and endogenous entry. We derive firm-level scale economies, which is the\ninverse cost elasticity or, equivalently, the ratio of average cost to marginal cost. Firm-\nlevel scale economies are a function of fixed costs and returns to scale, and they vary\nendogenously with firm size.1The fixed cost and returns to scale determinants of scale\neconomies have di fferent aggregate productivity outcomes. Both tend to increase aggre-\ngate productivity, by reducing profits and in turn the number of active firms. Fewer\nactive firms enhances productivity through selection of high technical e fficiency firms\nand exploitation of increasing returns (if present). However, the e ffect of fixed costs on\naggregate productivity is independent of markups, whereas the e ffect of returns to scale\nis mitigated by the presence of markups. Quantitatively, estimated increases in fixed\ncosts cannot buoy aggregate productivity su fficiently to o ffset the negative e ffect on ag-\ngregate productivity from estimated increases in markups. On the other hand, estimated\nincreases in returns to scale can buoy aggregate productivity su fficiently to counteract\nrising markups.\n1Returns to scale are returns to scale in variable inputs. This measures the slope of the marginal cost\ncurve and is the sum of output elasticities to variable inputs.\n1We decompose aggregate productivity into allocative e fficiency and technical e ffi-\nciency components. Allocative e fficiency depends on the division of aggregate resources\nacross firms and how this interacts with returns to scale, as well as the fixed cost that each\nadditional firm must pay. Increasing returns favour concentrating resources on fewer,\nlarger producers, while decreasing returns favour the opposite. Technical e fficiency mea-\nsures the average technology of active firms. Technology is an exogenous productivity\ncharacteristic that is revealed to firms upon entry. Given a technology draw, a firm de-\ncides to be active or inactive based on a period-by-period fixed cost. Therefore, technical\nefficiency is determined by firm selection. That is, where the exogenous productivity\ndistribution is truncated.\nOur theoretical results show that rising scale economies, either through fixed costs or\nreturns to scale, strengthen selection, thus improving average technical e fficiency. How-\never, in high-markup environments, the selection channel is weaker. With high markups,\nselection weakens because small (low technology draw) firms get more revenue for each\nunit sold, so it is easier to cover fixed costs and survive. Allocative e fficiency declines\nbecause markups increase the number of firms which limits the exploitation of scale\neconomies. Therefore, ceteris paribus, increases in scale economies should increase pro-\nductivity. However, high mark-ups weaken the passthrough of scale economies to pro-\nductivity.\nOur theory emphasizes the importance of the returns to scale levels (decreasing, con-\nstant, or increasing) in understanding how rising returns to scale or fixed costs impact\naggregate productivity. Concentrating capital and labour among fewer firms increases\naggregate output if there are increasing returns, but decreases aggregate output if there\nare decreasing returns. We estimate increasing returns to scale levels in our data and\nthese have increased over time. Our model shows that rising returns to scale or fixed\ncosts reduce the number of active firms through lower profits. This strengthens the se-\nlection of high-technology firms, boosting productivity. Additionally, concentrating re-\n2sources within these fewer firms further enhances productivity from increasing returns.\nHence, there are two channels leading greater returns to scale and fixed costs to enhance\naggregate productivity. Higher markups counteract this e ffect because they increase the\nnumber of active firms through higher profits. Ultimately, the theory stresses the impor-\ntance of the number of active firms for aggregate output. Changes in underlying param-\neters a ffect the number of active firms, and they are a crucial determinant of aggregate\nproductivity as they characterise selection and the division of aggregate resources among\nproduction units, which matters in the absence of constant returns.\nOur quantitative exercise applies the theoretical insights to UK aggregate productiv-\nity. We show that estimated increases in returns to scale accompanied by estimated in-\ncreases in markups replicate UK aggregate productivity dynamics well. Rising fixed costs\ncannot explain the data as well. If markups had not increased, UK aggregate productivity\nwould have been 20% higher through e fficiency gains from scale economies.\nOur paper abstracts from the specific technologies that may have changed scale economies,\nother than to characterise them by increasing fixed costs or raising returns to scale (reduc-\ning MC). Industry studies provide some insight. Ganapati (2021) shows that information\ntechnology reduced marginal costs and increased markups in the wholesale sector. For\nthe manufacturing sector, Bloom, Garicano, Sadun, and Van Reenen (2014) study specific\ninformation technologies, such as enterprise resource planning, that increase managers’\nspan of control and, therefore, lower marginal costs. Syverson (2019) hypothesises a\nshift towards products with lower marginal costs, such as software and pharmaceuticals.\nLashkari, Bauer, and Boussard (2024) link IT price changes to changing scale economies\nusing French data. They find lower IT prices reallocates business to larger firms, with low\nscale economies, and this can cause a lower labour share.\nTherefore, our conclusion is that emerging technologies have increased returns to\nscale, which has decreased marginal costs and enhanced scale economies. These scale\neconomies should translate into productivity gains. However, increasing market power\n3limits the exploitation of scale economies and, in turn, productivity gains.\nRelated Literature\nOur paper connects theory on the aggregate impacts of microeconomic production prim-\nitives, with the measurement of these features at the firm level. Recent work by Bilbiie\nand Melitz (2020), Edmond, Midrigan, and Xu (2021), and Baqaee, Farhi, and Sangani\n(2023) demonstrates the importance of returns to scale for aggregate welfare. This work\nfocuses primarily on external returns to scale (love of variety) that arise from aggrega-\ntion. However, Baqaee, Farhi, and Sangani (2023) also note that returns to scale at the\nfirm level magnify aggregate returns to scale. Similarly to our analysis, the e ffects of\nscale economies are smaller in e fficient (low markup) economies. Baqaee and Farhi (2020)\nprovide non-parametric aggregation results for models with scale economies. Both our\nparametric approach and their non-parametric approaches show that the role of alloca-\ntive efficiency grows as distortions increase. And, we combine this theory with measure-\nment to show that firm-level scale economies are quantitatively-relevant to replicate UK\nproductivity dynamics.\nIn order to understand the consequences of rising market power, De Loecker, Eeck-\nhout, and Mongey (2021) present a quantitative model with oligopolistic competition and\nfixed costs. This allows them to compare the role of technology on the supply-side ver-\nsus competitive factors on the demand-side. We di ffer by focusing on analytical results\nto understand the supply-side mechanisms through which di fferent technologies a ffect\nscale economies, and in turn aggregate productivity. Our demand-side is restricted to\nmonopolistic competition for tractability. Collectively, our papers advance the idea that\nto reconcile changing technologies on the supply side, market power must increase on\nthe demand side.\nRecent research in endogenous growth theory shows that changing technologies af-\nfect firm cost structures, which in turn explains stagnating growth. De Ridder (2024)\n4models intangible inputs as reducing marginal costs and raising fixed costs. Unlike us,\nthe focus is the level of constant marginal costs, not the slope of marginal costs. Aghion,\nBergeaud, Boppart, Klenow, and Li (2023) model a fixed cost that increases with the num-\nber of product lines, but as technology improves, the fixed cost becomes less sensitive to\nthe number of products. Our paper di ffers from this research, which focuses on quan-\ntitative endogenous growth models with an important role for R&D, and a main aim of\nreplicating US stagnation facts. We present a parsimonious and tractable analysis based\non firm entry to directly link the firm-level determinants of scale economies to aggregate\nproductivity. Conceptually, this body of work, including our paper, contributes to the hy-\npothesis that recent changes in technology have a ffected firm cost structures, and lead to\nimportant aggregate e ffects. To our knowledge, our work is the first to directly compare\nthe effect of returns to scale and fixed costs, and formalise these e ffects of new technolo-\ngies through the economies of scale channel. Informally, it is understood that these are\ntwo sources of scalable technologies and are hallmarks of intangible capital (Haskel and\nWestlake 2017). We formalise that they both a ffect scale economies in the same way, but\ncan lead to distinct aggregate productivity e ffects.\nOur model is a neoclassical growth model with heterogeneous firms based on Hopen-\nhayn and Rogerson (1993), Restuccia and Rogerson (2008), and Barseghyan and DiCecio\n(2016). The model is similar to two-factor closed-economy versions of Melitz (2003) and\nGhironi and Melitz (2005). We include firm production with fixed costs and returns to\nscale similar to the models of J. Kim (2004), Atkeson and P . J. Kehoe (2005), Bartels-\nman, Haltiwanger, and Scarpetta (2013), and D. Kim (2021). Gao and Kehrig (2021)\npresent a partial equilibrium industry model under perfect competition and focus on\ncross-industry variation in returns to scale and productivity dispersion. Similarly to our\ntheory, they show a positive relationship between productivity and returns to scale across\nindustries, whereby a rise in returns to scale leads to selection of more-productive firms.\nSeveral recent articles provide estimates of returns to scale in the US economy. Gao\n5and Kehrig (2021) estimate slightly decreasing returns to scale in US manufacturing\nfirms. Using similar US data, Ruzic and Ho (2019) find a decline in returns to scale\nfrom 1982 to 2007. Using Compustat data, Chiavari (2022) documents rising returns\nto scale through production function estimation, and De Loecker, Eeckhout, and Unger\n(2020, Figure 7) documents increasing overhead cost shares as evidence of rising scale\neconomies. Baqaee, Farhi, and Sangani (2023) also document economies of scale in US\nfirms. Lashkari, Bauer, and Boussard (2024) find cost elasticity below one for French cor-\nporations, which implies economies of scale. For the UK economy, Oulton (1996), Harris\nand Lau (1998), and Girma and G ¨org (2002) document constant or slightly decreasing\nreturns to scale for manufacturing firms.\nThe remainder of our paper is as follows. In Section 1, we present some foundations\non scale economies and returns to scale. In Section 2, we present an empirical motiva-\ntion which shows rising fixed costs and returns to scale, concurrently with stagnating\nproductivity in the UK. In Section 3, we present our model, equilibrium conditions and\ncharacterise some properties of the model. In Section 4, we present comparative statics\non the e ffects of fixed costs and returns to scale on aggregate productivity. Informed by\nthese theoretical insights, in Section 5 we perform a quantitative analysis which simu-\nlates our model for an estimated timeseries of returns to scale, fixed costs and markups.\nWe present counterfactual experiments when each of these components changes inde-\npendently.\n1 Scale Economies Background\nIn this section, we define some concepts which are occasionally subject to ambiguity.\nInternal vs. External Returns to Scale: Our interest is internal returns to scale, not\nexternal returns to scale that arise from aggregation. Internal returns to scale and scale\neconomies arise within the firm from the production technology or fixed costs. External\n6returns to scale are gains in aggregate output from changing aggregate inputs. They arise\nfrom grouping firms together.2\nScale Economies: Scale economies describe the response of firm costs to output changes.\nThey are measured by the inverse cost elasticity, which is the average cost to marginal cost\nratio.3\nReturns to scale: Returns to scale are a property of the production technology. To be\nprecise, they are captured by the degree of homogeneity of the production function. On\nthe cost side, this parameter represents the slope of a firm’s marginal cost curve.4For ho-\nmothetic production functions, the scale elasticity of the cost function equals the returns\nto the scale of the production function.5Fixed costs lead to non-homothetic production\nfunctions which break this relationship.\nImprecision over the terms scale economies and returns to scale extends beyond se-\nmantics. Erroneous conclusions and calibrations occur when the AC/MC ratio is esti-\nmated but is interpreted as the production function returns to scale.6\n1.1 Graphical Intuition of Scale Economies\nTo aid understanding throughout the paper, it is helpful to present the cost curve sce-\nnarios of the production functions we consider. We define scale economies as the inverse\ncost elasticity, which is the ratio of average cost to marginal cost. With firm output y, we\n2On the demand-side, with a consumption aggregator, the analogous concept is love-of-variety. Other\nterms used are ‘thick markets’ (Caballero and Lyons 1992), Ethier e ffects (Ethier 1982), and agglomeration\neffects (Krugman 1991).\n3This definition of scale economies is common in industrial organization textbooks (Panzar 1989;\nChurch and Ware 2000; Davis and Garc ´es 2009), recent examples are Syverson (2019) and Conlon, Miller,\nOtgon, and Yao (2023). It is sometimes recognised in macroeconomics, for example Rotemberg and Wood-\nford (1993), Basu (2008), Baqaee, Farhi, and Sangani (2023), and Lashkari, Bauer, and Boussard (2024).\n4Occasionally, researchers recognise this parameter as ‘span of control’ since it is mathematically anal-\nogous to the span of control parameter in Lucas (1978). In that context, it captures diminishing returns in\nmanagerial span of control. Hopenhayn (2014) analyses the equivalence with returns to scale.\n5Silberberg and Suen (2000, Ch. 8) present traditional proofs.\n6Basu (2008) discusses this in detail. Since homothetic production functions are common in macroeco-\nnomics, the term returns to scale is often used universally even in the presence of fixed costs.\n7have:\nS(y)≡ ∂C\n∂yy\nC!−1\n=AC(y)\nMC(y)\nwhere AC≡C/yand MC≡∂C/∂y. There are economies of scale if S(y)>1; constant scale\neconomies if S(y) = 1; and diseconomies of scale if S(y)<1. Figure 1 presents a firm with\na U-shaped average cost curve due to increasing marginal costs and fixed cost.7At the\nintersection of average and marginal cost, a firm has constant scale economies. To the left\nthere are economies of scale. To the right there are diseconomies of scale. Therefore, the\nS(y) curve shows that size and scale economies are negatively related at the firm level.8\nACMC\nS(y)\nOutputCostsACandMC\nFigure 1: Fixed Cost with Increasing MC, U-Shaped AC Curve\nProfits, Markups and Scale Economies: Scale economies can be represented directly\nfrom the profit definition. This yields an expression based on market structure, namely\nmarkups and profits. Scale economies can also be written in terms of technical proper-\nties of the production function, namely fixed costs and the homogeneity parameter. This\nwill depend on the production function and can be derived from the cost function or the\n7In the appendix we present plots considering the three main cases that arise in our theory: a fixed cost\nwith increasing, constant or decreasing marginal cost.\n8In the appendix we present a graphical explanation of scale economies from the production side.\n8production function.9Consider the definition of profits as revenue minus costs\nProfit = Price×Output−Cost = Revenue−Cost.\nDivide by revenue, define AC=Cost/Output, and multiply by MC/MC, yields:\nAC\nMC=Price\nMarginal Cost \n1−Profit\nRevenue!\n.\nThis shows that a firm’s scale economies are its markup multiplied by its profit share re-\nmainder ( i.e.total cost share).10A firm that makes zero-profits has scale economies equal\nto its markup.11And, a firm with positive profits will have lower scale economies than\nthe zero-profit firm. Higher scale economies imply higher markups or lower profit shares.\nSince we develop a framework with constant markups, di fferences in scale economies\nare analagous to di fferences in profits shares. Large, high-productivity, firms have large\nprofit shares and low scale economies, whilst small, low-productivity, firms have low\nprofit shares and high scale economies.\nFigure 2 illustrates scale economies from the production side. It conveys the idea\nthat small firms have high scale economies, whilst large firms have low scale economies.\nThe figure represents an economy where firm output is produced directly by production\nlabour. In order to produce there is some overhead labour that is the same for both firms.\nTotal labour is the sum of production labour and overhead labour. The figure shows\nthat a 10% rise in total labour at a firm raises production labour by 100% for the small\nfirm, but only 13% for the large firm. Therefore, a proportional change in inputs has a\nproportionally larger e ffect on output for the small firm.\n9In this paper we will show this for labour denominated fixed costs beginning with the production\nfunction. Savagar (2021) shows it for output-denominated fixed costs beginning with the cost function.\n10The total cost share is the sum of the variable cost share and the fixed cost share.\n11This result was used in earlier empirical work on returns to scale, when profits in the US economy were\nclose to zero (Basu and Fernald 1997).\n9Small Large01020304040\n10\n9Overhead Labour\nProduction Labour\n10% Rise Total\nFigure 2: Scale Economies for Large and Small Firm\n2 Empirical Motivation\nWe are motivated by the presence of rising scale economies at the firm level, while aggre-\ngate measures of productivity are stagnating.\n2.1 Productivity\nFigure 3 shows UK aggregate TFP growth over time. Aggregate productivity growth in-\ncreases until 2007 but then declines and stagnates. This captures the UK ‘productivity\npuzzle’ (Barnett, Batten, Chiu, Franklin, and Sebastia-Barriel 2014; Goodridge, Haskel,\nand Wallis 2016).\n10Figure 3: UK TFP Growth, 1998 - 20141998\n2000\n2002\n2004\n2006\n2008\n2010\n2012\n201411.021.041.061.08\nTFP (aggregate)\nYearTFP Growth\nTFP growth (aggregate) is from the Penn World Table 10.01 (Feenstra, Inklaar, and Timmer 2015), ac-\ncessed from FRED: Total Factor Productivity at Constant National Prices for United Kingdom (RTFP-\nNAGBA632NRUG).\n2.2 Returns to Scale in Variable Inputs\nTo measure returns to scale, we estimate firm-level production functions on UK data\nfrom the Annual Respondents Database (ARDx). The data contains approximately 50,000\nfirms each year, 11 million workers, and two-thirds of gross value added. Firms report\na range of production data, including gross output, value added, labour, materials, and\ninvestment.12We assume that we observe variable inputs, net of fixed costs.\nWe assume that each firm ȷhas the following Cobb-Douglas production function\nyȷt=Aȷtkβk\nȷtℓβℓ\nȷt\nwhereyt,kȷt,ℓȷtare firm value-added and inputs of capital and labour. Aȷtis a measure of\n12In the appendix, we provide details about the data, data cleaning, deflation, capital construction, SIC\ncode matching, and summary statistics.\n11firm-level technical e fficiency which we do not observe. Our aim is to estimate the βkand\nβℓparameters which represent output elasticities. The sum of these output elasticities is\nreturns to scale in variable inputs.\nProduction function estimation su ffers from omitted variable bias. The bias occurs be-\ncause the input variables are correlated with the unobserved firm-level technology term.\nThere are various methods to address this problem (Olley and Pakes 1996; Levinsohn\nand Petrin 2003; Ackerberg, Caves, and Frazer 2015; Gandhi, Navarro, and Rivers 2020).\nSince we estimate Cobb-Douglas production functions, we obtain a single, time-invariant,\ncoefficient for each input in the production function.\nFigure 4 shows estimated returns to scale across firms in the UK using the estimation\nmethodology of Gandhi, Navarro, and Rivers (2020). There is a rising trend in returns\nto scale, from weakly decreasing to above unity. In the appendix, we provide estimates\nat the industry level and for alternative estimation methodologies. All the results imply\nrising returns to scale.\n12Figure 4: UK RTS, 2001 - 20142000\n2002\n2004\n2006\n2008\n2010\n2012\n20140.9911.011.021.031.041.05Mean\nTrend\nYearRTS\nRTS are the sum of firm-level coe fficients from a Cobb-Douglas, gross-output, production function esti-\nmated with the methodology of Gandhi, Navarro, and Rivers (2020). To obtain time-varying estimates of\nRTS, we estimate production functions over rolling windows.\n2.3 Fixed Cost Share in Revenue\nAn alternative contributor to firm scale economies is the fixed cost share. In Figure 5, we\nuse the administration expense share in revenue as a proxy for a companies’ fixed cost\nshare. This follows other literature such as De Loecker, Eeckhout, and Unger (2020). The\nfigure shows rising fixed cost shares which is consistent with rising scale economies at the\nfirm level. Administration expenses in UK company accounts are the costs incurred by a\ncompany that are not directly related to the production, manufacture or sale of goods or\nservices. In the Appendix we discuss the data in greater detail and provide examples of\nadministrative costs.\n13Figure 5: Median Fixed Cost Share in Sales, Source: BvD FAME\n2005\n2010\n2015\n20200.50.6\nYearAdmin. Cost Share in Sales\nThe plot shows the median ‘Administration Expenses’ share in ‘Turnover’ for UK firms.\n3 Model\nThe household side of the model follows a neoclassical growth setup. The production\nside of the economy has firm entry and exit, monopolistic competition, and production\nfunctions that have fixed costs and returns to scale.\n3.1 Households\nA representative household maximizes lifetime utility subject to a budget constraint\nmax\n{Ct,Kt+1}∞\nt=0∞X\nt=0βtC1−σ\nt−1\n1−σ, β∈(0,1),\ns.t.Ct+It=rtKt+wtLs+Πt+Tt (1)\nIt=Kt+1−(1−δ)Kt. (2)\nHouseholds own all firms in the economy and receive profits Πt.Ttis a lump sum transfer\nfrom the government that will be equal to the entry fees paid by the firms. Households\n14supply a fixed amount of labour that is not time-varying, we normalize this to one:\nLs= 1. (3)\nHouseholds own the capital stock and rent it to firms at a rental rate rt, hence the cap-\nital investment decision is part of the household problem. The household optimization\nproblem satisfies the following condition\n Ct+1\nCt!σ\n=β(rt+1+ (1−δ)). (4)\nplus a transversality condition and the resource constraint.\n3.2 Firms\n3.2.1 Final goods producer\nThe final goods aggregator is\nYt=Nt\"1\nNtZNt\n0yt(ı)1\nµdı#µ\n. (5)\nThere areNtintermediate producers on the interval ı∈(0,Nt). The parameter µ≥1\ncaptures product substitutability.13The aggregator has constant returns to scale.14\n13Perfectly substitutable products µ= 1 are admissible when intermediate producers have a fixed cost\nand increasing marginal cost ( φ> 0 andν∈(0,1)). This is the case of perfect competition where profit\nmaximizing intermediate producers take price as given. Under perfect competition all firms produce at the\nminimum on their average cost curves with perfectly-elastic, horizontal, demand curves.\n14A typical CES production function would have the pre-multiplying term as Nµ\nt, such that is cancels\nwith the 1/Ntinside the square brackets. However, this creates increasing scale economies in aggrega-\ntion. Since our interest is scale economies at the firm level, we remove this additional source of scale in\naggregation.\n15The maximization problem of the final goods producer is\nΠF\nt= max\nyt(ı)Yt−ZNt\n0pt(ı)yt(ı)dı (6)\ns.t.Yt=Nt\"1\nNtZNt\n0yt(ı)1\nµdı#µ\n(7)\nThe firm is infinitesimal so firm level output does not a ffectYt. The first-order condition\nwith respect to yt(ı) gives the inverse-demand for a firm\npt(ı) = Ntyt(ı)\nYt!1−µ\nµ\n. (8)\n3.2.2 Intermediate goods producer\nThe timeline for the intermediate goods producer is as follows. The firm pays cost κto\nenter. It receives a draw ȷ∈(0,1) from an i.i.d uniform distribution which translates to\nproductivity A(ȷ). It then decides whether to produce which incurs a fixed overhead cost.\nIf the firm does not produce it remains inactive which we refer to as endogenous exit. All\nfirms, active and inactive, exit at the end of one period.\nThe production function for a firm with productivity ȷis given by\nyt(ȷ) =A(ȷ)h\nkt(ȷ)αℓt(ȷ)1−αiν. (9)\nThe parameter 0 <α< 1 captures the capital cost in total variable cost. The parameter\nν>0 captures returns to scale in variable inputs. This represents returns to scale in vari-\nable inputs which captures the slope of the marginal cost curve. There are decreasing\nreturns in variable production when ν∈(0,1), constant returns when ν= 1, and increas-\ning returns when ν>1. Asν: 0→1 the marginal cost curve flattens which raises returns\nto scale, when ν= 1 the marginal cost curve is flat, and as ν: 1→∞ the marginal cost\n16curve is increasingly downward sloping.15The labour employed to produce output is:\nℓt(ȷ) =ℓtot\nt(ȷ)−φ, (10)\nwhereℓtot\nt(ȷ) represents the total labour employed by the firm, and φis an overhead\ncost.16Bothφandνdetermine scale economies.\nThe firm solves the following profit maximization problem:\nmax\nkt(ȷ),ℓt(ȷ)pt(ȷ)yt(ȷ)−rtkt(ȷ)−wt(ℓt(ȷ) +φ) (11)\nsubject to the production function (9) and inverse demand function (8). The optimality\nconditions imply constant factor shares in revenue:\nrtkt(ȷ)\npt(ȷ)yt(ȷ)=ν\nµα (12)\nwtℓt(ȷ)\npt(ȷ)yt(ȷ)=ν\nµ(1−α). (13)\nFor the second-order conditions on profit maximization to hold, a necessary condition is:\nν<µ . We present the first- and second-order conditions in Appendix C.1. Additionally,\nwe assumeαν< 1.17Therefore, we assume the following upper-bound on returns to scale\nin variable inputs.\n15We show that downward sloping MC curve must be shallower than the downward sloping demand\ncurve to ensure a profit-maximizing equilibrium where MR=MC exists.\n16We follow related theoretical literature in using labour-denominated overhead costs (Melitz 2003;\nHopenhayn, Neira, and Singhania 2022). Dhyne, Kikkawa, Komatsu, Mogstad, and Tintelnot (2022)\npresent empirical evidence of sizable fixed overhead costs in labour for Belgian firms. An output-\ndenominated overhead cost, as in Savagar (2021), limits the tractability of our analytical results.\n17This assumption is not required for profit maximization to hold. Imperfect competition ensures that\nfirm-level revenue is concave in inputs, even if output is not concave in inputs. That is, marginal revenue\nproducts are decreasing in their respective inputs, even if marginal products are not. Specifically, 0 <αν< 1\nensures firm-level output is concave in capital, and aggregate output is concave in aggregate capital and\nnot decreasing in aggregate labour.\n17Assumption 1. Increasing returns in variables inputs are limited as follows:\nν<min\Z1\nα,µ\n. (14)\nA higher markup and a lower capital cost share in variable costs allow for greater\nreturns to scale in variable inputs.\nFrom the factor market equilibrium conditions, the ratio ν/µ= (wℓ+rk)/pyis variable\ncost share in revenue. The remaining share, 1 −(ν/µ), is the profit plus fixed cost share in\nrevenue. Additionally, α=rk/(wℓ+rk) and 1−α=wℓ/(wℓ+rk) are the share of capital and\nproduction labour in variable costs. Also, αν=µ(rk/py ) is the capital share in revenue\nscaled by the markup.\n3.2.3 Ratio of firm size\nFirm output, revenue and inputs are proportional to productivity to the power of a con-\nstanty(ȷ)1\nµ,p(ȷ)y(ȷ),k(ȷ),ℓ(ȷ)∝A(ȷ)1\nµ−ν. Consequently, for a given distribution of A(ȷ) across\nfirms, changes in µandνaffect the distribution of labour, capital, revenue and output\nacross firms.\nThe inverse demand condition and factor price equilibrium conditions imply that for\nany two firms, ıandȷ, their relative revenue and input choices are proportional to their\nrelative (scaled) productivity:\npt(ȷ)yt(ȷ)\npt(ı)yt(ı)=kt(ȷ)\nkt(ı)=ℓt(ȷ)\nℓt(ı)= A(ȷ)\nA(ı)!1\nµ−ν\n,∀ı,ȷ. (15)\nAdditionally, if we use equation (8) to substitute out pt, we can write:\nyt(ȷ)\nyt(ı)= A(ȷ)\nA(ı)!µ\nµ−ν\n. (16)\n183.2.4 Zero-profit firm\nWe assume there is a threshold productivity draw Jt∈(0,1) characterised by zero profits,\nwhich yields threshold technology At. If a firm receives a productivity draw below the\nthreshold productivity level they would make negative profits from production. Conse-\nquently, they prefer to produce zero and make zero profits. Therefore we define profits\nand characterise the threshold productivity as follows:\nπt(ȷ) =pt(ȷ)yt(ȷ)−rtkt(ȷ)−wt(ℓt(ȷ) +φ) (17)\nπt(Jt) = 0. (18)\nA helpful reduced-form expression for profits combines the profit condition with equilib-\nrium factor prices, with the zero-profit condition and with the ratio of revenues to scaled\nproductivity:\nπt(ȷ) =φwt\n A(ȷ)\nAt!1\nµ−ν\n−1\n. (19)\n3.2.5 Free Entry\nAll firms die after one period. A firm produces if it makes positive profits, hence firm\nvalue is given by\nvt(ȷ) = max{πt(ȷ),0}. (20)\nWe assume a free entry condition which implies that the unconditional expected value\nfrom entering equals to the entry cost κ:\nE[vt(ȷ)] =κ. (21)\nThe cost of entry κis denominated in consumption units and is rebated to households\nin a lump-sum. Combining (20) and (21) with our reduced-form profit expression (19)\n19yields:\nφwt(1−Jt)\n ˆAt\nAt!1\nµ−ν\n−1\n=κ. (22)\nThis shows that profits from being active multiplied by the probability of being active\n1−Jtequals the entry cost. We have defined the power mean of technology, conditional\non being active, as\nˆA(Jt)≡E\nA(ȷ)1\nµ−νȷ>Jtµ−ν\n=\"1\n1−JtZ1\nJtA(ȷ)1\nµ−νdȷ#µ−ν\n. (23)\nThe power mean is a weighted average of firm-level productivity.18\n3.3 Entry\nOperating firms Ntare the subset of firms who decide to produce once receiving their\nproductivity draw. Entrants Etare all firms who pay the entry cost.\nNt=ZNt\n0dı=EtZ1\nJtdȷ=Et(1−Jt). (24)\nWe can interpret the productivity cut-o ffJtas the probability of exit and 1 −Jtas the\nprobability of surviving.\n3.4 Aggregation\nTo obtain aggregate output and aggregate inputs, we use that the index of operating firms\n(0,Nt) is equivalent to the measure of entering firms Etrestricted over the region of oper-\nation (Jt,1).\n18The term ˆA(Jt) generalizes Melitz (eq. 7 2003, p. 1700) and Colciago and Silvestrini (eq. 31 2022, p.\n10). This term is equivalent to these papers if ν= 1 and the markup is expressed in terms of elasticities of\nsubstitution between goods, for example µ=θ/(θ−1) whereθis the elasticity parameter. Notably, with\nν,1, we cannot represent the power mean of technology ˆAas an output-weighted harmonic average of\nunscaled technology draws.\n203.4.1 Aggregate Factor Inputs\nAggregate labour is comprised of production labour and non-production labour\nKt=ZNt\n0kt(ı)dı=EtZ1\nJtkt(ȷ)dȷ (25)\nLt=ZNt\n0[ℓt(ı) +φ]dı=EtZ1\nJt[ℓt(ȷ) +φ]dȷ. (26)\nWe defineutas the fraction of aggregate labour that goes to production\nut≡EtR1\nJtℓ(ȷ)dȷ\nLt=RNt\n0ℓt(ı)dı\nLt(27)\n1−ut=Et(1−Jt)φ\nLt=Ntφ\nLt. (28)\n3.4.2 Aggregate Output\nWe can express aggregate output as:\nYt=NtˆAth\n(Kt/Nt)α(utLt/Nt)1−αiν=N1−ν\ntˆAth\nKα\nt(utLt)1−αiν. (29)\nThe first expression shows that aggregate output is the sum across Nthomogeneous firms\neach with average technology ˆAt. The aggregate output expression is homogeneous of\ndegree one in capital, production labour and number of firms, which implies there are\nconstant returns in these factors. If Ntis treated as a fixed factor, then the function is\nhomogeneous of degree νin capital and production labour. In other words, external\nreturns to scale in aggregate capital and production labour are given by ν.\n213.4.3 Aggregate Factor Market Equilibrium\nThe wage, rental rate on capital and zero-profit condition are\nrt=αν\nµYt\nKt(30)\nwt= (1−α)ν\nµYt\nutLt(31)\nwt\nYtNtφ\nLt= \n1−ν\nµ! At\nˆAt!1\nµ−ν\n(32)\n3.5 Government Budget Constraint and Resource Constraints\nThe resource constraint is\nYt=Ct+It. (33)\nThe government rebates entry fees to households. The government budget constraint\nequates taxes to government expenditure\nTt=Etκ. (34)\nProfits and labour markets clear:\nΠt=ΠF\nt (35)\nLt=Ls. (36)\nAggregate profits received by the household from owning firms equate to profits earned\nby the final goods producer. The profits are zero in equilibrium. Labour demanded by\nthe firm equates to labour supplied by the household which is normalised to 1.\n223.6 Equilibrium Definition\nAn equilibrium is a sequence of prices {rt,wt}∞\nt=0; firm capital and labour demands {ℓt(ȷ),kt(ȷ)}∞\nt=0;\nfirms’ operating decisions to be active or inactive, measures of entry and active firms\n{Et,Nt}∞\nt=0; consumption and capital {Ct,Kt+1}∞\nt=0, such that\n1. households choose CandKoptimally by solving problem (1);\n2. firms compete decide optimally whether to produce or remain inactive, and de-\nmand factors according to (11);\n3. the free entry condition holds (21);\n4. markets clear for aggregate labour (26), aggregate capital (25), goods market (33),\nlabour market (36) and aggregate profits (35);\n5. the government budget constraint is satisfied (34).\n3.7 Model Characteristics\nAggregation allows us to remove individual firm heterogeneity ȷfrom the model. This\ndoes not mean heterogeneity is irrelevant. There would be no selection e ffect without\nheterogeneity. But aggregation allows us to summarise all the heterogeneity in one term\nˆAt, and then solve the model. In other words, the model economy with individual het-\nerogeneity is isomorphic to the model with homogeneous firms, each endowed with the\npower mean of technology ˆAt. Before imposing a Pareto distribution on the technology\ndrawsA(ȷ), we characterise some general properties of the model.\n233.7.1 Aggregate Labour Utilized for Production\nFrom (31) and (32), and using Ntφ/Lt= 1−ut, we get the level of aggregate labour utilized\nin production as a function of J:\nut=\n1 +1\n1−αµ\nν−1 At\nˆAt!1\nµ−ν\n−1\n.\nIn turn, by equation (31) this implies that the aggregate labour share wtLt/Ytis only a\nfunction of Jtthrough the ˆA/Aratio.\n3.7.2 Aggregate Productivity\nWe can rearrange aggregate output into Cobb-Douglas form which gives:\nYt= TFPtKαν\ntL1−αν\nt (37)\nwhere, TFP t≡ Nt\nLt!1−ν \n1−Ntφ\nLt!(1−α)ν\nˆAt (38)\n= 1−ut\nφ!1−ν\nu(1−α)ν\ntˆAt (39)\nAggregate total factor productivity (TFP) measures aggregate output that is not accounted\nfor by aggregate capital and aggregate labour. TFP is not the Solow residual because the\nexponents of aggregate capital and labour do not correspond to aggregate factor shares.19\nIt is helpful to decompose TFP into allocative e fficiency and technical e fficiency:\nTFPt=Ωt|{z}\nallocative× ˆAt|{z}\ntechnical. (40)\n19The termανis the aggregate capital share in output multiplied by the markup αν=µ×rK/Y .\n24We define ˆAtastechnical e fficiency , and we define allocative e fficiency as:\nΩt≡ Nt\nLt!1−ν\n|   {z   }\nScale e ffect× \n1−Ntφ\nLt!(1−α)ν\n|             {z             }\nResource duplication.\nAllocative e fficiency captures the negative e ffect of more firms duplicating fixed costs,\nand the scale e ffect of dividing aggregate labour among more firms, which will depend on\nreturns to scale ν⋛1. Technical e fficiency is the generalised mean, conditional on being\nactive, of exogenously drawn technology. It is determined by selection. Under Pareto\ndistributed A(ȷ), technical e fficiency is a linear function of the threshold productivity\nlevel A .20\n3.7.3 Scale Economies\nThe parameters νandφare both sources of scale economies in the model. Scale economies\nare measured as the ratio of average cost to marginal cost (the inverse cost elasticity). In\nthis section, we show this from the production side by summing output elasticities. The\nsame result can be shown from the cost function.21\nFrom equations (9) and (10), the response of firm output to a change in each variable\ninput is constant. Consequently, returns to scale in variable inputs is constant:\n∂lnyt(ȷ)\n∂lnkt(ȷ)=να,∂lnyt(ȷ)\n∂lnℓt(ȷ)=ν(1−α),∂lnyt(ȷ)\n∂lnkt(ȷ)+∂lnyt(ȷ)\n∂lnℓt(ȷ)=ν.\n20Our TFP decomposition is similar to Jaimovich, Terry, and Vincent (2023), but they do not have a\nresource duplication e ffect from entry. They study the e ffect of an output subsidy on the components.\n21Savagar (2021) shows this for a model with output denominated fixed costs.\n25The effect of a change in total labour input is decreasing in firm size:22\n∂lnyt(ȷ)\n∂lnℓtot\nt(ȷ)=ν(1−α) \n1 +φ\nℓt(ȷ)!\n=ν(1−α) + (µ−ν) At\nA(ȷ)!1\nµ−ν\n∈(ν(1−α),µ−αν).\nTherefore, scale economies at the firm are decreasing in firm size:\nSt(ȷ)≡∂lnyt(ȷ)\n∂lnkt(ȷ)+∂lnyt(ȷ)\n∂lnℓtot\nt(ȷ)=ν \n1 + (1−α)φ\nℓt(ȷ)!\n=ν+ (µ−ν) At\nA(ȷ)!1\nµ−ν\n∈(ν,µ).(41)\nA firm’s scale economies decrease as production labour rises relative to the labour over-\nhead, or as firm productivity rises relative to the productivity cut-o ff. Figure 6 plots (41)\nfor a given A . More productive firms have lower scale economies. The cut-o fffirm has\nthe highest level of scale equals to the markup, and scale converges on returns to scale in\nvariable inputs νfor high-productivity firms.\n22For the second equality, we use the zero-profit condition\n1−ν\nµ\npt(ȷ)yt(ȷ) =wtφ\nA(ȷ)\nAt1\nµ−νcombined with\nlabour demandwt\npt(ȷ)yt(ȷ)=ν(1−α)\nµ1\nℓ(ȷ)to yieldν(1−α)φ\nℓt(ȷ)= (µ−ν)At\nA(ȷ)1\nµ−ν.\n26Figure 6: Firm-level Scale Economies in Steady-State\nAµ\nνS(ȷ)\nA(ȷ)S(ȷ)\nPlot shows equation (41) scale of a firm given its productivity draw. In the shaded region firms are inactive\nand the dashed line shows their hypothetical scale economies if they were to produce. The horizontal lines\nshow the bounds on scale economies of active firms S(ȷ)∈(ν,µ). We have assumed A(ȷ) is Pareto distribution\nand we have set A arbitrarily.\n3.8 Model with Pareto Distribution\nWe assume that the technology variable is Pareto distributed. Given a random variable\nȷdrawn from the uniform distribution on the unit interval [0 ,1), then the productivity\nvariableA(ȷ) given by the quantile function:\nA(ȷ) =h\n(1−ȷ)1\nϑ. (42)\nThe parameter ϑ>1 is the Pareto shape parameter and his the scale parameter, which\nis the lowest value of technology, corresponding to ȷ= 0. We set h= 1. A thicker-tailed\nPareto distribution occurs as ϑ→1, which implies a higher density of high-productivity\ndraws and a lower density of low-productivity draws. A thinner-tailed Pareto distribution\noccurs asϑ→∞ which implies a lower density of high-productivity draws and a higher\ndensity of low-productivity draws.\n27Under Pareto, the power mean of technology is:\nˆAt= ϑ(µ−ν)\nϑ(µ−ν)−1!µ−ν\nAt=ΓAtwhere Γ≡ ϑ(µ−ν)\nϑ(µ−ν)−1!µ−ν\n. (43)\nThe constant Γis the unconditional expectation of scaled technology A(ȷ)1\nµ−ν. If the cuto ff\ntook its minimum value At= 1, such that all participants were active and there was no\nselectionJt= 0, this represents the average technology that would arise. To ensure that\nscaled technology A(ȷ)1\nµ−νhas a finite expectation, we require that the scaled Pareto shape\nparameter satisfies the following assumption.\nϑ(µ−ν)>1. (44)\nThis limits the degree of fat tails in the technology distribution. The assumption is anal-\nogous to the assumption ϑ>1 for the Pareto distributed technology before it is scaled.\n3.8.1 Equilibrium Conditions with Pareto Distribution\nGiven the constant ratio between the power mean of technology and cut-o fftechnology in\nequation (43), several equilibrium conditions simplify. Labour utilized for production is\nconstant, aggregate TFP is a linear function of cut-o fftechnology, and wage is a log-linear\nfunction of cut-o fftechnology:\nu= \n1 +ϑ(µ−ν)−1\nνϑ(1−α)!−1\n1−u=ϑ(µ−ν)−1\nϑ(µ−αν)−1(45)\nTFPt=ΩˆAt,where Ω≡ 1−u\nφ!1−ν\nu(1−α)νand ˆAt=ΓAt (46)\nwt=κ\nφ[ϑ(µ−ν)−1]Aϑ\nt. (47)\nThe final equation determines the wage from the free entry condition. The lowest value At\ncan take is 1 which is the lowest productivity draw corresponding to J= 0. The constant\n28uimplies that total production labour is always a fixed fraction of aggregate labour as an\neconomy transitions over time. Labour utilized for production is invariant to the fixed\ncost, increasing in returns to scale, and decreasing in the markup:\ndu\ndφ= 0,du\ndν=(1−α)ϑ(ϑµ−1)\n(ϑ(µ−αν)−1)2>0,du\ndµ=−(1−α)ϑ2ν\n(ϑ(µ−αν)−1)2<0. (48)\nThe constant uimplies that the number of active firms is constant\nN=1−u\nφ=1\nφϑ(µ−ν)−1\nϑ(µ−αν)−1. (49)\nTherefore, we can characterise the number of active firms as decreasing in the fixed cost\nand returns to scale, and increasing in the markup:\ndN\ndφ=−N\nφ<0,dN\ndν=−1\nφdu\ndν<0,dN\ndµ=1\nφdu\ndµ>0. (50)\nAs the marginal cost curve becomes flatter ν<1, horizontal ν= 1 and downward sloping\nν>1, optimal firm size (MR=MC) increases, and more total labour goes toward produc-\ntion (urises). With larger firms the number of firms declines. An increase in fixed cost\nφdoes not alter the fraction of production labour in total labour, so the number of firms\nmust decrease to keep the ratio of total fixed costs to labour fixed. An increase in the\nmarkup increases the number of firms because the demand curve becomes steeper which\nreduces optimal size, consequently there is more duplication of the fixed cost and the\nproduction labour share in total labour falls.23\nAn implication of constant uandNis that the aggregate labour share wtLt/Ytis con-\nstant:\nsL≡wL\nY=1\nµ\nµ−αν−1\nϑ\n.\n23This is the result of excess entry of ‘small’ firms under monopolistic competition (Dixit and Stiglitz\n1977; Mankiw and Whinston 1986).\n29The labour share is increasing in the markup, decreasing in returns to scale and invariant\nto the fixed cost.\nThe equilibrium conditions under Pareto reduce to a dynamic system in {Kt,Ct}:\nΩΓΨKανϑ\nϑ−1\nt−Ct=Kt+1−(1−δ)Kt (51)\n Ct+1\nCt!σ\n=β\"\nαν\nµΩΓΨKανϑ\nϑ−1−1\nt+1+ (1−δ)#\n. (52)\nwhere Ω,Ψ,Γare constants.24We impose the following:\n1−ϑ(1−αν)<0. (53)\nThis ensures that aggregate output is concave in aggregate capital, and therefore the price\nof capital is decreasing in aggregate capital. From equations (44) and (53), we have lim-\nited the thickness of the Pareto tail by making two assumptions, which we summarise\nbelow.\nAssumption 2. The Pareto shape parameter must satisfy\n1\nϑ<minµ−ν,1−αν	. (54)\n3.8.2 Steady-state with Pareto Distribution\nIn steady state the system satisfies Kt+1=Kt=KandCt+1=Ct=C. This yields the\nfollowing steady-state solution for capital and consumption:\nK=\"ανΩΓΨ\nµr#ϑ−1\nϑ(1−αν)−1\n(55)\nC=Kµr\nαν−δ\n. (56)\n24Full derivation in appendix.\n30wherer=1\nβ−(1−δ). The remaining steady-state variables follow by substituting the\nexpression for Kinto the reduced model, which we present in the appendix. In particular,\nsolving for the technology threshold A yields:\nA=\"\nνν1\nµα\nrαν\n(φ(1−α))ν(1−α)ϑµ−1(µ−ν)µ−ν1\nκ1−αν1\n(ϑ(µ−ν)−1)µ−αν# 1\nϑ(1−αν)−1\n. (57)\n4 Theoretical Analysis\nChanges in aggregate productivity occur through an allocation component dlnΩand a\ntechnical e fficiency component dlnˆA:\ndlnTFP =dlnΩ+dlnˆA\n4.1 The E ffect of Entry Cost on Aggregate Productivity\nThe entry cost κdoes not a ffect allocative e fficiency Ω, but a ffects technical e fficiency\nˆA. If the entry cost increases, then technical e fficiency decreases because the threshold\ntechnology level falls, thus weakening selection.25Selection weakens as the entry cost in-\ncreases because, by the free-entry condition, the expected value of the firm must increase.\nThe expected value increases if the threshold productivity declines.\n4.2 The E ffect of Fixed Costs on Aggregate Productivity\nChanges in fixed costs a ffect aggregate TFP through an allocation component and a tech-\nnology component:\ndlnTFP\ndlnφ=dlnΩ\ndlnφ+dlnˆA\ndlnφ\n25Barseghyan and DiCecio (2011) study this in a perfectly competitive economy, where the entry cost is\nin terms of output κ/Y. They find empirical evidence that higher entry costs decrease aggregate TFP across\ncountries.\n31Under Pareto, technical e fficiency depends on the technology threshold A only since the\nconstant Γis invariant to φ, therefore:\ndlnˆA\ndlnφ=dlnΓ\ndlnφ+dlnA\ndlnφ= 0 +ν(1−α)\nϑ(1−αν)−1>0.\nThe technology threshold is increasing in the overhead cost if ϑ(1−αν)−1>0. This is the\ncondition for the rental rate rto be decreasing in aggregate capital.\nThe allocation e ffect depends on the degree of returns to scale in variable production:\ndlnΩ\ndlnφ=−(1−ν).\nThe result is independent of the Pareto distribution assumption. We can interpret the al-\nlocation e ffect through the number of firms. Note that Ω=1−u\nφ1−νu(1−α)ν=N1−νu(1−α)ν\nanduis independent of φ. An increase in φ, decreases the number of active firms. With\nincreasing returns ( ν>1), allocative e fficiency is improved by having fewer firms, as they\nbenefit more from the increasing returns. On the other hand, with decreasing returns\n(ν<1), then having fewer firms is detrimental to allocative e fficiency, as the e ffect of de-\ncreasing returns is accentuated. Lastly, with constant returns ( ν= 1), the number of firms\nhas no e ffect on allocative e fficiency.\nCombining the allocative and technical e fficiency e ffects, shows that the response of\naggregate TFP to a change in fixed costs will depend on the level of returns to scale in\nvariable inputs ν.\ndlnTFP\ndlnφ=−(1−ν) +ν(1−α)\nϑ(1−αν)−1(58)\nFigure 7 simulates equation (58) for di fferent values of νbased on our benchmark\ncalibration (Table 1).\n32Figure 7: E ffect ofφon TFP for di fferentν\nIn Figure 8, we decompose the three cases from Figure 7.26Technical e fficiency always\nrises as the fixed cost increases, while the allocative e fficiency component is determined\nbyν⋛1, as previously discussed.\n26The effect ofφon TFP is the same regardless of µ.\n33Figure 8: E ffect of lnφon TFP decomposed into ˆAandΩfor differentν\n4.3 The E ffect of Returns to Scale on Aggregate Productivity\nThe nonlinearity of Equation (57) in νmakes it di fficult to obtain a closed-form expres-\nsion for the influence of νon TFP . Therefore, we present simulations to illustrate this\neffect. The model is calibrated as in Table 1. We set νandµto the middle of the range\npresented as a baseline, but allow the evolution of both variables as estimated from the\nmicrodata and external sources.\n34Calibration\nTable 1: Parameter Values for Comparative Statics\nParameter Value Target\nβDiscount rate 0.96 Real interest rate\nδDepreciation rate 0.08 O ffice for National Statistics\nνVariable RTS 0.99 - 1.05 ABS (authors’ estimates)\nµMarkup 1.21 - 1.28 CMA (2022)\nαCapital share 0.25 ABS (authors’ calculations)\nϑPareto shape 10 Match firms per worker\nκEntry cost 0.017 Model-implied maximum given range of ν,µ\nφOverhead cost 0.85 Match share inactive firms\nWe set the discount factor βto match the average real interest rate of 2.08 percent over\nthe period. To do this, we use the equation for steady-state interest rate r=1\nβ+ 1−δ.27\nThe depreciation rate δis determined by a weighted-average from ONS data. Our esti-\nmates of the returns to scale νcome from our estimates of the production function using\nthe estimation of Gandhi, Navarro, and Rivers (2020). Markup estimates are from CMA\n(2022). They use a di fferent dataset and estimation strategy. These markup estimates\nare consistent with other studies that show rising markups over this time period (ONS\n2022; Hwang, Savagar, and Kariel 2022). Our results are not sensitive to these markup\nestimates. In the modelαν\nµis the capital share in revenue and(1−α)ν\nµis the production\nlabour share in revenue. Given our νandµestimates, we set α= 0.25 to match a capital\nshare of 20%.28\nThe entry cost parameter κand the fixed cost parameter φmust satisfy restrictions\nsuch thatJt∈(0,1). The model places an upper limit on κfor values of µ,ν. We setκ\n27Data on UK long-term government bond and inflation used to compute the real interest rate from FRED\ndatabase: IRLTLT01GBM156N and FPCPITOTLZGGBR.\n28The ratioν/µis the revenue elasticity, which is typically set to 0.85 in US studies (Restuccia and Roger-\nson 2008; Barseghyan and DiCecio 2011). Hopenhayn (2014) discusses this common calibration. Our\nestimates for νdivided by our calibrated markup µyield a ratio from 0.81 to 0.84 between 2001 and 2014.\n35at this maximum. We choose φto target the share of ‘inactive’ firms Jt, to match the\nshare of firms that do not produce but ‘re-activate’ within a two year window.29In the\nUK the average share of ‘inactive’ firms between 2016 - 2020 was 10%.30We also check\nour calibration of κandφby looking at the ratio κ/φw . Barseghyan and DiCecio (2011)\nreport a range of values from industry studies. In most industries, the ratio is less than\none, so entry costs are less than overhead costs. The average they report is 0.82. Our\nexperiments vary ν,φ,µ parameters, so the entry-to-overhead cost ratio will vary as we\nchange these values, but the outcome always remains below 1.\nOur theory imposes restrictions on the Pareto shape parameter ϑ. First,ϑ>1\nµ−νwhich\nensures scaled productivity is Pareto distributed and the first moment exists, and second,\nϑ>1\n1−ανwhich ensures aggregate output is concave in aggregate capital, so that the inter-\nest rate is decreasing in aggregate capital.31Our calibrated markup minus our estimated\nreturns to scale µ−νis between 0.198 and 0.234 from 2001 - 2014. Therefore, our re-\nstrictions imply that we must set ϑ>5, similar to Hopenhayn (2014) who sets the Pareto\nshape between 5 and 10.\nWe use the number of firms per worker N/L to calibrate the Pareto shape ϑ. Our\nmodel yields φN/L =ϑ(µ−ν)−1\nϑ(µ−αν)−1\n. We set the parameters φ,α as calibrated. We plug in the\nestimates for ν,µ. We obtain the number of firms from business population estimates32\nand the number of people employed from the ONS.33Combining the data on N/L, which\nrises from 0.126 to 0.170, we can back-out a series for ϑ. This yields ϑaveraging 8.6\nbetween 2001 - 2004, rising to 10.4 at the end of the sample from 2011 - 2014. It averages\n10 over the sample, so we choose this calibration, which is also the upper bound from\n29This is a standard approach by the ONS and OECD to ensure accurate measures of firm\ndeaths. https://www.ons.gov.uk/businessindustryandtrade/business/activitysizeandlocation/\ndatasets/businessdemographyreferencetable\n30This is the only time frame for which the detail is available.\n31The first restriction implies that scaled technology, A(ȷ)1\nµ−ν= (1−ȷ)−1\nϑ(µ−ν), is Pareto distributed. In some\nexperiments, we take ν→µfrom below, and this requires us to raise the value of ϑ. The relevant value for\nus is the scaled Pareto parameter ϑ(µ−ν), since labour is distributed proportionally to this term.\n32https://www.gov.uk/government/statistics/business-population-estimates-2022 .\n33MGRZ series, Labour Market Statistics: https://www.ons.gov.uk/employmentandlabourmarket/\npeopleinwork/employmentandemployeetypes/timeseries/mgrz/lms .\n36Hopenhayn (2014). If we allow ϑto rise in our quantitative exercise, the results are do\nnot change substantively.\nFigure 9 shows the e ffect ofνon aggregate productivity for di fferent values of the\nmarkupµ. We observe that aggregate productivity rises unambiguously in νin a low\nmarkup economy, but not when the markup is higher. Both the level and the slope of the\nrelationship is falling in µ.\nFigure 9: E ffect of variable RTS on ln TFP for di fferent levels of the markup\nln TFP for calibrated model for a range of νandµ.\nIn Figure 10 we provide a decomposition into technical e fficiency and allocative ef-\nficiency for each of these markup cases. We observe that the weakening passthrough of\nreturns to scale to TFP occurs because of weakening technical e fficiency (i.e. less selec-\ntion), and worsening allocative e fficiency.\n37Figure 10: E ffect ofνon TFP decomposed into ˆAandΩfor differentµ\nAs returns to scale νincrease, technical e fficiency ˆAincreases. This implies stronger\nselection of high A(ȷ) firms. However, the e ffect is weaker as market power increases.\nHence, in high-markup economies, there is weaker selection of high productivity firms\nas returns to scale increase.\nReturns to scale νhave a U-shaped relationship with allocative e fficiency. This oc-\ncurs because an increase in νdecreases the number of firms. With decreasing returns\n(ν<1), fewer firms harm allocative e fficiency. However, with increasing returns ( ν>1),\nfewer firms improve allocative e fficiency. As market power increases, the minimum point\nmoves right, causing a wider range of declining allocative e fficiency. This occurs because\nhigher markups increase the number of firms. Hence, the benefits of growing returns to\nscale for allocative e fficiency are counteracted by higher markups, reducing the size of\nfirms and limiting their ability to benefit from increasing returns.34\n34In Appendix C.3 we present aggregate output as a function of Nt, which shows these channels formally.\n384.4 The E ffect of Returns to Scale and Fixed Costs on Aggregate Pro-\nductivity\nTo summarise, the impact of changing νand changing φon aggregate productivity, op-\nerates through their e ffect on the number of active firms Nt, which, in turn, reflects the\nlevel of profits for a given productivity draw. Higher returns to scale or fixed costs both\nreduce profits which reduces the number of active firms. Whereas, a higher markup in-\ncreases profits which increases the number of active firms. The number of active firms is\nimportant for aggregate output because it determines technical e fficiency through selec-\ntion (fewer active firms means more selection), and it a ffects allocative e fficiency through\nboth a scale e ffect and resource duplication e ffect.\nAn important di fference between the e ffects of higher fixed costs and higher returns\nto scale on aggregate productivity is that the impact of returns to scale is a ffected by the\nmarkup, whereas fixed costs a ffect aggregate productivity the same regardless of the level\nof markup.35As returns to scale increase their e ffect of reducing the number of firms and\nenhancing productivity is strongly mitigated in higher markup environments. This is\nprimarily because the selection e ffect is weakened, limiting gains in technical e fficiency,\nwhilst there is also a drag from allocative e fficiency too.\nOverall, we conclude that both higher fixed costs or higher returns to scale tend to\nincrease aggregate productivity. However, this unambiguous outcome depends on the\npresence of increasing returns ν >1 in levels, which is what we find in our estimation\non UK data. In the presence of decreasing returns ν<1, the e ffects of higher fixed costs\nor higher returns to scale are more ambiguous. This is because as these parameters in-\ncrease, which reduces the number of active firms, aggregate resources are concentrated\non a smaller number of firms and these firms are subject to decreasing returns. In an\nenvironment of decreasing returns, it is better for aggregate output to spread aggregate\n35As our quantitative exercise will show, higher markups still have a direct e ffect of increasing the num-\nber of firms and reducing productivity, but they do not enhance or diminish the e ffect of greater fixed\ncosts.\n39resources across more active firms.\n5 Quantitative Application\nIn Section 4, we examined the impact on aggregate productivity of the parameters of\nthe production function that cause scale economies. We concluded that either higher\nfixed costs or higher returns to scale tend to increase aggregate productivity, though this\nrelies on increasing returns ν >1 to be unambiguous. We now analyse the quantitative\nplausibility of scale economies alongside stagnating productivity, which has occured in\nthe US and UK in recent years. We find that changing returns to scale in variable inputs\nalongside rising markups explains the data well, but rising fixed costs alongside rising\nmarkups cannot explain the data as well.\n5.1 Rising Returns to Scale\nWe calibrate the parameter νto our annual estimates from 2001 to 2014, while the pa-\nrameterµis set to annual estimates from CMA 2022. We set φ= 0.135 such that the share\nof inactive firms is empirically plausible in our benchmark calibration.\nFigure 11 compares the trends in TFP in the data and our model. It reveals a rise in\nboth series prior to the Financial Crisis, followed by a sharp decline in the data and a\nmore gradual decrease in the model. Fixing the markup to its 2001 value highlights the\nsignificant impact of rising returns to scale on aggregate productivity. If market power\nhad remained constant, higher returns to scale would have boosted aggregate productiv-\nity by over 20% between 2001 and 2014. However, when we incorporate the simultaneous\nincrease in markups and returns to scale, our estimated productivity trend aligns more\nclosely with observed data.\n40Figure 11: TFP Growth: Model vs Data\nWe give the model estimates of µand estimates of νand solve in each year for steady-state to obtain the\nmodel-implied TFP . The TFP data series is from the Penn World Table 10.01 (Feenstra, Inklaar, and Timmer\n2015), accessed from FRED: Total Factor Productivity at Constant National Prices for United Kingdom\n(RTFPNAGBA632NRUG).\n5.2 Rising Overhead Costs\nThe rise in both νandµin the UK explains aggregate productivity growth well. However,\nour empirical evidence shows that payments to administration costs as a share of sales has\nincreased for the median firm. We consider this data series as a proxy for wtφ/Ytin the\nmodel.36\nIn Figure 12 we calibrate φto match our estimates of this ratio. The results highlight\nthe opposing response of aggregate TFP conditional on the level of νthat we discussed\nin our theoretical analysis. Therefore the level of returns to scale in variable production\nis crucial for the implied e ffect of changing overhead costs. In our estimates, νis greater\nthan one, which implies productivity should have risen 10% over the period.\n36Since changing φhas general equilibrium e ffects onwtandYt, increasing this ratio does not necessarily\nmeanφincreases each period. This is relevant because our theoretical analysis focuses on changing φ, not\nthe ratio. However, in practice for our calibration, φand the ratio move together.\n41Figure 12: TFP Growth: Model (fixed νandµ, with variable φ) vs Data\nWe fixµto its 2001 level and calibrate φto match the overhead share in BvD data. We solve the model\nsteady-state in each year to obtain the model-implied TFP . The TFP data series is from the Penn World Table\n10.01 (Feenstra, Inklaar, and Timmer 2015), accessed from FRED: Total Factor Productivity at Constant\nNational Prices for United Kingdom (RTFPNAGBA632NRUG).\nIn Figure 13, we also re-calibrate µeach year to match CMA (2022) estimates. In this\ncase, aggregate TFP growth underperforms TFP growth in the data, regardless of returns\nto scale in variable production. Therefore, the markup e ffect dominates the fixed cost\neffect and we do not observe opposing dynamics for productivity conditional on ν⋛1.\n42Figure 13: TFP Growth: Model (fixed ν, with variable µandφ) vs Data\nWe give the model estimates of µand calibrate φto match the overhead share in BvD data. We solve the\nmodel steady state in each year to obtain the model-implied TFP . The TFP data series is from the Penn\nWorld Table 10.01 (Feenstra, Inklaar, and Timmer 2015), accessed from FRED: Total Factor Productivity at\nConstant National Prices for United Kingdom (RTFPNAGBA632NRUG).\n5.3 Rising Returns to Scale Versus Rising Fixed Costs\nOverall, the model with changing νandµreplicates the TFP data better than the model\nwith changing φandµ. And, in both cases treating the markup µas fixed implies the UK\neconomy should have experienced large productivity increases. Our theory explains that\nthis is because both e ffects enhance selection, and reduce the number of active firms, and\na reduced number of firms has a further positive e ffect on aggregate productivity if there\nare increasing returns to scale at the firm-level because aggregate resources are concen-\ntrated on fewer firms, and those firms benefit from the returns to scale. Higher returns\nto scale alongside higher markups appear to be a better candidate than higher fixed costs\nalongside higher markups because given the rise in markups always leads to a strong\nnegative e ffect on productivity, the higher returns to scale have a stronger positive e ffect\non aggregate productivity than higher fixed costs. The stronger positive e ffect on produc-\n43tivity is necessary to buoy aggreg', 'anthonysavagar@gmail.com', 'Joel Kariel, Anthony Savagar', '', '../pdf_files/67498237a9c00-Scale Economies and Aggregate Productivity.pdf', 557635, 74, 15726, 101489, '2024-11-29 08:58:32', '2024-11-29', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(18, '2901515339', '34', 1, 15, 'Pricing Multi-strike Quanto Call Options on Multiple Assets with Stochastic Volatility, Correlation, and Exchange Rates', '2024-11-29 21:12:39.806516', '2024', 'Quanto options allow the buyer to exchange the foreign currency payoff into the domestic currency at a fixed exchange rate. We investi gate quanto options with multiple underlying assets valued in different foreign currencies each with a different strike price in the payoff func tion. We carry out a comparative performance analysis of different stochastic volatility (SV), stochastic correlation (SC), and stochastic exchange rate (SER) models to determine the best combination of these models for Monte Carlo (MC) simulation pricing. In addition, we test the performance of all model variants with constant correla tion as a benchmark. We find that a combination of GARCH-Jump SV, Weibull SC, and Ornstein Uhlenbeck (OU) SER performs best. In addition, we analyze different discretization schemes and their re sults. In our simulations, the Milstein scheme yields the best balance between execution times and lower standard deviations of price esti mates. Furthermore, we find that incorporating mean reversion into stoch', 'Stochastic Correlation,Stochastic Exchange Rates', 'Pricing Multi-strike Quanto Call Options on\nMultiple Assets with Stochastic Volatility,\nCorrelation, and Exchange Rates\nBoris Ter-Avanesov1and Gunter Meissner2\nColumbia University, New York, USA\n1bt2522@columbia.edu ,2gm2718@columbia.edu\nNovember 26, 2024\nAbstract\nQuanto options allow the buyer to exchange the foreign currency\npayoff into the domestic currency at a fixed exchange rate. We investi-\ngate quanto options with multiple underlying assets valued in different\nforeign currencies each with a different strike price in the payoff func-\ntion. We carry out a comparative performance analysis of different\nstochastic volatility (SV), stochastic correlation (SC), and stochastic\nexchange rate (SER) models to determine the best combination of\nthese models for Monte Carlo (MC) simulation pricing. In addition,\nwe test the performance of all model variants with constant correla-\ntion as a benchmark. We find that a combination of GARCH-Jump\nSV, Weibull SC, and Ornstein Uhlenbeck (OU) SER performs best.\nIn addition, we analyze different discretization schemes and their re-\nsults. In our simulations, the Milstein scheme yields the best balance\nbetween execution times and lower standard deviations of price esti-\nmates. Furthermore, we find that incorporating mean reversion into\nstochastic correlation and stochastic FX rate modeling is beneficial for\nMC simulation pricing. We improve the accuracy of our simulations\nby implementing antithetic variates variance reduction. Finally, we de-\nrive the correlation risk parameters Cora and Gora in our framework\nso that correlation hedging of quanto options can be performed.\nKey Words: Quanto Option; Multi-strike Option; Stochastic Volatility\n(SV); Stochastic Correlation (SC); Stochastic Exchange Rates (SER); Cora;\n1arXiv:2411.16617v1  [q-fin.PR]  25 Nov 2024Gora; Correlation Risk\nThis paper is structured as follows: Section 1 provides the introduction and\noutlines the methodology. Section 2 gives a detailed description of the dif-\nferent stochastic differential equation (SDE) models used for volatility, cor-\nrelation, and exchange rates. Section 3 focuses on the options being studied,\nwith an emphasis on the payoff structures, underlying assets, and the over-\nall model framework. Section 4 discusses the three discretization schemes,\nincluding their adaptation for SDEs with Jumps, and the Monte Carlo sim-\nulation pricing methodology with antithetic variates for variance reduction.\nSection 5 presents a comparison of results, accompanied by a discussion of\noutput plots and tables. Section 6 delves into the derivation of the Cora and\nGora correlation risk parameters. Section 7 concludes the paper, followed by\na brief outline of future work, the bibliography and references, and a list of\nfigures.\n1 INTRODUCTION & METHOD\nIn modern finance, tradable assets are typically modeled with stochastic\nvolatility, which was introduced by Hull and White in 1987 [1]. Stein and\nStein (1991) introduced a mean-reverting stochastic volatility model where\nthe volatility of asset returns follows a Brownian motion mean-reverting pro-\ncess [2]. This model reflects the observation that volatility tends to return to\na long-term average level over time, providing a more realistic depiction of\nmarket behavior compared to constant volatility models. In 1993, Heston [3]\ncorrelated the stochastic stock price and stochastic stock price volatility by\ncorrelating their Brownian motions. Another example of a stochastic volatil-\nity model was developed by Ball and Roma (1994) [4]. Their model presents\na framework for option pricing that accounts for stochastic volatility by sim-\nplifying the Fourier option pricing techniques and implementing power series\nmethods. They demonstrate that the characteristic function of the average\nvariance is crucial in this approach, particularly when there is no correlation\nbetweensecuritypriceinnovationsandvolatility. Thismodelcorrectscertain\nbiases in the Black-Scholes model, improving on Stein and Stein’s analysis\n[4]. Bates’ (1996) [5] model further extends Heston’s model by incorporating\njumps in the asset price process, thereby capturing sudden, large movements\nin the market, which is a common feature observed in financial time series\ndata. Modeling volatility as stochastic captures the empirical observation\nthat market volatility tends to cluster over time, reflecting periods of high\n2and low market uncertainty, which cannot be explained by a constant volatil-\nity model. Moreover, the phenomenon of volatility smiles has been studied\nextensively and seems to be alleviated by models with non-constant volatil-\nity ([3], [22], [23], [21], [44]).\nHowever, it is much less common in comparison to see such models ex-\ntended further with a correlation that varies stochastically over time. Some\nexisting research concerned with modeling correlations as stochastic is En-\ngle 2002 [6], Lu & Meissner 2014 [7], Buraschi et al. 2010 [8] [9], and Da\nFonseca et al. 2007/2008 [10]. Modeling correlation as stochastic (SC) is\nbeneficial because it reflects the reality that correlations between asset re-\nturnsarenotconstantandcanchangeduetovaryingmarketconditions, such\nas shifts in economic cycles or changes in investor sentiment. This variability\nin correlation can significantly impact the pricing and hedging of multi-asset\nderivatives. In his research, Pricing Foreign Equity Options with Stochastic\nCorrelation and Volatility (2009), Jun Ma develops a novel model of this\ntype for foreign equity option pricing. Foreign equity, FX, and currency\nderivatives are widely traded on a global scale. Crucially, participants incur\nadditional risk due to exchange rate uncertainty when trading foreign equity\noptions, as highlighted by Ma in his paper [11]. Moreover, when trading\nderivatives that rely on multiple underlying assets, participants also incur\nan additional correlation risk that has to be accounted for. As clarified by\nMa, Quanto options do not yield to pricing via the BS risk-neutral frame-\nwork when we incorporate stochastic correlation [11]. In cases when a simple\nclosed-form solution is unknown, some popular alternatives for pricing such\nderivatives are numerical methods, simulations, or series solutions.\nThe primary aim of this paper is to use simulations to tackle the prob-\nlem of pricing Quanto options on two and three underlying assets under\nstochastic correlation and volatility driven by different stochastic differential\nequations (SDEs). The following models are tested and compared: Hes-\nton, GARCH, GARCH-Jump, 3/2 diffusion, and Bates for volatility, and\nJacobi, Wright-Fisher diffusion, Weibull diffusion, and a mean-reverting SC\nfor correlation. The study is focused specifically on Quanto options on two\nor three foreign equity market indices. These options act like a basket cor-\nrelation option with the payoff depending on multiple correlated assets but\nalso on exchange rates between the currencies of the indices. We test three\ndifferent models of exchange rate dynamics, with both rates being either\nGBM, a mean reverting SDE inspired by the OU process, or an exponential\nlevy process that incorporates jumps. The stochastic differential equations\n3governing all of these SV, SC, and SER models and their key features can be\nfoundinsection2ofthepaper. ThemostuniquefeatureofQuantooptionsis\nthe payoff structure since it is paid in the foreign currency of the underlying\nbut then converted to the domestic currency. Details of the payoff structure\nand the overall model outlines are discussed fully in section 3 of the paper.\nSection 4 of our paper outlines the methodology of the Monte Carlo simu-\nlation and clarifies details of the discretization schemes for the SDEs, whilst\nsection 5 discusses the results. Due to the additional correlation risk, it is\nprudent to also consider how to effectively hedge such products with Cora\nand Gora, which is done in section 6.\nWe collect observed market prices for the indices SP500, FTSE100, and\nSTOXX600 (underlying assets), as well as the GBP/USD, EUR/USD, and\nEUR/GBP exchange rates from Yahoo Finance. The code written for this\npaper allows the user to select what date range the option will be over and,\nhence, what data to collect. For the paper, we focus on 2021-2022 and 2022-\n2023 as two specific time periods to test. We perform the comparison of all\nmodel variants and the discretization schemes for both cases of the option\nand for both of these date ranges as the lifetimes of the option. The con-\nstant parameters of the SDEs of the volatilities, correlations, and exchange\nrates are calibrated to real market data based on summary statistics of the\nSP500, FTSE100, and STOXX600 indices and USD/GBP, USD/EUR ex-\nchange rates values. For example, aside from the starting points of all the\nprocesses, we also selected the volatility parameters of the FX rate SDEs\nbased on the rolling standard deviations for the exchange rates. Similarly,\nthe mean-reversion level ( µ) and rate ( θ) of the Ornstein-Uhlenbeck (OU)\nprocess for modeling FX rates are determined using historical average ex-\nchange rates and autocorrelation analysis. Likewise, we use historical long-\nrun averages, rolling standard deviations, and rolling correlations to select\nthe parameters of the SV and SC SDEs. We ensure that look-ahead bias\nis avoided by only using data available on the start date of each option for\nthe calibration. To facilitate a visual comparison with the plots of paths\nof different processes produced by the simulation, we standardize the plots\nof the observed trajectories of our underlying assets and exchange rates in\ndifferent years to plot them with the same starting points with 100 used as\nan example value (Figures 29 and 30). We also plot rolling window volatil-\nities and correlations of the assets and exchange rates for different window\nsizes (Figures 31 and 32). We use the 13-week US Treasury Bill rate from\nYahoo Finance as the US domestic interest rate (Figure 24). The Bank of\nEngland [25] and European Central Bank [26] interest rates are used for the\n4two foreign interest rates.\nFigure 1 shows the starting values for the underlying assets and the\nexchange rates. These values are used as the starting parameters for the MC\nsimulations as discussed in section 4.\nFigure 1: Values of indices and exchange rates.\n2 MODELS of STOCHASTIC VOLATILITY, COR-\nRELATION & EXCHANGE RATES\nThe quest for pricing models that incorporate random volatility is driven by\nempirical evidence from various studies of financial time series supporting\nthe hypothesis of stochastic volatility. Ma (2009) emphasizes that implied\nvolatilities, calculated using the Black-Scholes formula [12], exhibit random\nfluctuations over time, manifesting in the term structure of implied volatil-\nity. Moreover, when we fix a maturity time T, and consider varying strike\nprice K, it can be seen that implied volatility is higher for options contracts\nwith only the moneyness level being different, which is often referred to as\nthe volatility smile or skew. This pattern arises because the Black-Scholes\nmodel assumes constant volatility, which does not align with its market be-\nhavior, where volatility varies over time and across strike prices. While the\nvolatility smile is typically symmetric for both puts and calls, this pattern\nis more common in currency (FX) and commodity markets, where implied\nvolatility curves form a valley or smile shape, rising at both ends for deep\nin-the-money (ITM) and OTM options. In contrast, equity markets often\nexhibit a downward-sloping implied volatility graph, commonly referred to\nas a skew or smirk. In such markets, OTM put options tend to have higher\nimplied volatility than ITM put options (left to right downward slope) and\nOTM call options tend to have lower implied volatility than ITM call options\n(right to left downward slope). Also, this pattern is more pronounced for\nputs than for calls due to increased demand for downside protection, reflect-\ning perceived risks of large negative movements in asset prices. According to\nMa, stochastic volatility models elucidate deviations from constant implied\n5volatility, and it has been shown that they can capture the volatility smile\nbetter.\nTraditionally, in the vast body of financial and economic literature on\nmulti-asset options, the correlation coefficient between correlated variables\nhas been assumed to be constant (e.g., see Black and Scholes, 1973 [12]; Mar-\ngrabe, 1978 [13]; Garman, 1992 [14]). However, Ma (2009) highlights that\nrelying on long-term estimates of constant correlation can be misleading,\npotentially resulting in significant mispricing and risk management issues.\nHistorical correlations must be used with caution as they can be more un-\nstable than volatility [11]. An alternative approach involves inferring implied\ncorrelations from market prices, akin to implied volatility, which offers an\nestimation of stochastic correlation based on market data [11]. In this study,\nwe test different models of stochastic volatility of the underlying assets, of\nstochastic correlation between their Brownian motions, and of stochastic\nexchange rates.\n2.1 Volatility Models\nAsmentionedintheintroduction, wetestfivemodelsforstochasticvolatility:\nHeston, 3/2 volatility, GARCH, Bates, and GARCH-Jump. The first two\nrely on a mean reversion drift term, with the parameters kappa and theta\nbeingtherateofmeanreversionandthelong-runvaluetowhichthevolatility\nprocess reverts, respectively. Also, the first two have the parameter sigma\nto control the standard deviation of the random fluctuations. 3/2 volatility\ncan be thought of as a higher-order extension of Heston volatility. Bates\nand GARCH-Jump processes introduce jumps to replicate the behavior of\nsudden moves of volatility observed in markets with Poisson-process-driven,\nNormally distributed jumps. We ensure that the simulation functions do not\nproduce negative volatility for all of the SDEs of stochastic volatility models.\n2.1.1 Heston Model\ndvt=κ(θ−vt)dt+σ√vtdWt (1)\nNote that setting\n2κθ > σ2(2)\nin the Heston model ensures the process is strictly positive (Feller condition\n[15]).\n62.1.2 GARCH Inspired Model\nThe time-homogeneous GARCH process satisfies the following linear SDE\naccording to Li et al. as described in their 2018 paper [94]. Hence, this\nmodel is very similar to the Heston model discussed above, but the diffusion\nterm is multiplied by√vtto raise the power on the volatility component\nfrom 1/2 to 1 ...\ndvt=κ(θ−vt)dt+σvtdWt (3)\n2.1.3 GARCH Inspired Model with Jumps\nThe GARCH-Jump model extends the standard GARCH (Generalized Au-\ntoregressiveConditionalHeteroskedasticity)frameworkbyincorporatingjumps,\nprovidingamorecomprehensivetooltocapturetheaforementionedvolatility\ndynamics observed in financial markets. This model is particularly useful in\ncapturing the sudden large movements or jumps in asset prices that cannot\nbe explained by continuous processes alone. The GARCH-Jump model was\ndeveloped and extensively analyzed by Duan et al. (2004), who highlighted\nits efficacy in better fitting historical time series data and explaining the\nobserved volatility smile in option prices. Their research demonstrated that\nincorporating jumps into the GARCH framework significantly improves the\nmodel’s performance in capturing the empirical features of asset returns and\nvolatility [16]. We implement a variant of GARCH-Jump SV by adding a\njump term to our GARCH-inspired model discussed above.\ndvt=κ(θ−vt)dt+σvtdWt+ζdJt (4)\nIn our code implementation, the jumps are modeled as a compound Poisson\nprocess where the jump sizes are normally distributed. Specifically, dJtis\nconstructed by first generating a number of jumps using a Poisson distri-\nbution with intensity parameter λ. For each jump, the size is drawn from\na normal distribution with mean µJand standard deviation σJ. The total\njump impact dJtis then the sum of all individual jump sizes occurring within\na given time interval dt. Hence, the jumps are modeled as follows:\ndJt=NtX\ni=1Yi∼Poisson (λ·dt)× N(µJ, σ2\nJ) (5)\nHere, N(t)is a Poisson process with intensity λ, and Yiare i.i.d. normal\nrandom variables with mean µJand variance σ2\nJ. Duan et al. (2004) em-\nployed the GARCH-Jump model to explore option pricing under conditions\n7where both price and volatility exhibit jump-diffusion behavior. They found\nthat the GARCH-Jump model provides a robust framework for understand-\ning and predicting market behaviors characterized by sudden and significant\nchanges. The model’s ability to capture jumps makes it particularly valuable\nfor pricing derivatives and managing financial risk in environments subject\nto abrupt market movements [16].\n2.1.4 Bates Model\nThe Bates volatility model extends Heston volatility with jumps [5]. Here,\nthe parameters kappa, theta, and sigma have the same use as for the Heston\nvolatility model.\ndvt=κ(θ−vt)dt+σ√vtdWt+ζdJt (6)\nwhere dJtrepresents the jumps with normally distributed jump sizes. muJ\nandsigma Jare two more parameters in the simulation of this model, which\ncontrol the mean size and standard deviation of the jumps, respectively, as\ndiscussed above. Here ζis a multiplier that controls the magnitude of the\neffect of the jumps as above.\n2.1.5 3/2 Model\nThe 3/2 stochastic volatility model is an extension of the constant elasticity\nofvariance(CEV)modelandwasdevelopedbyCarrandSun(2007)tobetter\ncapturethe dynamicsof financialmarkets. Inthis model, thevolatilityof the\nunderlying asset is driven by a process that is proportional to the power 3/2\nof the volatility itself. The stochastic differential equation (SDE) governing\nthe 3/2 model is given by:\ndvt= (ω−θvt)vtdt+σv3/2\ntdWt, (7)\nIn this context:\n•ωis the speed of mean reversion, determining how quickly the process\nreverts to its long-term mean θ.\n•θis the long-term mean level of the variance process.\n•σrepresents the volatility of the variance process, indicating the mag-\nnitude of random fluctuations.\n8The 3/2 model is particularly useful in capturing the empirical features of\nvolatility observed in financial markets, such as the leverage effect and the\nfact that volatility tends to spike during market downturns [17]. Carr and\nSun (2007) developed this model to provide a more accurate framework for\npricing options and other derivative securities. According to Carr and Sun,\nthe 3/2 model has several desirable properties. The process remains non-\nnegative and exhibits mean-reverting behavior, where the speed of mean\nreversionisproportionaltotheleveloftheprocess. The3/2modelalsoyields\nclosed-form solutions for the joint Fourier-Laplace transform of returns and\ntheir quadratic variation, which is useful for efficiently pricing and hedging\nderivatives [17].\n2.2 Correlation Models\nCorrelations can be influenced by factors such as industrial production, T-\nbill rates, and unanticipated inflation, often acting as a business cycle indi-\ncator. Even after adjusting for business cycle effects, correlation risk persists\n(Driessen, Maenhout, and Vilkov, 2006 [60]). Although the correlation co-\nefficient between two assets is not directly tradable, it remains crucial to\ndevise hedging strategies for correlation risk. Developing robust frameworks\nfor constructing portfolios to hedge against correlation risk can ensure more\nsecure risk management practices [11]. For all of the stochastic correlation\nmodels, the SDEs have mean reversion or bounds or are clipped to ensure\nthat correlations remain within [-1, 1]. Four models for stochastic correlation\nof increasing complexity are implemented in this study. The simplest is a\nstochastic correlation SDE inspired by the modeling of processes in studies of\ngenetics, which has a diffusion term, making sure it stays within [-1, 1]. The\nnext simplest is the Jacobi correlation used by Ma, which gives the user the\noption to keep the correlation process within bounds h and f by altering this\ndiffusion term. The second most complicated model is the mean-reverting\nextension of the first two simpler models. The most complex model that is\ntested is the Weibull distribution stochastic correlation model.\n2.2.1 Wright-Fisher (WF) Model\nWright-Fisher diffusions are used in biology and biochemistry to model gene\nfrequencies and other natural/bodily processes. As explained in their pa-\nper,A mean-reverting SDE on correlation matrices , Ahdida et al focus on\nstochastic differential equations ’valued on correlation matrices’ [18] and de-\nvelop a mean-reverting extension of the Wright-Fisher SDE to model corre-\n9lations in finance. In our paper, we test both the original diffusion on [-1,1]\nand the mean-reverting extension developed by Ahdida et al. as alterna-\ntives for modeling correlation. We do not implement the original version\nof the diffusion on [0, 1] since we want the process to mimic the variability\nacross the range [-1, 1] when modeling financial correlations. The classic WF\ndiffusion on [-1,1] has the SDE:\ndρt=κ(¯ρ−ρt)dt+σq\n1−ρ2\ntdWt (8)\nHere, ρtrepresents the instantaneous correlation at time t.κis the mean\nreversion rate, determining how quickly the process reverts to the long-term\nmean correlation ¯ρ.¯ρis the long-term mean correlation towards which ρt\nreverts. σrepresents the volatility of the correlation process, indicating\nthe extent of random fluctuations around the mean, and dWtis a standard\nWiener process, as usual. Ahdida et al. highlight that the termp\n1−ρ2\nt\nensures that the correlation ρtremains within the interval [−1,1]. This\nterm becomes zero when ρtapproaches the boundaries, preventing it from\nexceeding these limits. This bounded characteristic makes this version of\nthe WF diffusion particularly suitable for modeling correlations in finance,\nwhere it is critical to maintain realistic correlation values [18].\n2.2.2 Jacobi Process\nThe Jacobi process is used to model stochastic correlation and is described\nby the following stochastic differential equation (SDE):\ndρt=κ(¯ρ−ρt)dt+σp\n(h−ρt)(ρt−f)dWt (9)\nwhere ρtrepresents the correlation at time t,κis the mean reversion rate,\n¯ρis the long-term mean correlation, and handfare the upper and lower\nbounds of the correlation, respectively. The term dWtdenotes a standard\nWiener process as usual. The parameter κdetermines the speed at which\nthe correlation reverts to its long-term mean ¯ρ. A higher value of κimplies a\nfaster reversion. The parameters handfset the natural boundaries for the\ncorrelation, ensuring that it remains within a realistic range. The volatility\nparameter σcontrols the amplitude of fluctuations around the mean [11].\nThe Jacobi process is particularly useful for modeling correlation because\nit can capture both the mean-reverting nature and the bounded behavior of\ncorrelation coefficients. The square root termp\n(h−ρt)(ρt−f)ensures\nthat the correlation stays within the interval (f, h). Ma (2009) introduced\n10the use of the Jacobi process in the context of pricing foreign equity options\nwith stochastic correlation. This model allows for a more accurate reflection\nof market dynamics compared to constant correlation models. The Jacobi\nprocesscanbeseenasanextensionofothermean-revertingprocesses, suchas\nthe Ornstein-Uhlenbeck process, but with the added complexity of bounded\nbehavior. This makes it particularly suited for financial applications since\ncorrelations tend to naturally exhibit such characteristics [11].\n2.2.3 Mean-Reverting Correlation\nThis is an extension of the WF diffusion on [-1, 1] developed by Ahdida et\nal. (Ahdida 2013), which includes an adaptive mean-reversion component.\nThe mean-reverting SDE is given by:\ndρt= (κ(¯ρ−ρt)−σ2ρt)dt+σq\n1−ρ2\ntdWt (10)\nHere ρt,κ,barρ,σ,areallthesameasfortheWFcorrelationmodeldiscussed\nabove. Also, the termp\n1−ρ2\nthas the same use of ensuring that the correla-\ntionρtremains within the interval [−1,1]. By adjusting the mean-reverting\ndrift term κ(¯ρ−ρt)−σ2ρt, Ahdida et al extend the process to capture the\nempirically observed tendency of correlations to revert to a long-term mean\nwith the inclusion of the σ2ρtto ensure that the reversion speed adjusts\ndynamically based on the current correlation level [18].\n2.2.4 Weibull Model\nThe Weibull model is characterized by the following stochastic differential\nequation:\ndρt=−α(ρt−µW)dt+b1b2dWt (11)\nwhere µWis a mean term derived from Weibull distribution parameters.\nThis model was originally proposed by Miñano et al. (2013) for wind speed\nmodeling, demonstrating its efficacy in generating wind speed trajectories\nwith desired statistical properties [19]. In this context, b1andb2are diffusion\nterms uniquely defined to ensure the model captures the desired statistical\nproperties. Specifically, b1andb2are given by:\nb1(ρt) =2α\npW(ρt), (12)\nb2(ρt) =λΓ\n1 +1\nk,ρt\nλk\n−µWe−(ρt/λ)k, (13)\n11where pW(ρt)is the probability density function (PDF) of the Weibull distri-\nbution, λis the scale parameter, kis the shape parameter, and Γrepresents\ntheGammafunction. Theinclusionof b1andb2ensuresthemodel’sdiffusion\nterm is appropriately scaled to reflect the nature of the underlying process.\nThis formulation makes the Weibull model particularly suitable for phenom-\nena where the Weibull distribution provides a good fit, such as wind speed\ndata and potentially skewed financial data. Specifically, this model was de-\nsigned to simulate wind speeds that follow a Weibull distribution and exhibit\nexponential autocorrelation, as discussed in the work by Miñano et al. [19].\nTheir objective was to accurately replicate the statistical properties of wind\nspeed for applications in power systems, highlighting the model’s ability to\ngenerate realistic wind speed trajectories for various simulations and anal-\nyses. To ensure the mathematical validity of the model, it is essential that\nρtpaths stay non-negative and k >0, as the Weibull distribution is defined\nonly for non-negative values and requires a positive shape parameter. These\nconditions guarantee that the diffusion terms b1andb2are well-defined, en-\nsuring the stochastic process remains within the domain where the Weibull\ndistribution accurately describes the behavior. Therefore, this SC model\nworks in situations when we want to model positive correlations.\nIt has been shown that the Johnson SB distribution is a best-fit dis-\ntribution for equity and default probability correlation distributions [20].\nAlso, Gunter Meissner et al conducted a comprehensive analysis of corre-\nlation behavior based on daily closing prices of 30 stocks within the Dow\nJones index, spanning the period from January 1972 to October 2012 [24].\nTheir findings indicate that correlation levels are at their lowest during pe-\nriods of robust economic growth, wherein equity prices are predominantly\ninfluenced by idiosyncratic factors rather than broader macroeconomic con-\nditions. Conversely, during recessions, correlation levels typically rise as\nmacroeconomic factors overshadow idiosyncratic influences, leading to si-\nmultaneous downturns across multiple stocks. Furthermore, the volatility of\ncorrelations is observed to be lowest during economic expansions and higher\nduring normal periods and recessions [24]. The study also highlighted that\nthe Johnson SB distribution, characterized by its shape, location, and scale\nparameters, provided the most accurate fit for modeling these correlations.\nThis distribution’s flexibility effectively captures the intricate properties and\nvariations of the correlation data observed under different economic condi-\ntions [24]. Something we want to explore further in future work is to apply\nthe approach used for the Weibull correlation model to capture statistical\nproperties of the distribution in the SDE to develop a stochastic correlation\n12model that captures desired properties of the Johnson SB distribution and\nincorporates mean reversion.\n2.3 Models of Stochastic Exchange Rates\nThe domestic currency for the investor in these Quanto options is US dol-\nlars. In our paper, one of the underlying assets is denominated in the home\ncurrency (US dollar). For all choices of correlation and volatility, the un-\nderlying assets are modeled with the same SDEs throughout. We test three\nSDEs for the exchange rates (scenarios 1-3). The simplest model is for both\nexchange rates to be GBM [27] with different parameters based on observed\nstarting values and summary statistics (as outlined in section 1). We also\ntest a model with mean-reversion incorporated into the SDEs used for both\nexchange rates. It has been shown in many studies that foreign exchange\nrates tend to exhibit strong mean reversion [28] [29]. In the third model,\nboth exchange rates follow an exponential Lévy process, which incorporates\njumps into the GBM model of scenario 1 [30] [31]. The foreign risk-free\ninterest rate is rf1. This is the risk-free rate of return in the first foreign\ncurrency, which could be the interest rate of a government bond or another\nrisk-free security in the foreign market of GBP. rf2is the risk-free rate of\nreturn in the second foreign currency, and rdis the domestic interest rate. In\nthe equations below, θrepresents the rate of mean reversion, µis the mean\nlevel to which the process reverts, σFXis the volatility, and dWFX(t)is the\nincrement of the Wiener process.\n2.3.1 Geometric Brownian Motion (GBM)\nThe GBM is characterized by its exponential growth with constant drift and\nvolatility [27].\ndFX (t) =FX(t)\0\n(rf−rd−0.5σ2\nFX)dt+σFXdWFX(t)\n(14)\n2.3.2 Ornstein-Uhlenbeck (OU) Process\nIn this scenario, we model the exchange rates as an OU process, which\nintroduces mean reversion into the drift term.\ndFX (t) =θ(µ−FX(t))dt+FX(t)\0\n(rf−rd−0.5σ2\nFX)dt+σFXdWFX(t)\n(15)\n132.3.3 Exponential Lévy Process\nInthisscenario, theexchangeratesfollowanexponentialLévyprocess, which\nincorporates jumps into the SDEs, accounting for sudden and significant\nchanges in the exchange rates [30] [32]. The key parameters in this model\ninclude σFXfor volatility, λLfor the jump intensity, µLfor the mean jump\nsize, and σLfor the jump size volatility.\ndFX (t) =FX(t)\0\n(rf−rd−0.5σ2\nFX)dt+σFXdWFX(t)\n+dJt(16)\nWhere dJtis the jump component, modeled as before (sections 2.1.3 and\n2.1.4) for the GARCH-Jump and Bates SV. These jumps account for sud-\nden, significant changes in the exchange rates, making the exponential Lévy\nprocess a suitable candidate for modeling FX rates with jumps [32] [33].\n3 BASKET QUANTO CALLS\nWe test all combinations of choices of the 5 SV, 4 SC, and 3 SER models\noutlined above for pricing 2 types of basket Quanto call options. Case 1 in-\nvolves two underlying assets and one exchange rate, whilst Case 2 has three\nunderlying assets and two exchange rates. Both Cases 1 and 2 include an un-\nderlying asset in the domestic currency of US dollars, and the other asset(s)\nmust be converted into dollars using the exchange rate(s). In this paper, we\nmodel the domestic and foreign interest rates as constants throughout the\nlifetime of the options. We pick the values observed on the start dates of the\noptions. However, as shown in Figure 24, the interest rates are not usually\nconstant in practice, even over a 1-year time window. We use the 13-week US\nTreasury Bills rate from Yahoo Finance as the US domestic interest rate, and\nit can be seen to change in value significantly throughout 2022-2023 (more\nthan 5% change) but remain relatively constant in the prior year. Similar\nobservations can be made with the BoE rates. Thus, it could be prudent\nto model interest rates as a deterministic function of time, mixed jump dif-\nfusion, or discrete event/jump process (compound Poisson or Hawkes, for\nexample), with appropriate adjustments for monthly or quarterly frequen-\ncies but this extension is left for future work. In addition, modeling interest\nrates with SDEs would also allow us to explore whether we should introduce\ncorrelations between them. As seen in Figure 24, all three interest rates\nappear to be strongly positively correlated.\n14The overall models for the pricing of our Quanto calls using specific\nchoices of the SDE models for SV, SC, and SER can be written as follows:\n3.1 Case 1: Two Underlying Assets - Single FX Rate\n3.1.1 Variables\n•SGBP(t): Price of the 1st underlying (e.g. GBP asset).\n•SUSD(t): Price of the 2nd underlying (e.g. USD asset).\n•FXGBP(t): FX rate (e.g. for USD/GBP).\n3.1.2 Stochastic Differential Equations\nUnderlying Asset Prices\ndSUSD(t) =SUSD(t)\nrddt+p\nvUSD(t)dWUSD(t)\n(17)\ndSGBP(t) =SGBP(t)\nrf1dt+p\nvGBP(t)dWGBP(t)\n(18)\nSV Choice (same process for both underlying assets)\ndvUSDt=mv(vUSDt, t)dt+sv(vUSDt, t)dWv_USDt+ωv(vUSDt, t)dJv_USDt\n(19)\ndvGBP t=mv(vGBP t, t)dt+sv(vGBP t, t)dWv_GBPt+ωv(vGBP t, t)dJv_GBPt\n(20)\nSC Choice\ndρt=mρ(ρt, t)dt+sρ(ρt, t)dWρt+ωρ(ρt, t)dJρt (21)\nSER Choice\ndFX GBP(t) =mf(FX GBP(t), t)dt+sf(FX GBP(t), t)dWft+ωf(FX GBP(t), t)dJft\n(22)\n153.1.3 Correlation between Brownian Motions\ndWUSD(t) =ρ(t)dWGBP(t) +p\n1−ρ(t)2dZ(t)\ndWFX(t) =dZFX(t)(23)\nHere, dZ(t)anddZFX(t)are independent standard Brownian motions.\n3.1.4 Payoff\nPayoff = max ( SUSD(T)−K1, SGBP(T)·FX(T)−K2,0)(24)\nHere, dJvtdenotes the jump component of volatility, dJρtdenotes the jump\ncomponent of correlation, and dJftdenotes the jump component for the FX\nrate, as defined in Section 2. Our choice of the SV, SC, and SER models\ndetermines the m, s, and ωfunctions above. For example, GARCH-Jump SV\nhasmv(vt, t)=β0+ (β1−1)vt,sv(vt, t)=0, and ωv(vt, t)=β2vt. Similarly,\nwe can write the general equations for our model for Case 2 as shown below.\n3.2 Case 2: Three Underlying Assets - Two FX Rates\n3.2.1 Variables\n•SGBP(t): Price of the GBP asset.\n•SUSD(t): Price of the USD asset.\n•SEUR(t): Price of the EUR asset.\n•FXGBP(t): FX rate for USD/GBP.\n•FXEUR(t): FX rate for USD/EUR.\n3.2.2 Stochastic Differential Equations\nUnderlying Asset Prices\ndSUSD(t) =SUSD(t)\nrddt+p\nvUSD(t)dWUSD(t)\n(25)\ndSGBP(t) =SGBP(t)\nrf1dt+p\nvGBP(t)dWGBP(t)\n(26)\ndSEUR(t) =SEUR(t)\nrf2dt+p\nvEUR(t)dWEUR(t)\n(27)\n16SV Choice (same process for all underlying assets)\ndvUSDt=mv(vUSDt, t)dt+sv(vUSDt, t)dWv_USDt+ωv(vUSDt, t)dJv_USDt\n(28)\ndvGBP t=mv(vGBP t, t)dt+sv(vGBP t, t)dWv_GBPt+ωv(vGBP t, t)dJv_GBPt\n(29)\ndvEUR t=mv(vEUR t, t)dt+sv(vEUR t, t)dWv_EURt+ωv(vEUR t, t)dJv_EURt\n(30)\nSC Choice (between both pairs, USD-GBP and USD-EUR)\ndρt=mρ(ρt, t)dt+sρ(ρt, t)dWρt+ωρ(ρt, t)dJρt (31)\nSERChoice(sameprocessforbothFXRates,USD/GBP,&USD/EUR)\ndFX GBP(t) =mf(FX GBP(t), t)dt+sf(FX GBP(t), t)dWf1t+ωf(FX GBP(t), t)dJf1t\n(32)\ndFX EUR(t) =mf(FX EUR(t), t)dt+sf(FX EUR(t), t)dWf2t+ωf(FX EUR(t), t)dJf2t\n(33)\n3.2.3 Correlation between Brownian Motions\ndWUSD(t) =ρ(t)dWGBP(t) +p\n1−ρ(t)2dZ(t)\ndWEUR(t) =ρ(t)dWGBP(t) +p\n1−ρ(t)2dZEUR(t)\ndWFXUSD/GBP(t) =dZFXUSD/GBP(t)\ndWFXUSD/EUR(t) =dZFXUSD/EUR(t)(34)\nHere, dZ(t),dZEUR(t),dZFXUSD/GBP(t), and dZFXUSD/EUR(t)are indepen-\ndent standard Brownian motions.\n3.2.4 Payoff\nPayoff = max ( SUSD(T)−K1, SGBP(T)·FXGBP(T)−K2,\nSEUR(T)·FXEUR(T)−K3,0)(35)\n17Hence, as highlighted before, we correlate the Brownian motions of the pro-\ncesses of the underlying assets and model this correlation as stochastic. Also,\nwe model the volatility of the underlying as stochastic and independent from\nthe level of the underlying. Moreover, the FX rates are modeled as stochastic\nand independent from each other as well as from the level of their respective\nunderlying asset. In the simulation, we use different sets of increments of\nBrownian motion for all the stochastic processes and only introduce a corre-\nlation between those of the underlying assets. This correlation, between the\nBrownian motions of USD and GBP assets as well as between the Brownian\nmotions of the USD and EUR assets, is the same in our experiments. In\nall of the SC models, we tested ωρ(ρt, t)= 0 as we do not investigate the\npresence of jumps in correlation.\n4 DISCRETIZATION of SDEs & MC SIMULA-\nTION\nWe test all 60 (= 5*4*3) combinations of different choices of the SV, SC,\nand SER models with three different discretization schemes and we use the\nEuler-Maruyama scheme only for the SDEs of the underlying assets through-\nout. The Euler-Maruyama Scheme is the simplest computationally as it\nonly includes the first three terms of the Ito-Taylor expansion applied to\nthe SDE. However, it is expected to yield limited accuracy since this ap-\nproximation expands the drift term to O(∆t)but only expands the diffu-\nsion term to O(√\n∆t). The Milstein scheme should yield improved accu-\nracy since a second diffusion term is added, expanding the diffusion term to\nO(∆t)as well. Although the Milstein scheme has a higher order, its main\ndrawback is that we need to compute the first derivative of the volatility\nfunction. This may not always be possible, or it may be computation-\nally expensive. The Runge-Kutta scheme can be used to alleviate this\nissue while maintaining this higher-order by leveraging the Runge-Kutta\napproximation of the derivative required in the Milstein scheme. Higher-\norder Runge-Kutta schemes can be derived by including a more detailed\napproximation of this derivative. The SDE of a general Itô diffusion Itis\ndIt=a(It, t)dt+b(It, t)dWtand can be discretized via the three alternatives\nas described below. Here, when discretizing and simulating the increments of\nBrownianmotion, ∆Wj=Wtj+1−Wtji.i.d∼N(0,∆t), wewrite ∆Wj=√\n∆tZj\nwith Zji.i.d∼N(0,1),∀j, and ∆t=tj+1−tj. To apply the Euler-Maruyama,\nMilstein, and Runge-Kutta discretization schemes for SDEs that include an\n18additional jump term, such as those in the GARCH-Jump, Bates Stochastic\nVolatility (SV), and Exponential Lévy FX rate models, these schemes need\nto be adjusted as described below. A Itô process with an additional jump\ncomponent can be written as:\ndIt=a(It, t)dt+b(It, t)dWt+c(It, t)dJt (36)\nwhere dJtrepresents the jump term, often modeled as a compound Poisson\nprocess. Indeed, in our paper, the jumps are modeled as compound Poisson\nprocesses as discussed in section 2.1.3. Here, we have ∆Jj=Jtj+1−Jtj,\nwhere ∆Jjrepresents the cumulative effect of jumps in the interval [tj, tj+1].\nSpecifically, ∆Jj=PNj\nk=1Yk, where Nj∼Poisson (λ∆t)represents the\nnumber of jumps occurring in the time interval ∆t=tj+1−tj, and each\nYki.i.d∼N(µJ, σ2\nJ)represents the jump sizes drawn from a normal distribution\nwith mean µJand variance σ2\nJ. Thus, ∆Jj∼Poisson (λ·∆t)× N(µJ, σ2\nJ).\n4.1 Euler-Maruyama Scheme\nˆItj+1=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)∆Wj (37)\n=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)√\n∆tZj (38)\n4.2 Euler-Maruyama Scheme with Jumps\nˆItj+1=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)√\n∆tZj+c(ˆItj, tj)∆Jj(39)\n4.3 Milstein Scheme\nˆItj+1=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)∆Wj+1\n2b(ˆItj, tj)b′(ˆItj, tj)\n(∆Wj)2−∆t\n(40)\n=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)√\n∆tZj+1\n2b(ˆItj, tj)b′(ˆItj, tj)∆t(Z2\nj−1)(41)\n4.4 Milstein Scheme with Jumps\nˆItj+1=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)∆Wj+1\n2b(ˆItj, tj)b′(ˆItj, tj)∆t(Z2\nj−1)+c(ˆItj, tj)∆Jj\n(42)\n194.5 Runge-Kutta Scheme\nˆItj+1=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)∆Wj+ (43)\n1\n2√\n∆th\nb(˜Itj, tj)−b(ˆItj, tj)i\n(∆Wj)2−∆t\n=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)√\n∆tZj+ (44)\n1\n2h\nb(˜Itj, tj)−b(ˆItj, tj)i√\n∆t\n(∆Zj)2−1\nwhere\n˜Itj=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)√\n∆t (45)\n4.6 Runge-Kutta Scheme with Jumps\n˜Itj=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)√\n∆t+c(ˆItj, tj)∆Jj(46)\nˆItj+1=ˆItj+a(ˆItj, tj)∆t+b(ˆItj, tj)√\n∆tZj+ (47)\n1\n2h\nb(˜Itj, tj)−b(ˆItj, tj)i√\n∆t\n(∆Zj)2−1\n+c(ˆItj, tj)∆Jj\nIn summary, to handle an additional jump term in our SDEs we add the\njump component directly to the discretization for the Euler-Maruyama and\nMilstein schemes, and the Runge-Kutta scheme also requires calculating the\nintermediate values including the jump component, and then adjusting the\nfinal update accordingly. These modifications ensure that each discretiza-\ntion scheme accurately captures the effects of both continuous and jump\ncomponents in the SDEs.\n4.7 Simulation Procedure\n1.Initialize paths: Set initial values for SGBP(0),SUSD(0),FX(0),\nρ(0),vGBP(0), and vUSD(0). Set T (time to expiration in years and\nnstepsper path in days is T*252), N (number of paths in simulation),\nset increment dt = T/ nstepsfor daily time series.\n2.Simulate paths over time:\n•For each time step, generate Brownian increments and jump in-\nstances.\n•Update the volatility paths using the specified volatility model\nand discretization scheme.\n20•Updatethecorrelationpathsusingthespecifiedcorrelationmodel\nand discretization scheme.\n•Update the FX rate paths using the specified model and dis-\ncretization scheme.\n•Update the underlying asset paths using the simulated volatil-\nity and correlation paths according to the Euler-Maruyama dis-\ncretization scheme.\n3.Calculate payoffs: Use the final asset prices and FX rate values to\ncalculate the payoff for each simulated path. For Case 1, the payoff for\neach path is calculated as:\nPayoffi= max ( SUSD,i (T)−K1, SGBP,i (T)·FXi(T)−K2,0)(48)\nFor Case 2, the payoff for each path is calculated as:\nPayoffi= max\0\nSUSD,i (T)−K1, SGBP,i (T)·FXUSD/GBP,i (T)−K2,\nSEUR,i (T)·FXUSD/EUR,i (T)−K3,0\n(49)\n4.Discount and average payoffs: Discount the payoffs to present\nvalue and average them to get the option price. The discounted option\nprice is given by:\nOption Price =e−rdT·1\nNNX\ni=1Payoffi (50)\nwhere Nis the number of simulated paths, rdis the domestic risk-free\nrate, and Tis the time to maturity.\n4.8 Variance Reduction - Antithetic Variates\nVariance reduction methods seek to improve the efficiency of an estimator,\nenabling more accurate results for a given number of simulations, N. Some\nchoices of variance reduction that could be applied to our Monte Carlo sim-\nulations include control variates, which leverage the known expectation of\nauxiliary variables to reduce variance, and randomized Quasi-Monte Carlo\n(QMC), which replaces purely random sampling with low-discrepancy se-\nquences (e.g. Halton, Sobol, or Fauer) to enhance convergence properties.\nIn this paper, we implement antithetic variates as a form of variance reduc-\ntion to improve our Monte Carlo simulations. Antithetic variates aim to\n21reduce the variance of the estimator by introducing a negative correlation\nbetween paired simulations, thereby improving the convergence rate of the\nMonte Carlo estimator without increasing the number of simulations. In our\ncontextofMonteCarlosimulationsinvolvingstochasticdifferentialequations\n(SDEs), this involves generating antithetic paths by using the negative of the\noriginal Brownian motion increments. Then, by averaging the results from\nthe original and antithetic paths, the variance of the estimator is reduced.\nSpecifically, let Xbe an estimator of the option price based on the original\nsimulations, and X′be the estimator based on the antithetic simulations.\nThe combined estimator is then:\nˆC=1\n2(X+X′) (51)\nNow, since XandX′are negatively correlated, the variance of ˆCis reduced\ncompared to the variance of either XorX′alone. The variance of our\nestimator can be expressed as follows:\nVar(ˆC) =1\n2\0\nVar(X+X′)\n=1\n4\0\nVar(X) +Var(X′) + 2·Cov(X, X′)\n(52)\nand our X’s both have equal variance so this expression can be simplified\nfurther as follows:\nVar(ˆC) =1\n4\0\n(2∗2)Var(X) + 2·Cov(X, X′)\n=Var(X) +1\n2Cov(X, X′)\n(53)\nwhich means that the variance of our antithetic estimator is less than that\nof the original estimator by |1\n2Cov(X, X′)|if the covariance between the\nantithetic and original versions of the random variables is negative:\nVar(ˆC)<Var(X)⇐⇒ Cov(X, X′)<0 (54)\nHence, the effectiveness of the antithetic variates method depends on the\nextent of the negative correlation between the estimators XandX′. The\nmorenegativelycorrelatedtheyare, thegreaterthevariancereduction. Since\nVar(X) =Var(X′), we can rewrite this reduction in variance as follows:\n|1\n2Cov(X, X′)|=|1\n2ρσxσx′|=|1\n2ρVar(X)| (55)\n224.8.1 Antithetic Brownian Increments\nTo incorporate antithetic variates into our simulation process, for each path\nin the simulation, we generate a corresponding antithetic path by using the\nnegative of the samples of a standard normal random variable in the Brow-\nnian increments used in the original path. This approach is applied to all\nthe Brownian motions involved in the simulation. Specifically, if we let ∆Wj\nbe the Brownian increments generated for the original path at time step tj.\nThen, by writing Z′\nj=−Zj, we get that the antithetic increments ∆W′\njare\ngiven by:\n∆W′\nj=√\n∆tZ′\nj=−√\n∆tZj=−∆Wj\n4.8.2 Modification of the Simulation Procedure\nWe modify the steps of our simulation process outlined in section 4.7 as\ndescribed below to incorporate antithetic variates. Step 1 is the same as in\nthe original version, but steps 2 and 3 change slightly as we have to include\nthe generation of the antithetic versions for all Brownian increments and\nupdating all paths (including the antithetic versions), respectively. Step 4\nalso mainly stays the same but we need to compute the payoffs for both\nthe antithetic paths and the normal paths. Then, the key adjustment is in\nchanging step 5 as follows:\nNew step 5 - discount and average combined payoffs: Compute the\ncombined payoff for each pair of original and antithetic sets of paths as:\nPayoffi=1\n2\0\nPayoffi+Payoff′\ni\n(56)\nAs before, discount the combined payoffs and average them to obtain the\noption price estimate:\nOption Price =e−rdT·1\nNNX\ni=1Payoffi (57)\nIn both case 1 and case 2 of our options, since our payoff functions are mono-\ntonic in the asset prices (& FX rates) and all the SDEs we use are linear in\nthe Brownian increments, the negative correlation introduced at the level of\nthe Brownian increments propagates through to the terminal asset prices,\nand the option payoffs. Also, the symmetry of the Gaussian distribution\nguarantees that when we negate a (zero-mean) Normal random variable it is\nstill distributed according to the same distribution. Because of this, for any\n23of our SDEs, the solution of the version modified with antithetic Brownian\nincrements has the same distribution as the original SDE’s solution. Indeed,\nwith this, it can be shown that the antithetic and original option price es-\ntimates are identically distributed and have a negative covariance [56] - as\nrequired for variance reduction via antithetic variates.\n5 RESULTS COMPARISON & DISCUSSION\nWe use the number of simulation paths with N = 500,000 for all of the\nsimulations in this study. This number of realizations performed well in the\npreliminary testing of the code. The lists of parameter values used for the\nsimulations of 2021 and 2022 starting dates, respectively, are shown in the\nlast two figures. To compare the performance of the discretization schemes\nand model variants, we compute the standard deviation of the option value\nestimates and 95% confidence intervals (using z* = 1.96). Then, all 180\nmodel variants are ordered from lowest standard deviation to highest, and\nwe compute the average price estimate of the 40 best variants to be the\n’true’ value of the option. Then, all the models are re-ordered by the lowest\nto highest percentage error from this value, and the top 30 are displayed in\nbold in the results tables. Figures 2 and 3 below display the top 30 models\nby percentage error (PE) for cases 1 and 2 respectively and for both start\ndates we test (2021 on the left and 2022 on the right subplots).\nFigure 2: Case 1 top 30 models by percentage error for 2021 (left) and 2022\n(right) start dates.\nFigures 4-19 (inclusive) show the outputs for all model variants and dis-\ncretization schemes ordered by PE. From our simulations, the target values\n(average of 40 best models by standard deviation) for case 1 of the option\n24Figure 3: Case 2 top 30 models by percentage error for 2021 (left) and 2022\n(right) start dates.\nwith 2021 and 2022 start dates were $ 2653.73 and $ 2837.10, respectively\n(2 d.p.). For case 2 of the option, our simulations yield the values $ 2667.76\nand $ 2854.90 for 2021 and 2022 start dates, respectively (2 d.p.). It makes\nsense that these options were slightly more expensive with the 2022 start-\ning date since all the assets were significantly more expensive on 2022-01-04\nthan on 2021-01-4, as shown in Figure 1. These are call options, so the\nstrike is subtracted from the respective underlying (weighted by exchange\nrate) in each component of the payoff. This means the option price should\nbe greater if the prices of the underlying assets are all higher ceteris paribus.\nComparing models by percentage error relative to this calculated value is an\nattempttoperformmodelselectioneventhoughwedonothaverealobserved\nprices, another pricing method, or a closed-form/series solution to compare\nour MC simulation prices and performance to. As shown in Figures 2 and\n3, the best-performing combination of SV, SC, and SER models for case 1 is\n(GARCH-Jump, Weibull, OU) for both start dates of the option. For case 2,\nthe best-performing combination is also (GARCH-Jump, Weibull, OU). The\n3/2 SV model was a close runner-up in our simulations but a higher number\nof the top 10 models across both cases and start dates of the options include\nGARCH-Jump SV. The combination of the Weibull SC and OU SER models\nperforms better than all the alternatives we tested for SC and SER choices.\nFigures 33-41 show plots of some sample paths from each of the (9) SDEs in\nour best model over 252 time steps.\nAs a benchmark, we also test the performance of all model variants with\nconstant correlation. Figures 20-23 (inclusive) show the outputs of the MC\n25simulations with constant correlation with the tables of the model variants\nordered by percentage error. The best-performing model variants with con-\nstant correlation achieve 0.436 (case 1 with 2021 start), 0.154 (case 2 with\n2021 start), 0.147 (case 1 with 2022 start), and 0.431 (case 2 with 2022\nstart) percentage error. These best-performing model variants have the fol-\nlowing combinations of SV, SER, and discretization scheme: (3/2, GBM,\nRunge-Kutta) for case 1 with 2021 start, (3/2, GBM, Euler) for case 2 with\n2021 start, (GARCH-Jump, GBM, Runge-Kutta) for case 1 with 2022 start,\nand (GARCH-Jump, GBM, Milstein) for case 2 with 2022 start. For case\n1 of the option with a 2021 start date, this performance places the best\nconstant correlation model 13th overall by percentage error when compared\nto the results of all models with stochastic correlation. This indicates that\nthe inclusion of stochastic correlation significantly improves pricing via MC\nsimulation. However, for case 2 with the same start date and both cases of\nthe option with the 2022 start date, the best performing constant correlation\nmodels place 4th, 4th, and 5th, respectively, when compared to the 30 best\nmodel variants with SC. As highlighted by Ma, market data analysis reveals\nthat implied correlation often deviates from realized correlation, indicating\na non-zero correlation risk premium [11] (Buraschi, Porchia, and Trojani,\n2006 [59]; Driessen, Maenhout, and Vilkov, 2006 [60]). Moreover, Figure 20\nshows that correlations seem to fluctuate randomly over time and are far\nfrom constant. This evidence supports the inclusion of random correlation\nstructures in derivative pricing models.\nThe execution times of the simulations of all of the model variants are\nalso recorded in the code and displayed in seconds. The Euler scheme gen-\nerally exhibits faster execution times and performs well. The Milstein and\nRunge-Kutta schemes show lower stdevs, indicating higher accuracy com-\npared to the Euler scheme. The Runge-Kutta scheme often shows the low-\nest stdevs, indicating the best accuracy, albeit with longer execution times.\nBased on our simulations, the Milstein discretization scheme offers the best\nbalance between execution times and lower standard deviations. However,\nthe Runge-Kutta scheme should be used when the derivative of the coeffi-\ncient of the diffusion term is not available or hard to compute. In addition,\nthe simulations for the 2022-2023 period generally showed slightly increased\nexecution times and wider confidence intervals compared to the 2021-2022\nperiod, reflecting the increased volatility and market uncertainty during that\ntime frame. This is also reflected in the increased rolling correlations. Also,\nthe simulations took slightly longer on average for case 2 of the option than\nfor case 1 as it involves more processes to be simulated. For the same reason,\n26price estimates for case 2 of the option generally have wider CIs on average\nthan those for case 1.\n6 HEDGING CORRELATION RISKS\nIn the context of our foreign equity quanto call options, Cora and Gora are\nmetrics used to quantify and manage the correlation risks associated with\nthe inclusion of multiple correlated underlying assets in the payoffs of these\ncomplex derivatives. Cora (correlation delta) measures the sensitivity of the\noption’s value to changes in the correlation between the underlying assets\nand Gora (correlation gamma) measures the second-order sensitivity. It is\na crucial parameter for understanding how variations in correlation impact\nthe option’s price, especially when the correlation itself is stochastic. By\nusing Cora and Gora, traders and risk managers can better understand and\nmanage the impact of correlation changes on the option prices, ensuring\nmore effective hedging strategies for portfolios that include basket foreign\nequity quanto call options such as those explored in our study [61]. Cora is\ndefined as the first-order partial derivative of the option price (discounted\nexpectation of payoff) with respect to correlation:\nCora =∂C\n∂ρ(58)\nGora is defined as the second-order partial derivative of the option price with\nrespect to correlation:\nGora =∂2C\n∂ρ2(59)\nThe discount factor can be taken outside of these derivatives, so the main\ntask of deriving Cora and Gora becomes taking derivatives of the option’s\npayoff and applying the chain rule. Also, in our models the SC only applies\nto the BMs driving the stochastic processes of the underlying assets and\nthe BMs driving the FX rate processes are independent of this stochastic\ncorrelation process. This allows us to simplify the formulas for Cora and\nGora as all partial derivatives of the FX rate processes with respect to this\nSC are 0.\n276.1 Case 1: Single FX Rate\nFor the single FX rate case, where the option payoff is given by:\nPayoff = max ( SUSD(T)−K1, SGBP(T)·FX(T)−K2,0)(60)\nThe Cora and Gora metrics can be derived as follows: Cora measures how\nsensitive the option’s value is to changes in the correlation between the GBP\nasset price and the USD asset price. Mathematically, this sensitivity is ex-\npressed as:\nCora =∂C\n∂ρGBP,USD(61)\nGora measures the rate of change of the sensitivity (Cora) with respect to\nthe correlation between the GBP and USD asset prices. It captures the\ncurvature of the option price with respect to correlation changes, indicating\nhow Cora itself responds as the correlation changes:\nGora =∂2C\n∂ρ2\nGBP,USD(62)\nUsingthechainrule,thefirstpartialderivativeof Cwithrespectto ρGBP,USD\nis:\n∂C\n∂ρGBP,USD=∂C\n∂SGBP·∂SGBP\n∂ρGBP,USD+∂C\n∂SUSD·∂SUSD\n∂ρGBP,USD+∂C\n∂FX·∂FX\n∂ρGBP,USD\n(63)\nthen, since the partial derivative of the FX rate process with respect to the\ncorrelation is 0, we get:\nCora =∂C\n∂SGBP·∂SGBP\n∂ρGBP,USD+∂C\n∂SUSD·∂SUSD\n∂ρGBP,USD(64)\nFor the second partial derivative, we get:\n∂2C\n∂ρ2\nGBP,USD=∂\n∂ρGBP,USD∂C\n∂SGBP·∂SGBP\n∂ρGBP,USD+∂C\n∂SUSD·∂SUSD\n∂ρGBP,USD\n=∂\n∂ρGBP,USD∂C\n∂SGBP\n·∂SGBP\n∂ρGBP,USD+∂C\n∂SGBP·∂\n∂ρGBP,USD∂SGBP\n∂ρGBP,USD\n+∂\n∂ρGBP,USD∂C\n∂SUSD\n·∂SUSD\n∂ρGBP,USD+∂C\n∂SUSD·∂\n∂ρGBP,USD∂SUSD\n∂ρGBP,USD\n(65)\n28Simplifying fully, we get:\nGora =∂2C\n∂SGBP∂ρGBP,USD·∂SGBP\n∂ρGBP,USD+∂C\n∂SGBP·∂2SGBP\n∂ρ2\nGBP,USD\n+∂2C\n∂SUSD∂ρGBP,USD·∂SUSD\n∂ρGBP,USD+∂C\n∂SUSD·∂2SUSD\n∂ρ2\nGBP,USD(66)\n6.2 Case 2: Two FX Rates\nFor the two FX rates case, the option payoff is given by:\nPayoff = max\0\nSUSD(T)−K1, SGBP(T)·FXUSD/GBP (T)−K2, SEUR(T)·FXUSD/EUR (T)−K3,0\n(67)\nHere, Cora and Gora metrics need to account for multiple correlations: be-\ntween GBP and USD asset prices and between EUR and USD asset prices.\nThe Cora for each of these correlations would be defined as:\nCora GBP,USD =∂C\n∂ρGBP,USD(68)\nCora EUR,USD =∂C\n∂ρEUR,USD(69)\nSimilarly, the Gora metrics would measure the second-order sensitivity for\neach of these correlations, indicating how each Cora changes with respect to\nchanges in the corresponding correlations:\nGora GBP,USD =∂2C\n∂ρ2\nGBP,USD(70)\nGora EUR,USD =∂2C\n∂ρ2\nEUR,USD(71)\nUsingthechainrule,thefirstpartialderivativeof Cwithrespectto ρGBP,USD\nis:\n∂C\n∂ρGBP,USD=∂C\n∂SGBP·∂SGBP\n∂ρGBP,USD+∂C\n∂SUSD·∂SUSD\n∂ρGBP,USD\n+∂C\n∂SEUR·∂SEUR\n∂ρGBP,USD+∂C\n∂FX USD/GBP·∂FX USD/GBP\n∂ρGBP,USD\n(72)\n29Similarly, the first partial derivative of Cwith respect to ρEUR,USD is:\n∂C\n∂ρEUR,USD=∂C\n∂SEUR·∂SEUR\n∂ρEUR,USD+∂C\n∂SUSD·∂SUSD\n∂ρEUR,USD\n+∂C\n∂SGBP·∂SGBP\n∂ρEUR,USD+∂C\n∂FX USD/EUR·∂FX USD/EUR\n∂ρEUR,USD\n(73)\nSimplifying further, we get:\nCora GBP,USD =∂C\n∂SGBP·∂SGBP\n∂ρGBP,USD+∂C\n∂SUSD·∂SUSD\n∂ρGBP,USD\n+∂C\n∂SEUR·∂SEUR\n∂ρGBP,USD(74)\nCora EUR,USD =∂C\n∂SEUR·∂SEUR\n∂ρEUR,USD+∂C\n∂SUSD·∂SUSD\n∂ρEUR,USD\n+∂C\n∂SGBP·∂SGBP\n∂ρEUR,USD(75)\nFor the second partial derivatives:\n∂2C\n∂ρ2\nGBP,USD=∂\n∂ρGBP,USD∂C\n∂SGBP·∂SGBP\n∂ρGBP,USD+∂C\n∂SUSD·∂SUSD\n∂ρGBP,USD\n+∂C\n∂SEUR·∂SEUR\n∂ρGBP,USD\n=∂\n∂ρGBP,USD∂C\n∂SGBP\n·∂SGBP\n∂ρGBP,USD+∂C\n∂SGBP·∂\n∂ρGBP,USD∂SGBP\n∂ρGBP,USD\n+∂\n∂ρGBP,USD∂C\n∂SUSD\n·∂SUSD\n∂ρGBP,USD+∂C\n∂SUSD·∂\n∂ρGBP,USD∂SUSD\n∂ρGBP,USD\n+∂\n∂ρGBP,USD∂C\n∂SEUR\n·∂SEUR\n∂ρGBP,USD+∂C\n∂SEUR·∂\n∂ρGBP,USD∂SEUR\n∂ρGBP,USD\n(76)\n30Similarly, for ρEUR,USD :\n∂2C\n∂ρ2\nEUR,USD=∂\n∂ρEUR,USD∂C\n∂SEUR·∂SEUR\n∂ρEUR,USD+∂C\n∂SUSD·∂SUSD\n∂ρEUR,USD\n+∂C\n∂SGBP·∂SGBP\n∂ρEUR,USD\n=∂\n∂ρEUR,USD∂C\n∂SEUR\n·∂SEUR\n∂ρEUR,USD+∂C\n∂SEUR·∂\n∂ρEUR,USD∂SEUR\n∂ρEUR,USD\n+∂\n∂ρEUR,USD∂C\n∂SUSD\n·∂SUSD\n∂ρEUR,USD+∂C\n∂SUSD·∂\n∂ρEUR,USD∂SUSD\n∂ρEUR,USD\n+∂\n∂ρEUR,USD∂C\n∂SGBP\n·∂SGBP\n∂ρEUR,USD+∂C\n∂SGBP·∂\n∂ρEUR,USD∂SGBP\n∂ρEUR,USD\n(77)\nTherefore, we get:\nGora GBP,USD =∂2C\n∂SGBP∂ρGBP,USD·∂SGBP\n∂ρGBP,USD+∂C\n∂SGBP·∂2SGBP\n∂ρ2\nGBP,USD\n+∂2C\n∂SUSD∂ρGBP,USD·∂SUSD\n∂ρGBP,USD+∂C\n∂SUSD·∂2SUSD\n∂ρ2\nGBP,USD\n+∂2C\n∂SEUR∂ρGBP,USD·∂SEUR\n∂ρGBP,USD+∂C\n∂SEUR·∂2SEUR\n∂ρ2\nGBP,USD\n(78)\nGora EUR,USD =∂2C\n∂SEUR∂ρEUR,USD·∂SEUR\n∂ρEUR,USD+∂C\n∂SEUR·∂2SEUR\n∂ρ2\nEUR,USD\n+∂2C\n∂SUSD∂ρEUR,USD·∂SUSD\n∂ρEUR,USD+∂C\n∂SUSD·∂2SUSD\n∂ρ2\nEUR,USD\n+∂2C\n∂SGBP∂ρEUR,USD·∂SGBP\n∂ρEUR,USD+∂C\n∂SGBP·∂2SGBP\n∂ρ2\nEUR,USD\n(79)\n317 CONCLUSION\nUltimately, we conclude that to accurately price and hedge multi-asset for-\neign equity quanto options, it is essential to incorporate stochastic cor-\nrelations alongside stochastic volatilities and the appropriate modeling of\nstochastic FX rates. The payoffs of our Quanto call options incorporate\nmultiple correlated underlying assets weighted by the FX rate values (which\nare uncorrelated in our paper). This makes accurate modeling of the FX\nrates and stochastic correlation between the BMs of the underlying assets\nessential for achieving optimal performance in MC simulations. By system-\natically testing all combinations of choices for a varied selection of SDEs for\nSC, SV, and SER, we identify the most effective configuration of our model.\nOverall, the combination of GARCH-Jump SV, OU FX rates, Weibull SC,\nand the Milstein or Runge-Kutta discretization scheme consistently performs\nwell across both cases of the option and start dates we tested. We also find\nthat incorporating mean reversion into stochastic correlation or stochastic\nFX rate modeling is beneficial for MC simulation pricing. Specifically, it\nseems that incorporating mean reversion into stochastic correlation models\nis beneficial not only to ensure simulated correlation paths stay within the\nrealistic range [-1, 1] but also since the motions of correlations between assets\nobserved in the market demonstrate this property.\nMoreover, hedging correlation risks is a crucial aspect of using multi-asset\nQuanto options effectively in practice. We derive formulas for Cora and\nGora of our Quanto options in terms of partial derivatives. Our derived\nCora and Gora expressions can be made even more explicit by evaluating\nthe partial derivatives for specific choices of SV and SC of the underlying\nassets, which allows for efficient hedging of correlation risk for both cases of\nthe options. Finally, based on our findings, we conjecture that the choice\nto model volatility as stochastic (vs. constant) is relatively more significant\nfor pricing accuracy than modeling correlations as stochastic. Something we\nwant to explore further is whether there is some number (of correlated pro-\ncesses acting as the underlying assets for the option) for which this relative\nimportance of modeling volatility or correlation as stochastic is reversed. In-\ncreasing the number of correlated assets should increase the correlation risk\nassociated with the option, and hence, this should increase the importance of\nhow we model correlations. However, it is not clear whether there are some\nconditions for the option’s setup for which modeling correlations as stochas-\ntic have more of an effect on pricing accuracy than modeling volatilities as\nstochastic. Hence, it would be beneficial to study further how the relative\n32effectiveness of these choices changes with different market conditions.\nFuture Work\nThe next step in our research is to extend our framework to handle payoffs\ninvolving three or more assets without necessarily including an asset in the\ninvestor’s domestic currency. The primary challenge of this extension is the\nincreased number of stochastic differential equations (SDEs) that must be\ndiscretized and simulated, which grows quickly with the addition of more\ncurrencies and foreign equity indices. Another potential consideration for\nfuture work is introducing jumps into the stochastic correlation processes as\nwe did with volatility (Bates and GARCH-Jump models). Whilst we do not\ntest such models in this paper, sudden moves in correlations are also feasible\nin some market conditions, so this should be studied. In addition, modeling\nvolatilities as driven by fractional Itô processes (’fractional stochastic’ or\n’rough’ volatility models) is worth exploring ([71], [72], [73], [74], [75], [76],\n[77], [78], [79], [80], [81], [82], [83], [84], [85]). As proposed by Comte and\nRenault (1998) in their development of the Fractional Stochastic Volatility\n(FSV) model [67], fractional Brownian motion (fBM) with Hurst parameter\nH >1\n2can be used to better capture the long-memory property of volatility.\nThe fractional stochastic differential equation considered in their model is\ngiven by:\ndXt=−κXtdt+σdBα\ntx0= 0, κ > 0, α:=H−1\n2,0< α <1\n2(80)\nThe FSV model utilizes fractional Brownian motion BH\ntto incorporate\nlong-memory effects, where the increments of BH\ntare positively correlated\nwhen H >1\n2. This allows the model to capture the mean-reverting nature\nof volatility without explicit mean-reversion terms, as explained by Shi et\nal. in their paper Fractional Stochastic Volatility Model (2021) [68]. The\nsignificance of the Hurst exponent Hlies in its ability to describe the rough-\nness or smoothness of the volatility paths, with H <1\n2indicating roughness\nandH >1\n2indicating smoothness. This approach has the advantage of\nsupposedly aligning better with observed market volatilities compared to\ntraditional models [68]. Additionally, there is potential to extend this frame-\nwork to model stochastic correlation, allowing for both fractional stochastic\nvolatility and fractional stochastic correlation. As shown in Figure 32, for\nshorter rolling windows the observed correlations look like they could poten-\ntially be modeled more effectively by a fractional stochastic process.\n33References\n[1] Hull, J.C. and White, A., \"The Pricing of Options on As-\nsets with Stochastic Volatilities,\" The Journal of Finance , vol.\n42, pp. 281-300, 1987. Available at: https://doi.org/10.1111/j.1540-\n6261.1987.tb02568.x.\n[2] Stein, E.M., and Stein, J.C., \"Stock Price Distributions with Stochastic\nVolatility: An Analytic Approach,\" Review of Financial Studies , vol. 4,\nno. 4, pp. 727-752, 1991.\n[3] Steven Heston, \"A closed-form solutions for options with stochastic\nvolatility,\" Review of Financial Studies , vol. 6, pp. 327-343, 1993.\n[4] Ball, C.A., and Roma, A., \"Stochastic Volatility Option Pricing,\" Jour-\nnal of Financial and Quantitative Analysis , vol. 29, no. 4, pp. 589-607,\n1994. Available at: https://doi.org/10.2307/2331111.\n[5] D.S.Bates, \"JumpsandStochasticVolatil', 'raytos.bsinfotech@gmail.com', ' Boris Ter-Avanesov and Gunter Meissner', '', '../pdf_files/6749bdc42cac2-Pricing Multi-strike Quanto Call Options on Multiple Assets with Stochastic Volatility, Correlation, and Exchange Rates.pdf', 10506688, 76, 12231, 84055, '2024-12-03 18:05:49', '2024-12-04', 'Accepted', 0, 1);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(31, '5217627810', '6745cf4203d9a', 1, 15, 'Density-Functionalized QM/MM Delivers Chemical Accuracy For Solvated Systems', '2024-12-01 14:32:36.769646', '2024', 'We present a reformulation of QM/MM as a fully quantum mechanical theory of interacting subsystems, all treated at the level of density functional theory (DFT). For the MM subsystem, which lacks orbitals, we assign an ad hoc electron density and apply orbital-free DFT functionals to describe its quantum properties. The interaction between the QM and MMsubsystems is also treated using orbital-free density function als, accounting for Coulomb interactions, exchange, correlation, and Pauli repulsion. Consistency across QM and MM subsystems is ensured by employing data-driven, many-body MM force fields that faithfully represent DFT functionals. Applications to water-solvated systems demonstrate that this approach achieves unprecedented, very rapid convergence to chemical accuracy as the size of the QM subsystem increases. We validate the method with several pilot studies, including water bulk, water clusters (prism hexamer and pentamers), solvated glucose, a palladium aqua ion, and a wet monolayer of MoS2', 'Quantum,Computational,Modular,Mechanics', 'Density-Functionalized QM/MM Delivers\nChemical Accuracy For Solvated Systems\nXin Chen,,†Jessica A. Martinez B.,,‡Xuecheng Shao,,¶Marc Riera,,§Francesco\nPaesani,,§Oliviero Andreussi,,∥and Michele Pavanello∗,,†\nE-mail: m.pavanello@rutgers.edu\nAbstract\nWe present a reformulation of QM/MM as a fully quantum mechanical theory of\ninteracting subsystems, all treated at the level of density functional theory (DFT). For\nthe MM subsystem, which lacks orbitals, we assign an ad hoc electron density and\napply orbital-free DFT functionals to describe its quantum properties. The interaction\nbetween the QM and MM subsystems is also treated using orbital-free density function-\nals, accounting for Coulomb interactions, exchange, correlation, and Pauli repulsion.\nConsistency across QM and MM subsystems is ensured by employing data-driven,\nmany-body MM force fields that faithfully represent DFT functionals. Applications to\nwater-solvated systems demonstrate that this approach achieves unprecedented, very\nrapid convergence to chemical accuracy as the size of the QM subsystem increases.\nWe validate the method with several pilot studies, including water bulk, water clusters\n(prism hexamer and pentamers), solvated glucose, a palladium aqua ion, and a wet\nmonolayer of MoS 2.\n1arXiv:2411.17844v1  [physics.chem-ph]  26 Nov 2024Significance\nQM/MM is a powerful computational method used to model a critical, small portion of a\ncomplex molecular system—such as a protein’s active site–using quantum mechanics, while\ntreating the surrounding environment with classical force fields. While QM/MM has ad-\nvanced our understanding of enzymes and biological systems, it often struggles with accu-\nracy, even when the QM and MM regions are not covalently bonded. A notable challenge is\nthe slow convergence of system-environment interaction energies as the size of the QM region\nincreases. This work demonstrates that incorporating quantum mechanics in the description\nof the MM subsystem leads to dramatically improved models. By assigning the MM subsys-\ntem a physically meaningful electron density, and using ab-initio density functionals for the\nQM-MM interaction (accounting for exchange, correlation, and Pauli repulsion), chemical\naccuracy in QM/MM models of aqueous solutions is achieved for the first time.\nIntroduction\nQM/MM (standing for quantum mechanics/molecular mechanics) has revolutionized com-\nputational biochemistry.1Since the pioneering work of Honig and Karplus,2the combination\nof a quantum mechanical (QM) description for a subsystem with a classical point-charge de-\nscription of its environment has led to major breakthroughs in fields such as enzymatics,3,4\ndrug development,5,6and materials design.7Since its conception, methods handling the QM\nand MM subsystems have dramatically evolved. Today’s MM force fields can integrate data-\ndriven potentials,8polarizable models,9–15and even machine learning techniques.16,17QM\nmethods have also evolved dramatically, from DFT methods to wavefunction theory methods\nroutinely used in conjunction with QM/MM.18\nThe nature of the QM-MM interaction has also evolved. Initially, these were handled\nmechanically,3with Coulomb interactions calculated a posteriori , influencing only the forces\nand total energy, but without affecting the QM wavefunction or density. The advent of\n2electrostatic embedding improved accuracy by incorporating MM partial charges directly\ninto the QM Hamiltonian.19Ultimately, mutual QM-MM polarization was achieved using\npolarizable force fields,9,13a concept anticipated in early QM/MM work.20\nThe computational cost of QM/MM simulations is greatly reduced compared to fully\nquantum mechanical treatments. However, incorporating QM / polarizable-MM interac-\ntions in an efficient manner remains challenging. Methods based on judicious partitioning\nof the induction response have demonstrated excellent scalability.14,21Additionally, algorith-\nmic advances have been supported by steady progress in software development.17,22–28To\nextend QM/MM simulations to condensed phases, periodic boundary conditions (PBC) have\nbeen implemented. Ewald summation techniques are commonly used, and adaptations for\nmolecular condensed phases29–32and material systems26,28,33,34are now widely available.\nHow accurate are QM/MM models? A common way to address this question is to evaluate\nthe convergence of the results with respect to the size of the QM subsystem. Unfortunately,\ngenerally such a convergence is slow. Protein environments, for example, are exceptionally\ncomplex, and the search for effective ways to include relevant protein regions in QM/MM\nsimulations continues.35–38Particularly challenging has been capturing charge transfer inter-\nactions on larger scales.37,39\nA slow convergence of the QM/MM setup has also affected those systems where partition-\ning in QM and MM subsystems involves no bond breaking. For example, water solvation.40\nIronically, independent QM-only or MM-only treatments of liquid water can provide ac-\ncurate results, but their combination in QM/MM workflows results in an overall reduced\naccuracy.26,41Accurately modeling aqueous environments with QM/MM is essential due to\nthe need to consider large water environments to properly account for the static and dynamic\nresponses at water-material interfaces.42,43Therefore, representing these polarization effects\nin water bulk, which can extend for several nanometers, is crucial for capturing significant\neffects on the energetics of solvated species.44,45\nThe culprit is the difficulty to accurately capture QM-MM interactions with a compu-\n3tationally efficient method. The MM subsystem is typically described using methods that\nlargely (or completely) neglect its electronic structure. Point charges or, at times, point\npolarizable dipoles do not faithfully represent any electronic structure! The polarizable em-\nbedding method46tackles this problem by dividing the MM subsystem into two regions:\none near the QM subsystem is assigned a QM density derived from isolated fragment cal-\nculations, while the remaining MM atoms are treated using conventional point charge or\ndipole models. This embedding approach improves the accuracy of the QM Hamiltonian\nby capturing both electrostatic and non-electrostatic interactions, leading to better results\nthan traditional QM/MM setups.47Similar methods, such as QM/ESP,48QM/GEM,49and\nQXD,50as well as approaches in density embedding51and many-body expansions,52further\nexplore these concepts. While attempts to account for the purely quantum mechanical Pauli\nrepulsion within QM/MM have yielded mixed outcomes,53some methods address this by\nparametrizing the mechanical embedding interaction energy without introducing new terms\nin the QM Hamiltonian.54–56\nThus, our approach in this work is to treat QM and MM subsystems on a more equal\nbasis, aiming to reduce the impact of an imbalanced QM-MM interface and an imbal-\nanced treatment of the internal energy of QM and MM subsystems. We propose “density-\nfunctionalizing” the MM subsystem, assigning it an electron density such that it can be\nhandled like an electronic subsystem within the rigorous framework of subsystem DFT.57–61\nThis standardization of QM and MM subsystems allows for the use of first-principles density\nfunctionals for evaluating the QM-MM interaction, inherently capturing all relevant physical\neffects, such as exchange, correlation, Pauli repulsion, electrostatics, and charge penetration.\nThe next section details the theoretical framework for this density-functionalized QM/MM\napproach, with additional, less critical details provided in the supplementary materials.62\n4A density-functionalization of QM/MM\nThe central idea is to assign an electron density to both the QM subsystem, ρQM(r), and\nto the MM subsystem, ρMM(r), with the total electron density given by their sum and the\nenergy functional borrowed from rigorous subsystem DFT57–59(sDFT, hereafter),\nρ(r) =ρQM(r) +ρMM(r), (1)\nE[ρQM, ρMM] =E[ρQM] +E[ρMM] +Enad[ρQM, ρMM]. (2)\nAlthough formally the electronic energy is strictly a density functional, in practice, the\nexternal potential (electron-nuclear attraction) is known ahead of time and is thus specified\nfor the QM subsystem, vQM(r), and for the MM subsystem, vMM(r), such that the additive\npart of the energy is given by (disregarding for the time being the nuclear-nuclear repulsion)\nE[ρQM] =Ts[ρQM] +EH[ρQM] +Exc[ρQM] +Z\nvQM(r)ρQM(r)dr, (3)\nE[ρMM] =Ts[ρMM] +EH[ρMM] +Exc[ρMM] +Z\nvMM(r)ρMM(r)dr, (4)\nwhere Ts,EHandExcare the noninteracting kinetic energy, the classical electron-electron\nrepulsion (Hartree) and the exchange-correlation functionals, respectively. The nonadditive\nenergy is thus given by\nEnad[ρQM, ρMM] =Tnad\ns[ρQM, ρMM] +Enad\nxc[ρQM, ρMM]+ (5)\n+ZρQM(r)ρMM(r)\n|r−r′|drdr′+Z\nρMM(r)vQM(r)dr+Z\nρQM(r)vMM(r)dr\nwhere Tnad\ns[ρQM, ρMM] =Ts[ρQM+ρMM]−Ts[ρQM]−Ts[ρMM] and equivalently for Enad\nxc.\nThe equations above can be exploited for a variational minimization of the energy func-\ntional with respect to variations in both ρQMandρMM, provided that suitable approxima-\ntions for the relevant density functionals are available. When both subsystems are treated\n5at the Kohn-Sham DFT level, this approach yields sDFT, which was found to be accurate\nin the limit of weak inter-subsystem interactions. This is the case for systems such as wa-\nter molecules in liquid water63or CO 2molecules in fluid CO 2.64In fact, sub-1 kcal/mol\naccuracy is now routinely achieved in sDFT calculations either with Kohn-Sham subsys-\ntems,65–67orbital-free subsystems,68and proper multiscale simulations.69–72Inter-subsystem\ninteractions involving hydrogen bonds, are the focus of this work and are particularly well\ndescribed by the nonadditive PBE exchange-correlation and revAPBEk nonadditive kinetic\nenergy functionals65(and in general many GGA nonadditive functionals73).\nIn a QM/MM framework, Eq. (4) is usually replaced by a classical force-field expression,\nwhich involves electrostatic interactions between atom-centered point charges and possi-\nbly atom-centered polarizable dipoles, as well as (typically empirical) expressions for short\nrange dispersion-repulsion interactions and bonded terms. In common implementations of\nQM/MM approaches, the tool associated with the classical component is responsible for the\ncalculation of this energy term. However, the electrostatic multipoles present in the MM\nforce-field are also involved in the electrostatic terms of the QM-MM interaction energy term\nin Eq. (5). Usually, ad-hoc corrections to describe short-range dispersion-repulsion interac-\ntions and avoid unphysical behaviors when the QM and MM subsystems are too close are\nintroduced to approximate the first two terms of Eq. (5). Once the analytic dependence\nof Eq. (2) on the atomic positions of the MM subsystem is defined, the functional deriva-\ntive of Eq. (2) with respect to ρQM(r) allows the optimization of the QM subsystem via a\nself-consistent field (SCF) approach.\nPoint-charges and point-dipoles introduced in the definition of the MM part of the sys-\ntem can be tuned to fit empirical results for the MM system, or they can be optimized to\nreproduce properties connected to the electronic density of the MM components computed\nfrom first principles (e.g., binding energies or the behavior of the electrostatic potential).\nBecause the permanent charges in MM force fields are independent of the geometry of the\nsystem and of its surrounding environment, atomic polarizabilities may be included in the\n6force field in order to capture the system’s electrostatic response to external fields. The\nresulting polarizable force fields will, therefore, respond to the non-additive term in Eq. (5)\nas it contributes to the induced dipoles in the MM subsystem. This results in mutually\npolarized QM and MM subsystems.\nThe typical approximations in the above approach lead to significant inaccuracies when\nthe boundary between QM and MM regions varies systematically. Drawing from existing\nQM/MM methods that account for electron densities in the MM subsystem46,74and the\nsuccesses of the sDFT framework, we hypothesize that a QM/MM framework based on Eqs.\n(2–5) can accurately model solute-solvent systems. This extends to weakly interacting QM\nand MM subsystems, provided consistent forward and backward mappings between first-\nprinciples electronic densities and force field multipoles are established.\nFor the forward mapping between electronic-structure calculations and accurate classi-\ncal electrostatics, the many-body polarizable approach by Paesani and collaborators showed\nthat it is possible to effectively describe statistical properties of bulk systems by carefully\nparametrizing a classical force-field on a large database of accurate few-body first-principles\nsimulations.75,76While the initial developments of MB-Pol focused on high-accuracy coupled-\ncluster simulations of water dimers and trimers, the approach can be applied to DFT-based\ncalculations77giving rise to, e.g., the MB-PBE force field. The resulting force-fields describe\nelectrostatic interactions in terms of atomic charges and polarizabilities. As in similar ap-\nproaches in the literature, short-range corrections are introduced to avoid self-polarization\nand the unphysical divergence of the induced dipoles when different polarizable systems are\ntoo close to each other. In this work, we hypothesize that using an MM subsystem whose\nelectrostatic interactions are fully consistent with the level of theory of the QM component\nwill allow the seamless convergence of QM-MM calculations as the boundary between the\ntwo regions is varied.\nFor the backward mapping between the classical force-field used in the MM region and\nan effective electronic density to use in the density functionalized QM-MM interaction term,\n7we introduce the following approach. We treat each atomic nuclei and core electrons using\npseudopotentials. To keep the approach computationally efficient for large MM subsys-\ntems, we use the local part of the ultrasoft pseudopotentials from Garrity and Vanderbilt\n(GBRV),78which are designed for fast, high-throughput simulations that require low plane\nwave cutoffs. This assignment can be efficiently handled in a computationally linear scaling\nmanner using the particle-mesh Ewald method.79For the valence electrons, we convert the\npoint-like charge multipoles computed and used by the classical force-field into a smooth\nelectronic charge density. Namely, for each atom i, the valence electron density is rep-\nresented by a Gaussian centered at the ion’s position, Ri, with an adjustable width σi:\nρqi(r) = (Ni−qi)gσi(r−Ri), where gσiis a normalized Gaussian and the prefactor is crucial\nfor accurately representing the ion’s permanent charges, qi, while accounting for the isolated\natom’s number of valence electrons, Ni. If the force-field involves higher multipoles in the\ndescription of its electrostatic interactions, they can be included in the reconstructed elec-\ntron density by using derivatives of the normalized Gaussian. In particular, we can map\na point-like dipole into a corresponding smooth density using the gradient of a Gaussian\nfunction as ρµj(r) =−⃗ µj·⃗∇gσj(r−Rj), where ⃗ µjis the induced dipole at the dipole site j.\nSimilarly, higher-order multipoles can be mapped using higher-order derivatives. The total\nvalence electron density becomes\nρMM(r) =X\ni∈MM chargesρqi(r) +X\nj∈MM dipolesρµj(r). (6)\nWe stress that the proposed formulation relies on a set of element-specific widths (the σi)\nthat can significantly affect the final shape of the reconstructed electronic density (both\npermanent charges and polarization density due to the induced dipoles).\nFor the forward mapping, we hypothesize that using the Gaussian widths that provide\nthe best match between QM/MM vs QM/QM (sDFT) interaction energies will allow for\nthe accurate description of the mutual polarization effects and the seamless convergence of\n8QM/MM calculations as a function of an increasing size of the QM subsystem.\nThe functional derivatives of the non-additive interaction energy with respect to the QM\nor MM subsystem densities yields the embedding potentials\nvQM\nemb(r) =δEnad[ρQM, ρMM]\nδρQM(r)=vMM(r) +Z\ndr′ρMM(r′)\n|r−r′|+δTnad\ns\nδρQM(r)+δEnad\nxc\nδρQM(r), (7)\nvMM\nemb(r) =δEnad[ρQM, ρMM]\nδρMM(r)=vQM(r) +Z\ndr′ρQM(r′)\n|r−r′|+δTnad\ns\nδρMM(r)+δEnad\nxc\nδρMM(r), (8)\nthat can be used to optimize the QM or MM degrees of freedom. In particular, Eq. (8) enters\nthe Hamiltonian of the QM subsystem(s) at each SCF step and it is used for the calculation\nof the ground state QM electronic densities as well as for the optimization of QM atomic\npositions. The sDFT framework and the implementation of this approach in the eDFTpy\nsoftware80allows for the coupling of the QM/MM embedding potential into multiple QM\nsubsystems.\nEq. (7) instead can be used by the MM engine to compute the QM effects on the induced\ndipoles and on the interatomic forces. For the former, the gradient of the MM embedding\npotential needs to be added to the classical electric field used to compute induced dipoles.\nWhile all the terms in Eq. (7) would ideally be included in the embedding field that polarizes\nthe MM component, the current definition of atomic polarizabilities within polarizable force\nfields is only meaningful for a classical description of long-range polarization effects. Thus, in\nthe current implementation, we only keep the first two terms, which are related to classical\nelectrostatic interactions, and we neglect the effect of the non-additive kinetic and exchange-\ncorrelation terms, which are more relevant for short-range interactions.\nThe evaluation of the QM additive energy in (3) can utilize the sDFT implementation\nof eDFTpy with either a single QM subsystem or multiple QM subsystems. When NSQM\nsubsystems are involved, the QM electron density is represented as the sum of contributions\nfrom each subsystem, and the QM energy is decomposed into additive and nonadditive terms,\n9Figure 1: Workflow of the QM/MM method with emphasis on the software implementation.\nSee details in section .\nfollowing the structure of (2). Namely,\nρQM(r) =NSX\nI=1ρI(r), (9)\nE[ρQM] =NSX\nI=1E[ρI] +Enad[{ρI}]. (10)\nIn the results Section , we will refer to a one-subsystem treatment of the QM region as\nfragmentation type 1 (or Frag. 1) while a many-subsystem treatment as fragmentation type\n2 (or Frag. 2).\nDetails of the implementation\nWe now discuss the details of the implementation of the QM/MM algorithm in the eDFTpy\nsoftware.80Figure 1 illustrates the QM/MM workflow of the SCF cycle in the presence of a\nMM subsystem. It begins with initial guesses for the MM and QM density and wavefunctions.\nIn eDFTpy, we use QEpy81as QM solver (a python implementation of Quantum ESPRESSO\n7.282) and a python interface to MBX as the MM solver.83The initial guess density for the\n10QM subsystem is usually taken from the sum of atomic densities from the pseudopotential\nfiles. For the MM subsystem, a valence electron density consistent with the value of the\npermanent charges (which are fixed, independent of geometry) is used.\neDFTpy then directs QEpy, the QM solver, to solve for the electronic structure of the\nQM system. This is done either by a single QEpy instance when a single QM subsystem\nis considered, or by multiple QEpy instances when several QM subsystems are considered.\nThe QM subsystems require the computation of QM-in-QM embedding potentials which are\nhandled also by eDFTpy as indicated by the blue arrows connecting the QEpy solvers to\nthe eDFTpy circle in the figure. The QM electrostatic field formally given by the negative\ngradient of the MM embedding potential in Eq. (7), −⃗∇vMM\nemb(r) is then represented on the\nMM polarizable dipole sites. For large systems, representing the QM electric field on the\nMM sites is a task of non-negligible computational complexity.33,34,84,85The QM electric field\nis then represented on the grid point closest to each of the MM polarizable dipole sites. This\nis accurate enough given the exceptional smoothness of the QM field in the MM region34\nand saves the inconvenient step of splining the field on the exact position of the ions. Spline\nwould require an MPIGATHER operation which carries a high wall-time cost. In eDFTpy, the\nMM cell is spanned by a grid fine enough to properly represent the ionic pseudopotentials\ncentered on each QM ion and MM site. In our simulations, we use a 100 Ha cutoff for this\ngrid, which is fine enough to produce real-space grid points spaced by about 0.23 a0.\nOnce the electric field is represented on the MM sites, the MM solver is tasked with solving\nthe Coulomb problem in the MM cell to yield the MM polarizable dipoles. The MM density\nis then built using Eq. (6). Having the MM density and the density of all QM subsystems\nallows eDFTpy to compute the required embedding potentials for each subsystem, including\nthe MM subsystem. The SCF cycles then continue until convergence is achieved, which is\ncalibrated on the convergence of the QM density. At convergence, QM density and MM\ndipoles are fully mutually polarized.\nIn the eDFTpy implementation we take full advantage of plane wave reduction techniques\n11that were developed for sDFT.68,69,86–88Specifically, MM and QM subsystems are represented\nby different simulation cells, grids and thus plane wave basis sets. The QM simulation cell is\nsmaller compared to the physical cell which coincides with the MM cell. Coulomb fields and\nother long-ranged energy functionals are evaluated on the large, physical cell. Employing\nsuch a multi-cell/grid approach is crucial in the context of QM/MM simulations as the MM\nsubsystem is usually dramatically more extended than any of the QM subsystems. In the\nsupplementary materials62we further discuss our parallelization strategy.\nRO-O\nFigure 2: Water dimer energy curve (structure shown) for O–O distances ranging from 2.3\nto 7.7 ˚A. The black line represents the QM/QM result, where both the donor and acceptor\nmonomers are treated at the QM level. The shaded area represents the deviation of the\nQM/MM result from QM/QM. Green and blue lines correspond to the QM hydrogen bond\ndonor (QM/MM) and acceptor (MM/QM), respectively. The inset shows a correlation plot\nof QM/MM and MM/QM interaction energies. Yellow markers represent geometries in the\nrepulsive region of the curve ( RO-O<2.9˚A), while red markers correspond to those in the\nattractive region ( RO-O>2.9˚A).\nThe current implementation also features analytic energy gradients for the atoms in the\nQM region. In the supplementary materials we devote a section to the implementation of\nthe forces and results are shown in Tables ??and??.\n12Computational Details\nPseudopotentials, Density Functionals and Plane Wave Cutoffs\nGBRV pseudopotentials78are used for all elements considered of both the QM and MM\nsubsystems. The PBE exchange-correlation functional89and the revAPBEk noninteracting\nkinetic energy functional90are employed for approximating additive Excand nonadditive\nExcandTsfunctionals. All calculations include Grimme’s D3 correction.91We choose plane\nwave basis sets for the QM subsystems with a cutoff energy of 20 Ha for wavefunctions\nand 200 Ha for charge density and potential unless otherwise stated (see supplementary\nTable ??). The energy convergence threshold for the SCF was set to 10−8Ha/atom. The\nBrillouin zone was sampled by a 5 ×5×1 k-point mesh for MoS 2and the Γ point for all\nother calculations. MM calculations were conducted using the MBX package83using the\nMB-PBE and MB-Pol water models, which were developed to quantitatively reproduce PBE\nor CCSD(T) water,77,92respectively.\nAll inputs/output files, Jupyter notebooks needed to analyze the data and reproduce\nthe figures in this work, as well as links to tagged versions of the software (MBX, eDFTpy,\nQEpy, and DFTpy) used for the simulations, are available as reported in the supplementary\nmaterials.62\nParameters Defining the MM Density\nAs described in the sections above, the proposed framework relies on the conversion of\nclassical permanent charges and polarizable dipole sites into a smooth electronic density.\nFor each atomic charge and polarizable dipole, this involves the fit of the width, σ, of the\ncorresponding normalized Gaussian functions that contribute to the expansion in Eq. (6).\nIn our applications to solvated systems, MM sites only involve oxygen and hydrogen atoms,\nfor a total of 4 parameters that need to be fitted.\nWe also considered an additional MM-induced dipole self-energy correction. Although\n13the induced point-dipole self-energy is given by1\n2µ2α−1,93where αis the isotropic dipole\npolarizability, we recognize that the dipoles considered in our work are not point dipoles,\ne.g., their charge density overlaps with the QM density at the QM/MM interface. Thus, we\nadded an additional term to the self-energy for each site equal to kSE\ni|⃗ µ−⃗ µ′|2, where ⃗ µ′is\nthe induced dipole at the same site when only the MM subsystem is considered, and kSE\ni\nare element-dependent proportionality constants. Additional details about this correction\nand about how the permanent charge density was generated for the MB-PBE and MB-Pol\nforce fields (which use the so-called M-site) are available in the supplementary materials\ndocument.62\nThe parameters defining the MM density were fitted so as to reproduce the QM-QM\ninteraction energies for a single water molecule in bulk water. Ten snapshots of 64-water\nmolecule cubic systems were taken from Ref. 94. These provided 640 water-bulk interaction\nenergies. More details about this system will be given in the results section. The final values\nof the parameters for both MB-PBE and MB-Pol force fields are listed in Table ??.\nThe use of bulk simulations as a reference for the parametrization of the density func-\ntionalization approach provides a robust and general strategy that reduces the need for\napplication-specific benchmarks. Results on small water clusters and solvation effects on\nmolecules and materials (reported in the following) highlight the transferability of the ob-\ntained parameters.\nResults and Discussion\nWater Dimer\nWe start by comparing the QM/MM potential energy curves shown in Figure 2 and the\npolarization density depicted in Figure 3 for water dimers. The dimer structures, sourced\nfrom Ref. 95, were placed in a 20- ˚A cubic simulation cell and evaluated against benchmark\nQM/QM simulations performed using sDFT.\n14QM/QM\nQM/MM MM/QM\nH\nH\nOOH\nHOO\nHH\nOOH\nH\nOOMM/MM(a)\n(c) (d)\n(b)Figure 3: Polarization density, defined as ρ(r)−ρiso(r), where ρisois the sum of the elec-\ntron densities of the isolated water monomers, for the water dimer at the equilibrium O–O\ndistance. In each panel, we present isosurfaces (top) and contour plots (bottom) generated\nwith a cutoff of ±0.0007 e·a−3\n0.\nThe key aspect of this system lies in its asymmetry, as one monomer is a hydrogen\nbond donor, and the other is an acceptor. Even though both QM and MM monomers are\nmodeled by PBE (the MM subsystem is described by the MB-PBE model), the nature of\nthe QM-MM interface is dramatically different whether one considers a QM hydrogen bond\ndonor (QM/MM) or acceptor (MM/QM). Despite this, the curves are remarkably similar.\nThe QM/MM and MM/QM minima (at 2.90 ˚A O–O distance) are less than 0.15 kcal/mol\naway from each other, and both deviate from the reference by a similar measure. These\nresults show that the QM/MM interface is extremely well characterized by the nonadditive\nfunctionals. Crucially, the repulsive part of the curve is also well reproduced. Our ∼0.2\nkcal/mol error compares well with the ∼0.6 kcal/mol error for the dimer reported in Ref. 41\nfor their QM/MM (AMOEBA) method.\n15In the inset of Figure 2, we report the correlation between the interaction energies of the\nQM/MM and MM/QM systems, showing that they are in extremely good agreement. The\ninteraction energies in the attractive part of the curve follow the ideal trend, i.e., the points\nsit on the diagonal line. However, those in the repulsive part (yellow color coded markers)\nshow a slightly deviated trend. A behavior indicative of an asymmetry in accounting for\ncharge penetration effects of the H QM-OMMvs H MM-OQM. To ensure our results are not\naffected by possible artifacts due to the use of PBCs, we recalculated the interaction energy\nminima in a larger simulation cell with lattice constant a= 50 ˚A finding a shift of less than\n10−3kcal/mol.\nFigure 3 shows the polarization density (defined in the caption) of the water dimer system.\nIt is clear that the MM polarization is only qualitatively similar to the QM polarization.\nSpecifically, comparing the QM/QM (panel a) with the MM/MM (panel b) shows that the\nlatter misses several potentially important details near the ion’s core and along the O–O line.\nThese are well-known deficiencies in the electrostatic response of dipole-only polarizable force\nfields.96,97Interestingly, the QM/MM treatment improves the polarization of both monomers.\nPanels (c) and (d) show that the MM molecule polarization gains features that are prominent\nin the QM response of that monomer but that are absent (or weakly present) in the MM/MM\ncase. This shows that the handling of the QM/MM interface by our method is accurate not\nonly by the interaction energy measure (recall Figures 2) but also by the much more stringent\ntest of subsystem mutual polarization.\nWater Hexamer\nHexamer water structures play a crucial role in quantum chemistry due to their complex\nhydrogen-bond topologies. Accurately predicting their relative energies is often seen as a\nbenchmark for a model’s ability to represent water across its various stable phases.98Here,\nfollowing Ref. 8, we focus on the most stable hexamer, the prism hexamer, to examine the\neffect of the QM-MM boundary. In the prism hexamer all water monomers act as both\n16hydrogen bond donors and acceptors, with either 1/2 or 2/1 accepted/donated hydrogen\nbonds.\nThe root mean square errors (RMSEs) of the computed interaction energies defined as\nthe energy of the hexamer minus the energy of the 6 isolated water molecules are collected\nin Figures ??and??for the MM treated with MB-PBE and MB-Pol, respectively. When\nmultiple water molecules are treated at the QM level, the sDFT framework allows flexibility\nin how the QM waters are grouped: they can be combined into a single subsystem (Frag. 1\nin the figure) or divided into separate subsystems (Frag. 2). For each partition type with k\nQM or MM water molecules, there are\06\nk\npossible members of the partition (i.e., ways to\nsplit the hexamer into QM and MM subsystems).\nIdeally, all members of each partition should yield the same interaction energy. Therefore,\na larger RMSE for the predicted interaction energy indicates a lower accuracy of the method.\nRecognizing that no practical fragmentation method is perfect, we find a relation between\nthe RMSE for the k-th partition ( σQM/MM(k)) and the square root of the number of members\nin the partition99(q\06\nk\n). This relationship is confirmed by R2values of 0.99 for all QM/MM\nand fragmentation methods considered (see Figure ??). The slope of this linear relationship\nis proportional to the average error per QM/MM boundary in the partitions (error = slope\n·pπ\n2), yielding a predicted error per boundary ranging between 0.2 and 0.3 kcal/mol for the\nmethods considered. This error is consistent with the results for water dimers and, as we\nwill see in the next section, also aligns with the RMSEs for the pentamer clusters extracted\nfrom bulk liquid structures.\nBulk and First Solvation Shell Water Environment\nTo further assess our method, we consider the dipole moment and the molecule-environment\ninteraction energy of water molecules embedded in an MM environment of bulk liquid water.\nThe benchmark is once again sDFT. Dipole moments of embedded molecules are accessible\nin sDFT, calculated with the subsystem electron density. This procedure was found to be\n17accurate for a variety of embedded molecular species.57,94,100,101We consider 10 snapshots of\nan ab-initio dynamics trajectory of 64 independent water molecules in a cubic cell of lattice\nconstant 12.42 ˚A that was presented elsewhere63,94(also available in the supplementary\nmaterials62). We use the nomenclature n/m to denote a simulation where nmolecules are\ntreated at the QM level and mare treated at the MM level. In all cases, the reported quantity\nis the interaction of a single water molecule with the environment. For example, 1/63 means\nthere are 63 MM water molecules and one QM water, for a total of 64 water molecules.\nWe use sDFT to generate benchmark values for the water-environment interaction energy.\nWithin a sDFT framework, one may treat all 63 environment molecules as a single subsystem\nor as 63 coupled subsystems (for the 1/4 system we only consider 4 environment water\nmolecules). Owing to the accuracy of sDFT for bulk water simulations,45,63we employed\nboth approaches, which resulted in very similar trends, as reported in Figure ??of the\nsupplementary materials. For the discussion in the following, we consider the benchmark\nwhere all 63 molecules in the environment are grouped in a single subsystem. Leveraging\nthe available bulk configurations, inspired by Ref. 41, we also considered the performance\nof our QM-MM approach on “first shell” structures, where each water molecule of the bulk\nis embedded only by the nearest 4 water molecules of the environment, giving rise to a\ncollection of water pentamer structures (denoted by 1/4). We also test our QM/MM scheme\non a partition “minimal solvation” where each water molecule and the nearest 4 water\nmolecules of the environment are included in the QM subsystem and the remaining 59 water\nmolecules are kept in the MM subsystem (system 5/59). Because in each snapshot there\nare 64 water molecules and there are 10 snapshots, 640 total structures / data points are\navailable.\nPanels (a) and (b) of Figure 4 show that the interaction energy between water molecules\nand their environment in liquid water ranges from -35 to -7 kcal/mol for the bulk calculations\nand from -20 to -1 kcal/mol for the first shell calculations. Such energy scales are in line\nwith comparable calculations in the literature.41As indicated in the figure, the root mean\n18QM/MM (1/63) QM/MM (1/4) QM/MM (5/59)Figure 4: Panels (a), (b) and (c): correlation plots of the interaction energy (in kcal/mol) of\na single water molecule with its environment in a model of liquid water. (a) Bulk: QM/MM\nwith 1 QM water molecule and 63 MM water molecules. (b) First shell: 1 QM water\nmolecule and 4 MM water molecules (only the first solvation shell). (c) Minimal solvation: 5\nQM water molecules and 59 MM water molecules. Panels (d), (e), and (f): correlation plots\nof the dipole moment length of the embedded molecule (in Debye) for the same systems as\nfor panels (a–c).\n19square errors (RMSEs) of the QM/MM interaction energy compared to the QM/QM ones\nare 1.32 kcal/mol for the bulk and 1.05 kcal/mol for the first shell calculations. The minimal\nsolvation setup improves upon the bulk with an RMSE of 1.11 kcal/mol. The RMSE of\nthe first shell simulations compares well with 1.4 kcal/mol from a similar simulation from\nRef. 41 where MM was treated with the AMOEBA force field. To our knowledge, a similar\ncomparison for the bulk or minimal solvation results is not available.\nFigure 5: Polarization density (defined as the difference of the embedded and isolated\nmolecular electron density) of an embedded water molecule employing the methods indicated\nin the figure. Top panels: single water molecule polarization. Bottom panels: environment\npolarization. The isosurface value is set to ±0.0025 e ·a−3\n0.\nSuch RMSEs are also consistent with the accuracy of the hexamer structure discussed\nbefore. However, ∼1 kcal/mol accuracy for bulk systems is even more impressive. In the\nhexamer, the interaction energies (mbpol) average about 8.00 kcal/mol per water molecule.\nIn the bulk water, the QM–QM interaction energy averages to a much larger value ( ∼22.42\nkcal/mol) due to a stronger polarization. In fact, the ∼1 kcal/mol accuracy leads us to\nconclude that the QM-MM mutual polarization predicted by the QM/MM simulation in\nbulk and minimal solvation setups is well represented. As we can see in Figure 5, both\n20the polarization of the embedded water molecule (see panels a, b, and c) as well as of the\nenvironment (see panels e, f, and g) are fairly well represented by the QM/MM calculations.\nAn interesting aspect of the MM polarization in panels (e) and (d) of Figure 5 is that,\nin comparison to the QM/QM polarization they only feature a small component from the\nsecond solvation shell. An explanation for this effect is the fact that polarizable force fields\ntypically employ slightly damped atomic dipole polarizabilities compared to the reference\nQM value.102,103The damping is crucial to fend off overpolarization, which in our framework\nwould stems from the neglect of the nonadditive components of the embedding potentials,\nsee Eq. (7). In follow-up work, it will be interesting to analyze the effect of these additional\nterms on the MM polarization and the chosen values of the atomic dipole polarizabilities.\nPanels (d) (e) and (f) of Figure 4 present the dipole lengths of the central, embedded\nwater molecule. These range from 1.6 D to 4.5 D for both 1/63 and 5/59 bulk simulations,\nand from 1.3 D to 3.5 D for the 1/4 first-shell calculations. Generally, we notice that the\ndipole lengths are underestimated in the QM/MM treatment compared to the reference\nQM/QM. The QM/MM dipoles, however, correlate very well with the reference QM/QM\n(sDFT) dipoles showing Pearson’s correlation coefficients above 0.9. We also computed an\nRMSE for the dipoles of the 1/4 calculations of 0.29 D which compare well with the 0.62 D\nof Ref. 41. The dipole results and the results from the interaction energies sustain our claim\nthat our method is the most accurate QM/MM result for liquid water available to date.\nFigure 4 also shows (red diamonds) results labeled as “charge only,” which are from\nQM/MM simulations where the polarization of the MM subsystem is neglected (i.e., the\npolarizable dipoles are set to zero). While for the first shell systems the results are still\nacceptable (dipole correlation of 0.91, dipole RMSE of 0.42 D, and for the interaction energy\nof 1.73 kcal/mol), the results for the bulk system are qualitatively incorrect. In the bulk,\nthe RMSE for the interaction energy jumps to 7.33 kcal/mol. An unacceptable deviation is,\nhowever, in line with the expected accuracy of a typical electrostatic embedding QM/MM\nsimulation of condensed phases.104,105\n21When employing 63 coupled subsystems to represent the QM/QM benchmark, the inter-\naction energies and dipole moment correlations are consistent with what is presented above,\nsee supplementary Figure ??. We also note that MB-Pol provides us with a very accurate\nbenchmark for the interaction energies. We thus include a comparison of the computed\nQM/MM interaction energies for the 1/63 system against an MB-Pol reference in supple-\nmentary Figure ??.\nConvergence with respect to the QM size\nAn important test for QM/MM simulations of solvated species is the convergence with\nrespect to the number of water molecules included in the QM subsystem. As mentioned in\nthe introduction, having an accurate model for the QM-MM interface and employing an MM\nforce field that is consistent with the QM method (we use the MB-PBE force field) should\nallow us to showcase strong QM/MM convergence. The typical target is a ±2 kcal/mol from\nthe reference QM calculation.40In Figure 6, we present the interaction energies of glucose\n(left panel) and the [Pd(H 2O)4]2+aqua ion, counterbalanced by 2 Cl−ions (right panel),\nwith the water bulk environment as a function of the number of water molecules included\nin the QM subsystem. For glucose (a neutral molecule), the figure clearly shows that the\n±2 kcal/mol target is reached (in fact, a ±1 kcal/mol is achieved) already when only 14\nwater molecules are included in the QM subsystem. This amounts to including less than\nthe first solvation shell. Interestingly, the convergence for this system is much worse when\na charge-only MM model is used (i.e., as done before, we simply neglect the polarization\nof the MM subsystem) for which 26 QM water molecules are needed to reach convergence.\nFor PdCl 2, despite the presence of a doubly charged cation, we find an essentially identical\nbehavior with convergence being reached already with 13 QM water molecules. Conversely,\nthe charge only QM/MM method does not reach the ±2 kcal/mol goal even when 46 QM\nwater molecules are included. Therefore, we conclude that similar to the glucose system,\nincluding polarization in the MM subsystem dramatically improves the convergence of the\n22interaction energy with the size of the QM subsystem.\nOur results on the need to include polarization in the MM subsystem find justification\nin the fact that, for a condensed phase system, including the inductive response of the\nenvironment, is crucial to obtain a physical picture, particularly for charged solutes.41\nQMMM 14QM/193MM 26QM/181MM 49QM/158MM QM/QM(207QM)70\n60\n50\n40\n30\n20\nInteraction Energy (kcal/mol)\nQM/QM\npolarizable charge only\nQMMM 13QM/96MM 29QM/80MM 46QM/63MM QM/QM(109QM)420\n400\n380\n360\n340\n320\n300\nInteraction Energy (kcal/mol)\nQM/QM\npolarizable charge only\nFigure 6: Convergence of the glucose (left panel) and the [Pd(H 2O)4]2+aqua ion (coun-\nterbalanced by 2 Cl−ions, right panel) solute-water interaction energy with respect to the\nnumber of water molecules included in the QM subsystem. An orange bar representing the\nsDFT reference is labeled as QM/QM in each plot. The dot-dashed line marks ±2 kcal/mol,\nand the shade marks ±1 kcal/mol window from the sDFT reference.\nIn supplementary Figure ??, we also present the polarization density of glucose and\nits water environment, showing once again that the polarization of the QM/MM model\nreproduces fairly accurately the polarization of the reference QM/QM simulation.\nWet Surfaces\nIn the supplementary information document,62we also present a QM/MM calculation of a\nmonolayer MoS 2solvated by water, see Figures ??and??. The conclusions of that analysis\nare consistent with what has been presented so far. That is, QM/MM simulations reproduce\nwithin a reasonable error the QM/QM result for the interaction energy. For this system,\nwe record a QM/MM interaction energy of -0.11 kcal/mol ·˚A−2at the equilibrium distance\ncompared with a QM/QM reference of -0.23 kcal/mol ·˚A−2, and QM/MM polarization\ndensities very close to the QM/QM benchmark. The equilibrium water-MoS 2distance of 2.1\n23˚A is predicted by both QM/QM and QM/MM methods.\nConclusions\nWe introduced a novel QM/MM framework that incorporates density-functional theory\n(DFT) for the QM and the MM subsystems that leverages an orbital-free treatment for\nthe MM region and the QM-MM interaction. By assigning an electron density to the MM\nsubsystem and accurately capturing nonadditive interactions (such as exchange, correlation,\nCoulomb, and Pauli repulsion effects) our density-functionalized QM/MM approach achieves\nchemical accuracy in modeling complex solute-solvent systems. We validated the approach\nagainst a variety of water-based systems, including water clusters, bulk water, solvated ions,\nand a wet monolayer of MoS 2, demonstrating consistent accuracy and achieving unprece-\ndented fast convergence to chemical accuracy with respect to increasing size of the QM\nsubsystem. Reaching chemical accuracy with the proposed method requires only the inclu-\nsion of the first solvation shell in the QM region–a significant advancement over traditional\nQM/MM schemes.\nParticularly striking is the performance of our density functionalized QM/MM method\nfor H 2O in water. There we find that the excellent performance of the method for clusters\n(dimers, pentamers and hexamers) seamlessly translates to accurate models of bulk liquid\nwater. A prime example is given by the dipole of the solute molecule which we predict an\nRMSE with QM/MM of 0.29 D, or 12%, for both bulk and pentamers compared to 0.624 D\nfor pentamers from Ref. 41.\nOur results highlight the critical role of (1) employing ab-initio density functionals for\nthe QM-MM interactions instead of ad-hoc parametrizations; (2) properly accounting for\nmutual polarization at the QM-MM interface; and (3) employing MM force fields that are\nconsistent with the QM method employed (here we use MB-PBE for MM and DFT with the\nPBE exchange-correlation functional for QM). We found that following these three principles\n24significantly improves convergence with respect to the size of the QM region compared to\nstandard QM/MM methods. Our pilot simulations have showed that for both neutral and\ncharged solutes, the interaction energies reached the target accuracy of within ±2 kcal/mol\nusing a minimal QM region, with further refinement yielding sub-1 kcal/mol errors when\nmerely the first shell of solvent molecules is included in the QM subsystem. This level of\naccuracy, achieved even in bulk water systems, underscores the robustness of our method for\nsimulating condensed-phase environments.\nOverall, this work presents a significant step forward in extending the applicability of\nQM/MM methods to treat larger, more complex systems than typically approached by stan-\ndard QM methods while maintaining chemical accuracy. Future work will explore the impact\nof including beyond-Coulomb, ab-initio terms in the MM embedding potential, so that the\nMM dipole response can more closely resemble the true electronic response of the electrons\nin the MM subsystem. We plan to apply the density-functionalized QM/MM framework to\nchemical environments other than water, for example those provided by biomolecules and\nmaterials interfaces as well as non-aqueous solvents.\nAcknowledgements\nThis research was partially funded by the U.S. National Science Foundation grants No. CHE-\n2154760 (MP, JMB and XC), OAC-2321103 (MP, JMB and XC), OAC-2311260 (MR and\nFP) and CHE-2306929 and OAC-2321102 (OA). All computations were carried out on the\nPrice supercomputer of Rutgers University-Newark acquired through an NSF MRI grant\nNo. OAC-2117429 (MP) and managed by the Office of Advanced Research Computing at\nRutgers.\n25Authors contributions\nPavanello, Andreussi and Paesani conceived the work and co-wrote the manuscript. Pa-\nvanello managed the students and the project. Shao and Riera developed the software.\nMartinez B. and Chen carried out the simulations and co-wrote the manuscript.\nReferences\n(1) Karplus, M. Development of Multiscale Models for Complex Chemical Systems:\nFrom H+H 2to Biomolecules. Nobel Lecture, 2013; https://www.nobelprize.org/\nuploads/2018/06/karplus-lecture.pdf .\n(2) Honig, B.; Karplus, M. Implications of torsional potential of retinal isomers for visual\nexcitation. Nature 1971 ,229, 558–560.\n(3) Senn, H. M.; Thiel, W. QM/MM studies of enzymes. Current Opinion in Chemical\nBiology 2007 ,11, 182–187.\n(4) Kulik, H. J. Large-scale QM/MM free energy simulations of enzyme catalysis reveal\nthe influence of charge transfer. Phys. Chem. Chem. Phys. 2018 ,20, 20650–20660.\n(5) Raghavan, B.; Paulikat, M.; Ahmad, K.; Callea, L.; Rizzi, A.; Ippoliti, E.; Man-\ndelli, D.; Bonati, L.; De Vivo, M.; Carloni, P. Drug Design in the Exascale Era: A\nPerspective from Massively Parallel QM/MM Simulations. Journal of Chemical Infor-\nmation and Modeling 2023 ,63, 3647–3658, PMID: 37319347.\n(6) Lin, H.; Zhang, Y.; Pezeshki, S.; Duster, A. W.; Wang, B.; Wu, X.-P.; Zheng, S.-\nW.; Gagliardi, L.; Truhlar, D. G. QMMM 2023: A program for combined quantum\nmechanical and molecular mechanical modeling and simulations. Computer Physics\nCommunications 2024 ,295, 108987.\n26(7) Ma, C.; Martin-Samos, L.; Fabris, S.; Laio, A.; Piccinin, S. QMMMW: A wrapper for\nQM/MM simulations with Quantum ESPRESSO and LAMMPS. Computer Physics\nCommunications 2015 ,195, 191–198.\n(8) Lambros, E.; Lipparini, F.; Cisneros, G. A.; Paesani, F. A Many-Body, Fully Polariz-\nable Approach to QM/MM Simulations. Journal of Chemical Theory and Computation\n2020 ,16, 7462–7472.\n(9) Gresh, N.; Cisneros, G. A.; Darden, T. A.; Piquemal, J.-P. Anisotropic, Polarizable\nMolecular Mechanics Studies of Inter- and Intramolecular Interactions and Ligand-\nMacromolecule Complexes. A Bottom-Up Strategy. Journal of Chemical Theory and\nComputation 2007 ,3, 1960–1986.\n(10) Lu, Z.; Zhang, Y. Interfacing ab Initio Quantum Mechanical Method with Classical\nDrude Osillator Polarizable Model for Molecular Dynamics Simulation of Chemical\nReactions. Journal of Chemical Theory and Computation 2008 ,4, 1237–1248.\n(11) Ganguly, A.; Boulanger, E.; Thiel, W. Importance of MM Polarization in QM/MM\nStudies of Enzymatic Reactions: Assessment of the QM/MM Drude Oscillator Model.\nJournal of Chemical Theory and Computation 2017 ,13, 2954–2961.\n(12) Loco, D.; Lagard` ere, L.; Caprasecca, S.; Lipparini, F.; Mennucci, B.; Piquemal, J.-P.\nHybrid QM/MM Molecular Dynamics with AMOEBA Polarizable Embedding. Jour-\nnal of Chemical Theory and Computation 2017 ,13, 4025–4033.\n(13) Bondanza, M.; Nottoli, M.; Cupellini, L.; Lipparini, F.; Mennucci, B. Polarizable\nembedding QM/MM: the future gold standard for complex (bio)systems? Phys. Chem.\nChem. Phys. 2020 ,22, 14433–14448.\n(14) Reinholdt, P.; Kongsted, J.; Lipparini, F. Fast approximate but accurate QM/MM\ninteractions for polarizable embedding. J. Chem. Theory Comput. 2021 ,18, 344–356.\n27(15) Giovannini, T.; Puglisi, A.; Ambrosetti, M.; Cappelli, C. Polarizable QM/MM Ap-\nproach with Fluctuating Charges and Fluctuating Dipoles: The QM/FQF µModel.\nJournal of Chemical Theory and Computation 2019 ,15, 2233–2245, PMID: 30875213.\n(16) Zinovjev, K. Electrostatic embedding of machine learning potentials. J. Chem. Theory\nComput. 2023 ,19, 1888–1897.\n(17) Giese, T. J.; Zeng, J.; Lerew, L.; McCarthy, E.; Tao, Y.; Ekesan, S.; York, D. M.\nSoftware Infrastructure for Next-Generation QM/MM- ∆MLP Force Fields. J. Phys.\nChem. B 2024 ,\n(18) Ratcliff, L. E.; Mohr, S.; Huhs, G.; Deutsch, T.; Masella, M.; Genovese, L. Challenges\nin large scale quantum mechanical calculations. Wiley Interdisciplinary Reviews: Com-\nputational Molecular Science 2017 ,7, e1290.\n(19) Groenhof, G. Introduction to QM/MM simulations. Biomolecular simulations: meth-\nods and protocols 2013 , 43–66.\n(20) Warshel, A.; Levitt, M. Theoretical studies of enzymic reactions: dielectric, electro-\nstatic and steric stabilization of the carbonium ion in the reaction of lysozyme. Journal\nof molecular biology 1976 ,103, 227–249.\n(21) Lipparini, F. General linear scaling implementation of polarizable embedding schemes.\nJournal of Chemical Theory and Computation 2019 ,15, 4312–4317.\n(22) Bondanza, M.; Nottoli, T.; Nottoli, M.; Cupellini, L.; Lipparini, F.; Mennucci, B. The\nOpenMMPol library for polarizable QM/MM calculations of properties and dynamics.\nJ. Chem. Phys. 2024 ,160.\n(23) Olsen, J. M. H.; Bolnykh, V.; Meloni, S.; Ippoliti, E.; Bircher, M. P.; Carloni, P.;\nRothlisberger, U. MiMiC: a novel framework for multiscale modeling in computational\nchemistry. Journal of chemical theory and computation 2019 ,15, 3810–3823.\n28(24) Cruzeiro, V. W. D.; Manathunga, M.; Merz Jr, K. M.; G¨ otz, A. W. Open-source\nmulti-GPU-accelerated QM/MM simulations with AMBER and QUICK. Journal of\nChemical Information and Modeling 2021 ,61, 2109–2115.\n(25) Pederson, J. P.; McDaniel, J. G. PyDFT-QMMM: A modular, extensible software\nframework for DFT-based QM/MM molecular dynamics. J. Chem. Phys. 2024 ,161.\n(26) Dziedzic, J.; Mao, Y.; Shao, Y.; Ponder, J.; Head-Gordon, T.; Head-Gordon, M.;\nSkylaris, C.-K. TINKTEP: A fully self-consistent, mutually polarizable QM/MM ap-\nproach based on the AMOEBA force field. J. Chem. Phys. 2016 ,145.\n(27) Lu, Y.; Sen, K.; Yong, C.; Gunn, D. S.; Purton, J. A.; Guan, J.; Desmoutier, A.;\nNasir, J. A.; Zhang, X.; Zhu, L., et al. Multiscale QM/MM modelling of catalytic\nsystems with ChemShell. Phys. Chem. Chem. Phys. 2023 ,25, 21816–21835.\n(28) Dohn, A.; Jonsson, E. O.; Levi, G.; Mortensen, J. J.; Lopez-Acevedo, O.; Thyge-\nsen, K. S.; Jacobsen, K. W.; Ulstrup, J.; Henriksen, N. E.; Møller, K., et al. Grid-based\nprojector augmented wave (GPAW) implementation of quantum mechanics/molecular\nmechanics (QM/MM) electrostatic embedding and application to a solvated diplat-\ninum complex. J. Chem. Theory Comput. 2017 ,13, 6010–6022.\n(29) Nam, K.; Gao, J.; York, D. M. An Efficient Linear-Scaling Ewald Method for Long-\nRange Electrostatic Interactions in Combined QM/MM Calculations. J. Chem. Theory\nComput. 2005 ,1, 2–13, PMID: 26641110.\n(30) Holden, Z. C.; Richard, R. M.; Herbert, J. M. Periodic boundary conditions for\nQM/MM calculations: Ewald summation for extended Gaussian basis sets. J. Chem.\nPhys. 2013 ,139, 244108.\n(31) Bonfrate, S.; Ferr´ e, N.; Huix-Rotllant, M. Analytic Gradients for the Electrostatic\nEmbedding QM/MM Model in Periodic Boundary Conditions Using Particle-Mesh\n29Ewald Sums and Electrostatic Potential Fitted Charge Operators. J. Chem. Theory\nComput. 2024 ,20, 4338–4349.\n(32) Pederson, J. P.; McDaniel, J. G. DFT-based QM/MM with particle-mesh Ewald for\ndirect, long-range electrostatic embedding. J. Chem. Phys. 2022 ,156.\n(33) Laino, T.; Mohamed, F.; Laio, A.; Parrinello, M. An efficient linear-scaling electro-\nstatic coupling for treating periodic boundary conditions in QM/MM simulations. J.\nChem. Theory Comput. 2006 ,2, 1370–1378.\n(34) Laino, T.; Mohamed, F.; Laio, A.; Parrinello, M. An efficient real space multigrid\nQM/MM electrostatic coupling. J. Chem. Theory Comput. 2005 ,1, 1176–1184.\n(35) Brandt, F.; Jacob, C. R. Systematic QM region construction in QM/MM calculations\nbased on uncertainty quantification. J. Chem. Theory Comput. 2022 ,18, 2584–2596.\n(36) Pedraza-Gonz´ alez, L.; Mar´ ın, M. D. C.; Jorge, A. N.; Ruck, T. D.; Yang, X.; Valen-\ntini, A.; Olivucci, M.; De Vico, L. Web-ARM: a web-based interface for the automatic\nconstruction of QM/MM models of rhodopsins. J. Chem. Inf. Model. 2020 ,60, 1481–\n1493.\n(37) Kulik, H. J.; Zhang, J.; Klinman, J. P.; Mart´ ınez, T. J. How large should the QM\nregion be in QM/MM calculations? The case of catechol O-methyltransferase. J.\nPhys. Chem. B 2016 ,120, 11381–11394.\n(38) Karelina, M.; Kulik, H. J. Systematic quantum mechanical region determination in\nQM/MM simulation. J. Chem. Theory Comput. 2017 ,13, 563–576.\n(39) Kulik, H. J. Large-scale QM/MM free energy simulations of enzyme catalysis reveal\nthe influence of charge transfer. Phys. Chem. Chem. Phys. 2018 ,20, 20650–20660.\n(40) P´ erez-Barcia, ´A.; C´ ardenas, G.; Nogueira, J. J.; Mandado, M. Effect of the QM size,\n30basis set, and polarization on QM/MM interaction energy decomposition analysis. J.\nChem. Inf. Model. 2023 ,63, 882–897.\n(41) Dziedzic, J.; Head-Gordon, T.; Head-Gordon, M.; Skylaris, C.-K. Mutually polariz-\nable QM/MM model with in situ optimized localized basis functions. The Journal of\nChemical Physics 2019 ,150, 074103.\n(42) Moscato, D.; Mandelli, G.; Bondanza, M.; Lipparini, F.; Conte, R.; Mennucci, B.;\nCeotto, M. Unraveling Water Solvation Effects with Quantum Mechanics/Molecular\nMechanics Semiclassical Vibrational Spectroscopy: The Case of Thymidine. J. Am.\nChem. Soc. 2024 ,146, 8179–8188.\n(43) G´ omez, S.; Giovannini, T.; Cappelli, C. Multiple facets of modeling electronic absorp-\ntion spectra of systems in solution. ACS Physical Chemistry Au 2022 ,3, 1–16.\n(44) Coons, M. P.; Herbert, J. M. Quantum chemistry in arbitrary dielectric environments:\nTheory and implementation of nonequilibrium Poisson boundary conditions and ap-\nplication to compute vertical ionization energies at the air/water interface. Journal\nChem. Phys. 2018 ,148.\n(45) Martinez B, J. A.; Paetow, L.; Tolle, J.; Shao, X.; Ramos, P.; Neugebauer, J.; Pa-\nvanello, M. Which Physical Phenomena Determine the Ionization Potential of Liquid\nWater? J. Phys. Chem. B 2023 ,127, 5470–5480.\n(46) Olsen, J. M. H.; Steinmann, C.; Ruud, K.; Kongsted, J. Polarizable density embedding:\nA new QM/QM/MM-based computational strategy. J. Phys. Chem. A 2015 ,119,\n5344–5355.\n(47) Kvedaraviciute, S.; Carrasco-Busturia, D.; Møller, K. B.; Olsen, J. M. H. Polarizable\nEmbedding without Artificial Boundary Polarization. J. Chem. Theory Comput. 2023 ,\n19, 5122–5141.\n31(48) Viquez Rojas, C. I.; Slipchenko, L. V. Exchange repulsion in quantum mechani-\ncal/effective fragment potential excitation energies: Beyond polarizable embedding.\nJ. Chem. Theory Comput. 2020 ,16, 6408–6417.\n(49) Gokcan, H.; Kratz, E.; Darden, T. A.; Piquemal, J.-P.; Cisneros, G. A. QM/MM sim-\nulations with the Gaussian electrostatic model: A density-based polarizable potential.\nJ. Phys. Chem. Lett. 2018 ,9, 3062–3067.\n(50) Kuechler, E. R.; Giese, T. J.; York, D. M. Charge-dependent many-body exchange\nand dispersion interactions in combined QM/MM simulations. J. Chem. Phys. 2015 ,\n143.\n(51) Treß, R. S.; Hattig, C.; Hofener, S. Employing pseudopotentials to tackle excited-state\nelectron spill-out in frozen density embedding calculations. J. Chem. Theory Comput.\n2022 ,18, 1737–1747.\n(52) Gillan, M.; Alf` e, D.; Bygrave, P.; Taylor, C.; Manby, F. Energy benchmarks for water\nclusters and ice structures from an embedded many-body expansion. J. Chem. Phys.\n2013 ,139.\n(53) Ben-Nun, M.; Mart´ ınez, T. J. Direct evaluation of the Pauli repulsion energy using-\nclassical’wavefunctions in hybrid quantum/classical potential energy surfaces. Chem.\nPhys. Lett. 1998 ,290, 289–295.\n(54) Giovannini, T.; Lafiosca, P.; Cappelli, C. A General Route to Include Pauli Repulsion\nand Quantum Dispersion Effects in QM/MM Approaches. Journal of Chemical Theory\nand Computation 2017 ,13, 4854–4870, PMID: 28898079.\n(55) Bedrov, D.; Piquemal, J.-P.; Borodin, O.; MacKerell, A. D. J.; Roux, B.; Schr¨ oder, C.\nMolecular Dynamics Simulations of Ionic Liquids and Electrolytes Using Polarizable\nForce Fields. Chemical Reviews 2019 ,119, 7940–7995, PMID: 31141351.\n32(56) Hrˇ sak, D.; Olsen, J. M. H.; Kongsted, J. Optimization and transferability of non-\nelectrostatic repulsion in the polarizable density embedding model. Journal of compu-\ntational chemistry 2017 ,38, 2108–2117.\n(57) Krishtal, A.; Ceresoli, D.; Pavanello, M. Subsystem real-time time dependent density\nfunctional theory. J. Chem. Phys. 2015 ,142.\n(58) Jacob, C. R.; Neugebauer, J. Subsystem density-functional theory. WIREs: Comp.\nMol. Sci. 2014 ,4, 325–362.\n(59) Wesolowski, T. A.; Shedge, S.; Zhou, X. Frozen-density embedding strategy for mul-\ntilevel simulations of electronic structure. Chem. Rev. 2015 ,115, 5891–5928.\n(60) Mi, W.; Luo, K.; Trickey, S.; Pavanello, M. Orbital-free density functional theory:\nAn attractive electronic structure method for large-scale first-principles simulations.\nChem. Rev. 2023 ,123, 12039–12104.\n(61) Jacob, C. R.; Neugebauer, J. Subsystem density-functional theory (update). Wiley\nInterdisciplinary Reviews: Computational Molecular Science 2024 ,14, e1700.\n(62) Supplementary Materials. See supplementary materials document at [url-to-be-\ninserted].\n(63) Genova, A.; Ceresoli, D.; Pavanello, M. Avoiding fractional electrons in subsystem\nDFT based ab-initio molecular dynamics yields accurate models for liquid water and\nsolvated OH radical. J. Chem. Phys. 2016 ,144.\n(64) Mi, W.; Ramos, P.; Maranhao, J.; Pavanello, M. Ab initio structure and dynamics of\nCO2 at supercritical conditions. J. Phys. Chem. Lett. 2019 ,10, 7554–7559.\n(65) Shao, X.; Mi, W.; Pavanello, M. GGA-level subsystem DFT achieves Sub-kcal/mol ac-\ncuracy intermolecular interactions by mimicking nonlocal functionals. J. Chem. Theory\nComput. 2021 ,17, 3455–3461.\n33(66) Mi, W.; Pavanello, M. Nonlocal subsystem density functional theory. J. Phys. Chem.\nLett.2019 ,11, 272–279.\n(67) Schl¨ uns, D.; Klahr, K.; M¨ uck-Lichtenfeld, C.; Visscher, L.; Neugebauer, J. Subsystem-\nDFT potential-energy curves for weakly interacting systems. Phys. Chem. Chem. Phys.\n2015 ,17, 14323–14341.\n(68) Shao, X.; Mi, W.; Pavanello, M. Density embedding method for nanoscale molecule–\nmetal interfaces. J. Phys. Chem. Lett. 2022 ,13, 7147–7154.\n(69) Shao, X.; Lopez, A. C.; Khan Musa, M. R.; Nouri, M. R.; Pavanello, M. Adaptive\nsubsystem density functional theory. J. Chem. Theory Comput. 2022 ,18, 6646–6655.\n(70) Chen, X.; Cifuentes-Lopez, A.; Shao, X.; Lin, L.; Prokopchuk, D.; Pavanello, M.\nUnraveling the Hydration Shell Structure and Dynamics of Group 10 Aqua Ions. J.\nPhys. Chem. Lett. 2024 ,15, 5517–5528.\n(71) Schmitt-Monreal, D.; Jacob, C. R. Density-based many-body expansion as an efficient\nand accurate quantum-chemical fragmentation method: Application to water clusters.\nJournal of Chemical Theory and Computation 2021 ,17, 4144–4156.\n(72) Focke, K.; Jacob, C. R. Coupled-cluster density-based many-body expansion. The\nJournal of Physical Chemistry A 2023 ,127, 9139–9148.\n(73) Kevorkyants, R.; Dulak, M.; Wesolowski, T. A. Interaction energies in hydrogen-\nbonded systems: A testing ground for subsystem formulation of density-functional\ntheory. J. Chem. Phys. 2006 ,124.\n(74) Cisneros, G. A. Application of Gaussian Electrostatic Model (GEM) Distributed Mul-\ntipoles in the AMOEBA Force Field. J. Chem. Theory Comput. 2012 ,8, 5072–5080.\n(75) Babin, V.; Leforestier, C.; Paesani, F. Development of a “First Principles” Water\nPotential with Flexible Monomers: Dimer Potential Energy Surface, VRT Spectrum,\n34and Second Virial Coefficient. Journal of Chemical Theory and Computation 2013 ,9,\n5395–5403, PMID: 26592277.\n(76) Babin, V.; Medders, G. R.; Paesani, F. Development of a “First Principles” Water\nPotential with Flexible Monomers. II: Trimer Potential Energy Surface, Third Virial\nCoefficient, and Small Clusters. Journal of Chemical Theory and Computation 2014 ,\n10, 1599–1607, PMID: 26580372.\n(77) Riera, M.; Lambros, E.; Nguyen, T. T.; G¨ otz, A. W.; Paesani, F. Low-order many-\nbody interactions determine the local structure of liquid water. Chem. Sci. 2019 ,10,\n8211–8218.\n(78) Garrity, K. F.; Bennett, J. W.; Rabe, K. M.; Vanderbilt, D. Pseudopotentials for high-\nthroughput DFT calculations. Computational Materials Science 2014 ,81, 446–452.\n(79) Shao, X.; Mi, W.; Xu, Q.; Wang, Y.; Ma, Y. O(NlogN) scaling method to evaluate\nthe ion–electron potential of crystalline solids. J. Chem. Phys. 2016 ,145.\n(80) Shao, X.; Mi, W.; Pavanello, M. eDFTpy: An Object-Oriented Platform for Den-\nsity Embedding Simulations. available at http://edftpy.rutgers.edu, 2024; http:\n//edftpy.rutgers.edu , (Last accessed on: 04/25/2024).\n(81) Shao, X.; Andreussi, O.; Ceresoli, D.; Truscott, M.; Baczewski, A.; Camp-\nbell, Q.; Pavanello, M. QEpy: Quantum ESPRESSO in Python. Available at\nhttps://gitlab.com/shaoxc/qepy, 2024; https://gitlab.com/shaoxc/qepy , (Last ac-\ncessed on: 04/25/2024).\n(82) Giannozzi, P. et al. Advanced capabilities for materials modelling with QUANTUM\nESPRESSO. Journal of Physics: Condensed Matter 2017 ,29, 465901.\n(83) Riera, M.; Knight, C.; Bull-Vulpe, E. F.; Zhu, X.; Agnew, H.; Smith, D. G. A.;\nSimmonett, A. C.; Paesani, F. MBX: A many-body energy and force calculator for\n35data-driven many-body simulations. The Journal of Chemical Physics 2023 ,159,\n054802.\n(84) S. Nørby, M.; Magnus Haugaard Olsen, J.; Kongsted, J.; Aagard Jensen, H. J. Mul-\ntipole moments for embedding potentials: Exploring different atomic allocation algo-\nrithms. J. Comp. Chem. 2016 ,37, 1887–1896.\n(85) Ferr´ e, N.; ´Angy´ an, J. G. Approximate electrostatic interaction operator for QM/MM\ncalculations. Chem. Phys. Lett. 2002 ,356, 331–339.\n(86) Genova, A.; Ceresoli, D.; Krishtal, A.; Andreussi, O.; DiStasio Jr, R. A.; Pavanello, M.\neQE: An open-source density functional embedding theory code for the condensed\nphase. Int. J. Quantum Chem. 2017 ,117, e25401.\n(87) Mi, W.; Shao, X.; Genova, A.; Ceresoli, D.; Pavanello, M. eQE 2.0: Subsystem DFT\nBeyond GGA Functionals. Comp. Phys. Comm. 2021 ,269, 108122.\n(88) Genova, A.; Pavanello, M. Exploiting the locality of periodic subsystem density-\nfunctional theory: efficient sampling of the Brillouin zone. J. Phys.: Condens. Matter\n2015 ,27, 495501.\n(89) Perdew, J. P.; Burke, K.; Ernzerhof, M. Generalized Gradient Approximation Made\nSimple [Phys. Rev. Lett. 77, 3865 (1996)]. Phys. Rev. Lett. 1997 ,78, 1396–1396.\n(90) Laricchia, S.; Fabiano, E.; Constantin, L.; Della Sala, F. Generalized gradient ap-\nproximations of the noninteracting kinetic energy from the semiclassical atom theory:\nRationalization of the accuracy of the frozen density embedding theory for nonbonded\ninteractions. J. Chem. Theory Comput. 2011 ,7, 2439–2451.\n(91) Grimme, S. Supramolecular binding thermodynamics by dispersion-corrected density\nfunctional theory. Chemistry–A European Journal 2012 ,18, 9955–9964.\n36(92) Babin, V.; Leforestier, C.; Paesani, F. Development of a “first principles” water po-\ntential with flexible monomers: Dimer potential energy surface, VRT spectrum, and\nsecond virial coefficient. J. Chem. Theory Comput. 2013 ,9, 5395–5403.\n(93) B ¨OTT', 'm.pavanello@rutgers.edu', 'Xin Chen, Jessica A. Martinez B., Xuecheng Shao, Marc Riera, Francesco  Paesani, Oliviero Andreussi, and Michele Pavanello', '', '../pdf_files/674c030206641-Density-Functionalized QM-MM Delivers Chemical Accuracy For Solvated Systems.pdf', 5183270, 38, 10080, 67329, '2024-12-01 06:32:36', '2024-12-01', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(55, '1545767915', '51', 5, 5, 'INTRODUCTION TO INFORMATION TECHNOLOGY ', '2024-12-02 13:55:06.121821', '2024', 'We present our experience in designing a course of Introduction to Information Technology (IIT) for the first-year students. The main purpose of this course is to introduce the concepts of computing and computer, and to present a hierarchy of information technology (IT) knowledge from basic to advance through the introduction of syllabus system, research trends of our faculty, IT applications in society, ethics and career potentials in IT. The content of this course is set up to meet the Standard 4 in CDIO. We divide the introduction into two courses and teach the first- year students in the first and second semesters. The first course is the introduction of computer, computing, internet, ethics, and some technical skills of analysis, design, implementation, and testing. This is an overview of IT from the outsiders. The second is a hierarchy of IT knowledge from basic to advance through education systems and research in our faculty. This is an overview of IT from inside viewpoint. We also present some experiences about the project based approach for labs and explain how we train personal skills and professional attitude for our students. Finally, we conclude by providing comments with pros and cons in operating the courses.', 'Standard 4,Introduction to Information Technology,CDIO syllabus,Project-based learning', 'Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n INTRODUCTION TO INFORMATION TECHNOLOGY  \n \n \n \nSon T hai Tran, Le Ngoc Thanh, Nguyen Quoc Binh, Dang Binh Phuong , Le Hoai Bac   \n \nFaculty of Information Technology,  \nUniversity of Science, Hochiminh city, Vietnam  \n \n \nABSTRACT  \n \nWe present our experience in designing a  course of Introduction to Information Technology (IIT) \nfor the first -year students. The main purpose of this course is to introduce the concepts of \ncomputing and computer, and to present a hierarchy of information technology (IT)  knowledge \nfrom basic to a dvance through the introduction of syllabus system, research trends of our faculty, \nIT applications in society, ethics and career potentials in IT. The content of this course is set up \nto meet  the Standard 4 in CDIO. We divide the introduction into two cou rses and teach the first - \nyear students in  the first and second semesters.  The first course is the introduction of computer, \ncomputing, internet, ethics, and some technical skills of analysis, design, implementation, and \ntesting. This is an overview of IT from the outside rs. The second is a hierarchy of IT knowledge \nfrom basic to advance through education systems and research in our faculty. This is an \noverview of IT from inside viewpoint. We also present some experiences about the project -\nbased approach fo r labs an d explain how we train person al skills and professional attitude for \nour students. Finally, we conclude by providing  comments with  pros and cons in operating th e \ncourse s. \n \n \nKEYWORDS  \n \nStandard 4, Introduction to Information Technology , CDIO syllabu s, Project -based learning  \n \n \nINTRODUCTION  \nIn CDIO standard, the standard 4 [1] plays an important role to pro vide a general view about \ncurriculum , syllabus system, future  career  and beginning concepts of CDIO for the first -year \nstudents in our university. Many similar work s in engineering ha ve been published in the CDIO \nconference. Ramon Bragós , et. al. [2], presented a method that they have conceived, designed \nand implement ed \"Introduction to Engineering\" course at Telecom BCN, UPC, Barcelona using \nthe CDIO  syllabus and standards. The basic concepts  and professional  skills were  given to the \nstudents through lessons and simple  projects. From that, the students were  able to recognize  \nproblems of which solutions we were going to teach in the following courses o f the curriculum.   \nYingzi Wang , et. al. [3], introduced  the implementation of the cornerstone project. They \ntransform ed the name of “Introduction to Civil Engineering” into “Introduction to Civil Engineering \nDesign”. The difference is that students are put  into an environment where they could learn and \nuse knowledge and professional skills  to study design actively . Xiaohua Lu , et.al.  [4], introduced \none approach of multi -disciplinary project  for the introduction course.  In his class,  the students \nwere  divided into different disciplinary group s and join ed in project -based learning. That project \nrequired student s to design and build a computer -controlled tower crane at Shantou University. \nThis process help ed students  to understand the different modules and the  input/output of each \nmodule. As a result, the multi -disciplinary p roject i s a good approach to introduction  courses . Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n Goran Gustafsson, et. al. [5],  presented his work of engineering education program s. The  first-\nyear introductory course  was discussed and shared to improve and increase student motivation. \nThey have identified projects and teamwork as important parts of the first-year courses. With the \nCDIO approach, a new model for engineering education is developed to be able to implement \nthis projects and  professional  skills.  In many  previous work s, we rarely see the first-year \nintroductory course to information technology (IT). In this paper, w e present our experience in \ndesigning a course of Introduction to Information Technology (IIT) for the first -year students. On \none hand, t he main purpose of this course is to introduce the concepts of computing and \ncomputer, and to present a hierarchy of IT knowledge from basic to advance through the \nintroduction of syllabus system, research trends of our faculty, IT  applications in society, ethics \nand career potentials in IT.  On the other hand, the purpose of this course will introduce the \nrelationship between the contents of 4 year learning in the university with IT career after \ngraduation  to first -year students . The IIT course also shows students the social requirements to \nIT not only in Vietnam but also worldwide . After studying this course, the first -year student will \nhave another point of view  about their role in  the development of IT. From that starting point, it \nwill help student s to think and navigate  their future career in IT.  It also influences to students ’ \ndecision in course selections for undergraduate program at the current time or their intention to \nenter the graduate program in the future. This course wi ll also help the  students to identify the \nimportance of engineering skills and appropriate  attitudes for the success in their future career \npath. From the above mot ivation, the design and implementation  of this course have been \nconsidered seriously by our senior lecturers and professors in our faculty.  We have already \nspent more than one year to prepare the learning outcome, syllabus, teaching /learning  \ndocuments, and workspace for  this course  [6]. This paper will present our experiences in design, \nbuilding , teaching, and evaluation of this course to the first -year students in 2012.  \n  \nThe content of this paper is presented as follows; Section 2 presents the design and building of \ncourse goals  and learning outcomes for IIT course. Section 3 presents the appro ach of project -\nbased learning to embed CDIO concepts in teaching and training for students.  Section 4 \npresents the meeting and feedback between IT companies and the first -year students. Section 5 \npresents the assessments and some rubrics for this course. S ection 6 is our discussions  about \npros and cons in operating this course  at our faculty.  Section 7 is the conclusions.   \n \n \nCOURSE GOALS AND  LEARNING OUTCOME S \nDesign and building the course goals and learning outcome s of one course in CDIO system is  \nnot easy  because the scope of course goal s must be suitable to the learning outcome s of the \ncurriculum . Figure 1 presents our workflow in the design of course goals and learning outcome s \nfor o ne course by using CDIO approac h. In Fig. 1, we can see that the learnin g outcome s are \ndefined from the course goals while  the course goals are defined by the learning outcome s of \nour curriculum. In practice, the number of course goals is less than or equal to 8 and there are \nabout 2 to 4 learning outcomes corresponding  to eac h course goal.  We can see that t he content \nof course goals is presented more in details by the learning outcomes. Most important contents \nin the course goal s will be  the objectives of the assessment  corresponding to Source of \nEvidence in Fig.1 . It is notic ed that the course goals and the learning outcome will involve \ndirectly to the design of the course.  The solid lines in Fig.1 show the task order in workflow and \nthe dash lines show the revision and comparison. The total score is the final score of student s \nafter studying the course.  We divide the content  of IIT  into two courses and teach the first year \nstudents in the first and second semesters.  \n Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \nFigure 1: Workflow to build a CDIO syllabus  \n \nThe first course is the introduction of computer, computing, in ternet, ethics, and some technical \nskills of analysis, design, implementation, and testing.  This is an overview of IT from outside \nviewpoint. The second is a hierarchy of IT knowledge from basic to advance through systems of \neducation and research in our f aculty. This is an overview of IT from inside viewpoint  of our \nfaculty . The course goal of Introduction to Information Technology can be written into two stages \nas follows;  \na) The course goals of the first course  \n Explain general knowledge of IT include basic knowledge about counting system, \noperating system, internet, email, and office applications . \n Describe the basic values related to professional ethics of those working in IT \nsector . \n Describe the work  and job position  in a company, related to IT, which is one  IT \nstudent can undertake  after graduation.  \n Recognize the  importance of self study, team work, and communication skills.  \n Recognize the professional attitude, regulatory compliance, and reliability.  \n \nThe first course is taught in ten weeks with 15 hours in class, 20 hours in lab an d 15 hours of \nself studying at home  (Note that  details of weekly c lasses will be  provided by contacting the \nauthors ). \n \nb) The course goals of the second  course  \n Describe relationship between  the syllabus system , researches,  and the IT career \ndevelopment in the Department of Information Technology, University of Science, \nHoch iminh city, Vietnam.   \n Describe basic concepts related to the fields of Information Systems, Software \nEngineering, Computer Networking & Telecommunications, Knowledge \nEngineering , and Machine Vision & Robotics.  \nProceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 2 : The course outline of Introduction to Information Technology (IIT) 1 & 2.  \n \n Describe outline of jobs which directly and indirectly related to the above IT fields .  \n Recognize the importance of self study, team work, and problem solving.  \n Recognize the professional attitude, regulatory compliance, and reliability.  \n \nThe second course is similar to the first course. It also takes ten weeks with 15 hours in \nclass, 20 hours in lab and 15 hours of self studying at home.  Knowledge  \nGeneral introduction to IT  \nConcept / Basic knowledge of IT  \nOS / Network /Internet/ Virus  \nWord processor / Excel / \nPresentation  \nGeneral introduction to IT career  \nConcept of Analysis / Design / \nImplement  / Operation and Testing  \nIT professional ethics  Skills  \nPersonal skills:   \nteamwork, communication  \nProfessional skills  Attitudes  \nProfessional attitudes  \nRegulatory compliance \nand relia bility \nKnowledge  \nIT Career and IT Programs  \nInformation System Introduction  \nSoftware Engineering Introduction  \nComputer Network and \nTelecommunication Introduction  \nComput ing Science Introduction  \nKnowledge Engineering \nIntroduction  \nComputer Vision & Ro botic \nIntroduction  Skills  \nPersonal skills: \nteamwork, presentation  \nProfessional skills  Attitudes  \nProfessional attitudes  \nRegulatory compliance \nand reliability  - Search information using \ninternet . \n- Scan, detect and kill \nvirus on computer  \n- Use word proces sor, \nexcel, power point  \n- Present and explain one idea \nin front of the audiences  \n- … \nIT Integrated Field Introduction  - Think about problem, \nsystem, and solution  \n- Test and evaluate one \nsoftware  \n- Read and comprehend \nmanual book of one \nsystem  \n- Survey one gi ven \nproblem  \n- … Introduction to \nInformation \nTechnology 1  ( Theory: \n2 credits ; Lab: 3 \ncredits )  \nIntroduction to \nInformation \nTechnology 2  ( Theory: \n2 credits ; Lab: 3 \ncredits )  Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \nFigure 3: The concept of CDIO for  studying and training  in our IIT courses . \n \nBased on the course goal of the 1st and 2nd courses, the outline of two IIT courses is presented \nin Fig. 2. We can see that the content of the second course describes more in details about the \nsystem of research and education in our faculty.  It provides experiences and case study about \nthe influence and importance of advanced courses in the syllabus system to career selection of \nstudents. Through the content of this course, we also give students a general view of IT \napplications and potential fields, where IT can be integrated successfully.  \n \nBeside s providing knowledge, we apply  the project -based approach to embed skills and \nattitudes into the teaching/learning activities of two IIT courses. Here the CDIO concept s can be \nexplained easily to our students by using  a simple project first, and then the requirements  in the \nsecond project  are upgraded to higher level in order to give students a chance of thinking, \nrecognizing, and implementing their knowledge, skills and att itudes. Figure 3 presents the \nconcept of CDIO for studying and training in our two IIT course s. In the first course, one simple \nproject is proposed to introduce the first -year students about D -I-O. Meanwhile, the project in the \nsecond course is designed to  train the first -year students all stages of C -D-I-O.  \n \nPROJECT -BASED APPROACH  \nAs mentioned above, the project -based approach is appli ed in both two IIT courses in our IT \nprogram. When we design the project  system , our expectation is to present  the four st ages of C -\nD-I-O to students as soo n as possible. However, most first -year students cannot understand the \nconcept of conceives  when we give them a set of initial conditions to produce software . The \nlimitation of students to recognize and understand all stag es of C-D-I-O is describes as follows;  \n Limitation of knowledge and time.  \n Limitation of personal skills and professional skills.  \nAs a result, we propose one project , where students will study D -I-O instead of C -D-I-O. In the \ncontent of the first course, we see that there is a relation between the concept s of \nanalysis/design/implement/operation and testing to the concept s of D-I-O. In practice, it t akes  a \nshort time, around  2 classes, for the first -year students to understand D -I-O concepts.  We divide \nthe cla ss into many groups, with 5 members for each . \n \n \n \n \n \nProceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n    \nProject:  House Prototype Building    \n \nA. Build a prototype of house by using paper and bamboo stick such that  :  \na) It can be waterproof . \nb) Shape of house must  be stable when  we put 330 gram on  the roof for di agnostic load \ntest. \nc) Maximum size of house is 20 cm x 20 cm x 20 cm.  \nB. Material : \n3 daily papers, 250 bamboo sticks (0.2 cm x 5cm / stick), 3 glue bottles (50 ml / bottle) .   \nC. Outputs:  \n- House prototype . \n- Report  and documents  of design, solution, work load (time and position) , balance \nsheet, salary & price, and explanation  of testing result.   \n- Slide and presentation . \n \nSome of  first-year students wonder why we give them  the above project .  The question is why IT \nstudent s must study to build a house prototype instead of one software . The answer comes \nfrom the output of the projects, where using IT app lications such as Word processor, Excel, and \nPower point is one of the important requirements and the concepts of D -I-O must be reflected in \nthe report of students. Teamwo rk can be evaluated by the quality of house prototype and sheet \nof workload. We can also check students ’ communication skill through their slide s and \npresentation. Figure 4 presents some examples of house prototype from the above project.                         \n \n \n \nFigure 4: Some examples of house prototype.  \n \nIn the second course, the level of project is upgraded to present the concept  of C-D-I-O. We \ngroup the contents of Information System, Software Engineering, Network and \nTelecommunication  into one pro ject. Meanwhile,  those o f Computing Science, Knowledge \nEngineering, Computer Vision and Robotics are designed  in one other C -D-I-O project.  For \ninstances, a three -month project is to build a small social network where students must study \nand work with web design, web programming , database management, and network \nmanagement to release the first and second demo s. This project  asks student s work in team \nand gives them a large freedom to generate  ideas, make design, find solution, and implement  \nboth software an d hardware.  The lecturer and TA play a role of the end user s or customer s of \ntheir service.  The output of this project is evaluated  by checking  demo softwares , reports, and \npresentation s. One other kind of the project is to build a system  of data analysis for multimedia  \ndata such as video information retrieval or video / audio processing  by using free ware . \nAdditionally , we have also provided some projects related to research of our departments  by \nusing available  toolboxes  or open source s. \n \nProceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n MEETING OF COMPAN IES AND STUDENTS  \nBeside the course, we have organized a meeting between company and the first -year student s. \nThe purpose of the meeting is to give our students a chance to listen the  vision , tendency, and \ndemand  from companies. Through  the meeting, student s, our faculty  staffs,  and company  \nmembers  can share viewpoints  about the development of IT in Vietnam and in the world. After \nthe meeting, we can have some thoughts about  important demand s from IT companies  in \nVietnam  such as :  \n Personal skills , specifical ly team work and communication,  play an important role for the \nsuccess of one’s career path . \n Problem solving  capa bility is the key of admission to company . \n For most companies, r eliability and loyalty are the most precious characteristics.   \n \n \nASSESSMENT  AND FEEDBACKS  \nAssessment  is the main difference between CDIO approach and the conventional teaching \nmethods. We divide 70% of final exam and 30% of project in the first course. Meanwhile, the \nratio of final exam and project in the second course is 60% and 40%,  respectively. The \nassessment  of each  project is checked monthly in three months.  Figure 5 presents some rubrics \nof project and report evaluation . The detail of assessment has been shown to students at the \nbeginning of the course. During the course, studen ts have been reminded about the assessment \nand we have also encouraged them to provide a good strategy  of learning for each group s o that \nall members of the same group can receive a good result.  In practice, the peer review gives \nobjective  evaluation. It h elps students have a strong responsibility and a serious thinking about \ntheir contributions to the final results of their group.  \n \nOrder  Outputs  Evaluation \nmembers  Applicants  Ratio  \n1.  Hardcopy of report  Lecturer  Group  30% \n2.  Demo  software  Lecturer  Group  30% \n3.  Presentation  Lecturer  Group / member  10% \n4.  Member  \nperformance  Inside group \n(peer review)  Member  15% \n5.  Group  performance  Other group \n(peer review)  Group  15% \na) Project evaluation  \n \nOrder  Outputs  0 1 2 3 Ratio  \n1.  Introduction, \nmotivation and \nsurvey  None  \nUncle ar Clear  but not \nenough  Enough and logical  15% \n2.  Description of basic \nconcepts  None  Unclear  Clear but not \nenough  Enough and logical  15% \n3.  Formulation of \nproblem  None  Unclear  Clear but not \nenough  Enough and logical  15% \n4.  Experiment \nexplanation  None  Unclear  Clear but not \nenough  Enough and logical  15% Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n 5.  Description of  demo  \nsoftware  None  Unclear  Clear but not \nenough  Enough and logical  10% \n6.  Creativity  None  Unclear  Clear but not \nbetter  Clear and better  10% \n7.  Presentation  None  Unclear  Clear  Clear and logical  10% \n8.  Documentation  None  Not \nenough  Enough but \nnot logical  Enough and logical  5% \n9.  Reference  None  Not \ncorrect  Correct and \nnot enough  Enough and \ncorrect  5% \nb) Report evaluation  \n \nFigure 5: Some rubrics of project and report evaluation . \n \nAfter assessment, we make s ome QA to receive the feedbacks from students. There are 170  of \n450 students returning feedbacks.  The result of feedback is presented as the following table ; \n \nTable 1:  Feedback of students  \n 1 2 3 4 5 NC \nHomework/Project is evaluated fairly and positively.  65 74 25 4 1 1 \nHomework/Project is evaluated on the fixed schedule \nexactly.  48 72 45 4 0 4 \nSyllabus is well prepared.  44 86 31 6 0 3 \nSyllabus content is presented in a suitable order.  56 83 26 3 0 2 \nSyllabus content is easily understandable.  43 78 43 4 0 2 \nCourse slide and other resources are provided on time  to \nbe useful for teaching and learning.  50 80 34 4 1 1 \na) Theory  \n \n 1 2 3 4 5 NC \nHomework/Project is evaluated fairly and positively.  76 74 17 3 0 0 \nHomework/Project is evaluated on the fixed sch edule \nexactly.  59 71 36 3 0 1 \nLab’s documents are well prepared.  49 79 37 4 0 1 \nLab’s documents are presented in a suitable order.  48 93 25 2 1 1 \nLab’s documents are easily understandable.  38 82 45 4 0 1 \nSlide and other resources of Lab experiments ar e \nprovided on time to be useful for teaching and learning.  52 79 33 4 0 2 \nb) Lab \n \n \nTable 2: Benchmark  \n \nAbsolutely agree  Agree  Neutral  Object  Absolutely object  No comments  \n1 2 3 4 5 NC \n \nTable 1 presents the feedbacks of 170 students and Table 2 gives the benchmark  of score value. \nWe can see that most distribution of feedbacks stays on “Agree” corresponding to the score \nvalue of 2.  It means that the feedbacks of students are positive  toward  CDIO approach.  However , \nthere are still some complain ts about overloa ded and stressful because the first -year students \nhave got a lot of project and homework deadl ines from the first semester of the undergraduate \nprogram in the University.   Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \nDISCUSSIONS  \nAfter one year implementing CDIO  to IT  program, we found some interesti ng points and \ndifficulties  in CDIO implementation . The approach of CDIO  helps us to clarify the quality of the \nsyllabus easily.  By checking the learning outcome and course goal s, we can see an overview to \nour whole program and find whether there is any inconsisten ce or overlap  in the undergraduate \nprogram.  The introduction of IT  course provides  the students motivation, prospective view of \ntheir career , and important  concept s of IT. Besides the advantage s, this course still has some \ndifficult problems in tea ching and learning activities  \n Some s tudents feel stressful because of overloaded project s and homework . Most \ncourses designed in CDIO approach have a requirement of project -based learning. \nConsequently,  the number of projects that a student needs to work o n during one \nsemester  increas e considerably.  As a matter of fact , the requirements  of project become \nmore difficult because it will check both knowledge and skills in the learning  outcomes . It \ntakes students a lot of time  and effort  to catch  up projects ’ deadlines and requirements . \nOne solution of the above  is to design one big project which can be applied for  multiple \ncourses . However, there is always a limitation  about  time and the coverage of learning \noutcomes  in a project.  It is not easy to make  decisi on whether we should select  or not \none learning outcome from a bunch of multiple courses.   \n The number of lecture rs and teaching assistants (T As) are not enough to cover a class of \n450 students.  Originally , CDIO program has been developed from engineering school, \nwhere the number of students in each class is just a few dozen. Now the number of first-\nyear students in our IT faculty is around 450 a year.  As a result, w e need more space \nand more T As to organize Teaching  and Learning  activities  in class.  One s olution is to \ndivide into many small classes with a few dozen students. However, this also brings \nsome difficulties in  scheduling and funding for extra -hour payment.  \n Lecturer s and T As are still familiar with the conventional teaching  approach . It will take  \ntime to change their thinking  and teaching approach . We have already organized some \ntraining programs for lecturers to explain CDIO program  and enhance their professional \nskills.  \n The CDIO approach requires  students, lecturer s, and T As spend more time  in \npreparation . Hence w e need an efficient administration to support and encourage them in  \nlong run . As mentioned above, scheduling and workspace management play a very \nimportant role in our CDIO p rogram. If administration staff  could  be trained well, they will \nhelp us to save much time in learning and teaching activities.  \n We need a sufficient funding  to set up  the workspace , evaluate  the learning outcomes , \nand revise the program every year.  \n CDIO -based  program  is usually  applied for the first -year students and we must wait  until \nfour years later , when all the first -year students graduate,  in order  to receive the \nfeedbacks from the sta keholders to decide  the CDIO program  successful or not . \nAbsolutely, nobody wants to see it  failed after four years. Therefore, we must clarify what \nwe should evaluate and revise periodically (e.g. yearly) in order to  ensure that the CDIO \nprogram is develop ed with high efficiency . Since  we invest  more  time, money, and \nhuman resource  to follow the CDIO program, we really need the posit ive evidence  to \npersu ade our students, faculty staff , the university, and the society for supporting us to \nkeep it going on.  \n \n \n \nCONCLUSIONS  Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n We present  our experience of designing a course of Introduction to Information Technology (IIT) \nfor the first -year s tudents.  We design two courses for IT introduction: One is a general view from \noutsiders  to IT and the other is an introduction of research in IT. We have experiences to teach \nthose two courses for 450 students and receive both positive and negative feedba cks. Most  of \nthe students think  that those two courses are useful to motivate them to IT and give them a near \nvision of their career in the future. Students have been trained personal and professional skills. It \nmakes  them more confident than students of the conventional classes.  Although  most students \nthink  that CDIO -based approach is interestin g, it makes them a bit pressure with  deadlines. \nLecturer s and TAs also find it difficult in handling  a few hundred student  class . Last but not least, \nthe CDIO -base d program needs a sufficient and stable  fund to support it in the long run. In fact,  \nonce  we decide to start CDIO program, we  must k eep it going until the result  of our program \ncomes up  (i.e. feedback from stakeholders once student graduation ).   \n \n \nREFEREN CES \n \n[1]     Crawley, E. F. The CDIO Syllabus: A Statement of Goals for Undergraduate Engineering \nEducation,  MIT CDIO Report #1, 2001.  \n[2] Ramon Bragós, et. al., Conceiving and Designing an “Introduction To Engineering” Course \nwithin the New Curricula at T elecom BCN, UPC Barcelona , Proceedings of the 6th \nInternational CDIO Conference, École Polytechnique, Montréal, June 15 -18, 2010.  \n[3] Yingzi Wang, et.al., CDIO in Practice in Cornerstone Project for Civil Engineering Program , \nProceedings of the 4th Interna tional CDIO Conference, Hogeschool Gent, Gent, Belgium, \nJune 16 -19, 2008  \n[4] Xiaohua Lu, Yinghui Fan, Stephen Banzaert, Joshua Jacobs, Multi -Disciplinary Design -\nBuild PBL As An Introduction to Engineering , Proceedings of the 6th International CDIO \nConferen ce, École Polytechnique, Montréal, June 15 -18, 2010.  \n[5] Goran Gustafsson, et.al., First-Year Introductory Courses as a Means to Develop \nConceive – Design – Implement – Operate Skills in Engineering Education Programmes , \nPresented the SEFI Annual Conferenc e, Firenze, Italy, 08 -11 September 2002.  \n[6] Edward Crawley , Johan Malmqvist , Soren Ostlund , Doris Brodeur , Rethinking Engineering  \nEducation: The CDIO Approach , Springer, 2007.  \n \n \nBIOGRAPHICAL INFORMATION  \n \nSon Thai  Tran is lecturer at the Faculty of Information Technology  (FIT), University of Scie nce, \nHochiminh city, Vietnam. He is the Deputy H ead of Department  of Computer Vision and \nRobotics . He joined the CDIO program as a designer of I ntroduction to Information Technology  \ncourse  in 2012. His research interests are in Statistical Data Analysis, C omputer Vision, and \nDiscrete Optimization.   \n \nLe Ngoc Thanh  is the Deputy Head of Computer Science Department. He is also a member of \nthe CDIO project that implemented in FIT. With this promotion, he is responsible for evaluating \nand applying CDIO standard  into Introduction to Information Technology course. In addition, he \njoins in the construction of other course’s syllabus based on CDIO approach to ensure the \nstudents achieve learning outcomes thoroughly. Tha nh’s research interests are in Data Mining, \nSocial Network, and Graph T heory.  \nNguyen  Quoc Binh is teaching assistant at the Faculty of Information Technology  (FIT), \nUniversity of Science, Hochiminh city, Vietnam. He is at Department  of Knowledge Engineering . Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n He joined the CDIO program as a teaching ass istant of Introduction to Information Technology \ncourse  in 2012 . His research interests are in Cryptography , Privacy, and Statistical Data \nAnalysis.  \n \nDang Binh Phuong is lecturer at the Faculty of Information Technology  (FIT), University of \nScience, Hochim inh city, Vietnam. He is at Department  of Software Engineering . He joined the \nCDIO program as a lecturer of Introduction to Information Technology course in 2012 and 2013. \nHis research interests are in Software Engineering and Mobile Programming.  \n \nLe Hoai Bac is associate professor at the Faculty of Information Technology  (FIT) , University of \nScience, Hochiminh city, Vietnam. He is the Vice Dean of the Facu lty of Information Technology, \nHead of Computer Science  Department . He is monitoring and controlling t he progress of the \nCDIO program at the FIT . He is an active member in adopting CDIO in FIT. Prof. Le Hoai Bac’s \nresearch interests are in Data Mining, Soft C ompu ting and Artificial  Intelligence . \n \nCorresponding Author   \n     \nSon Thai Tran  \nDeputy Head of Depa rtment of Computer Vision & Robotics  \nFaculty of Information Technology  \nUniversity of Science – HCMC Vietnam National University  \n227 Nguyen Van Cu, District 5TH, Hochiminh city, Vietnam  \nEmail: ttson@fit.hcmus.edu.vn  \n \n \nThis work is licensed under a  Creative Commons Attribution -NonCommercial -NoDerivs 3.0 \nUnported License . \n \n', 'raytos.bsinfotech@gmail.com', 'Son Thai Tran, Le Ngoc Thanh, Nguyen Quoc Binh, Dang Binh Phuong, Le Hoai Bac ', '', '../pdf_files/674d4bb6a6aeb-INTRODUCTION TO INFORMATION TECHNOLOGY.pdf', 712615, 11, 5025, 31333, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(56, '5512525319', '51', 5, 5, ' Information Technology and Growth', '2024-12-02 14:02:23.086112', '1999', 'The goal of this paper is to provide new evidence on the substitution of IT for other types of capital and labor inputs in the U.S. economy. For this purpose, we extend the pioneering analysis of Stephen Oliner and Daniel Sichel (1994) and our own earlier work, reported in Jorgenson and Stiroh (1995). We focus on the massive substitu tion toward computers in both business and household sectors as the price of computers fell dramatically in the 1980’s and 1990’s. We show that, in response, profit-maximizingirms and utility-maximizing consumers substituted IT for other goods and services, replacing other types of equipment and economizing on the use of labor effort.', 'IT,Technology,Information Technology', '109\n/ 3y16 my18 Mp 109 Thursday Dec 09 03:50 PM LP±AER my18PRODUCTIVITY GROWTH: CURRENT RECOVERY\nAND LONGER-TERM TRENDS²\nInformation Technology and Growth\nByDALEW. JORGENSON AND KEVINJ. STIROH*\nThe rapid diffusion of information technol-\nogy (IT) is a direct consequence of the swiftdeclineinthepriceofcomputer-relatedequip-ment, which has led to a vast and continuingsubstitution of IT equipment for other formsof capital and labor. This substitution gener-ates substantial returns for the economicagents who undertake IT investments and re-structuretheiractivitiesinordertoincreasetherole of IT. There is little evidence, however,that substitution is accompanied by technicalchange as this term is used by economists.While this appears highly paradoxicaltotech-nologists, who think of substitution of a moreIT-intensive mode of production for a lessIT-intensive mode as a change in technology, itisentirelyconsistentwiththeeconomicframe-work developed by Robert M. Solow (1957).\nWhat do economists mean by ``technical\nchange\'\' and how could this exclude the sub-stitution of a more IT-intensive productionprocess for one that is less IT-intensive? Sub-stitution represents movement along a givenproduction function, while technical changecorresponds to a shift in the production func-tion. Substitution takes place if the intro-duction of computer-intensive equipmentproduces bene®ts that are fully capturedorin-ternalized by the users of IT and their sup-pliers. Technical change occurs only if more\n²Discussants: Jack Triplett, Brookings Institution;\nJohn C. Williams, Federal Reserve Board.\n* Department of Economics, Harvard University,\nCambridgeMA02138,andFederalReserveBankofNewYork, 33 Liberty Street, NewYork,NY10045.Theopin-ions expressed in this paper are those of the authors onlyanddonotnecessarilyre¯ectthoseoftheFederalReserveBank of New York, the Federal Reserve System, or theirstaffs.output is produced from the sameinputs(e.g.,\nifsomeofthebene®tsspillovertothirdpartiesnot involved in the transaction). This funda-mental distinction between substitution andtechnical change goesback atleasttoSolow\'sseminal work and offers a simple solution tothe``Solowproductivityparadox\'\'ofrapidITinvestment and slow productivity growth.(Erik Brynjolfsson and Shinkyu Yang [1996]summarize the empirical literature on theSolow paradox and Jack Triplett [1998] re-views common explanations.)\nWhy do economists persist in using this\ncounterintuitive and even paradoxical termi-nologyindescribingtheimpactofinformationtechnology? The reasons are very transparent,at least to an economist. Substitution does notrequire intervention in markets, since the ap-propriate incentives for investment are pro-vided by the price signals that accompany thebalance between demand and supply for ITequipment. Technical change, by contrast, re-quires intervention, since markets fail to pro-vide adequate incentives to undertake ITinvestments. Some portion of the returns spillover to the fortunate third parties who bene®tfrom the deployment of IT without undertak-ing investments in IT equipmentorrestructur-ing their own economic activities.\nThe goal of this paper is to provide new\nevidence on the substitution of IT for othertypes of capital and labor inputs in the U.S.economy. For thispurposeweextendthepi-oneering analysis of Stephen Oliner andDaniel Sichel (1994) and our own earlierwork, reported in Jorgenson and Stiroh(1995). We focus on the massive substitu-tion toward computers in both business andhousehold sectors as the price of computersfell dramatically in the 1980\'s and 1990\'s. Weshow that, in response, pro®t-maximizing110 AEA PAPERS AND PROCEEDINGS MAY 1999\n/ 3y16 my18 Mp 110 Thursday Dec 09 03:50 PM LP±AER my18®rms and utility-maximizing consumers sub-\nstituted IT for other goods and services,replacing other types of equipment and econ-omizing on the use of labor effort.\nFrom 1990 to 1996 the acquisition price of\nIT equipment for investment fell 16.6 percentannually,whilethepriceofcomputersforcon-sumption fell even faster, at 24.2 percent peryear. This rapid price decline cuts two waysin determiningthecostofdeployingITequip-ment. First, a fall in prices reduces the acqui-sition cost of IT equipment; second, the rateof decline itself adds to the cost of using thisequipment. At ®rst blush this appears to beanother paradox. How can a rapid decline inthe price of a computer make it cheaper to ac-quire a computer, but more expensive to useit? The resolution of this apparent paradox isthat the cost of using a computer is differentfromthecostofacquiringit.Thecostofusingacomputeristheannualizedcostoverthelife-time of the equipment, while the acquisitioncost is the present value of these annualizedcosts. The annualized cost includes the for-gone opportunity of waiting for an evencheaper computer.\nThe large decline in the annualized cost or\nrental price of computers has induced both®rms and households to alter their spendingpatterns and accumulate increasingly less ex-pensive computers. During the 1990\'s, com-puter services to ®rms and households grewby 20 percent per year, exceeding the growthofotherinputsbyafactoroften!Theseresultsprovide persuasive evidence that ®rms andhouseholds respond to relative price changesby substituting IT equipment for other goodsand services.\nThe question that remains is whether the\nmassivesubstitutionofITequipmentforotherinputs has been accompanied by technicalchange in the economic sense. For this pur-pose, it is necessary to use the tool devisedbySolow (1957), namely, the residual in eco-nomic growth, to quantify spillovers. Solowshowedthatthesespilloversappearasresidualeconomic growth after the growth of all otherinputs, including inputs of IT equipment, aretaken into account. The Solow paradox arisesfromthefactthatthisresidualhasslowedcon-siderably since 1973, precisely when IT in-vestment has risen to new heights. This hasgenerated a kind of Computer Cargo Cult\namong economists and economic historians,patiently awaiting a deluge of spillovers likethose that supposedly accompanied earliertechnological revolutions.\nTo address this issue, we summarize recent\nevidence on technical change, using this termin its precise, if counterintuitive, economicmeaning. Technical change also goes by thenameofthegrowthoftotalfactorproductivity(TFP)oroutputperunitoffactorinput.Thereis little evidence for a revival of TFP growthin the 1990\'s. After accounting for both thequantity and the quality of capital and laborinputs, aggregate TFP growth was only 0.23percent per year for 1990±1996. This isslightlylessthantheannualaveragefor1973±\n1990of0.34percent.A¯oodofspilloversac-\ncompanying the massive deployment of ITequipment would be accompanied by an in-crease in TFP growth, not a decline.\nWe conclude that the story of the computer\nrevolution is one of relatively swift price de-clines, huge investment in IT equipment, andrapid substitution of this equipment for otherinputs.Perhapssurprisingly,thistechnologicalrevolution has not been accompanied by tech-nical change in the economic sense of theterm, since the returns have been captured bycomputer producers and their customers.\nI. Measuring the Sources of Growth\nOur analysis of the sources of economic\ngrowth employs the Laurits Christensen andJorgenson (1973) framework to distinguishbetween output of investment and consump-tion goods and inputs of capital and labor ser-vices. The novel contribution of our paper isto quantify the importance of IT equipmentasboth an input into production by ®rms and asa form of consumption by households. Thisenables us to quantify the substitution of theservices of IT equipment for other inputs andto measure the growth of TFP over the period1948±1996, beginning before the commer-cialization of computers and continuingthrough the present.\nThe aggregate production function de-\nscribes how inputs of capital services K, con-\nsumers\'durableservices D,laborinput L,and111 VOL. 89 NO. 2 PRODUCTIVITY GROWTH\n/ 3y16 my18 Mp 111 Thursday Dec 09 03:50 PM LP±AER my18technology T, are used to create outputs of\ninvestment goods I, consumption goods and\nservicesC, and a ¯ow of services from con-\nsumers\' durable goods S:\ng(I,C,S)f(K,D,L,T). (1)\nIn this framework, consumers\' durables are\ntreated symmetrically with investment goods,since the accumulated stock of investmentgoods provides a ¯ow of capital services intoproduction, while the accumulated stock ofconsumers\'durablesprovidesa¯owofcapitalservices into consumption. These servicesappear as both an input into the aggregateproduction function Dand an output of pro-\nductionS.\nTo isolate the impact of computers we de-\ncompose equation (1) as\ng(I,I,C,C,S,S) (2)\ncn c n c n\nf(K,K,D,D,L,T) cncn\nwhere a ``c\'\' subscript refers to the computer\nportion and a ``n\'\' subscript refers to the non-computer portion. Equation (2) can be rewrit-ten in terms of weighted averages of growthrates of inputs and outputs to obtain agrowth-accountingequation.Ouranalysisislimitedtothe private, domestic economy, and we do notexplicitlyexaminetheroleofcomputersinthegovernment or rest-of-the-world sectors.\nA.Capital Services\nWe employ the model of capital as a factor\nof production as summarized in Jorgenson(1996). Capital services are proportional tothe stocks of assets, including computers, butaggregation requires weighting the stocks byrental prices rather than acquisition prices forassets. The rental price for each asset incor-poratestherateofreturn,thedepreciationrate,and the rateof declineintheacquisitionprice.The rental prices employed in our analysis ofeconomic growth also depend on features ofthe tax structure for capital income that enterinto the annualized cost of deploying capital.The rental price equals the marginal productof capital for a pro®t-maximizing ®rm,sothat®rms substitute among inputs in response tochanges in rental prices. Given the large de-\ncline in the rental price of computers, thesub-stitutionofITequipmentforotherinputsisanimmediate implication of the model of capitalas a factor of production.\nThe Bureau of Economic Analysis (BEA,\n1998)providesdetailedinvestmentdatafor35typesofproducers\'durablegoods,22typesofnonresidential structures, and 48 types of res-idential assets. The investment data include abreakdown of computer equipment into main-frame computers, personal computers, direct-access storage devices, printers, terminals,tape drives, and storage devices beginning in1958, when computers ®rst appear as separateentity in the NationalIncomeandProductAc-counts.Wecombinethesesixcomponentsintoa single ``computer\'\' series, which serves asour data on the output of computers as invest-ment goods. A central feature of BEA\'s esti-mates is that price indexes for computers andperipheral equipment hold the quality of thisequipment constant (see Nadia Sadee [1996]for details).\nForeachasset,includingcomputers,wecal-\nculate capitalstockbytheperpetual-inventorymethod,usingdepreciationratesfromBarbaraFraumeni (1997). This is a departure fromour previous paper, where we utilized thecohort-andasset-speci®cretirementpatternsdeveloped by Oliner (1993) which weresubsequently incorporated into the of®cialcapital stock estimates by BEA. We found lit-tle difference between a detailed approachbased on Oliner (1993) and a simpli®ed ap-proach that uses a geometric approximationlike that employed for other assets by BEA.We therefore selected a geometric deprecia-tionrateof31.5percent,whichisthebestgeo-metric approximation to the Oliner-basedretirement pro®les reported in BEA (1998).Weuseasimilarapproachinestimatingrentalprices for all assets that comprise our aggre-gate of capital services K.\nB.Services of Consumers\' Durables\nConsumers purchase nondurable con-\nsumption goods and services for consump-tion but acquire consumers\' durables inordertoprovidea¯owofservices.Thetreat-ment of consumers\'durablesbyChristensen112 AEA PAPERS AND PROCEEDINGS MAY 1999\n/ 3y16 my18 Mp 112 Thursday Dec 09 03:51 PM LP±AER my18TABLE1ÐANNUALGROWTHRATES, 1990±1996\nCategory Prices Quantities\nOutputs:\nTotal output 2.33 2.36\nNoncomputers 2.60 2.01Computers\n018.69 30.37\nInvestment goods ( Ic)016.55 28.32\nConsumption goods ( Cc)024.23 37.32\nConsumers\' durables\nservices ( Sc) 023.41 31.92\nInputs:\nCapital services ( K) 3.24 1.82\nNoncomputers ( Kn) 3.59 1.50\nComputers ( Kc) 014.94 18.71\nConsumers\' durables\nservices ( D) 1.95 2.87\nNoncomputers ( Dn) 2.28 2.49\nComputers ( Dc) 023.41 31.92\nLabor input ( L) 2.25 2.19\nNote:All values are average annual percentages.and Jorgenson (1973) is exactly parallel to\nthat of capital goods. We impute the valueoftheservicesofconsumers\'durablesonthebasisoftherental-priceconceptemployedinour estimates of the services of investmentgoods. Consumers maximize utility by sub-stituting among consumption goods and ser-vices in response to price changes. Thedecline in rental prices of IT equipment hasresulted in a massive substitution of the ser-vices of this equipment for other goods andservices by households.\nBEA (1998) provides data on purchases of\n13 types of consumer durable goods through1996, including ``computing equipment,\'\'which made its ®rst appearance in 1979. Thisseries serves as the measure of computer pur-chases in our consumption accounts. As be-fore, we estimate stocks of IT equipment inthe household sector using the perpetual-inventory method and depreciation ratesfrom Fraumeni (1997). We employ BEA\'sconstant-quality price index for computingequipment.The¯owsofconsumptionservicesfrom consumers\' durable goods, including ITequipment,areaggregatedtoformanindexofconsumption services, DandS, using our es-\ntimates of rental prices for all types ofdurables.\nII. Substitution Toward Computers\nProduction costs are minimized when mar-\nginal rates of substitution between inputs inproductionareequaltoinputpriceratios.Sim-ilarly, utility is maximized when marginalrates of substitution in consumption equalprice ratios of consumer goods and services.Under standard assumptions of diminishingmarginal products and decreasing marginalutility, a fall in the price of an input or a con-sumptiongoodwillleadtosubstitutiontowardthe relatively cheap input or consumptiongood. In adapting this framework to deal withIT equipment it is important to emphasize thefact that the appropriate prices for computerservices arerentalprices,whichre¯ectthean-nualized cost of using the equipment.\nAsaconsequenceofthepioneeringworkof\nBEA, it is well known that the acquisitionprice of computers, holding quality constant,hasfallenrapidly.InTable1weshowthattheprice ofcomputer investmentfell16.6percent\nper year from 1990 to 1996, and the price ofIT equipment to households fell 24.2 percentannually. These dramatic decreases in the ac-quisition prices resulted in corresponding de-clines in the rental prices of the services ofcomputer capital deployed by ®rms(14.9per-cent per year) and in the rental prices of com-puter services to households (23.4 percentperyear) during the 1990\'s. By contrast the priceof labor input increased 2.3 percent per year,whilethepriceoftheservicesofnoncomputercapital to ®rms rose by 3.6 percent annually,andthepriceofnoncomputerconsumers\'dur-ablesservicestohouseholdsroseattheannualrate of 2.3 percent.\nIn response to the rapid changes in relative\nprices, ®rms and households substituted theservices of IT equipment for other goods andservices. This required substantial investmentin computers, as well as restructuring of bothproduction and consumption activities to ab-sorb the new equipment. Investment in com-puters rose by 28.3 percent per year, whilehousehold purchases of computers increasedeven faster, at 37.3 percent per year. By1996,U.S. businesses spent over $160 billion (in1992dollars)onnewcomputers,andconsum-ersspentanadditional$52.7billion!Therapid113 VOL. 89 NO. 2 PRODUCTIVITY GROWTH\n/ 3y16 my18 Mp 113 Thursday Dec 09 03:51 PM LP±AER my18TABLE2ÐSOURCES OF U.S. ECONOMIC GROWTH,\n1948±1996\nSourceGrowth rate\n1948±1973 1973±1990 1990±1996\nOutputs:\nTotal output 4.020 2.857 2.363\nNoncomputer outputs 3.978 2.650 1.980\nComputer outputs 0.042 0.207 0.384\nInvestment\ngoods (Ic) 0.042 0.171 0.258\nConsumption\ngoods (Cc) 0.000 0.024 0.086\nConsumers\'\ndurablesservices ( S\nc) 0.000 0.012 0.040\nInputs:\nCapital services ( K) 1.073 0.954 0.632\nNoncomputers ( Kn) 1.049 0.845 0.510\nComputers ( Kc) 0.025 0.109 0.123\nConsumers\' durables\nservices ( D) 0.550 0.426 0.282\nNoncomputers ( Dn) 0.550 0.414 0.242\nComputers ( Dc) 0.000 0.012 0.040\nLabor input ( L) 1.006 1.145 1.219\nAggregate total factor\nproductivity 1.391 0.335 0.231\nNotes:Contribution of inputs and outputs are real growth rates\nweightedbyaverage,nominalshares.Allvaluesareaverageannualpercentages.accumulation of IT equipment resulted in in-\ncreases in ¯ows of computer services of 18.7percent and 31.9 percent per year in the busi-ness and household sectors, respectively.\nThe data we have presented in Table 1 pro-\nvide persuasive evidence of massive substitu-tion toward computers in both business andhousehold sectors. While computer serviceswere expanding dramatically from 1990 to1996, the output of the U.S. economy grewat only 2.4 percent per year, and labor in-put increased 2.2 percent, bringing labor-productivity growth almost to a standstill.Meanwhile,thegrowthincomputerinputsex-ceeded the growth in other inputs by a factorof ten! Note that we have substantiallyunder-stated the impact of IT equipment, since wehavefocusedspeci®callyoncomputersanddonot include closely related high-technologyproducts. For example, much telecommuni-cations gear is indistinguishable from ITequipment. Also, computers and semiconduc-tors are now routinely embedded in automo-biles and machinery, but we exclude theseintermediate inputs from the aggregate pro-duction function.\nStiroh (1998) has extended the sectoral\nmodelofproductionofJorgensonetal.(1987)toencompasscomputers.Atthesectorallevel,gross output rather than value added is theap-propriate measure of output, and intermediategoods are treated symmetrically with primaryinputs.Itiscrucialtopriceintermediateinputscorrectly in order to measure sectoral produc-tivity growth. Triplett (1996) shows that thisis a critical issue in measuring the growth ofproductivity in the computerandsemiconduc-tor sectors. (See Stiroh [1998] for sectorales-timates of productivity and Robert McGuckinand Stiroh [1998] for further discussion.)\nIII. The Sources of U.S. Growth\nIn equation (2) we have combined data on\ninvestment goods, consumptiongoods,capitalservices, services of consumers\'durables,andlabor services in order to analyze the sourcesof economic growth. Growth in output is ashare-weightedaverageofgrowthratesofvar-ious types of output or, equivalently, the sumofashare-weightedaverageofgrowthratesofinputs and the TFP residual. Table 2 reportsestimatesofthesourcesofgrowthfortheU.S.\nprivate domestic economy for 1948±1996,broken into three subperiods: 1948±1973,1973±1990, and 1990±1996. For the entireperiod (1948±1996), output grew 3.4 percentperyear.Capitalandconsumers\'durablesser-vices were the most important source ofgrowth, accounting for 43 percent of thetotal,while labor accounted for 32 percent, and theTFP residual accounted for the remaining 25percent.ThegrowthofoutputandTFPslowedsharplyafter1973,andtherehasbeenanother,smaller, decline since 1990.\nThe growth rate of output for 1990±1996\nwas 2.4 percent per year, almost half a per-centage point less than the average for1973±1990 of 2.9 percent annually. Bycontrast, the growth rate for 1948±1973 of4.0 percent per year was a percentage pointgreater. This contrast between growth ratesbefore and after 1973 has generated a volu-minous literature. The literature on thecomputerrevolution,postulatinganincrease114 AEA PAPERS AND PROCEEDINGS MAY 1999\n/ 3y16 my18 Mp 114 Thursday Dec 09 03:51 PM LP±AER my18in growth rates of output and TFP that is yet\ntobeobserved,isstillexpandingrapidlyandhas not been measurably slowed by the in-consistency between the basic thesisandthefacts we have presented in Table 2.\nAlthough the TFP residual decelerated\nslightly in the 1990\'s, the picture for TFPgrowth is subtly different from the growth ofoutput. Most of the slowdown in outputgrowth after 1973 can be attributed to a col-lapse in TFP growth, but the smaller declineof half a percent per year in output growthafter 1990 is primarily due to a decline in thegrowth of capital inputs. The contribution oflabor-input growth actually increased, whilethe contributions of capital services growth inthe business and household sectors fell, evenwith rapidly rising contributions from ITequipment services. After accounting for thequality and quantity of labor and capital in-puts, only 10 percent of aggregate growth re-mains unexplained by substitution amonginputs and must be attributed to the residual.(These TFP estimates are consistent with theestimates of the Bureau of Labor Statistics[1998], which reports that TFP growth fellfrom 2.1 percent per year for 1948±1973 to0.3percentfor1973±1990,and0.3percentfor1990±1996.)\nWe can break out the contribution of the\nthree types of computer outputs (investment,consumption purchases, and consumers\' du-rable services) and combine all other outputsintoasingleindexof``noncomputeroutputs.\'\'The data show that computers are most im-portant as an investment good, contributing0.26 percentage points to growth for 1990±\n1996. Purchases of computing equipment by\nhouseholds and the service ¯ow from thisequipment contributed an additional 0.13 per-centage points to growth, about half as much.Although computers contributed virtuallynothing to growth prior to 1973, nearly one-sixth of the 2.4-percent output growth for1990±1996 can be attributed to computeroutputs.\nAlternatively, we can express output\ngrowthasthesumofthecontributionsofthegrowth of capital services, consumers\' du-rable services, labor inputs, and the TFP re-sidual. The contributions of capital andconsumers\' durables can be decomposedinto computer and noncomputer com-\nponents. In the 1990\'s computers wereresponsible for nearly 20 percent ofthecon-tribution of capital inputs to growth and 14percent of the contribution of consumers\'durables services. Taken together, computerinputs contributed 0.16 percentage points tooutput growth of 2.4 percent per year for1990±1996. These sources of growth are adirect consequence of substitution towardrelatively cheap computers.\nThe resolution of the Solow paradox is\nthat computer-related gains, large returns tothe production and use of computers, andnetwork effects are fundamentally changingthe U.S. economy. However, they are notushering in a period of faster growth of out-put and total factor productivity. Rather, re-turns to investment in IT equipment havebeen successfully internalized by computerproducers and computer users. These eco-nomic agents are reaping extraordinary re-wards for mobilizing investment resourcesand restructuring economic activities. Therewards are large because of the swift paceof technical change in the production ofcomputers and the rapid deployment of ITequipment through substitution, not becauseof spillovers to third parties standing on thesidelines of the computer revolution.\nREFERENCES\nBrynjolfsson, Erik and Yang, Shinkyu. ``Infor-\nmationTechnologyandProductivity:ARe-view of the Literature.\'\' Advances in\nComputers , February 1996, 43, pp. 179±\n214.\nBureau of Economic Analysis. Fixed reproduc-\nible tangible wealth of the United States,1925±96 , NCN-0136. Washington, DC:\nU.S. Government Printing Of®ce, May1998.\nBureau of Labor Statistics. Multifactor produc-\ntivitytrends,1995and1996, USDL-98-187.\nWashington,DC:U.S.GovernmentPrintingOf®ce, May 1998.\nChristensen, Laurits R. and Jorgenson, Dale W.\n``Measuring Economic Performance in thePrivate Sector,\'\' in Milton Moss, ed., The\nmeasurement of economic and social per-115 VOL. 89 NO. 2 PRODUCTIVITY GROWTH\n/ 3y16 my18 Mp 115 Thursday Dec 09 03:51 PM LP±AER my18formance . New York: ColumbiaUniversity\nPress, 1973, pp. 233±38.\nFraumeni, Barbara. ``The Measurement of De-\npreciation in the U.S. National Income andProduct Accounts.\'\' Survey of Current\nBusiness, July 1997, 77(7),pp.7±23.\nJorgenson, Dale W. ``Empirical Studies of De-\npreciation.\'\' Economic Inquiry , January\n1996,34(1),pp.24±42.\nJorgenson, Dale W.; Gollop, Frank M. and\nFraumeni, Barbara M. Productivity and U.S.\neconomic growth . Cambridge, MA: Har-\nvard University Press, 1987.\nJorgenson, Dale W. and Stiroh, Kevin J. ``Com-\nputers and Growth.\'\' Economics of Inno-\nvationandNewTechnology ,1995,3(3±4),\npp. 295±316.\nMcGuckin, Robert H. and Stiroh, Kevin J.\n``Computers, Productivity, and Growth.\'\'Economic Research Report No. 1213-98-RR, The Conference Board, New York,1998.\nOliner, Stephen D. ``Constant-Quality Price\nChange, Depreciation, and the Retirementof Mainframe Computers,\'\' in Murray F.Foss, Marilyn E. Manser, and Allan H.Young, eds., Price measurements and theiruses.Chicago:UniversityofChicagoPress,\n1993, pp. 19±61.\nOliner,StephenD.andSichel,DanielE. ``Com-\nputersandOutputGrowthRevisited:HowBig Is the Puzzle?\'\' Brookings Papers on\nEconomic Activity , 1994,(2), pp. 273±\n334.\nSadee,Nadia. ``ComputerPricesintheNational\nAccounts:AnUpdatefromtheComprehen-sive Revision.\'\' Mimeo, National Incomeand Wealth Division, Bureau of EconomicAnalysis, June 1996.\nSolow, Robert M. ``Technical Change and the\nAggregateProductionFunction.\'\' Reviewof\nEconomics and Statistics , August 1957,\n39(3),pp.312±20.\nStiroh, Kevin J. ``Computers, Productivity,and\nInput Substitution.\'\' Economic Inquiry ,\nApril 1998, 36(2),pp.175±91.\nTriplett, Jack E. ``High-Tech Industry Produc-\ntivityandHedonicPriceIndices,\'\'inOECDProceedings, Industry productivity. Paris:\nOrganization for Economic Cooperationand Development, 1996, pp. 119±42.\n.``The Solow Productivity Paradox:\nWhat Do Computers Do to Productivity?\'\'Mimeo, Brookings Institution, May 1998.', 'raytos.bsinfotech@gmail.com', 'DALE W. JORGENSON AND KEVIN J. STIROH', '', '../pdf_files/674d4d6ef2f01-Information Technology and Growth.pdf', 62382, 7, 3206, 25855, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(57, '7130462724', '51', 5, 5, 'Innovating Mindfully with Information Technology', '2024-12-02 14:07:48.905460', '2004', 'Although organizational innovation with information technology is often carefully considered, band wagon phenomena indicate that much innovative behavior may nevertheless be of the \"me too\" variety. In this essay, we explore such differences in innovative behavior. Adopting a perspective that is both institutional and cognitive, we introduce the notion of mindful innovation with IT. A mindful firm attends to an IT innovation with reasoning grounded in its own organizational facts and specifics. We contrast this with mindless innovation, where a firm\'s actions betray an absence of such attention and grounding. We develop these concepts by drawing on the recent appearance of the idea of mindfulness in the organizational literature, and adapting it for application to IT innovation. We then bring mindfulness and mindlessness together in a larger theoretical synthesis in which these apparent opposites are seen to interact in ways that help to shape the overall opportunity for organizational landscape of innovation with IT. We conclude by suggesting several promising new research directions.', 'Information Technology,Innovation,Organizing vision,Mindfulness,Bandwagon Phenomena', ' Management Information Systems Research Center, University of Minnesota is collaborating with JSTOR to digitize, \n preserve and extend access to MIS Quarterly.\nhttp://www.jstor.org\nInnovating Mindfully with Information Technology \nAuthor(s): E. Burton Swanson and Neil C. Ramiller \nSource:   MIS Quarterly, Vol. 28, No. 4 (Dec., 2004), pp. 553-583\nPublished by:  Management Information Systems Research Center, University of Minnesota\nStable URL:  http://www.jstor.org/stable/25148655\nAccessed: 06-05-2015 13:10 UTC\nYour use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at http://www.jstor.org/page/\n info/about/policies/terms.jsp\nJSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content \nin a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. \nFor more information about JSTOR, please contact support@jstor.org.\nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \n^L tflC^%Ji % ^%_r*\" E.^T Research Article \nInnovating Mindfully with \nInformation Technology1 \nBy: E. Burton Swanson \nThe Anderson School \nUniversity of California, Los Angeles \n110 Westwood Plaza \nLos Angeles, CA 90095 \nU.S.A. \nburt.swanson@anderson.ucla.edu \nNeil C. Ramiller \nSchool of Business Administration \nPortland State University \nP. O. Box 751 \nPortland, OR 97207-0751 \nU.S.A. \nneilr@sba.pdx.edu \nAbstract \nAlthough organizational innovation with information \ntechnology is often carefully considered, band \nwagon phenomena indicate that much innovative \nbehavior may nevertheless be of the \"me too\" \nvariety. In this essay, we explore such differences \nin innovative behavior. Adopting a perspective \nthat is both institutional and cognitive, we introduce \nthe notion of mindful innovation with IT. A mindful \nfirm attends to an IT innovation with reasoning \n1Jane Webster was the accepting senior editor for this \npaper. grounded in its own organizational facts and spe \ncifics. We contrast this with mindless innovation, \nwhere a firm\'s actions betray an absence of such \nattention and grounding. We develop these con \ncepts by drawing on the recent appearance of the \nidea of mindfulness in the organizational literature, \nand adapting it for application to IT innovation. We \nthen bring mindfulness and mindlessness together \nin a larger theoretical synthesis in which these \napparent opposites are seen to interact in ways \nthat help to shape the overall landscape of \nopportunity for organizational innovation with IT. \nWe conclude by suggesting several promising new \nresearch directions. \nKeywords: Information technology innovation, \norganizing vision, organizational mindfulness, \nbandwagon phenomena, organizational \nmindlessness \nIntroduction \nWhether, when, and how to innovate with infor \nmation technology?this complex and crucial \nquestion confronts managers in virtually all of \ntoday\'s enterprises. Yet, it is by no means clear \nthat managers always engage the question in a \ndeliberative way. Reminiscing about his experi \nence as a Gartner Group analyst for enterprise \nresource planning (ERP) systems in the 1990s, \nMIS Quarterly Vol. 28 No. 4 pp. 553-583/December 2004 553 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nErik Keller recalls the explosive growth in this \nmarket: \nBy the mid-1990s, ERP was a topic that \nwas being bandied about in boardrooms. \nIt wasn\'t just an information technology \n(IT) project, but a strategic business \nimperative....The ERP genie was out of \nthe bottle?every company needed to \nhave an ERP implementation....When I \nasked (one client) why he was embarking \non an ERP program, he looked at me in \na puzzled way and said, \"No one ever \nasked me that before.\" After 45 minutes \nof further discussion, he could still not \ncome up with a reason. (Keller 1999, pp. \n45-46) \nSuch stories are familiar in information technology \npractice. Bandwagon phenomena (Abrahamson \n1991; Abrahamson and Fairchild 1999 Abraham \nson and Rosenkopf 1997) suggest that more than \na little innovative behavior may be of the \"me too\" \nvariety, where adopting organizations entertain \nscant reasoning for their moves. Especially where \nthe innovation achieves a high public profile, as \nwith ERP, deliberative behavior can be swamped \nby an acute urgency to join the stampeding herd, \nnotwithstanding the high costs and apparent risk \ninvolved. How should we account for such \nseemingly \"mindless\" behavior (Fiol and O\'Connor \n2003)? What are its antecedents and effects? \nWhat implications might it have for the develop \nment and prospects of the IT innovations them \nselves? Indeed, what implications might it hold for \nthe shaping of our own academic community\'s \nresearch agenda (Swanson 2000)? \nOn the other hand, perhaps we should regard such \nmindlessness as unsurprising. Consider IT inno \nvation as a practical matter. It can be a daunting \nchallenge to make sense of a major IT innovation \nin a way that fully considers its potential fit to the \nparticular circumstances of a real organization. \nSome of the challenge may reside in the inno \nvation itself; after all, given their frequently novel \ntechnological foundations, IT innovations are often \nsubject to \"several possible or plausible inter \npretations and therefore can be esoteric, subject to misunderstandings, uncertain, complex, and \nrecondite\" (Weick 1990, p. 2). But organizational \ndifficulties also intrude, and the firm trying to make \nsense of an IT innovation may confront ambig \nuous, portentous, and disruptive issues of organi \nzational transformation and strategic repositioning. \nIn this light, to witness an organization jumping on \nthe bandwagon in the pursuit of some widely \ntouted \"best practice\" should perhaps be regarded \nas commonplace. Indeed, it may be more \nremarkable to observe an organization being fully \n\"mindful\" in its engagement with an IT innovation. \nIn fact, where IT innovation is concerned, we \nbelieve it is apposite to wonder at both mindful and \nmindless organizational behavior. We do so in this \nessay. Our overall aim is to explore both mind \nfulness and mindlessness and, in so doing, break \nnew ground for research in the domain of IT \ninnovation. (For recent reviews, see Fichman \n2000; Gallivan 2001; Swanson 1994.) In parti \ncular, we undertake to theorize more richly than \nhas heretofore been done about the constitution of \norganizational rationality and sensemaking, where \nIT innovation is concerned. To accomplish this, \nour approach takes an institutional view that is, in \nitself, relatively novel to IT research (Orlikowski \nand Barley 2001). The concept of mindfulness \nalso enables us to offer a fresh perspective on IT \ninnovation adoption, a phenomenon that in the \npast has often implicitly been framed as a good \nthing to do and the earlier the better. (For a \nbroader discussion of pro-innovation bias in \ninnovation research, see Chapter 3 in Rogers \n1995.) Finally, we strive to connect IT innovation \nto larger issues of organizational capabilities and \ncompetence that are central to research in organi \nzation and strategy (Cohen and Levinthal 1990; \nDosi et al. 2001; Hamel and Prahalad 1990; Kogut \nand Zander 1992; Nelson and Winter 1982; Teece \n1998; Teece etal. 1997). \nWe proceed as follows. We first review the \nmindfulness concept as it has been developed by \nKarl Weick and his colleagues. To set the stage \nfor extending mindfulness into the arena of IT \ninnovation, we next introduce an institutional view \nthat embraces both the IT innovation and the firm\'s \ninnovation-engagement process. We then adapt \n554 MIS Quarterly Vol. 28 No. 4/December 2004 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nmindfulness to the IT-innovation context, after \nwhich we draw instructive contrasts to the condi \ntions and effects of mindlessness. We then outline \na preliminary theoretical synthesis, bringing mind \nfulness and mindlessness together as dynamically \ninterdependent complements, and we offer a \nrelated set of propositions to help frame future \nwork around this pair of concepts. We close with \na wider discussion of the possibilities for research \nin this domain. \nConceptual Foundations \nMindfulness in Organizations \nMindfulness, at its roots, is a psychological notion \nthat reflects upon the cognitive qualities of the \nindividual (Langer 1989b; Langer and Moldoveanu \n2000). The key qualities of a mindful state of \nbeing are said to involve: \n(a) openness to novelty; (b) alertness to \ndistinction; (c) sensitivity to different \ncontexts; (d) implicit, if not explicit, \nawareness of multiple perspectives; and \n(e) orientation in the present (Sternberg \n2000, p. 12; see also Langer 1989a, p. \n62). \nRecently, the idea of mindfulness has been \nextended from individuals to organizations, and \nmore specifically to high reliability organizations \n(HROs) ( Weick and Sutcliffe 2001; Weick et al. \n1999). HROs, such as naval aircraft carriers, \nnuclear power-generation stations, and air traffic \ncontrol units, \"operate in an unforgiving social and \npolitical environment, an environment rich with the \npotential for error, where the scale of conse \nquences precludes learning through experimen \ntation, and where to avoid failures in the face of \nshifting sources of vulnerability, complex pro \ncesses are used to manage complex technology\" \n(Weick et al. 1999, p. 83). Organizational mind \nfulness is necessary if an HRO is to avoid situa \ntions in which minor errors compound one another \nto precipitate catastrophic failure. High reliability, \nfor these firms, means achieving a high resistance \nto intolerable failure. For Weick and his colleagues, mindfulness is an \norganizational property grounded in, although not \nreducible to, the minds of participating individuals \nthrough a process of heedful interrelating (Weick \nand Roberts 1993). Heedful interrelating arises as \nindividuals interpret and act upon a model of the \norganizational situation in such a way that they \nproduce (and reproduce) that model in objective \nfact, fashioning their individual actions in \naccordance with the presuppositions that consti \ntute their complementary (if not entirely shared) \nmental representations of the situation. \nAlthough they take HROs as their point of \ndeparture, Weick and his colleagues argue for \nextending the mindfulness concept to other kinds \nof organizations: \nlonger term environmental conditions \nsuch as increased competition, higher \ncustomer expectations, and reduced \ncycle time create unforgiving conditions \nwith high performance standards and \nlittle tolerance for errors. These condi \ntions are likely to continue, as environ \nments become more competitive, uncer \ntain, turbulent, and complex (Weick et al \n1999, p. 104). \nIn general, then, for any organization seeking \nreliability or, to speak more broadly, viability, \nmindfulness concerns the adaptive management \nof expectations in the context of the unexpected. \nIt entails \nthe ongoing scrutiny of existing expecta \ntions, continuous refinement and differen \ntiation of expectations based on newer \nexperiences, willingness and capability to \ninvent new expectations that make sense \nof unprecedented events, a more \nnuanced appreciation of context and \nways to deal with it, and identification of \nnew dimensions of context that improve \nforesight and current functioning (Weick \nand Sutcliffe 2001, p. 42). \nAs a concerted venture into the unexpected, \ninnovation, we believe, constitutes a critical area \nfor organizational mindfulness. Innovative initia \nMIS Quarterly Vol. 28 No. 4/December 2004 555 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \ntives are frequently a core part of a substantively \nmindful response to emerging opportunities and \nchanging conditions (Van de Ven 1993). At the \nsame time, efforts at innovation may themselves \nbe more or less mindful. Accordingly, mindfulness \nplays a dual role in innovation, enhancing the \nrecognition of organizational circumstances \ndemanding an innovative response, while also \nfostering effectiveness in executing the response \nitself. Mindfulness, however, is not simplistically \npromotive of innovation. It may entail wariness in \nsome circumstances, and where needed it may \nfoster a resistance to jumping on innovation \nbandwagons (Fiol and O\'Connor 2003, p. 66). \nAccordingly, innovating mindfully may actually \nmean that the firm forestalls or foreswears a new \ninitiative, as facts and conditions relevant to the \nlocal organizational context dictate. \nWhat is true for mindfulness in organizational \ninnovation overall also holds more specifically for \nIT innovation. Mindfulness as the nuanced appre \nciation of context and ways to deal with it lies at \nthe heart, we believe, of what it means to manage \nthe unexpected in innovating with IT. But taken by \nitself, this rather general observation begs the \nquestion of what the context really comprises \nwhere IT innovation is concerned. Attempting to \nanswer that question sets one down the path \ntoward a conceptualization of mindfulness that is \nspecific to IT and its management. We begin that \nundertaking, next, with an examination of the \ninstitutional and processual nature of the IT \ninnovation phenomenon. \nThe IT Innovation Phenomenon \nWe will start by defining IT innovation, in process \nterms, as the pursuit of IT applications new to an \norganization. Our view is therefore oriented \naround how IT comes to be applied in novel ways. \n(Swanson [1994] provides a typology.) The \npotential for new applications is commonly created \nby the emergence of enabling technologies that \nare new in their own right. Nevertheless, there \nmay be significant lags between the first availability of a new IT and the eventual onset of important \nuses for it. Our view of innovation is also adopter \noriented. Even laggards can meaningfully be said \nto be innovators (Rogers 1995). \nWhile innovating with IT is at one level an \norganizational process (Fichman 2000; Gallivan \n2001), it also takes place in a wider institutional \nfield (DiMaggio and Powell 1983). While the firm \nis necessarily the site where the material instan \ntiation of an IT innovation occurs, the innovation \nas-concept simultaneously enjoys an existence at \nlarge, beyond the boundaries of any particular \nenterprise. We call the innovation in this form an \norganizing vision, which we define as a focal \ncommunity idea for applying IT in organizations \n(Swanson and Ramiller 1997). \nAn organizing vision is a construction in discourse \n(Foucault 1972; Porter 1992; Ramiller 2001c) that \nemerges from a heterogeneous collective con \nsisting of such parties as technology vendors, con \nsultants, industry pundits, prospective adopters, \nbusiness and trade journalists, and academics. \nThe organizing vision is always a work-in-progress, \nevolving to incorporate the experiences, insights, \nand beliefs of these diverse interests. It defines \nthe innovation it speaks to in broad strokes. In \ndoing so, it provides a focus for the innovation\'s \ninterpretation, aids in legitimizing it, and helps to \nmobilize associated material and commercial pro \ncesses (Swanson and Ramiller 1997). It influ \nences the sensemaking and decision making of \nprospective adopters. And eventually it advances \nthe material innovation toward institutionalization \nand a taken-for-granted status (Scott 2000; Zucker \n1987) or, alternatively, toward a collapse in \ncredibility and eventual abandonment. \nAn organizing vision is commonly recognizable by \none or a few \"buzzwords\" that serve as a topical \nlabel for the wider community discourse. Knowl \nedge management, customer relationship man \nageent (CRM), and Web services provide recent \nexamples. The proliferation of such buzzwords \nand the rapidity with which they come to promi \nnence and then fade away are themselves hall \nmarks of the general milieu of IT innovation. This \nebb and flow in discourse reflects the fact that \n556 MIS Quarterly Vol. 28 No. 4/December 2004 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nevery organizing vision has in effect a career, \nmarked by rising and falling visibility, prominence, \nand influence over time (Ramiller and Swanson \n2003). This discursive career parallels the mate \nrial diffusion of the innovation itself (Wang 2002). \nIf an organization\'s mindfulness toward an IT \ninnovation is a matter of careful attention to local \nspecifics, the larger community\'s organizing vision \nis nevertheless the point of embarkation for the \norganization\'s sensemaking journey. How its \nmembers engage that vision will weigh heavily in \nthe organization\'s determination of whether, when, \nand how it will innovate, and what measure of \nsuccess it will enjoy (Ramiller 2001c). \nThe organization\'s engagement with the com \nmunity discourse extends over time and evolves \nalong with the organization\'s practical involvement \nwith the material innovation. This brings us, then, \nto the processual character of IT innovation. In \nFigure 1, we depict a firm\'s involvement with an IT \ninnovation as a mosaic of several interrelated \nprocesses and intentionalities. We note that while \nthere is an inherently sequential order to the \nactivation of these processes and intentionalities, \nonce activated each process or intentionality is \nlikely to remain more or less active over the course \nof the firm\'s innovation. Hence Figure 1 is not, \nstrictly speaking, a stage model of innovation (see \nWolfe 1994). \nWe introduce the concept of intentionalities in \norder to emphasize the goal-oriented and \npurposeful character of IT innovation. Among the \nintentionalities, engagement and achievement are \npositionaT because they focus primarily on a state \nthe organization strives to achieve. Commitment \nis transitional because it revolves around the \nchange process itself. \nWe identify four processes: comprehension, \nadoption, implementation, and assimilation.2 The \n20ur four processes combine elements of Rogers\' (1995) \nfamiliar innovation-decision process model (p. 161) and \nhis model of the organization\'s innovation process (p. \n392). We draw sharper distinctions between compre \nhension and adoption, and implementation and \nassimilation, than does Rogers. We caution that we use firm\'s innovation journey begins with compre \nhension. Through the sensemaking efforts of its \nmembers, the firm engages the organizing vision \nin substantive terms and ponders the signals about \nits importance embedded in the broader com \nmunity\'s reaction to it (Swanson and Ramiller \n1997). As it learns more about the innovation, the \nfirm develops an attitude or stance toward it \n(Rogers 1995, Chapter 5) and positions itself, in a \nbasic way, as a prospective adopter or non \nadopter. \nIf adoption is entertained, a deeper consideration \nof the IT innovation follows in which the firm \ntypically develops a supportive rationale, or \nbusiness case (see, for example, Orlikowski 1993). \nOrganizational know-why becomes central to the \ndeliberations among the participants (Swanson \n2003). The organizing vision typically provides \nsome general principles to draw on, but know-why \ndemands attention to issues specific to the firm. \nBoth the business value of the innovation and the \nchallenge presented by the prospective change \nare likely to be weighed before the organization \ndecides whether to proceed and commit its \nresources. \nThe implementation process that follows then calls \nfor a myriad of considerations, choices, and \nactions that will shape the transition. Timing may \nbe a crucial issue, relative both to the organi \nzation\'s own preparedness and to the readiness of \nthe enabling technology and the maturity of \ncomplementary services in the larger community. \nKnow-when is accordingly a focus of the organi \nzation\'s attention. Know-how also comes to the \nfore as the firm navigates the details of what may \nbe, and commonly is, a perilous venture (Swanson \n1988). Some of this know-how may need to be \nacquired in the marketplace, and here the larger \ncommunity discourse may provide guideposts, \nalthough what is acquired will need tailoring to the \nseveral terms more narrowly than elsewhere in the \ninnovation literature, where the terms adoption, \nimplementation, and assimilation have sometimes been \nstretched to cover the innovation process in its entirety. \nFor other innovation process frameworks in an IT context \nsee Cooper and Zmud (1990), Fichman (2000), Gallivan \n(2001), Kwon and Zmud (1987), Larsen (1998). \nMIS Quarterly Vol. 28 No. 4/December 2004 557 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nComprehension \n/Positional \n(Engagement) \nAdoption \n. .. Transitional \nInnOVatlOn /rW,mitrr?_nt\\ (Commitment) \n\\ Implementation \nRe-positional \n(Achievement) \nAssimilation \nFigure 1. Organizational Innovation: Its Processes and Intentionalities \n(Innovation comprises four component processes: comprehension, adoption, \nimplementation, and assimilation. Each is associated strongly [solid line] or weakly \n[dotted line] with underlying positional and transactional intentionalities.) \nfirm-specific context. Bringing the innovation to \nproductive life for its users is the immediate aim, \nwith the wider goal being to advantageously \nreposition the firm in its larger environment. \nAssimilation commences as the IT innovation \nbegins to be absorbed into the worklife of the firm \nand to demonstrate its usefulness. In time, the innovation may come to be infused and routinized \n(Cooper and Zmud 1990), woven into the fabric of \nthe organization\'s work systems, even as the latter \nundergo their own adaptive change. The orga \nnizing vision that inspired and motivated the \ninnovation may then be largely forgotten. Alter \nnatively, the innovation may be visited by \npersistent and disruptive problems that eventually \n558 MIS Quarterly Vol. 28 No. 4/December 2004 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \ndiscredit it in the perceptions of management and \nusers, sometimes leading to its curtailment or \neventual rejection. In such an event, the larger \ncommunity discourse may now provide contrary \nrationales, particularly where the organization\'s \nown encounter with the innovation mirrors the \nproblematic experiences of others. \nIn summary, organizational process and purpose \nfulness interact with discursive and material \nresources in the larger institutional environment to \nshape the pattern of a firm\'s engagement with an \nIT innovation. While the journey begins with the \nfirm\'s consideration of what others in the field are \nbeing said to accomplish with the innovation, it \nends with its consideration of what it has itself \nachieved.3 \nPurposefulness implies that cognition counts in our \nunderstanding of IT innovation (Daft and Weick \n1984; Meindl et al. 1994; Weick 1995). Never \ntheless, simply pointing to the purposefulness of \ninnovation does not imply that organizational \nmindfulness necessarily obtains. Accordingly, we \nnext consider more closely what mindfulness \nentails when an organization undertakes to \ninnovate with IT. \nInnovating Mindfully with \nInformation Technology HHI \nMindfulness, again, concerns the adaptive \nmanagement of expectations in the context of the \nunexpected. In innovating with IT, there is often \nmuch that is unexpected. While the nostrums and \nprognostications that appear in the organizing \n3ln outlining the four processes, we mean to offer a \nuseful, albeit general, scheme for thinking about IT \ninnovation in process terms. We acknowledge that the \nreality is commonly more complicated. Thus, for \nexample, an organization can often experiment with an \ninnovation before committing to it (Rogers 1995, p. \n171)?in a sense, implementing it before adopting it. \nSimilarly, a firm may do a pilot rollout in one unit before \ndeciding whether to install it elsewhere. In practice, the \nfour processes will often be engaged in overlapping and \ncomplex ways. vision discourse provide some generic guidance in \napplying the technology?which may, indeed, \nimprove and become more useful over time? \norganizational particulars are missing. So alert \nness to the unexpected falls of necessity to the \nfirm itself, and depends on paying close attention \nto the IT innovation\'s fit to local circumstances. \nWhere innovations are involved, \nmindful decision making involves dis \ncriminating choices that best fit a firm\'s \nunique circumstances, rather than \nfamiliar and known behaviors based on \nwhat others are doing (Fiol and O\'Connor \n2003, p. 59). \nAccordingly, an organization is mindful in \ninnovating with IT when it attends to an innovation \nwith reasoning grounded in its own organizational \nfacts and specifics. Attention to organizational \nspecifics is crucial in supporting sound judgments \nabout whether adopting a particular innovation is \na good thing to do, when committing to the \ninnovation is likely best to take place, and how \nimplementation and assimilation can best be \npursued. This is so because context matters in \nrendering such judgments. \nIn short, although the term mindful might at first \nglance suggest merely a cognitive alertness, for \ntrue mindfulness such alertness must be joined to \ncontextually differentiated reasoning. By this we \nmean that the organization\'s engagement with the \nIT innovation must entail a learning process rich \nwith interpretation of the innovation\'s implications \nfor the organization\'s own situation. The situa \ntional specifics, in fact, can be quite complex, \nincluding, among other issues, the innovation\'s \nramifications for operational efficiencies and \nstrategic advantage; the organization\'s pre \nparedness for the change involved; the quality and \navailability of complementary resources needed; \nimplications for various common and conflicting \ninterests, both internally and in interfirm relation \nships; and the effects of adoption on the firm\'s \nlegitimacy with outside constituencies. \nHow, then, can an organization accomplish a high \nlevel of such contextually differentiated reasoning? \nMIS Quarterly Vol. 28 No. 4/December 2004 559 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nWeick and his colleagues identify five attributes of \nmindfulness that can provide a point of departure \nfor addressing this question (Weick and Sutcliffe \n2001; Weick et al. 1999), including a preoccupa \ntion with failure, a reluctance to simplify interpre \ntations, a sensitivity to operations, a commitment \nto resilience, and a reliance on expertise over \nformal authority. In the next section, we elaborate \nand adapt these attributes for use in the context of \nIT. We then suggest ways in which IT-innovation \nmindfulness, characterized in this manner, may \ncome into play during a firm\'s evolving engage \nment with an IT innovation. \nAttributes of Mindfulness \nin IT Innovation \nThe mindful organization, first, does not celebrate \nits successes. Instead, it is obsessed with the \npossibility of failure and interprets close calls as \ncautionary lessons. It regards quiescent periods \nmarked by smooth operation as potentially \ndangerous?an indication, perhaps, that important \nsignals of trouble are being overlooked. With \nregard to IT innovation, such a preoccupation with \nfailure can aid in identifying opportunities for \nrealizing value from an IT innovation. Sustaining \nand extending the firm\'s competence thus sets the \ncontext for mindfulness about the innovation itself. \nThis larger mindfulness may entail being alert for \nthe success that breeds failure, those paradoxical \ncompetency traps in which pronounced success \nduring a certain period in the organization\'s history \nfosters an inability to adapt to changing conditions. \nMore narrowly, the process of IT innovation is itself \nprone to failure, and reflective attention to the \npossibilities for failure in this domain also enlarges \nmindfulness. \nThe mindful organization resists the temptation to \nsettle into simplified and reproducible heuristics in \nits interpretation of events. Instead, recognizing \nthat complex responses are needed in complex \nenvironments (Weick 1995), it actively entertains \nnovel, diverse, and conflicting perspectives. Such \na reluctance to simplify interpretations applies to IT \ninnovation in a number of ways. Mindfulness calls for the organization to eschew stock or formulaic \ninterpretations of IT innovations. This entails \nresistance to the simplified image of the innovation \nthat is encoded in the organizing vision. That \nimage, commonly imbued with an exaggerated \nsense of discontinuity, tempts the firm to forgo \nthoughtful comparisons to current practices; often, \nthe image is also associated with the aura of best \npractice, which can undermine critical and con \ntingent thinking (Ramiller 2001 b). The exercise of \nmindfulness, by contrast, entails entertaining \ncomplex and even conflicting interpretations. On \nthe one hand, it demands an alert attention to \norganizational variability that may render certain \ngeneralities about an innovation of little account \nlocally. On the other, it entails vigilance against \nthe proverbial not-invented-here syndrome, a \nresponse to innovations of external origin, which \noccurs like an antibody to preserve routine and \n\"protect\" the firm from new ideas. \nThe mindful organization attends vigilantly to small \nand seemingly insignificant details in day-to-day \noperations. This reflects the fact that catastrophes \ncommonly originate in the interactions of minor \nerrors and random events. In the context of \nHROs, such a sensitivity to operations is valued \nbecause organizational reliability depends on \nsensemaking and responsiveness under extreme \ntime pressure. By contrast, innovating with IT \nmay call for entertaining a pronounced degree of \nunreliability in current operations. Indeed, IT \ninnovation commonly involves thinking beyond and \neventually dismantling one operational process, \nhowever reliable, and replacing it with another, \noften because of crucial miscues that appear \noutside moments of everyday operation but that, \nnevertheless, can still produce dire consequences \n(albeit over a longer timeframe). Still, innovating \nwith IT concerns reliability in the broader sense of \nassuring the firm\'s viability in a changing \nenvironment. Sensitivity to operations accordingly \nstill applies to the IT context. Often, improvement \nin problematic operations is itself the goal of the \ninnovation, providing the focal know-why for IT \ninnovation. Also, the innovation project itself \nconstitutes a kind of operation that interdigitates \nwith the business operations of the firm. It is the \noccasion for the firm not merely to implement the \n560 MIS Quarterly Vol. 28 No. 4/December 2004 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \ninnovation, but also to discover how it can best be \nmade to fit (Orlikowski 1996). How successful the \nfirm is in this undertaking will depend upon its \nsensitivity to the particulars that come to define the \nmutual adjustment and interaction between the \ninnovation and the firm\'s work systems (Alter \n1999, 2002). In practice, it seems that this lesson \nhas to be continually relearned. Thus, many ERP \nimplementations have encountered problems with \nbusiness process change, as opposed to software \nchange, through insensitivity to the complexities of \ntheir operations (see, for example, Markus and \nTannis 1999). \nThe mindful organization is resilient, favoring \nimprovisation over planning, adaptation over \nroutine, and effectiveness over efficiency. \nResilience entails the recognition that anticipation \nis necessarily incomplete: It is impossible to \nidentify and develop contingency plans for every \npossibility. In the context of IT innovation, com \nmitment to resilience is likely to assume increasing \nweight as time passes and unfolding reality \ndeparts ever more widely from the firm\'s initial \nexpectations. This implies a practical and realistic \nview, one that acknowledges that trade-offs \nbetween schedule, budget, and delivered func \ntionality may need creative adjustment. More \nbroadly, this implies a dedication to opportunistic \nlearning from the inevitable surprises and mistakes \nthat attend such undertakings, not only when new \nsystems are first rolled out to their users, but \nbeyond. \nMindfulness depends on a readiness to relax \nformal structure so that authority for action can \nflow in times of crisis to the individuals and units \nhaving the requisite expertise to deal with the \nproblem at hand. Such deference to expertise is \ncentral to mindfulness in IT innovation. But in \nbringing this attribute into the IT context, care must \nbe taken not to conceptualize expertise too \nnarrowly. Mindfulness in this domain is, again, \nabout attending to the innovation with reasoning \ngrounded in the firm\'s own facts and specifics? \nand these facts and specifics reach well beyond \nthe technology and \"system,\" narrowly conceived. \nIndeed, they also concern the firm\'s objectives, \nstructure, and processes, and the firm\'s rela tionship to its larger environment. This implies that \nthe requisite expertise is heterogeneous and \ndispersed, and that authority for action must flow \nreadily to different places over the course of the \ninnovation project. It means, more specifically, \nthat expertise is often found with senior manage \nment and other business-side participants (Ross \nand Weill 2002). Also, because the expertise \nneeded is to a substantial degree constructed \ncollectively through the very process of innovation, \norganizational mindfulness depends in part on the \non-going learning that organizational members can \nhelp to foster in one another. \nMindfulness Across the \nIT Innovation Process \nMindfulness, as characterized in the preceding \nmanner, is concerned not only with moving the \norganization from the abstractions of the \norganizing vision to the specifics of locally adapted \ninnovation; it also has to do with rising to a \nsuccession of emergent challenges during the \ncourse of innovation. \nIn first engaging the organizing vision for an IT \ninnovation (see comprehension in Figure 1), the \nmindful enterprise will not take generalized claims \nabout the innovation\'s benefits and applicability at \nface value but will instead critically examine their \nlocal validity. Organizational members will ask, \n\"Would this be true for us? How so?\" Boundary \nspanning activities (Adams 1976; Aldrich and \nHerker 1977) are key at this juncture, as the firm \nexploits its community ties in an effort to gather \navailable information and diverse interpretations. \nIn the process, it is likely to extend those \nrelationships in ways that serve the sensemaking \ntask. The mindful enterprise will also act to create \nsituations for rich and context-specific learning \n(Lave and Wenger 1991), expanding its compre \nhension through such activities as demonstrations, \nsite visits, R&D alliances, and experimental \nprototyping. \nThe mindful firm will cast a critical eye on model \nrationales for adopting the IT innovation that are \nMIS Quarterly Vol. 28 No. 4/December 2004 561 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nbeing promulgated in the wider community\'s \ndiscourse. Mindfulness here will be found in the \ncare with which the available rationales are \nconsidered and examined for fit to the firm\'s own \ncircumstances. The mindful firm will respond with \ncomplex interpretations that rely on the efforts of \ninternal experts, working in the relevant technical \nand business domains, who are able to relate the \nlarger vision to substantive problems in the firm\'s \nexisting operations. \nIn considering adoption (again, see Figure 1), the \nmindful firm will fashion its own rationale, for or \nagainst. A rationale in favor of adopting will be \ncontext-specific, rich in its consideration of local \norganizational facts, and focused on the \ninnovation\'s potential contribution to the firm\'s \ndistinctive competence (Selznick 1957). It is \nimportant to recognize, however, that the mindful \nfirm\'s rationale may actually point against \nadoption, or it may favor deferred adoption. A \nsignificant benefit of mindfulness is that it helps to \nopen up the option to reject innovations. A \npreoccupation with failure schools the mindful firm \nin caution, as it resists the powerful cultural norm \nthat suggests that innovation is perse a good thing \n(Rogers 1995), and as it works to counter the \nindustry hyperbole that often dresses up an IT \ninnovation with claims about revolutionary \nadvances and best practices (Ramiller 2001a). \nThe mindful firm, then, approaches the threshold \nof commitment through complex interpretations, \nthe marshaling of heterogeneous expertise, and \nclose attention to the problems of current opera \ntions. Furthermore, commitment to resilience now \ncomes into play, helping to keep the firm from \npremature commitment. \nEven if the mindful firm decides in favor of an \ninnovation, it will not necessarily settle on being an \nearly adopter. Being an early adopter, indeed, is \nnot always a good idea. An innovation may or may \nnot be an irresistible concept destined to sweep \nthe broader industry, and early adopters can find \nthemselves stranded with odd technologies and \npractices lacking network support (Shapiro and \nVarian 1999). The organization itself may or may \nnot be ready for the innovation, particularly in light \nof the relative lack of wider resources available early on to support implementation. Hence, the \nmindful firm is characterized more by early \ncomprehension and contingent engagement than \nit is, necessarily, by early commitment. It aims \nabove all to be a discerning and prudent adopter.4 \nThe mindful firm will chart an implementation \nstrategy with deliberateness, giving particular \nattention to the processes with which it will \nmanage its own on-going expectations. With its \nfocus on organizational-specific learning, it will be \nskeptical of simplistic, one-size-fits-all solutions, \nand it will look to reinvent the innovation as \nnecessary. Even so, the mindful firm will attend \nclosely to the experiences of the innovation\'s \nearlier adopters, seeking to capitalize on the \ncommunity\'s growing knowledge about the \ninnovation. Of course, the mindful firm that adopts \nrelatively late will enjoy access to richer community \nresources and will seek to take advantage of its \nlate entry by coming up the learning curve faster \nthan did earlier adopters (Swanson 2003). \nThe five attributes of mindfulness assume promi \nnence in implementation. Mindfulness begins with \nan appreciation of the significant potential for \nfailure along the way. Eschewing simplistic inter \npretations, then, the mindful firm will be attentive to \nproblems of all kinds, treating them not merely as \nobstacles to be overcome but also as potential \nsymptoms of prior misconceptions. Operational \nsensitivity will draw attention to small oversights or \nareas of neglect that might otherwise lead, through \ncomplex and poorly understood causal chains, to \nlarger failures. Meanwhile, with the expansion in \nparticipation that accompanies implementation, \ncare will be taken in marshaling, and giving \nThis claim, we note, represents a departure from \nclassical innovation adoption theory (Rogers 1995). We \nare proposing that the mindful firm is likely to be early, \nand even pioneering, in its sensemaking, but it may well \nnot be an early adopter. This suggests that the \ninnovation researchers\' traditional search for the \npredictors of early adoption is not entirely to the point. \nWe are likely to find the mindless as well as the mindful \namong both early and later adopters. The preoccupation \nin innovation research with early adoption therefore fails \nto effectively distinguish and explain mindful choices, \nwhenever they may be made over the course of the \ninnovation\'s diffusion. \n562 MIS Quarterly Vol. 28 No. 4/December 2004 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nauthority to, the requisite experts. On the other \nhand, external consultants, who often lack under \nstanding of the local context, will be used \njudiciously. Resilience will characterize the effort, \noverall. While planning is to be taken seriously, \nmindful implementation demands a readiness to \nmake needed adjustments. At the extreme, the \nmindful organization must be prepared to eschew \nescalation (Keil et al. 2000) and identify and \naccept implementation failure, if necessary, to \nserve its overall interests. \nIn assimilating the IT innovation, the mindful \nenterprise will shun rapid acceptance and closure, \nand will instead remain open to surprises, \ncontinued learning, and the potential for adapta \ntions that address unanticipated problems or \nrealize unforeseen potential. Apparently smooth \nassimilation may mask the overlooked opportunity \nor the unexpected threat. Accordingly, the mindful \nfirm will attend closely to what early users\' \nutilization reveals about the innovation\'s incorpora \ntion into work-system routines and its integration \ninto user knowledge-sets (Cooper and Zmud \n1990). It will also reflect on what this means for \nthe organizational benefits that might yet be \nachieved.5 \nFailure remains possible even at this stage but, \nabsent wholesale user rejection, catastrophic \nfailure is less a concern than the possibility that the \ninnovation will fail to deliver on its potential value. \nMindfulness in this phase is crucially served by a \ncommitment to resilience: Recognizing that the \ninnovation, as a locally constructed material fact, \nis still less than fully constituted helps to foster the \nlearning-by-doing (Rosenberg 1982) that real use \npromotes. Deference to expertise also matters \nnow: Here the focus of expertise shifts in great \npart to the innovation\'s users, whose sensitivity to \ntheir own operations and interpretive sophistication \nare essential to further organizational progress \nwith the innovation. \n5For instance, is a lack of mindfulness during \nassimilation a factor in the situation reported for many \nfirms that have failed to take advantage of the advanced \nfunctionality available with ERP (Davenport 2000; \nMarkus and Tannis 1999)? Mindlessness ^ M_____HH1 \nWe have presented mindfulness in innovating with \nIT as a kind of ideal type, in the Weberian sense of \nan elaborated abstract category for use in making \nempirical comparisons to real cases (Weber 1949). \nBut the reader may be tempted to infer that we are \nalso offering mindfulness as a normative ideal. \nIndeed, why should an organization be anything \nbut fully mindful in its engagement with IT \ninnovations? Of course, real organizational con \nduct, as we noted at the outset, commonly departs \nfrom this apparent ideal. In this section, we \nentertain some reasons why this should be so. \nWe begin by characterizing mindlessness, also, as \nan ideal type. We then consider what in the basic \nnature of organizations appears to make mindless \nness not only possible but even commonplace. In \naddition to considering origins, we also examine \nthe matter from the point of view of purposeful \naction, by looking at the rewards and risks of \nmindlessness. This will help set the stage for \nconsidering the interrelationship between mindful \nness and mindlessness, a task which we take up \nsubsequently. \nCharacterizing Mindlessness \nin IT Innovation \nIn contradistinction to mindfulness, an organization \nis mindless in innovating with IT when its actions \nbetray a lack of attention to organizational speci \nfics. This lack of attention manifests itself in a \nvariety of ways across the phases of the innova \ntion process. \nThe mindless firm pays little attention to identifying \nand exploring new IT innovations. It attaches little \nor no importance to the early comprehension of \norganizing visions. Content to be a follower rather \nthan a leader, it may believe that IT is not critical to \nits distinctive competence. Rather than actively \nseeking intelligence about IT innovations, it will \nwait for innovations to come to it?thrust upon it, \nsay, by a consultant selling a solution for a putative \nperformance gap, or by a CEO who happens to \nMIS Quarterly Vol. 28 No. 4/December 2004 563 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nencounter a fashionable idea (Ramiller 2001a). \nConfident that others will call the important \ninnovations to its attention when needed, the \nmindless enterprise conserves its cognitive \nresources, perhaps for other good ends. \nIf and when a bandwagon develops around an IT \ninnovation, the mindless firm may join it, caught up \nin the momentum generated by prior adopters, and \nimpressed by \"success stories\" that appear to \nvalidate the innovation as a good, maybe even an \nirresistible, idea (Strang and Macy 2001). To \njustify adoption, then, the mindless firm may be \ncontent with the rationale that \"everyone is doing \nit\" or the justification that \"it\'s time to catch up.\" It \nthereby places its faith in what the broader \ncommunity appears to know?in the common \ncompetence, so to speak?rather than pursuing by \nmeans of innovation its own distinctive compe \ntence. While, as we have already observed, the \nmindful innovator also draws upon the common \ncompetence, the mindless innovator seeks simply \nto attach itself to this learning, its engagement \nsuperficial and uncritical. \nMindless adoption can presage equally mindless \nimplementation. When mindless firms adopt an \nERP package, for example, they, like many of the \nmindful companies before them, may turn to the \ndominant vendor within their industry. They may \nthen join some of these other firms in imple \nmenting a \"plain vanilla\" version. Indeed, the \nmindless firm may see no need to consider \nanything else, since its decision to adopt was not \nguided by attention to organizational specifics. \nSince mindlessness entails an inattention to the \nfirm\'s own circumstances, assimilation is likely to \nbe regarded as unproblematic, a simple matter of \nrolling out the innovation to its end-users, who will \nin effect be left to fend for themselves. Initial \nconfusion, frustration, or resistance may be \ndismissed as anomalous or attributed to short \ncomings in the users themselves. Purposeful \nadaptation of the innovation based on users\' \nexperience will not be entertained; rather, users \nwill be left to devise work-arounds as needed. \nAbove all, management will stubbornly seek to \nstay the course, letting certain problems take care of themselves. Where conflict obtains, manage \nment will trust that a negotiated truce among \naffected parties can eventually be achieved \n(Nelson and Winter 1982, Chapter 5). \nThis characterization of mindless conduct across \nthe IT innovation process suggests, not unsur \nprisingly, that mindlessness may be deeply \nproblematic. It may become particularly so as the \nfirm\'s engagement with the innovation progresses. \nWhy, then, should we witness mindlessness at all? \nThe Origins of Mindlessness \nConditions endemic to organizational life tend to \nset the stage for mindlessness in organizations\' \nencounters with IT innovations. We suggest three \nsuch conditions here, which can operate sepa \nrately or in combination: attention deferral, con \ntextual insensitivity, and institutional preemption. \nMany things compete for the attention of \norganizational members (March and Simon 1993). \nAs cognitive effort isn\'t limitless or free, some \nissues, events, and opportunities are heeded while \nothers inevitably are not. One consequence, when \nit comes to innovating with IT, can be attention \ndeferral. In particular, an organization can some \ntimes sacrifice early comprehension without \nimmediate ill effects. When other matters press \nupon management\'s attention, there may be little \ntime for engagement with the new and especially \nwith that which may be \"not quite here yet.\" \nDeferral of attention can also extend into adoption, \na common occurrence where the decision is \nrushed under a sense of urgency induced by \nbandwagon pressures. \nMindlessness can also be traced to contextual \ninsensitivity on the part of the firm and its \nmanagement. This insensitivity may come about \nbecause the organization and its members take \nmuch of their circumstances for granted. The firm \n\"knows itself to a substantial degree tacitly (Brown \nand Duguid 2000), and while genuine skill and \ndeep knowledge is encoded in this manner, it can \nalso constitute a dark pool of unreflective, \n564 MIS Quarterly Vol. 28 No. 4/December 2004 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nunexamined assumptions that drifts into conflict \nwith the firm\'s shifting circumstances. Knowledge \nis also locked into organizational routines (Nelson \nand Winter 1982), which may enhance the \nreproducibility and efficiency of work under normal \nconditions, but can also narrow attention in a way \nthat reduces acuity for changing circumstances. \nContextual insensitivity can also follow from certain \nstrategic choices, often in the guise of innovation \nitself. We may witness this, for example, where a \nfirm\'s performance lags and its leadership calls for \nradical change, and perhaps brings new manage \nment in to shake things up. Here the attraction of \ninnovating with IT may be precisely because it can \nhelp to overthrow the established order. For \nexample, some managers have reportedly adopted \nERP as a means to force reengineering of the \nfirm\'s business processes, valuing the software \nfirst of all for its potential to foster creative \ndestruction (Champy 1997). In such circum \nstances, managers may be all but invited to be \ninsensitive to the current operational context. \nWhere destruction is the first order of business, \nmindlessness is sometimes entertained, while \nmindfulness is left to the rebuilding. \nFinally, mindlessness in innovating with IT may be \nrooted in what we will call institutional preemption. \nIn their IT structures and practices, as in many \nother respects, firms often come to look more alike \nthan might be expected given differences in their \nindividual circumstances. Such isomorphism \n(DiMaggio and Powell 1983) reflects the operation \nof institutional forces, of which three types have \nbeen described: coercive, based in political power \nand/or regulatory authority; normative, stemming \nprimarily from professionalism; and mimetic, \nderived from standard responses to uncertainty, \nwhich commonly have the effect of cognitively \nforeclosing the consideration of alternatives (Scott \n2000). Thus, firms are sometimes compelled by \nmore powerful parties to proceed with an innova \ntion (see, e.g., Hart and Saunders 1997). In other \ncircumstances they may be carried along toward \ninnovation by influential norms. And finally, there \nare occasions where it is simply difficult for an \norganization to think outside the box?that is, even \nto imagine a possibility outside the framing imposed by the larger community\'s organizing \nvision. All these influences tend to be preemptive, \nreinforcing the taken-for-granted in innovating with \nIT (Covaleski and Dirsmith 1988), and potentially \nundermining mindfulness. \nInstitutional effects of these kinds are, we believe, \nrather common and clearly important in IT \ninnovation. Organizing visions, being prescriptions \nfor new IT that attract a variety of powerful \ninterests, become focal points for institution \nbuilding activity (DiMaggio 1991; Galaskiewicz \n1991). IT innovations, accordingly, tend to acquire \nthe institutional quality of being \"infused with value \nbeyond the technical requirements of the task at \nhand\" (Selznick 1957, p. 17). \nTogether, the three conditions we have identified \ncan interact to produce a potently mindless \nresponse in a firm\'s engagement with an IT \ninnovation, especially in the context of fads and \nbandwagons. In providing sweeping legitimacy to \nan IT innovation, however transiently so, a band \nwagon can in effect legitimize the exercise of \nmindlessness. Attention deferral and contextual \ninsensitivity may appear to be unproblematic in the \nface of the overwhelming \"proof afforded by the \nlarger community\'s rush toward the innovation. \nMindlessness can therefore be rendered socially \nand politically acceptable, to some degree, in \ninnovating with IT. We note too that because IT \ninnovation is widely understood to be both good \nand problematic, a certain amount of failure can be \ntolerated (and even celebrated in the guise of \nlearning), providing ready excuses for the \nmisfortunes of mindlessness. In innovating with \nIT, mindlessness and its consequences can in part \nbe masked. \nMindlessness as Strategic Choice: \nRewards and Risks \nTo be mindless is certainly not a good thing, on the \nface of it. Still, we will suggest that there are \ncircumstances in which mindlessness may prove \nto be adaptive, and therefore may constitute a \nreasonable, if not fully reasoned, course of action. \nMIS Quarterly Vol. 28 No. 4/December 2004 565 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nIn fact, we will argue that organizations often \nchoose to be IT-mindless, at least in some \nrespects. They may do so relative to certain \ninnovations. Or they may do so during particular \nperiods of their engagement with a given \ninnovation. Because mindfulness represents a \ncostly and demanding sensemaking regime, a firm \nmay, as a matter of strategic choice, decide to \nforego or delay it. To do so does not necessarily \nimply that the organization\'s members are \nindulging in a wider disregard for the organization\'s \nown welfare. \nBroadly, mindlessness in innovating with IT can \nreasonably be entertained whenever and wherever \nits likely rewards outweigh its risks. Consider the \npractice of attention deferral in early compre \nhension of IT innovations. Firms that consider \nthemselves followers, rather than leaders, may \nreasonably choose to embrace this practice, as \nalready suggested. Consider too the phenomenon \nof apparently mindless adoption under bandwagon \npressures. In fact, relatively mindless adoption \nmay suffice where homogeneity in outcomes \nacross firms is basically acceptable. This can \nhappen with reception of a new industry standard, \nor when the firm sees no need to differentiate itself \nin its response from the larger community of \nadopters. Also, even a mindless adopter may be \nable to improve upon its situation, where it can \nemploy the innovation as a means to jettison \nparticularly bad legacy systems (Davenport 2000). \nMore generally, the mindless adopter can become \nthrough imitation a participant in a kind of trans \norganizational learning taking place in the wider \ncommunity. There is, after all, usually something \nto the best practices being touted, even if these \nlack contextual specificity. \nConsidering again the common competence, we \nnote that much learning associated with new IT in \nfact takes place within the broader community, \nrather than within the individual firm itself \n(Swanson and Ramiller 1997). The organizing \nvision constitutes a kind of umbrella for the \ncommon competence, providing a developing \ninnovation story that incorporates, and yet \ngeneralizes across, the experiences of a range of \nadopters. Of course, the vision itself merely alludes to the common competence; it hardly \ncaptures it. Still, it provides a kind of focal \nnarrative structure for organizing the activities and \ndiscourse of those working on the innovation, such \nas consultants, vendor representatives, and \nperipatetic IT professionals. This heterogeneous \ncollective gradually assembles a certain trans \norganizational know-how, which enables trans \nmission and replication of the common compe \ntence among firms. As experience mounts, a \ndegree of contingent thinking can feed back into \nthe organizing vision and help the community \nmove beyond one-size-fits-all thinking, where the \nspecific IT innovation is concerned. Accordingly, \nbandwagons in innovating with IT can in part be \nreflective of real, appropriable, learning. \nMindless adoption of a prominent IT-enabled best \npractice may also be justified by the enhanced \nlegitimacy a firm can enjoy with wider consti \ntuencies (DiMaggio and Powell 1983), such as \ntrading partners, the financial markets, and \nregulatory agencies. Such enhanced legitimacy \nmay yield benefits apart from those that \nmindfulness would identify (Staw and Epstein \n2000), an eminently practical consideration given \nthe importance of the firm\'s public image in \ngarnering access to external resources. Also, the \nmindless adopter can position itself to benefit from \nthe network effects that are characteristic of much \nIT innovation (Au and Kauffman 2001; Katz and \nShapiro 1986; Kauffman et al. 2000; Rohlfs 1974; \nShapiro and Varian 1999).6 \nIn short, mindless adoption can position an \norganization to enjoy benefits from an IT \ninnovation, however fortuitous these may appear \nto be. Even so, the hazards of inattention may be \nsignificant here. The integrity of the adoption \ndecision can be undermined by a neglect of firm \nparticulars pertinent to both strategic fit and organi \nse do not mean to suggest that organizational \nlegitimacy and network effects cannot be the subject of \nmindful attention. Because the magnitude of these \nbenefits is likely to depend to some degree on the firm\'s \ncircumstances, mindfulness toward them is likely to \nproduce outcomes superior to those that mindless \nconduct can achieve. \n566 MIS Quarterly Vol. 28 No. 4/December 2004 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nzational capability. Not every innovation is good \nfor everyone, common competence and best prac \ntices notwithstanding. Accordingly, the mindless \npursuit of a best practice may be just as likely to \nproduce real and sustained performance losses as \nit is accidental improvement (Nash 2000; O\'Neill et \nal. 1998). Legitimacy effects and network benefits \nmay be transitory, leaving the mindless adopter \nstranded?and even conspicuously de-legiti \nmized?when the tide of the larger community\'s \nenthusiasm for the innovation washes out. \nEven where adoption does prove to be appropriate \nin principle, mindlessness raises another set of \nissues when the organization engages in \nprocesses of implementation and assimilation. \nHere, as material investments come heavily into \nplay, the practical consequences of mindlessness \nbegin to be most keenly and gravely felt. \nOn the positive side, the mindless follower can let \nthe leaders bear the costs of working with insuffi \nciently tested technology and unproven imple \nmentation methods. It can subsequently benefit \nfrom well-tested, off-the-shelf methods that are \nrelatively easy to execute. The difficulty is that not \nall stock implementation approaches are equally \nsuitable in all situations, a point the mindless \nadopter is likely to miss. Relative to network \neffects, even as complementary technologies and \nservices grow around the IT innovation, the \nmindless implementer will be at risk of making bad \npicks from among them. It may face stiff compe \ntition for the community\'s knowledge resources, \nparticularly during an accelerated and crowded \ngrowth period, when these resources are likely to \nbe stretched thin (Swanson 2003). Having \ndeveloped little knowledge of its own, the mindless \ninnovator faces substantial implementation risks, \nnot the least of which may arise through the use of \nunder-skilled consultants and contractors who \nspring up to fill the larger void. \nIn assimilation, the new IT must be absorbed by \nthe firm\'s work systems (Alter 2002). Here, local \norganizational facts may raise a particularly \nobvious challenge to the mindless firm\'s on-going \ncourse of action. Nevertheless, as we have noted, \nmindlessness can persist. It can manifest itself especially plainly in regard to the users\' encounter \nwith the IT innovation. Under such conditions, \nassimilation is likely to be painful, and may pro \nduce negative human-resource effects such as \nexcessive turnover and knowledge loss. Inatten \ntion and insensitivity will fail to correct mismatches \nin the fit of IT to the task. Moreover, the implicit \ndiscounting of user experience may lead the \norganization to overlook opportunities for the \nmutual adaptation of technology and work sys \ntems. Thus, mindlessness in assimilation can \nmean a crucial loss of learning opportunity and a \ndiminishing of the larger organization\'s \nadaptability. \nIn summary, the me-too stance of the mindless \ninnovator may secure certain rewards, subject to \nassociated risks. Even if mindfulness generally \nrepresents better practice, mindlessness has its \nplace in IT innovation. Nevertheless, we would \nargue that mindlessness is in general entertained \nwith the lowest risk during the firm\'s early engage \nment with the innovation, and that risk tends to rise \nfrom comprehension, through adoption, implemen \ntation, and assimilation, as the firm\'s depth and \ncomplexity of engagement with the IT innovation \nincreases. Accordingly, the firm that begins as \nrelatively mindless in its engagement will tend to \nfind increasingly compelling reasons for mindful \nness as it advances. As a prelude to the following \ndiscussion, then, in which we bring mindfulness \nand mindlessness together, we offer the following \nproposition: \n(P1) The organization that innovates with IT will \nbe most prone to mindlessness in its early \nengagement with the innovation. It will be \nless prone to mindlessness the longer it has \nbeen engaged with the innovation. \nToward a Synthesis -I \nConsidering mindfulness and mindlessness in IT \ninnovation raises certain compelling questions. \nFor example, why do we tend to witness mindful \nness or mindlessness in varying degrees, at dif \nferent times, across populations of organizations? \nMIS Quarterly Vol. 28 No. 4/December 2004 567 \nThis content downloaded from 130.133.8.114 on Wed, 06 May 2015 13:10:52 UTC \nAll use subject to JSTOR Terms and Conditions Swanson & Ramiller/lnnovating Mindfully with IT \nDoes mindfulness simply displace mindlessness \n(or vice versa), or is it meaningful to talk about an \ninteraction between the two? Addressing ques \ntions like these calls for theory that accomplishes \na synthesis of mindfulness and mindlessness as \ncomplementary expressions of a common under \nlying phenomenon. This synthesis, we believe, \nhas to be based on threading back and forth \nbetween the organizational level, in which mindful \nness is realized and practiced, and the wider \ninstitutional environment\\Nh\\ch invariably affects all \nadopters, the relatively more mindful and the \nrelatively less mindful. While we do not seek to \ndepart from Weick\'s regard for mindfulness as an \norganizational property, we do intend to call \nattention to the interdependence of organizational \nmindfulness and the larger community discourse \nsurrounding the innovation, where the latter serves \nas the crucial site for the development, capture, \nand sharing of knowledge among firms. \nRevisiting the five attributes of mindfulness \n(Figure 2), we note that preoccupation with failure, \nsensitivity to operations, and commitment to \nresilience are by their nature organizational \naccomplishments. On the other hand, richness of \ninterpretation and the development and deploy \nment of expertise can be said to apply to both the \norganization\'s sensemaking and the interorgani \nzational discourse. Moreover, the firm and the \nlarger interorganizational field do a kind of trade in \ninterpretations and expertise. The firm draws on \nthe knowledge resources of the larger community \n(Attewell 1992), as it navigates the innovation \nprocess. Reciprocally, those resources are built \nup over time, in great part throu', 'raytos.bsinfotech@gmail.com', 'E. Burton Swanson, Neil C. Ramiller', '', '../pdf_files/674d4eb395761-Innovating Mindfully with Information Technology.pdf', 4533383, 32, 18737, 128343, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(58, '6076215897', '51', 5, 5, ' The role of information technology in the organization: a review, model, and assessment', '2024-12-02 14:09:40.417945', '2000', 'This paper reviews and extends recent scholarly and popular literature to provide a broad overview of how information technology (IT) impacts organizational characteristics and outcomes. First, based on a review of the literature, we describe two of the principal performance enhancing benefits of IT: information efficiencies and information synergies, and identify the main organizational outcomes of the application of IT that embody these benefits. We then discuss the role that IT plays in moderating the relationship between organizational characteristics including structure, size, learning, culture, and interorganizational relationships and the most strategic outcomes, organizational efficiency and innovation. Throughout we discuss the limitations and possible negative consequences of the use of IT and close by considering several key areas for future research.', 'IT,Information Technology', 'The role of information technology in the organization:\na review, model, and assessment\nTodd Dewett*, Gareth R. Jones\nDepartment of Management, Texas A&M University, College Station, TX 77843, USA\nReceived 5 May 2000; received in revised form 29 September 2000; accepted 13 December 2000\nAbstract\nThis paper reviews and extends recent scholarly and popular literature to provide a broad overview\nof how information technology (IT) impacts organizational characteristics and outcomes. First, basedon a review of the literature, we describe two of the principal performance enhancing beneﬁts of IT:information efﬁciencies and information synergies, and identify ﬁve main organizational outcomes ofthe application of IT that embody these beneﬁts. We then discuss the role that IT plays in moderatingthe relationship between organizational characteristics including structure, size, learning, culture, andinterorganizational relationships and the most strategic outcomes, organizational efﬁciency andinnovation. Throughout we discuss the limitations and possible negative consequences of the use ofIT and close by considering several key areas for future research. © 2001 Elsevier Science Inc. Allrights reserved.\n1. Introduction\nThe availability and use of information systems and technologies has grown almost to the\npoint of being commodity like in nature, becoming nearly as ubiquitous as labor. By 1991,U.S. companies spent more on information technology than any other form of investment;total spending on computers and related services doubled from approximately $80 billion in1984 to over $160 billion in 1998 (Taylor, 1998). Information systems include many different\nvarieties of software platforms and databases. These encompass enterprise-wide systemsdesigned to manage all major functions of the organization provided by companies such as\n* Corresponding author. Tel.: 11-979-845-3876; fax: 11-979-845-9641.\nE-mail addresses: tdewett@cgsb.tamu.edu (T. Dewett), gjones@tamu.edu (G. R. Jones).\nPergamon\nJournal of Management 27 (2001) 313–346\n0149-2063/01/$ – see front matter © 2001 Elsevier Science Inc. All rights reserved.\nPII:S0149-2063(01)00094-0SAP,PeopleSoft,JDEdwards,andsoon,tomoregeneralpurposedatabaseproductstargeted\ntowards speciﬁc uses such as the products offered by Oracle, Microsoft, and many others(e.g., Evans, 1999; Hickman, 1999; Kathleen, 1999; McKendrick, 1999; Menezes, 1999).Information technologies encompass a broad array of communication media and devices\nwhichlinkinformationsystemsandpeopleincludingvoicemail,e-mail,voiceconferencing,video conferencing, the internet, groupware and corporate intranets, car phones, fax ma-chines, personal digital assistants, and so on (e.g., Andolsen, 1999; Campbell, 1999; Ed-wards, 1999; Grahm, 1999; Schober, 1999; Spiegelman, 1999; Tarabour, 1999; Wildstrom,1999). Information systems and information technologies are often inextricably linked and,since it has become conventional to do so, for the rest of this paper we will refer to themjointly as information technology (IT).\nRecent scholarly and popular literature has examined the role that IT plays in promoting\ncollaborationandinformationsharingbothinsideandacrossorganizationalboundaries(e.g.,Barua, Sophie Lee & Whinston, 1995; Lind & Zmud, 1995; Pickering & King, 1995; Quinn,Anderson & Finkelstein, 1996a). In this paper we draw on recent IT management literatureto systematically review and assess the role of IT in the organization. Our paper builds onHuber’s (1990) suggestion that IT is a variable that can be used to enhance the quality andtimelinessoforganizationalintelligenceanddecisionmaking,thuspromotingorganizationalperformance. However, Huber’s analysis was offered at a time when IT was making its ﬁrstmajor inroads into organizational life and the current paper extends and updates Huber’sresearch in three main ways. First, building on recent research, we focus on the two strategicoutcomesofefﬁciencyandinnovationwhichcapturemanyofthespeciﬁcbeneﬁtsthatresultfrom the use of IT. Second, we apply this approach to the examination of organizationalfunctioning by describing the impact of IT on a broader array of organizational character-istics than was addressed in Huber’s work. Finally, Huber’s theory treats several organiza-tional characteristics as dependent variables with IT positioned as the independent variable.In order to offer a more encompassing view of IT and organizational functioning, weexamine IT as a moderator of the relationship between organizational characteristics andseveral organizational outcomes, most importantly, efﬁciency and innovation (See Fig. 1).We believe this approach both places IT in a more theoretically plausible position and offers\nFig. 1. The role of IT in the organization.314 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346a useful framework that allows for the discussion of IT and a larger array of strategic\norganizational issues.\nThe list of potential salient organizational characteristics that impact organizational\noutcomesislengthy.Wehavechosentohighlightthosethathavebeensuggestedbypreviousresearch, are important to organizational performance, and clearly related to IT. Similarly,many possible organizational outcomes could be addressed, but those of efﬁciency andinnovation also emerged from our review of previous research as having the most perfor-mance-enhancing potential in relation to IT. The justiﬁcation for posing IT as a moderatorin the model can be seen when one considers that non-IT enabled structural dimensions,information sources, communication processes, and so on, already serve to facilitate the linkbetween organizational characteristics and outcomes. It is our contention that, in general, ITserves to alter or change the impact of these organizational characteristics on outcomes, thusmoderating their effect in the model.\nFinally, the feedback loop connecting organizational outcomes to IT in the ﬁgure serves\nto recognize a temporal reality in the application of any new technology. Optimally ﬁtting agivenITtoitscontextandrampingupthelearningcurveassociatedwiththeIT(Orlikowski,Yates, Okamura & Fujimoto, 1995) both require continuous and/or periodic modiﬁcations toensure the IT’s maximum utility. However, the use of IT is not a panacea (Constant, Sproull& Kiesler, 1996; DeSanctis & Monge, 1999). It has long been noted that the use of IT canlead to undesirable side effects (e.g., Culnan & Markus, 1987; DeSanctis & Monge, 1999;Zuboff, 1988). When we consider that some traditional means of communication often scorehigher than advanced technologies with respect to acceptability, ease of use, and richness(e.g., Trevino, Lengel & Daft, 1987), it becomes clear that the effects of IT are notuniversally positive, but that when they are applied appropriately they can serve as apowerful addition to an organization’s communications infrastructure (Huber, 1990). Weaddress this reality by noting several potentially negative outcomes associated with ITthroughout the paper.\n2. IT: information efﬁciencies and information synergies\nIn the 1960s and 1970s, when many deﬁnitions of organizational technology were being\ndeveloped, IT was largely nonexistent with computers being almost entirely conﬁned to theworld of mainframes and backroom functional applications. Technology was conceptualizedin terms of technical complexity (Woodward, 1965); operations technology and variability(Pugh,Hickson,Hinings&Turner,1969;Hickson,Pugh&Pheysey,1969);interdependence(Thompson, 1967); routine-nonroutine (Perrow, 1967, 1970), and manageability of rawmaterials (Mohr, 1971). Following Perrow’s (Perrow, 1967) suggestion, we propose thattechnology should be viewed broadly as the process of managing the uncertainty and risksurrounding the transactions necessary to convert inputs into outputs (Thompson, 1967).GiventhattodayIThasbecomeaprimarymeansofmanagingandreducingtheuncertaintiessurrounding production and administrative processes we see technology and IT as inextri-cably linked.\nClearly, a list of the speciﬁc ways in which IT impacts an organization would be lengthy315 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346so we have chosen not to focus on the numerous speciﬁc capabilities IT affords organiza-\ntions. Instead, based on a review of the literature, we identify several major outcomesassociated with the application of IT, as noted in Fig. 1. Our detailed review of research onIT includes work within the last ﬁve years that has appeared in six leading managementjournals ( Academy of Management Journal, Academy of Management Review, Administra-\ntive Science Quarterly, Journal of Management, Organization Science, Strategic Manage-ment Journal ) and demonstrates the breadth of approaches scholars have used in this arena.\nIn an effort to structure these works as a useful reference, we have organized themchronologically and by the primary beneﬁt of IT that each focuses on, as will be discussedbelow. (See Table 1)\nInaddition,ananalysisofthisresearchleadsustoarguethat,atanevenhigherconceptual\nlevel of analysis, IT moderates the effects of organizational characteristics on outcomesthrough its ability to generate information efﬁciencies and information synergies.\nInformation efﬁciencies (INE) are the cost and time savings that result when IT allows\nindividualemployeestoperformtheircurrenttasksatahigherlevel,assumeadditionaltasks,andexpandtheirrolesintheorganizationduetoadvancesintheabilitytogatherandanalyzedata. For example, as the result of the application of IT in the organization it is very likelythat a reshufﬂing of tasks will occur as technologies increase peoples’ or subunits’ ability toprocess information. What before, for example, might have been a task that requires theinputsofthreedifferentpeopleorsubunitsbecomesataskthatoneindividualorfunctioncanperform effectively because IT helps to increase both the amount and quality of informationwhich can be adequately processed. As we have deﬁned them, INE are largely a within-person or within-group effect. Thus, on the one hand, IT might simply allow each individualorsubunittoperformmorework,cumulativelyprovidingagaininorganizationalefﬁciency.\nOntheotherhand, informationsynergies (INS)aretheperformancegainsthatresultwhen\nIT allows two or more individuals or subunits to pool their resources and cooperate andcollaborateacrossroleorsubunitboundaries,abetween-personorbetween-groupeffect.Forexample,informationsynergiesoccurwhenITallowsthedifferentindividualsorsubunitstoadjust their actions or behaviors to the needs of the other individuals or subunits on anongoing basis. In essence, information synergies arise when IT helps to promote themultiplicative and nonseparable gains that can be obtained from team-based cooperation(Alchian & Demsetz, 1972).\nBearing these two meta-beneﬁts in mind, the ﬁve broad categories of organizational\noutcomes we have identiﬁed from our review of the literature are: improved ability to linkand enable employees, improved ability to codify the organization’s knowledge base,improved boundary spanning capabilities, improved information processing that leads toincreased efﬁciency; and improved collaboration and coordination that promotes innovation.Below, each of these outcomes will be considered in turn as related to the concepts of INEand INS.\n2.1. IT links and enables employees\nAs compared to face-to-face communication, the use of electronic communication has\nbeen shown in the literature to increase the overall amount of communication in the316 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346Table 1\nRecent information technology related management literature\nAuthors Focus/Outcome examined Type of IT Theoretical approach Analyses/\nLevel of analysisPrimary IT\npropertyaddressed\nBarua et al., 1995 IT design, incentives, organization\nand task characteristics: peermonitoring and pressure,individual effort, groupperformanceGroup decision support\nsystemsGroup theories N/A; group A, D\nBorland &\nTenkasi, 1995IT design, perspective making and\ntaking: designing IT to supportknowledge workElectronic\ncommunicationCommunication, language,\ncognitionN/A; varied A, E\nDos Santos &\nPeffers, 1995Application of IT: market share\nand incomeATM machines Competitive advantage Regression;\norganzationD, E\nFulk & DeSanctis,\n1995Effect of IT: changing\norganizational formsCommunication\ntechnologiesVarious organizational\ntheoriesN/A; varied A, B, C,\nD, E\nHinds & Kiesler,\n1995Direction of use of IT, lateral\nversus horizontal by type ofworker: pattern of communicationmedia use by different types ofemployeesElectronic mail Various organizational\ntheoriesLogit regression;\nindividualA, D\nLeidner & Elam,\n1995Effect of IT on several\norganizational outcomes: decisionmaking speed, problemidentiﬁcation speed, informationavailability, involvement ofsubordinates in decision makingExecutive Information\nSystemHuber (1990) MANOVA, ANOVA;\nindividualA, B, C, D\nLind & Zmud,\n1995Effect of IT on interorganizational\nrelationships and ﬁnancialperformance: satisfaction withdyadic partner interactions,dealership sales performanceVoice mail Various organizational\ntheoriesLISREL, ANCOVA;\ninter-organization,DyadsC, D\nOrlikowski et al.,\n1995IT management in R&D\ndepartment: process ofmetastructuringElectronic\nconferencing/messagingTechnology structuring Descriptive;\norganizationA, B, D, E\n(continued on next page)317 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346Table 1(continued)\nAuthors Focus/Outcome examined Type of IT Theoretical approach Analyses/\nLevel of analysisPrimary IT\npropertyaddressed\nPickering &\nKing, 1995Effect of IT on weak ties: use of\ninter-organization computermediated communicationInter-organizational\ncomputer mediatedcommunicationNetwork theory, weak ties N/A; inter-\norganizationA, C, D\nWebster &\nTrevino, 1995Determinants of Use of IT within\nan organization: choice of mediaElectronic mail Media choice/social\ninﬂuencePolicy capturing;\nrepeated measuresANOVA, ANOVA,ANCOVA; individualA, D\nWeisband et al.,\n1995Effect of IT on group status and\nparticipation: group memberparticipation and inﬂuenceComputer mediated\ncommunicationGroup status/social\ninﬂuenceANOVA; group A, B, D\nZack &\nMcKenney,1995Determinants of Use of IT, social\ncontext and interaction: use of ITacross contextsGroup authoring &\nmessaging systemNetwork and\norganizational theoriesNetwork analysis;\ngroup, networkA, B, D\nConstant et al.,\n1996Effect of IT on weak ties:\nusefulness of advice receivedElectronic mail Network theory, weak ties Regression; individual A, D, E\nLawler & Elliot,\n1996Effect of IT in human resource\nmanagement: problem solvingaccuracy and efﬁciency,conﬁdence in use of ES,perceived ease of use, taskattitudeExpert system Behavioral decision thepry ANOVA, logistic\nregression; individualB, D\nAlavi et al., 1997 Effect of IT on management\neducation: dimensions of learningexperience for students andfacultyVideo-conferencing,\nelectornic groupsupport systemsInter-organizational\nTheoriesCase methods,\nANCOVA, individualA, B, C, D\nAng &\nCummings,1997Whether or not to outsource IT:\ndegree of bank IS outsourcingVarious IS resources Institutional theory Logit regression;\norganizationD\nHart & Saunders,\n1997Determinants of use of IT\nbetween organizations, power andtrust in adoption: EDI adoptionand useElectronic data\ninterchangePower and trust N/A; inter-\norganizationC, D, E\n(continued on next page)318 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346Table 1(continued)\nAuthors Focus/Outcome examined Type of IT Theoretical approach Analyses/\nLevel of analysisPrimary IT\npropertyaddressed\nHolland &\nLockett, 1997Effects of IT on network\nstructure: mixed mode networkstructuresInter-organizational\nsystemsMixed mode network\ntheoryCase methods; inter-\norganizationC, E\nPowell & Dent-\nMicallef, 1997IT as a competitive advantage IT technologies Resource based view of\nthe ﬁrm, competitiveadvantageRegression;\norganizationA, B, C,\nD, E\nNault, 1997 Effect of IT in a horizontal\nnetwork organization: increasedfranchisee proﬁt, more horizontalfranchise structureCustomer management\nsystemNetwork theory N/A; corporate,\nfranchiseB, C, D\nSwanson &\nRamiller, 1997Determinants of use of IT among\norganizations: adoption anddiffusion of new ITIT innovations Institutional theory,\norganizing visionN/A; inter-\norganizationE\nWebster &\nHackley, 1997Effect of IT on distance learning:\nstudent involvement, cognitiveengagement, technology self-efﬁcacy, etc.Distance learning\ntechnologiesTeaching effectiveness\ntheoriesRegression; individual A, D\nAnand et al., 1998 Role of IT in organizational\nmemory: effective informationmanagementInformation and\ncommunicationtechnologiesOrganizational memory N/A; individual,\norganizationA, B, D, E\nKraut et al., 1998 Determinants of use of IT within\nan organization: amount of videoconferencing useVideo telephone\nsystemMedia richness theory,\nutility theories, socialinﬂuence theories,contingency theoryTime series analysis;\nindividualA, D\nLado & Zhang,\n1998Effect of IT on competitive\nadvantage: knowledgedevelopment and use, competitiveadvantageExpert systems Resource based view N/A; organization B, D, E\nSarbaugh-\nThompson &Feldman, 1998Effect of IT on intra-\norganizational communication:volume of communication,efﬁcacy of communicationElectronic mail Network theory,\ncommunication theoriesNetwork analysis;\nnetworkA, D\n(continued on next page)319 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346Table 1(continued)\nAuthors Focus/Outcome examined Type of IT Theoretical approach Analyses/\nLevel of analysisPrimary IT\npropertyaddressed\nArgyres, 1999 Effect of IT on organizational identity:\ninter-ﬁrm coordination in productdevelopmentTelecommuting\ntechnologiesTransaction cost theory,\nagency theory,information processingtheoryCase methods; inter-\norganizationA, B, C,\nD, E\nDeSanctis &\nMonge, 1999Application of IT in virtual\norganizations: varied (introduction tospecial issue)Electronic\ncommunicationstechnologiesVarious organizational\ntheoriesN/A; individual\norganizationA, C, D\nGrifﬁth, 1999 Technology and sensemaking:\nsensemaking and adaptive structurationTools for instrumental\nactionAdaptive structuration,\nsocial constructionN/A; individual N/A\nJarvenpaa &\nLeidner, 1999Effect of IT on trust in virtual teams:\ntrustInternet, electronic\nmailTrust Descriptive;\nindividualA, B, D\nKraut et al., 1999 Effect on IT on outsourcing\nproduction: electronic network use,extent of outsourcing, perceived orderquality, satisfaction with supplierElectronic networks Transaction costs theory Regression;\ntransaction,organizationA, B, D\nKurland & Egan,\n1999Role of IT in justice perceptions:\njusticeTelecommuting\ntechnologiesJustice theories Regression; individual A, D\nMartins &\nKambil, 1999Effect of incumbent IT on new IT:\nthreat/opportunity framing; effectcertainty; response certaintyTechnologies for ﬁling\ntax returnsStrategic issue\ninterpretationRegression; individual N/A\nMitchell & Zmud,\n1999Effect of IT coupling with process\nstrategies on process innovation:project performanceIT technologies Loose coupling, process\ninnovationRegression; individual A, D, E\nStaples et al.,\n1999Effect of self-efﬁcacy on IT for remote\nworkers: individual performance,satisfaction, stress, etc.Various information\ntechnologiesSelf-efﬁcacy SEM; individual A, D\nWiesenfeld et al.,\n1999Effect of IT on organizational identity:\norganizational IdeniﬁcationTelecommuting\ntechnologiesOrganizational\nidentiﬁcationCase methods;\nindividualA, D\nYates et al., 1999 Effect of IT in an R&D group:\nemerging genres of useElectronic\nconferencing/messagingGenres of communication,\ntechnology-in-usemediationDescriptive; user\ngroupsA, B, D, E\nNote: for primary IT property addressed: A 5linking and enabling employees, B 5codifying the knowledge base, C 5increasing boundary spanning,\nD5promoting efﬁciency, E 5promoting innovation, N/A 5not applicable.320 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346organization (Hiltz, Johnson, & Turoff, 1986). This implies what is perhaps the most\nfundamental beneﬁt resulting from IT use in organizations; the ability to link and enableemployees both within and between functions and divisions–whether through databaserepositories, teleconferencing, or electronic mail—and achieve INE and INS. For example,one of the most direct ways in which IT impacts organizational functioning is through itseffects on horizontal coordination. The application of IT has been shown to aid cross-functional workﬂow (Monge & Fulk, 1995), concurrent engineering (Davidow & Malone,1992), and stockless production (Piore, 1994). Increasing online interdependencies makescritical information more accessible and transparent to employees and increases the inci-dence of problem-solving (Edmondson & Moingeon, 1998). IT can also play an importantrole in allowing organizations to explore new modes of structuring their workforce. Severalauthors have also shown how IT successfully links employees in many emerging organiza-tional forms, such as the virtual organization (Nohria & Berkley, 1994). For example,Kurland and Egan (1999) show that telecommuting increases employees’ positive percep-tions of both procedural and interactional justice. However, having to rely largely on IT forcommunication purposes in lieu of face-to-face communication can lead to increased alien-ation among employees (DeSanctis & Monge, 1999).\nAlthough empirical research on these issues is just beginning, one example of the utility\nof information exchanged through electronic ties is provided by Constant, Sproull, andKiesler (1996). They analyzed computer communications between information seekers andpotential information providers at Tandem Computer Corporation. Their ﬁndings suggestinformation providers gave useful advice and solved the problems of information seekers,despitetheirlackofanypersonalconnectionwiththeseekers.ThisissupportedbyDeSanctisand Monge (1999) who argue that the only issue the literature shows consistent ﬁndings onis that divergent thinking tasks are completed more effectively electronically rather thanface-to-face. Another example, from closer to home, is the Research Methods Network, acyber meeting place created by the Research Methods Division of the Academy of Man-agement. Through the service provided by the network, hundreds of scholars seekingassistance and resources relating to often complex research methodology questions areroutinely assisted by the voluntary efforts of other scholars on the network.\nThe beneﬁt of linking employees and creating information efﬁciencies has not been lost\non industry. For example, at General Motors, senior executives became concerned abouttheir process for using market information. They found that information about the kinds ofvehicles that appeal to customers had not been used speedily or effectively within thecompany, especially during new product development and product launches. They deter-mined that pertinent information was often available, yet was not acquired by the rightemployees in a timely fashion. In response to this problem the ﬁrm has implemented a newIT-based product development process which relies on a computerized “Inquiry Center” asa centralized source of market information, now ensuring that key employees are linkedtogether throughout the process (Barabba & Zaltman, 1990).\nIt should be noted that simply serving as a link does not guarantee that IT will positively\nimpact communication processes. It is also possible that even given the wide availability ofweak tie linkages (Granovetter, 1973) due to IT, the motivation of some organizationalmembers to provide information through these links may be low (Hanson, 1999). Nonethe-321 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346less, there are several reasons to expect that sufﬁcient motivation may be present. First,\nsharing expertise can increase a person’s self-esteem, identiﬁcation with the organization,respect from others, and feelings of commitment (Orr, 1989). Second, a person may bemotivated through feelings of organizational citizenship (Bateman & Organ, 1983). Inaddition, a third explanation may be that the organization’s culture has shaped norms whichencourage the use of IT media, a topic we will address shortly.\nThe downside to linking employees must be noted as well. It is possible that not only the\namount of good advice information seekers receive will increase, but bad advice mayincrease as well. Help seekers have no way of assessing the information providers expertise,motives, and so on (Constant et al., 1996). However, many ﬁrms work to ensure thereliability of information received via electronic weak ties by forming distinct on-linecommunities where collections of experienced employees within a given area can be located(e.g., a software developers forum, a sales force intranet, a manufacturing discussion group).By creating logical content communities, those who respond to information requests are ina sense prescreened as to the quality of advice they might offer (Davenport & Prusak, 1997;Kraut, Steinﬁeld, Chan, Butler & Hoag, 1999).\nFurther, several authors have noted that the use of IT for communications purposes is still\nlimited in that it does not allow users to obtain “soft” information (Mintzberg, 1975), “rich”information(Daft,Lengel&Trevino,1987),orthe“meaning”ofinformation(Weick,1985).Related to these ideas, Sarbaugh-Thompson and Feldman (1998) suggest that two possiblenegative effects of the use of electronic communication are the reduction in casual conver-sation and that it may lead to fewer opportunities to signal “communication trustworthiness”in social situations. These ideas suggest a deﬁciency in IT capabilities with respect to thedepth of information exchanged. However, Huber (1990) disagrees and notes that theseinstances are much rarer than one might think. He cites research suggesting that communi-\ncators use a medium of communication that ﬁts their needs (e.g., Daft et al., 1987), such thattheITusedtocommunicateinagiveninstanceisappropriateforthespeciﬁccontextortask.In addition, where one does wish to convey tacit information via IT, we would add that dueto advances in technology the use of IT no longer precludes the capture of soft or tacitknowledge as several authors have warned. For example, IT applications allowing for thesimultaneoususeofaudioandvideomediaingroupsettingstoconveymessagesisbecomingwidespread, overcoming earlier concerns that were based on single-media IT applications(e.g., electronic mail).\n2.2. IT codiﬁes the knowledge base\nMemory is clearly fallible and subject to erosion and error; the human capacity for\nmemory as a component of organizational memory is less than perfect (Huber, 1990). Insidean organization, memory has also been quite fallible because, as a collective of individuals,the ﬁrm is only able to maintain a minuscule portion of the information that is currentlyavailable to it. Advances in IT have greatly facilitated organizational memory and the abilityto capture and integrate explicit knowledge by making it easy to codify, communicate,assimilate, store, and retrieve (Anand, Manz & Glick, 1998; Rockart & Short, 1989). What322 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346this translates into is INE through an improved ability to apply past and current knowledge\nto issues facing the organization.\nAgoodexampleoftheutilityofknowledgecodiﬁcationthroughITisprovidedbyLeidner\nand Elam (1995). They explore managers’ use of executive information systems (EIS), adevicewithasingledatabaserepositorythattransmits,communicates,orprocessescompanyrelevant information digitally for use in managerial decision making. Their empirical worksuggests that when used frequently over time an EIS is positively related to problemidentiﬁcation and decision making speed for senior and middle managers. Similarly, Ladoand Zhang (1998) examine expert systems (ES), computer systems speciﬁcally designed tohelp executives and managers make particular types of decisions. These systems storevolumes of facts and heuristics and utilize software the makes interpretations of data ordraws conclusions about a speciﬁc problem. The codiﬁcation of knowledge allows criticaldocuments to be stored on-line and discussions to be conducted online, building on the INEbeneﬁts of linking employees. In addition, electronic networks can maintain listings ofemployees and their area of specialization (Zorn, Marshall & Paned, 1997) allowing em-ployeestoidentifyandcommunicatewithspecialistswhoseexpertisetheymayneed(Senna,1997), providing a context for collaboration, and potential INS.\nExamples of knowledge codiﬁcation and management in organizations are appearing\nrapidly. For example, at McKinsey and Company the need for accurate and timely infor-mation resources to support their consultants in the ﬁeld has led to the creation of the RapidResponse Network. A group of experienced consultants assemble knowledge on-line fromevery level of the ﬁrm and then use in-house IT to disseminate information to consultantsthroughout the organization–information that would otherwise not have been available tothem (Peters, 1992). Similarly, Chase Manhattan Bank has made document scanning anddistribution the cornerstone of their knowledge management strategy. Their IT, ChaseInformation Exchange, enables all their bankers to use one single communications system toprovidethemwithtimelyinformationandworkwithcolleaguesthroughoutthebanktosolveclient problems (Davenport & Prusak, 1997).\nOn the downside, given that the role of many information networks is to screen, package,\nandinterpretmessages,itispossiblethatITcanleadtoinformationoverload(e.g.,DeSanctis& Monge, 1999; Huber, 1990). Sorting through such large amounts of data may impedemanagers’ ability to make timely decisions. Nonetheless, there is reason to believe that thisproblem may not be as serious as some have claimed. Research by Hiltz and Turoff (1985)found that social norms and management practices develop over time to mitigate thisproblem. Leading technology and management consulting ﬁrms actively screen and managethe process of adding any information to the organizations’ information infrastructure toensure the proper size and utility of their information repositories. For example, Hewlett-Packard has adopted a pull strategy for information management whereby its vast reposito-ries of online information are managed for size and utility. Document usage is measured bythe department that “owns” the information in order to determine how long documentsshould remain in the repository (Davenport & Prusak, 1997). In addition, recent advances inIT have dramatically increased the ability of information seekers to search for and retrievethe precise information they are seeking, further mitigating the negative effects of dataoverload.323 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–3462.3. IT increases boundary spanning\nIn the case of boundary spanning activities, IT offers an organization substantial infor-\nmationefﬁcienciesandsynergies.Fromtheperspectiveoftheboundaryspanner,ITdoesnotjustallowaccesstopriorknowledge,asmightresultfromknowledgecodiﬁcation,butallowsan employee to search for and absorb new knowledge that is relevant to a problem at hand(Tushman, 1977). For example, in complex organizations employees working on one task orproject may often wish to obtain useful knowledge residing in other operating units, but theemployees may not know whether or not this knowledge exists and where it might reside.Organizationalmembersarethenfacedwiththeneedtosearchtheirnetworkforinformation.Using Granovetter’s (1973) arguments, Hanson (1999) describes how individuals or projectteams use weak individual or interdepartmental ties to provide access to nonredundantinformation, information the focal unit did not have direct tie access to. Since messagestransmittedviaITcutacrosspersonalandprofessionaldomains,individualstendtomaintainand monitor communications links (e.g., e-mail, voice mail) after hours and while they areaway from the ofﬁce which leads to an erosion of generally accepted personal and profes-sional boundaries of time and space. Equipping large numbers of organizational memberswith communications links (e.g., internet access, intranet access, car phones, fax machines,audio and video conferencing) has dramatically expanded the access of any individual tovarious sources of information as well as increased their level of participation in variousinformation networks (Yan & Lewis, 1999). IT thus helps eliminate labels suggesting thatorganizational members are boundary spanners or nonboundary spanners.\nSimplyprovidingaccesstonewsourcesofinformationmaycreateINEgiventimesavings\nassociated with information search. By allowing quicker access to both internal and externalinformation,ITenablesfasterscanningandmonitoringoftheexternalenvironment(Rockart& DeLong, 1988), often an impetus for boundary spanning activity. In terms of INS,Feldman(1987)predictedthatinterorganizationalelectronicmailwouldgreatlyfacilitatetheestablishment of weak ties. Pickering and King (1995) suggest that these IT enabled weakties in interorganizational relationships create changes in personal social tie networks, linkscreating potential synergies for the organization. Thus, IT can provide employees withknowledgeofindustrybestpractices,informationonrelevantleadingedgetechnologies,andthe goings on at professional associations relevant to their work. In short, access to such richboundary spanning information makes opportunities more salient. In terms of potentiallynegative effects of IT in this context, future research might consider the notion of decisionspeed or urgency. Given high decision urgency it is reasonable to speculate that informationoverload through codiﬁcation and boundary spanning may be an impediment to expedientdecisionmaking.However,researchexaminingdecisionenvironmentssuggeststhatdecisionspeed is associated with the simultaneous consideration of many alternatives (Judge &Miller, 1991) and that fast decision makers actually use more information as compared toslower decision makers (Eisenhardt, 1989), although IT was not a major focus of this work.\n2.4. IT promotes efﬁciency\nAs the previous discussion implies, and as Huber (1990) has argued, IT has many\nuseful properties that can affect organizational efﬁciency. IT produces many efﬁciencies324 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346in communication including the ability to communicate more easily and less expensively\nacross time and geographic location; the ability to communicate more rapidly and withgreater precision to targeted groups; the ability to record and index more reliably andinexpensively the context and nature of communication events; and the ability to moreselectively control access and participation in a communication event or network. IToffers many decision-making efﬁciencies including the ability to store and retrieve largeamounts of information more quickly and inexpensively; the ability to more rapidly andselectively access information created outside the organization, the ability to morerapidly and accurately combine and reconﬁgure information; the ability to more con-cisely store and quickly use experts’ judgments and decision models; and the ability tomore reliably and inexpensively record and retrieve information about the context andnature of organizational transactions.\nPickering and King (1995), for example, found that individuals using interorganizational\nelectronic mail claimed that this technology reduces their information costs; and DeSanctisand Gallupe (1987) showed that IT reduces the cost of monitoring teamwork because it iseasier to track progress when the group members have a common electronic workspace.Henderson and Venkatraman (1994) note two features of IT that directly address the issueof efﬁciency. First, IT offers dramatic increases in the speed of communication, with highvolumes of data moving from one location to another at rates unimaginable even a few yearsago. Second, IT dramatically reduces the costs of communication due to advances incomputer and telecommunication technology that lead to economies of scale and scope.Finally,Argyres(1999)arguedthatITreducesthecostofinformationprocessing,thatis,thecost of sending and receiving information between actors, thus making some organizationalstructures more efﬁcient than others.\nKuperman (1998) highlights the efﬁciency-enhancing role of IT in discussing the way\nhis advertising ﬁrm, Chiat/Day, uses IT. An advertising agency’s core competence isprimarilybasedonitsemployees’skillsandcompetenciesandonorganizationalroutinesand a common language. So, to build on and enhance these competencies Chiat/Day’s ITwas designed to promote collaboration and information sharing. No longer must infor-mation move from person to person sequentially, rather knowledge is posted online andthe system notiﬁes the right person that a ﬁle or advertising copy has been delivered tothem. As a result, their old giant manila sacks and mechanical ﬁles have been replacedby “electronic job jackets” containing all needed information and digitized photographs.This procedure has completely eliminated the traditional role of “trafﬁc managers” andgreatly increased the time efﬁciencies of their common routines. These kinds of efﬁ-ciency gains are most commonly measured in terms of their effect on labor productivity,and the increases in labor productivity that have occurred during the 1990s are usuallyseen as a principal beneﬁt to be gained from the application of IT in organizations (e.g.,Greenspan, 2000).\n2.5. IT promotes innovation\nMyers and Marquis (1996) deﬁne innovation as “a complex activity which proceeds from\nthe conceptualization of a new idea to a solution of the problem and then to the actual325 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346utilization of economic or social value.” Kanter (1983) views innovation “as the process of\nbringing any new problem-solving ideas into use.” West and Farr (1990) deﬁne innovationbroadly to “include the intentional introduction and application within a role, group, ororganizationofideas,processes,productsorprocedures,newtotherelevantunitofadoption,designed to signiﬁcantly beneﬁt the individual, the group, organization, or wider society.”Our review of the IT literature leads us to the conclusion that the role of IT in promotinginnovation is very underrepresented in the literature because of the focus on its efﬁciency-enhancing properties. For example, in the literature highlighted in Table 1, efﬁciency,especially when coupled with one or more of the three other outcomes moderated by IT, isaddressed almost three times as much as innovation. As we suggest in the remainder of thepaper,however,ITisanimportantbutneglectedmeansoffacilitatingtheinnovationprocess.This is because IT moderates many aspects of the process of bringing “new problem-solvingideas into use” given that it determines the way information is stored, transmitted, commu-nicated, processed, and acted upon.\nINE facilitates innovation by improving the initial base of knowledge to draw from when\nemployees engage in problem solving and decision making. This creates a larger and richerpool of codiﬁed knowledge for any given employee to draw from, reducing the cost ofinformation search. However, knowledge or information availability alone will not lead toinnovation; it is the ability to creatively use knowledge that is the key to promotinginnovation and creating competitive advantage (Leavy, 1998). Prahalad and Hamel (1990),for example, suggest that it is not the absolute level of knowledge a ﬁrm possesses whichleads to competitive advantage, but the velocity with which it is circulated in the ﬁrm.Knowledge optimization speaks directly to INS. Recognizing that knowledge is ofteninextricably linked to human resources and the way individuals and groups interact, theinformationsynergiespossiblethroughITwillonlyberealizedwhentheﬁrmisabletomovefurther and actually utilize knowledge in its optimal location within the organization. Thisimplies that organizations must move beyond knowledge circulation as described by Pra-haladandHamel(1990)andactuallyreallocateknowledgeresourcestotheplacewheretheycan add the highest value to the organization as the need arises.\nProject based work provides a vivid example of this process. As a project progresses, the\nneed for particular team members waxes and wanes. Some employees will be part of aproject from beginning to end and others will only be asked to participate at key times whentheir expertise is required. IT provides management with the real-time capability to monitorproject progress and needs and allocate knowledge resources accordingly in an effort tooptimize the overall value added of each employee, and, in turn, optimizing knowledge useand the potential for INS. In this vein, Davidow and Malone (1992) argue that traditionally,product design has involved sequential processing across functions, with handoffs as eachstageoftheprocessiscompleted.ThislinearprocessisbeingreplacedbyparallelprocessingandconcurrentengineeringmadepossiblethroughtheapplicationofIT,allowingemployeesto work simultaneously with continual interaction through electronic communication, whichcan promote innovation.\nAs another example of how IT can promote innovation, Amabile (1988) argues that\nbeyond a person’s cognitive style or intrinsic motivation, a person’s domain relevant skillsare a vital input into creative, innovative activity. Domain relevant skills include a person’s326 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346factual knowledge, technical skills, and special talents in the domain and represents the\nindividual’s complete set of response possibilities from which a new response is to besynthesized. The ability of IT to enhance a person’s domain relevant skills is an importantinput into the innovation process. To the degree that IT enhances the knowledge baseavailable to each employee (INE) and allows these employees to work together (INS),innovativepotentialisincreased.Forexample,consultationthroughinformallateralchannelsimproves employees’ ability to keep up with changes in techniques and new knowledge,helping them understand and adopt innovations (e.g., Abbott, 1991; Rice & Aydin, 1991).Constant et al.’s (1996) study examining the impact of advice offered through electronicweak ties also supports the idea that IT can build domain skills. They found that electronicweak ties offered information seekers useful technical information or referrals. Informationprovidersgavevaluableadviceandhelpedsolvetheproblemsofinformationseekersdespitethe lack of personal relationship with requesters.\nAt a more macrolevel, as discussed earlier, IT is changing organizational forms and\npromoting creativity and innovation inside virtual organizational forms. Some authorssuggest that the real power of IT enabled virtual forms is when relationships amongelectronically connected people or ﬁrms produce new and/or qualitatively different commu-nication that yields product or process innovation (Ring & Van de Ven, 1994). For example,one type of IT-enabled interorganizational relationship noted by Venkatraman (1994) isknowledge leveraging, the sharing and integrating of expertise within a team or partnershipthrough real-time, interconnected IT. Some beneﬁts from these arrangements include thedevelopment of cross-functional synergies which may result in competitive advantage in theform of product or service differentiation. Unlike more rigid bureaucratic organizationalforms, new IT-enabled forms are viewed as more innovatively responsive to varied envi-ronmental pressures such as heightened market volatility, the globalization of business,increased uncertainty, and demographic changes in labor and consumer sectors (Daft &Lewin, 1993; Halal, 1994; Heydebrand, 1989).\nAs in the case of efﬁciency, the ways in which IT can promote innovation are only now\nbeing discovered. IT enhances the possibilities of furthering creative and coordinatedbehaviors at all levels both inside and between organizations, a topic we turn to next.\n3. IT: The link between organizational characteristics and organizational\noutcomes\nIn this section we address the other component of our conceptual model, the role IT plays\nin moderating the relationship between organizational-level characteristics and the organi-zational outcomes we have just identiﬁed and reviewed. Speciﬁcally, we consider how ITmoderates the effects of organizational structure, size, learning, culture, and interorganiza-tional relations on the two most strategic organizational outcomes just discussed, efﬁciencyandinnovation.Sinceresearchconcerningtheseissuesisinitsinfancy,ourdiscussionbelowshould be treated as a series of concerns, suggestions, or assertions that future researchersmight ﬁnd useful as a guide to the way they frame their research studies.327 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–3463.1. Structure\nResearchlinkingorganizationalstructuretooutcomessuchasefﬁciencyorinnovationhas\nalways resulted in conﬂicting research ﬁndings because of the existence of contingencyfactors such as the environment, strategy, or technology that may affect the nature of therelationship (Child, 1972; Fry, 1982). For example, in relation to innovation, Damanpour’s(1991)researchaddressedwhatmanyscholarshavesuggestedareinconsistentﬁndings(e.g.,Dewar & Dutton, 1986; Kimberly & Evanisko, 1981; Zmud, 1982). His meta-analysis ofover forty studies found that specialization, formalization, centralization, and vertical dif-ferentiation were all meaningfully correlated with innovation such that innovation waspromoted in more organic organizational settings. Drawing on Damanpour (1991), who inturn drew on the work of earlier organizational theorists (e.g., Blau, 1970; Pugh, Hickson,Hinings, MacDonald, Turner, & Lupton, 1963), the way IT moderates the effects of thesestructural dimensions on organizational outcomes is discussed below.\n3.1.1. Specialization\nSpecialization typically refers to the number of different specialties or job types in a ﬁrm\n(e.g.,Aiken,Bacharach&French,1980;Hage&Aiken,1967).Specializationtypicallyleadsto the development of subunit orientations that reduce peoples’ abilities to understand thewider context within which they are contributing their skills and expertise (Lawrence &Lorsch, 1968). IT can mitigate this tendency by providing greater information access tospecialiststhroughsuchtechnologiesasemail,corporateintranets,accesstotheinternet,andso on. Easier access to information sources provides INE. Thus, for any given decision theyface, employees will be better able to understand how their decision options mesh with theother decisions being made that are most closely related to their own area of work, how theyrelate to ﬁrm goals and objectives, and how well their options align with industry practices.In the absence of IT, this knowledge is often only available afterwards and employees maymake decisions without regard for their organizational-level implications (Ciborra & Lan-zara, 1990). When employees have a wider, and more immediate, appreciation of theorganization innovation is more likely because information that is potentially useful for agiven innovative effort is only as useful as it is timely and can be quickly assimilated(Barabba & Zaltman, 1990).\nFurther, consider the model of innovation noted earlier by Amabile (1988) where one of\nthe main organizational factors impacting innovation is resources in the task domain.Amabilearguesthatresourcesinthetaskdomain(deﬁnedasanareatargetedforinnovation)include people with knowledge of the feasibility of implementing particular innovations,people who have familiarity with relevant markets, and people with other types of relevantexperience in the domain. All of these resources are knowledge based, innovation requiresthe contribution of specialist knowledge, and in as much as IT can help to overcome thedistance between specialists, innovative potential will increase.\n3.1.2. Formalization\nFormalization is the process of developing routine responses to recurring problems or\nopportunities that specify how individuals and functions are to coordinate their actions to328 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346accomplish organizational goals (e.g., Aiken et al., 1980; Blau & McKinley, 1979; Ettlie,\nBridges & O’Keefe, 1984). Formalization can be achieved through the use of rules andstandard operating procedures and through the development of common and shared normsand values (Weber, 1947). Fundamentally, formalization speaks to the desire for lessambiguity and more efﬁciency (Perrow, 1986), goals that IT is particularly suited to address.IT facilitates the recording and retrieval of information about organizational events andactivities making the control of behaviors and processes through formalization more viable(Huber,1990).ITofferstheabilitytodiminishthenegativeeffectsofformalization-thecostof search associated with locating company resources detailing relevant standards andprocedures. To the degree that IT leads to INE by reducing search times and interruptions inworkﬂow, the administrative cost of formalization is reduced, increasing efﬁciency, and bycontributing to slack resources this can be beneﬁcial to the pursuit of innovation (Daft &Becker, 1978; Miller & Friesen, 1982).\nSupportforthisperspectiveisprovidedbyGroth(1999)whoanalyzedthewayITaffected\nthe development of the Boeing 777. The 777 was the ﬁrst aircraft which was completelydesignedusingreal-timeITthatcoordinatedtheactivitiesofover5000peopleatovertwentysitesintwodifferentcountries.Boeing’snewITsystemmanagedthousandsofdrawingsanddocuments which were studied, evaluated, updated, and changed constantly. Subsequent useof this system has allowed Boeing to create custom versions of the aircraft in 18 monthscompared to the traditional average of 52 months (Groth, 1999).\n3.1.3. Centralization/decentralization\nCentralization refers to the extent to which decision making authority is dispersed or\nconcentrated in an organization (Pfeffer, 1981). Traditionally, input into corporate andoperational strategies has been the domain of top management. Because of increaseddomestic and global competition throughout the 1990s, many ﬁrms have begun to movestrategic decision making lower in the organization to take advantage of specialized workerswho possess more accurate and timely local information (e.g., Fulk & Dutton, 1984). ITdirectly improves such endeavors in two major ways. First, they result in INE because theyincrease local information by supplementing it with more intimate knowledge of consumerand market trends and opportunities. For example, IT in customer support centers directedat solving customer problems via the internet has become a widespread means of increasingefﬁciency.Second,ITcanproduceINSbecausetheyfacilitateincreasedcommunicationandcoordination between decentralized decision makers and central planners and upper man-agement such that local action does not necessarily become more fragmented with respect tocorporate goals as decision making authority moves lower in the hierarchy, but may actuallybecome better aligned.\nA more fundamental question is whether or not IT will lead to centralization or decen-\ntralization. In terms of centralization, by enabling managers to obtain more information,more quickly and accurately, management information systems reduce uncertainty and leadmanagers to make decisions that they otherwise may not have made (e.g., Blau, Falbe,McKinley & Tracey, 1976; Child & Partridge, 1982; Lado and Zhang, 1998). In contrast,decentralization through other forms of IT (e.g., electronic bulletin boards and discussiongroups) enable lower and middle level managers to stay better informed about the organi-329 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346zation’s overall situation and about the nature of current problems and issues allowing them\nto be more globally optimized in their work (e.g., Argyres, 1999; Fulk & Dutton, 1984;Dawson & McLoughlin, 1986; Lawler, 1998; Zenger & Hesterly, 1997).\nThe literature suggests that IT can thus enable both centralization and decentralization.\nScholars seem to agree that the use of IT allows organizations to place decision makingauthority across a greater range of hierarchical levels without sacriﬁcing decision quality ortimeliness (e.g., Groth, 1999; Huber, 1990; Keen, 1990). Keen (1990) combined the notionsof centralization and decentralization in what is termed a federated organization whereorganizations no longer have to choose between centralized and decentralized modes oforganization; IT permits simultaneous centralization-with-decentralization (e.g., Burris,1993; Keen, 1990). The effect is to move authority towards that part of the organizationwherethepertinentinformationistobeutilizedtomakeinformeddecisions,supportingwhatwe have referred to as INE. The link between this line of reasoning and INS may be foundin the literature on ambidextrous organizations which attempt to simultaneously sustaindifferent organizational architectures in order to nurture multiple types of innovations (e.g.,Tushman, Anderson & O’Reilly, 1997) suggesting that different types of innovative out-comes require different types of communication and collaboration processes.\n3.1.4. Vertical differentiation\nVertical differentiation is a function of the number of levels in the organizational\nhierarchy (Damanpour, 1991). Extending the arguments on centralization and decentraliza-tion above, one of the most powerful ways IT moderates vertical differentiation is its abilityto produce INE that allow fewer levels in the hierarchy to handle as much or more problemsolvinganddecisionmaking,resultinginaﬂatterorganization.ITsystems,byincreasingthelevelofformalizationorallowing“controlled”decentralizationcanactasasubstituteforthecontrol typically provided by a hierarchy. In addition, since IT provides lower-level em-ployees with more freedom to coordinate their actions, this results in INS as employees canexperiment and ﬁnd better ways of performing their tasks. Support for this notion is foundin the increasing incidence of ﬂat, empowered, organizational structures with virtual orga-nizations being an extreme case of low-cost organization that has begun to materialize (e.g.,Shao, Liao & Wang, 1998; Snow, Lipnack & Stamps, 1999).\nThus, the link between IT, vertical differentiation, and innovation is evident in that\ninnovation requires the sharing of information and the ability to mobilize action towardsproblem solving. To the extent that IT reduces the ﬂow of information across vertical levelsand knowledge ﬂows more freely cross-functionally (Monge & Fulk, 1995), and in concertwith more ﬂexible decision making authority across levels (Keen, 1990), opportunities canbe acted on more proactively.\n3.2. Size\nNumerous forms of network organization, based on the application of different types of\nIT, have begun to appear including the inverted organization, the spider’s web, and thestarburst (Quinn, Anderson & Finkelstein, 1996b; Ensign, 1999; Grandori, 1997; Miles &Snow, 1995). Since network organizations permit ﬁrms to increase the value they can create330 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346while forgoing the need to increase in size (in terms of numbers of employees or assets),\nseveral authors (e.g., Groth, 1999; Fulk and DeSanctis, 1995) have suggested that IT maylimit or even reduce ﬁrm size in the traditional sense. For example, Brynjolfsson, Malone,Gurbaxani and Kambil (1994) ﬁnd broad support for the contention that investments in ITare signiﬁcantly associated with decreases in the average size of ﬁrms across severalmeasures of size. They suggest that one explanation is organizations’ increasing reliance onmarkets for coordinating value creation activities following investments in IT, such as thegrowth in business-to-business networks.\nIn addition, others have argued that IT reduces size because INEs will lead to fewer\nnumbers of middle managers (e.g., Groth, 1999) as the role of subordinates who provide theanalysis that supports high-level decision making is reduced (Rockart & DeLong, 1988).This thought is echoed by Fulk and DeSanctis (1995) who suggest that the most commonobservation in the discussion of new organizational forms is the dwindling ranks of middlemanages and administrative support. The ability of IT to facilitate a reduction in workforcesize has been shown repeatedly. For example, a textile ﬁbers division of DuPont was one ofthe ﬁrst to adopt early retirement incentives in an effort to downsize. Unexpectedly, abouthalf of the divisions middle tier of managers decided to take the early retirement package.DuPont executives now claim that if it were not for their newly installed electronic mailsystem they might not have survived the loss of so many managers at one time (Davenport& Prusak, 1997).\nOn the other hand, recent literature examining the effect of IT on ﬁrm size (Huber, 1990)\ncombined with an examination of modern industry trends towards merger and acquisition ofeven the largest companies, for example, oil and gas or entertainment, suggests that IT mayallow organizations to become bigger without any sacriﬁce of efﬁciency or innovativeness;indeedlargersizemayleadtoeconomiesofscaleinmanaginginputandoutputtransactions.There has been little or no research into these issues, and future research needs to take intoaccount the fact that in some instances although ﬁrms may be growing larger in terms of thenumber and scope of their activities so that the numberof internal decision making units\nincreases; the sizeof the units themselves may be shrinking because of the effect of INEs\nnoted above.\n3.3. Learning\nIn an effort to achieve success in uncertain, dynamic environments practitioners and\nscholars alike have focused attention on the concept of learning because organizationallearning is a key antecedent of innovation (Hurley & Hult, 1998). In industry, this trend hasbecomehighlyvisible.ChiefKnowledgeOfﬁcersandChiefLearningOfﬁcershaveappearedat Coca-Cola, General Electric, Sequent Computer, Young & Rubicam, and many leadingconsulting ﬁrms such as Ernst & Young, Coopers & Lybrand, and Booz-Allen and Hamilton(Davenport&Prusak,1997)as“knowledgemanagement”becomesincreasinglyinvogue.Ina similar vein, techniques to increase organizational efﬁciency, such as those that comprisetotalqualitymanagement(Reger,Gustafson,Demarie&Mullane,1994)arealldependentonthe ability of managers and workers to learn and assimilate new ways of thinking andbehaving.ITcanplayanimportantroleintheseprocessesbyprovidingemployeeswitheasy331 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346and ﬂexible access to information and by facilitating problem solving, thus promoting\nlearning (e.g., Huber, 1990; Malone & Rockart, 1991).\nPerhaps the most relevant treatment of the learning construct in regards to IT is the\nconcept of absorptive capacity. Cohen and Levinthal (1990) deﬁne absorptive capacity as aﬁrm’s ability to recognize the value of new external information, assimilate it, and apply itcommercially. They argue that this ability is premised on the organization’s level of priorexistingknowledge-whichincludesfactorssuchasbasicskillspossessedbyemployees,thecommon language they share and also includes knowledge of the most recent scientiﬁc ortechnological developments in a given ﬁeld. Thus when IT, through INE and INS, promoteslearning derived from absorptive capacity this may result in increased organizational efﬁ-ciency and innovation. For example, IT may generate an increased ability to process newknowledge and promote product development (Nonaka, 1990); the reconﬁguration of exist-ing knowledge to form architectural innovations (Henderson & Clark, 1990), and so on.\nAbsorptive capacity has two dimensions, knowledge assimilation and knowledge integra-\ntion (Cohen & Levinthal, 1990). With regard to knowledge assimilation, Cohen andLevinthal (1990) suggest ﬁrms should collect many sources of internal and external infor-mation. The use of IT (e.g., electronic mail, use of the internet to meet as part of on-lineassociations or to subscribe to third party data sources) provides the requisite boundaryspanning capabilities to collect relevant information and offers INE relative to traditionalmeans of collecting such data. The use of IT for codiﬁcation purposes translates thisinformation into a more widely accessible format for use by the organization, another resultof INE. With respect to knowledge integration, various IT applications (e.g., groupware,project management programs, video conferencing) provide an infrastructure through whichto integrate and circulate knowledge to achieve knowledge optimization, building thepotential for INS and innovation. Here it is important to recognize that a ﬁrm’s absorptivecapacity is not simply the sum of individual’s absorptive capacity, rather it depends on theongoing exchanges of individuals embedded in organizations who continually share theirknowledge and expertise, building upon the notion that information sharing is critical toorganizational knowledge since intellectual assets, unlike physical assets, increase in valuewith use (Quinn et al., 1996a).\n3.4. Culture\nCulture can be deﬁned as a complex pattern of beliefs, expectations, ideas, values,\nattitudes,andbehaviorssharedbythemembersofanorganization(Trice&Beyer,1993).ITfacilitates the sharing of beliefs, values and norms because it allows for the quick and vividtransmission of rich information between people and subunits. Hence, IT can moderate theeffects of culture on employee attitudes, beliefs, values, and behaviors in several ways.\nIT can help enhance the motivational effects of cultural values that are supportive of\nefﬁciency or innovation. Using IT an organization can make available to employees a slewof supportive messages and statements, often contained in an organization’s mission andvision, corporate goals, strategies, operating procedures, and so on. Email, voicemail, andintranets, for example, provide mechanisms for transferring and disseminating informationabout the organization to employees and can help promote the cultural shared norms, values,332 T. Dewett, G.R. Jones / Journal of Management 27 (2001) 313–346and expectations that can facilitate support for efﬁciency or innovation. Increased exposure\nto colleagues’ efforts; the richer information context stemming from an increasing numberofpossibleinformationsources,andaccesstomoreindividualstocollaboratewith,increasesthe potential for INE and INS. To the extent that organizational members perceive that theiruseofITisincreasingtheireffectivenessinfulﬁllingorganizationalgoals,theiruseofITwillbecome self-reinforcing (Huber, 1990). Over time this implies possible changes and modi-ﬁcations in the use of IT as employees ﬁnd new and appropriate uses for the technology, asnoted in our conceptual model.\nNote that IT can be used to accomplish very different outcomes depending on the value\nattributed to the outcome (Leidner & Elam, 1995). As a result there is a need for a culturalunderstanding of IT in the organization. For example, Zack and McKenney (1995) exploredthe use of computer-mediated communication (CMC) and concluded that past research hastoo often assumed that given an appropriate design, once the IT is implemented, commu-nicationsprocessesandpatternswillchangeinthedesiredandintendedways.TheydisagreeandnotethatrarelyisthecultureorsocialcontextthatisrequiredtosupporttheITexamined.Whether on not a given IT moderates the effects of culture on organizational outcomesdependsontheparticularsocialcircumstancesinwhichtheITisapplied(e.g.,Fulk&Boyd,1991). Zack and McKenney (1995) demonstrate that distinct groups within an organizationcan have very different patterns of IT use given the different culture or social context withinwhich they are embedded (controlling culture not conducive to sharing information vs. acommitment oriented culture providing clear support for the sharing of information).\nFor new communications media, social explanations of use are important given that\nstandard ways of communicating by these means have not yet become fully institutionalized(Sitkin, Sutcliffe & Barrios-Choplin, 1992; Webster & Trevino, 1995). For example, overtime, as employees develop attitudes towards a new IT and beliefs about its usefulness, thesymbolic meanings imposed by peers and superiors will be instrumental in determiningorganizational outcomes. For example, Isaksen, Lauer and Ekvall (1999) suggest that whenemployees feel welcome to present new ideas and express a wide variety of viewpoints thiswill make the organization supportive of innovation. Research has demonstrated that share', 'raytos.bsinfotech@gmail.com', ' Todd Dewett, Gareth R. Jones', '', '../pdf_files/674d4f24171f8-The role of information technology in the organization - a review, model, and assessment.pdf', 198010, 34, 14833, 115270, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(59, '6115264080', '51', 5, 5, 'Information Technology and  Productivity: A Review  of the Literature ', '2024-12-02 14:11:29.328631', '1999', 'In recent years, the relationship between information technology (IT) and productivity has become a source of debate. In the 1980s and early 1990s, empirical research on IT productivity generally did not identify significant productivity improvements. More recently, as new data are identified and more sophisticated methodologies are applied, several researchers have found evidence that IT is associated not only with improvement in productivity, but also in intermediate measures, consumer surplus, and economic growth. Nonetheless, new questions emerge as old puzzles fade. This survey reviews the literature, identifies remaining questions, and concludes with recommendations for applications of traditional methodologies to new data sources, as well as alternative, broader metrics of welfare to assess and enhance the benefits of IT.', 'IT,Technology,Information Technology', 'Information Technology and \nProductivity: A Review \nof the Literature \nERIK BRYNJOLFSSON AND SHINKYU YANG \nMIT Sloan School of Management \nCambridge, Massachusetts \nAbstract \nIn recent years, the relationship between information technology (IT) and pro- \nductivity has become a source of debate. In the 1980s and early 1990s, empirical \nresearch on IT productivity generally did not identify significant productivity \nimprovements. More recently, as new data are identified and more sophisticated \nmethodologies are applied, several researchers have found evidence that IT is \nassociated not only with improvement in productivity, but also in intermediate \nmeasures, consumer surplus, and economic growth. Nonetheless, new questions \nemerge as old puzzles fade. This survey reviews the literature, identifies remain- \ning questions, and concludes with recommendations for applications of tradi- \ntional methodologies to new data sources, as well as alternative, broader metrics \nof welfare to assess and enhance the benefits of IT. \n1. The “Productivity Paradox”-A Clash of Expectations and Statistics ...... 179 \n2. Research on Economy-wide Productivity and Information Worker \nProductivity ................................. 187 \n3. Industry-Level Studies of Information Technology Productivity. ........ 192 \n4. Firm-Level Studies of Information Technology Productivity .......... 196 \n4.1 Service Sector Studies. ........................ 196 \n4.2 Studies of Manufacturing Sector and Cross-Sector Studies. ........ 198 \n5. Contribution to Consumer Surplus and Economic Growth ........... 201 \n6. Conclusion: Where Do Wc Go from Here? .................. 205 \nBibliography. ................................ 209 \n1. The “Productivity Paradox”-A Clash of \nExpectations and Statistics \nDuring the past decade, both academics and the business press have \nperiodically revisited the so-called “productivity paradox” of computers: \n179 Copyright 0 1996 by Academic Pre%, Inc \nAll rights of reproductinn In any form rewved ADVANCES IN COMPUTERS. VOL 43 180 ERIK BRYNJOLFSSON AND SHINKYU YANG \nWhile delivered computing power in the United States has increased by \nmore than two orders of magnitude since the early 1970s (Fig. l), productiv- \nity, especially in the service sector, seems to have stagnated (Fig. 2). Despite \nthe enormous promise of information technology (IT) to effect “the biggest \ntechnological revolution men have known” (Snow, 1966), disillusionment \nand frustration with the technology are evident in headlines like “Computer \nData Overload Limits Productivity Gains” (Zachary, 1991). \nInterest in the “productivity paradox” has engendered a significant \namount of research. Although researchers analyzed statistics extensively \nduring the 1980s, they found little evidence that information technology \nsignificantly increased productivity. As Robert Solow quipped, “you can \nsee the computer age everywhere but in the productivity statistics.”’ \n80 \n70 \n20 \n10 \n0 \n1955 1960 1965 1970 1975 1980 1985 1990 1995 \nYear \nFIG. 1. Investment in information technology is growing at a rapid pace. [Note: Constant \ndollars (base year 1987) calculated by hedonic price method, see Dulberger (tYXY).] [Based \non data from BEA, National Income and Wealth Division, and adapted from Jorgenson and \nStiroh (1995).] \n’ Solow, Robert M., “We’d Better Watch Out,” New York Times Book Review, July 12, \n1987, p. 36. \nINFORMATION TECHNOLOGY AND PRODUCTIVITY 181 \n30‘ \n5 Mfg. \nNon Mfg. \n1945 1955 1965 1975 1985 1995 \nYear \nFIG. 2. Productivity in the service sector has not kept pace with that in manufacturing. \n(Based on data from Bureau of Labor Statistics, Productivity & Testing Division.) \nNow, after some researchers found firm-level evidence that IT invest- \nments earned hefty returns, the media pendulum has swung in the opposite \ndirection. Businessweek’s proclamation of “the productivity surge” due to \n“information technology,”2 and Fortune magazine’s headline heralding the \narrival of “technology payoff”-’ represent the latest trend. A growing num- \nber of academic studies also report positive effects of information technol- \nogy on various measures of economic performance. \nJust as the business media’s premature announcement of a “productivity \nparadox” was out of proportion to the more carefully worded academic \nresearch, the current cover stories on “productivity payoff” are often over- \nblown. A consensus on the relationship between IT investment and eco- \nnomic performance is still elusive. More than a decade ago, one of the \nearliest surveys concluded that we still had much to learn about measuring \nthe effects of computers on organizations (Attewell and Rule, 1984). A \nmore recent survey also reports a “sobering conclusion: our understanding \nof how information technology affects productivity either at the level of \nthe firm or for the economy as a whole is extremely limited” (Wilson, 1995). \n* Wildstrom, Stephen H. “The Technology Payoff,” Businessweek June 14, 1993, p. 56-68. \nMandel, Michael J., “The Digital Juggernaut,” Businessweek, The Information Revolution, \nMay 18,1994, Bonus Issue, pp. 22-31. Businessweek recently ran another cover story, “Produc- \ntivity to the Rescue,” October 9, 1995. \nMagnet, Myron, “Productivity Payoff Arrives,” Fortune, June 27, 1994, pp. 77-84. 182 ERIK BRYNJOLFSSON AND SHINKYU YANG \nAs more research is conducted, we are gradually developing a clearer \npicture of the relationship between IT and productivity. However, produc- \ntivity measurement is not an exact science; the tools are blunt, and the \nconclusions are not definitive. Thus, while one study shows a negative \ncorrelation between total factor productivity and high share of high-tech \ncapital formation during the 1968-86 period (Berndt and Morrison, 1995), \nanother study suggests that computer capital contributes to growth more \nthan ordinary capital (Jorgenson and Stiroh, 1995). More recently, Brynjolf- \nson and Hitt (1996) report positive effects of IT based on firm-level evi- \ndence. \nThis article seeks to summarize what we know; distinguish the central \nissues from peripheral ones; and clarify the questions that future research \nshould explore. Results and implications of different studies should be \ninterpreted in the context of specific research questions. The question of \naggregate economic performance differs from the question of firm-level \neconomic performance. Data sources and performance measures may also \ndepend on the level of aggregation. Even within one level of aggregation, \nresults may depend on the measure of performance or research method. \nIt is hoped that the process of reviewing studies of the productivity mystery \nwill serve as a useful springboard for examining alternative methodologies \nand the broader issues involved. \nAs a prelude to the literature survey, it is useful to define some of the \nterms used and to highlight some of the basic trends in the economics of IT. \nDefinitions: \n0 Information technology can be defined in various ways. In terms of \ncapital, among the most common is the BEA’s (U.S. Bureau of Eco- \nnomic Analysis) category “Office, Computing and Accounting Machin- \nery” (OCAM), which consists primarily of computers. Some research- \ners look specifically at computer capital, whereas others consider the \nBEA’s broader category, “Information Processing Equipment (IPE).” \nIPE includes communications equipment, scientific and engineering \ninstruments, photocopiers, and related equipment. In addition, soft- \nware and related services are sometimes included in the IT capital. \nRecent studies often examine the productivity of information systems \nstaff, or of workers who use computers. \n0 Labor productivity is calculated as the level of output divided by a \ngiven level of labor input. Multifactor productivity (sometimes more \nambitiously called total factor productivity) is calculated as the level \nof output for a given level of several inputs, typically labor, capital, \nand materials. In principle, multifactor productivity is a better measure INFORMATION TECHNOLOGY AND PRODUCTIVITY 183 \nof a firm or industry’s efficiency because it adjusts for shifts among \ninputs, such as substituting capital equipment for labor. However, the \ndata needed to calculate multifactor productivity are more complex. \n0 In productivity calculations, output is defined as the number of units \nproduced times their unit value, proxied by their real price. Determin- \ning the real price of a good or service requires the calculation of \nindividual price deflators to eliminate the effects of inflation. \nTrends: \nThe price of computing has dropped by half every 2-3 years (Figs. 3a \nand b).4 If progress in the rest of the economy had matched progress \nin the computer sector, a Cadillac would cost $4.98, while 10 minutes’ \nlabor would buy a year’s worth of groceries.’ \n0 There have been increasing levels of business investment in informa- \ntion technology equipment. These investments now account for more \nthan 10% of new investment in capital equipment by American firms \n(Fig. 4, Table II).6 \nInformation processing continues to be the principal task undertaken \nby America’s workforce. More than half the labor force is employed \nin information-handling activities (Fig. 5) \n0 Overall productivity growth appears to have slowed significantly since \nthe early 1970s and measured productivity growth has fallen especially \nsharply in the service sectors, which account for 80% of IT investment \n(Fig. 2, Table 4). \nWhite collar productivity statistics have been essentially stagnant for \n20 years (Fig. 6). \nThis relationship has been dubbed “Moore’s law” after John Moore, who first documented \nthe trend in microprocessors. It is widely projected to continue at least into the next century. \nIn the last 35 years, the quality-adjusted costs of computing have decreased over 6000-fold \nrelative to equipment prices outside the computer sector (Gordon, 1987b). ’ This comparison was inspired by the slightly exaggerated claim in Forbes Magazine 11980) \nthat “If the auto industry had done what the computer industry has done, . . . a Rolls-Royce \nwould cost $2.50 and get 2.000,OOO miles to the gallon.” The $4.98 Cadillac is based on a price \nof $30,890 for a 1991 Sedan de Ville divided by 6203, the relative deflator for computers. The \ngrocery comparison is based on a wage of $10 an hour and $10,000 worth of groceries, each \nin 1991 dollars. ’ Some studies estimate that as much as 50% of recent equipment investment is in informa- \ntion technology (Kriebel, 1989). This higher figure seems to be partly due to a broader \ndefinition of IT. A discrepancy also arises when recent investments are expressed in 1982 \ndollars, when IT was relatively more expensive. This has the effect of boosting IT’S real share \nover time faster than its nominal share grows. The recent change by BEA to a chain-weighted \nindex, instead of a fixed-weight index, will largely alleviate this problem. b 1ooO.O \nlW.0 \n10.0 \n1 .o \n0.1 \n1955 1960 1965 1970 1975 1980 1985 1990 \nYear \n52%/year \n42%iyear growth \ngrowth \nYear \n-#-Mcroprocessor A DRAM \nFIG. 3. (a) The cost of computing has declined substantially relative to other capital pur- \nchases. PDE, producer’s durable equipment. (Based on data from U.S. Department of Com- \nmerce, Survey of Current Business.) (b) Microchip performance has shown uninterrupted \nexponential growth. (P6, P7 microprocessors and 256M, lG, 4G DRAMS are estimated by \nIntel and the Semiconductor Industry Association.) [Based on data from Grove (1990), and \nIntel data. Trend lines are by authors’ estimations.] \nINFORMATION TECHNOLOGY AND PRODUCTIVITY 185 \n0.2 \n0.16 \n0.14 \n0.12 \nu f 0.1 \nr t \n0.08 \n0.06 \n0.04 \n0.02 \n0 \n1558 1963 1968 1973 1978 1983 1988 1993 1998 \nYear \nFIG. 4. Computers comprise about 10% of current-dollar investment in PDE. (Based on \ndata from BEA, National Income and Wealth Division.) \nThese trends suggest the two central questions of the productivity paradox: \n(1) Why would companies invest so heavily in information technology if it \ndid not add to productivity? (2) If information technology does contribute \nto productivity, why is its contribution so difficult to measure? \nThis article builds on a number of earlier literature surveys.’ This review \nconsiders more than 150 articles, but is not comprehensive. Rather, we aim \n’ Much of the material is adapted from a previous paper by Brynjolfsson (1993). Crowston \nand Treacy (1986) surveyed 11 articles from 1975 to 1985 on the impact of IT on enterprise- \nlevel performance and conclude that attempts to measure the impact of IT were surprisingly \nunsuccessful. They attribute this to poorly defined variables, a result of inadequate reference \ndisciplines and methodologies. A review of research combining information systems and \neconomics, by Bakos and Kemerer (1992), includes particularly relevant work. In addition, \nmany papers that seek to assess IT productivity directly begin with a literature survey: the \nreviews by Brooke (1992), Barua ef al. (1991), and Berndt and Morrison (1995) were particu- \nlarly useful. Most recently, the first part of Landauer (1995) details research on the productivity \npuzzle. Wilson (1995) also provides a useful survey of articles. \n186 ERIK BRYNJOLFSSON AND SHINKYU YANG \n120 \n.* P \n%I10 - \nY \ne \n:! Q \nPI 8 100 \n3 go \n80 50 \n- White Collar \nProductivity - Infomation \nAgricultum \nIndustry _c_ \n!bNb -+.-.. \n0 \n1850 1800 in50 2000 \nYear \nFic. 5. Information processing is the largest category of employment. The defining criterion \nfor information workers is whether the primary activity is knowledge creation, warehousing, \nor dissemination. [Based on data from Porat (1977).] INFORMATION TECHNOLOGY AND PRODUCTIVITY 187 \nto clarify the principal issues surrounding IT and productivity. We assimilate \nthe results of a computerized literature surrounding IT and productivity. \nWe assimilate the results of a computerized literature search of 30 leading \njournals in information systems and economics.8 In addition, many of the \nleading researchers in this area identified recent research that has not yet \nbeen published. \nThe productivity of IT can be measured using data on the whole economy, \non specified industries, or on individual firms. In the 1980s and early 1990s, \ndisappointment in information technology was chronicles in articles disclos- \ning broad negative correlations with economy-wide productivity. Several \neconometric estimates also indicated low IT capital productivity in a variety \nof manufacturing and service industries. More recently, researchers began \nto find positive relationships between IT investment and various measures \nof economic performance at the level of individual firms. The principal \nempirical research studies of IT and productivity are listed in Table I. \n2. Research on Economy-wide Productivity and \nInformation Worker Productivity \nEconomists have been unable to explain the slowdown in measured \nproductivity growth that began in the early 1970s. Labor productivity grew \nabout 2.5% per year from 1953 to 1968, but dropped to about 0.7% per \nyear from 1973 to 1979. Multifactor productivity growth declined from \n1.75% a year to 0.32% (Baily, 1986b). Even after accounting for factors \nsuch as the oil price shocks, changes in the quality of the labor force, and \npotential measurement errors, most researchers still find an unexplained \nresidual drop in productivity that roughly coincides with the rapid increase \nin the use of information technology. \nJorgenson and Stiroh\'s (1995) more recent growth accounting confirms \nthis correlation. They calculate that average multifactor productivity growth \ndropped from 1.7% per year for the 1947-73 period to about 0.5% for the \n\' The journals searched were American Economic Review, Bell (Rand) Journal of Econom- \nics, Brookings Papers on Economics and Accounting, Econometrica, Economic Development \nReview, Economica, Economics of Innovation and New Technology, Economics Journal, \nEconomist (Netherlands), In formation Economics & Policy, International Economics Review, \nJournal of Business Finance, Communications of the ACM, Database, Datamation, Decision \nSciences, Harvard Business Review, IEEE Spectrum, IEEE Transactions on Engineering Man- \nagement, IEEE Transactions on Software Engineering, Information & Management, Interfaces, \nJournal of MIS, Journal of Systems Management, Management Science, MIS Quarterly, Opera- \nrions Research, and Sloan Managemenr Review. Articles were selected if they indicated an \nemphasis on computers, information systems, information technology, decision support sys- \ntems, expert systems, or high technology combined with an emphasis on productivity. TABLE I \nPRINCIPAL EMPIRICAL STUDIES OF IT AND PRODUCT~VITY \nCross-sector Manufacturing Services \nAggregate-level studies \n(economy-wide and \nindustry-level) \nMicro-level studies \n(firm and workers) Jonscher (1983, 1994) \nBaily (1986b), Baily & Chakrabarti (1988). \nRoach (1987, 1989b) \nBrooke (1992) \nLau & Tokutsu (1992) \nOliner & Sichel (1994) \nJorgenson & Stiroh (1995) \nOsterman (1986) \nDos Santos er al. (1993) \nKrueger (1993) \nBrynjolfsson & Hitt (1994) \nHitt & Brynjolfsson (1994) \nLichtenberg (1995) \nBrynjolfsson & Hitt (1996) Baily & Gordon (1988) Morrison & Berndt (1991) \nBerndt et al. (1992) \nBerndt & Morrison (1995) \nSiegel & Griliches (1992) \nSiegel (1994) Brand & Duke (1982) \nBaily (1986a) \nRoach (1987, 1989a, 1991) \nLoveman (1994) \nWeill (1992) \nDudley & Lasserre (1989) \nBarua er al. (1991) \nBrynjolfsson & Hitt (1993, 1995, 1996) Cron & Sobol (1983) \nPulley & Braunstein (1984) \nBender (1986) \nBresnahan (1986) \nFranke (1987) \nStrassmann (1985, 1990) \nHarris & Katz (1991) \nParsons et al. (1990) \nDiewert & Smith (1994) INFORMATION TECHNOLOGY AND PRODUCTIVITY 189 \n1973-92 period. At the same time, OCAM capital as a percentage of all \nproducers’ durable equipment (PDE) investment rose from about 0.5% in \nthe 1960s to 12% in 1993. A broader category of IT capital, information \nprocessing equipment (IPE), now constitutes 34.2% of all PDE investment \n(Table 11). Although productivity growth, especially in manufacturing, has \nrebounded somewhat recently, the overall negative correlation between \nproductivity and the advent of computers underlies many arguments that \ninformation technology has not helped the United States’ productivity and \nthat information technology investments have been counterproductive. \n[see, for example, Baily (1986b)l. \nThis argument was made more explicitly by Stephen Roach (1987,1988) \nwho focused on the productivity of information workers. In the past, office \nwork was not very capital intensive, but recently the level of IT capital \nper “white collar” information worker has approached that of production \ncapital per “blue collar” production worker. Concurrently, the ranks of \ninformation workers have ballooned and the ranks of production workers \nhave shrunk. Roach shows that output per production worker grew by \n16.9% between the 1970s and 1986, while output per information worker \ndecreased by 6.6%. He concludes: “America’s productivity shortfall [is] \nconcentrated in that portion of the economy that is the largest employer of \nwhite-collar workers and the most heavily endowed with high-tech capital.” \nRoach’s analysis provided quantitative support for widespread reports of \nlow office productivity.’ \nBut the economy’s productivity record in the 1970s and 1980s cannot be \nblamed on the investment in information technology; many other factors \nalso affect productivity and, until recently, computers were not a major \nshare of the economy. Consider an order of magnitude estimate. In 1992, \nIT capital stock (OCAM) was equal to about 10% of GDP (with a base \nyear of 1987). If, hypothetically, IT’S marginal product were 50% (exceeding \nthe return to most other capital investments), then the level of gross domes- \ntic product (GDP) would be directly increased about 5% (10% X 50%) \nbecause of the current stock of IT. However, information technology capital \nstock did not jump to its current level in 1 year; rather, the increase must \nbe spread over about 30 years, suggesting an average annual contribution \nto aggregate GDP growth of 0.15%. This contribution would be very difficult \nto isolate because so many other factors affected GDP, especially in the \nrelatively turbulent 1970s and 1980s. Indeed, if the marginal product of IT \nFor instance, Lester Thurow (1987) has noted that “the American factory works, the \nAmerican office doesn’t,’’ citing examples from the auto industry indicating that Japanese \nmanagers are able to get more output from blue collar workers (even in American plants) \nwith up to 40% fewer managers. \'1 90 ERIK BRYNJOLFSSON AND SHINKYU YANG \nTABLE I1 \nSELECTED INVESTMENT COMPONENTS IN 1970 AND 1993 \n(CURRENT. DOLLARS) \nPercentage of Percentage of \nInvestment Fixed Investment Fixed \n1970 Investment PDE 1993 Investment PDE \nItem \\ Year ($ Billion) (910) (%) ($ Billion) (%) \nFixed investment 148.1 \nNonresidential 106.7 \ninvestment \nPDE 66.4 \n(nonresidential) \ninformation 14.3 \nprocessing \nOCAM 4.1 \nComputer 2.7 \nIndustrial 20.2 \nTransportation 16.1 equipment \nequipment 100.0 \n72.05 \n44.83 \n9.66 \n2.77 \n1.82 \n13.64 \n10.87 866.7 \n616.1 \n100.00 442.7 \n21.54 151.5 \n6.17 53.7 \n4.07 47 .O \n30.42 96.7 \n24.25 104.2 100.0 \n71.1 \n51.1 100.0 \n17.5 34.2 \n6.2 12.1 \n5.4 10.6 \n11.2 21.8 \n12.0 23.5 \nSources: Survey of Current Business, July 1994; U.S. Bureau of Economic Analysis (1992, \nNote: Information processing equipment: OCAM (office, computing and accounting machin- Vol. 2. Tables 5.4 and 5.8); adapted from Oliner and Sichel (1994). \nery), communication equipment, and scientific and engineering equipment. \ncapital were anywhere from 0 to +65%, it would still not have affected \naggregate GDP growth by more than about 0.2% per year.\" More compre- \nhensive growth accounting exercises confirm this estimate (see Section 5). \nThus, very large changes in capital stock are needed to change total \noutput measurably, although computers may have had significant effects \nin specific activities, such as transaction processing, and on other characteris- \ntics of the economy, such as employment shares, organizational structure, \nand product variety. However, as the information technology stock contin- \nues to grow and the share of the total economy accounted for by computers \nbecomes substantial, we should begin to find changes in the level of aggre- \n\'\" Each white collar worker is endowed with about $10,000 in IT capital, which at a 50% \nROI, would increase his or her total output by about $5000 per year over precomputer levels \nof output. In contrast, it costs about $100,000 or so in salary and overhead to employ a white \ncollar worker. INFORMATION TECHNOLOGY AND PRODUCTIVITY 191 \ngate GDP.” Some recent studies report a high contribution of computers \nto GDP growth [see, for example, Jorgenson and Stiroh (1995)l. \nJust as it is hard to isolate information technology’s effect on the econ- \nomy, white collar productivity cannot be directly inferred from the number \nof information workers per unit of output. For instance, if a new delivery \nschedule optimizer allows a firm to substitute one clerk for two truckers, \nthe increase in the number of white collar workers is evidence of an increase \nin their relative productivity as well as the firm’s productivity. Osterman \n(1986) suggests that such efficiency improvements can explain why firms \noften hire more clerical workers after they introduce computers, and Berndt \net al. (1992) confirm that information technology capital is, on average, a \ncomplement for white collar labor and is correlated with fewer blue collar \nworkers. Berman etal. (1994) also find that the “increased use of nonproduc- \ntion workers is strongly correlated with investment in computers and \nR&D.” Unfortunately, it is exceedlingly difficult to measure directly the \nproductivity of office workers. \nIndependent of its implications for productivity, growth in the white \ncollar workforce cannot be attributed solely to information technology. \nAlthough almost half of workers now use computers in their jobs (Katz \nand Kreuger, 1994), the ranks of information workers began to surge even \nbefore the advent of computers (Porat, 1977). In fact, Jonscher (1994) \nargues that the increased demand for information technology created econ- \nomies of scale and learning in the computer industry, thereby reducing the \ncost of computers. \nIn line with this argument, the unbalanced growth hypothesis may provide \na sensible economic explanation.’* Economic growth may slow down be- \ncause of intrinsically slow technical progress in the white colalr sector, since \nit is less subject to automation. Then why is the white collar sector’s share \nin the economy growing? One possible answer is the higher income elasticity \n(and lower price elasticity) of demand for services of this sector. As income \n” An important study of computer-using workers by Krueger (1993) indirectly supports \nthis view. He found that computer-using workers earned wages 10 to 18% higher than nonusers. \nIn 1984, 24.6% of workers were using computers at work. By 1989, this number had grown \nto 37.4%. Katz and Krueger (1994) also report that this share of workers had risen to 47% \nby 1993. Assuming that workers are paid according to their productivity, this implies that \ncomputers at work increase GDP level by 3% (3% = 0.7 X 0.1 X 37.4%. 0.1 is the excess \nmarginal product, and 0.7 is the labor share of GDP). Although this numbcr is not sufficient \nto compensate for the annual 1% productivity slowdown after the early 1970s. it indicates \nthat information technology may boost office worker productivity. ’’ Sce. for example, Baumol (1967), and Baumol et al. (1985). 192 ERIK BRYNJOLFSSON AND SHINKYU YANG \nincreases, people demand more services of white collar sectors. Thus, even \nif information technology does not add to productivity, companies in devel- \noped countries may be forced to invest in it. Since it is difficult to measure \nwhite collar sector output, the story becomes complicated. Companies in- \nvest in computers to produce “unmeasurables,” as argued in Griliches \n(1994). In short, the increased IT use may not be a source of the productivity \nslowdown, but simply a response to the overall transformation of the econ- \nomy. Furthermore, the main benefits from using computers appear to be \nin areas such as improved quality, variety, timeliness, and customization, \nwhich are not well-measured in official productivity statistics (Brynjolf- \nsson, 1994). \n3. Industry-Level Studies of Information \nTechnology Productivity \nThe preceding section has shown that contrasting the economy-wide \nproductivity slowdown with increasing IT investment is an obtuse ap- \nproach, because so many other factors may intervene. Going down to \nthe firm level helps to control many problems that arise from aggregation, \nbut it is often difficult to find data representative for the whole economy. \nIndustry-level studies may provide a middle-of-the-road alternative. Table \nI11 summarizes some of the important studies. We start with studies on \nservice sectors. \nIt has been widely reported that most of the productivity slowdown is \nconcentrated in the service sector (Schneider, 1987; Roach, 1987, 1991). \nBefore about 1970, service and manufacturing productivity growth rates \nwere comparable, but since then the trends have diverged significantly.I3 \nMeanwhile services have dramatically increased as a share of total employ- \nment and, to a lesser extent, as a share of total output. Because services use \nup to 80% of computer capital (Table IV), the slow growth of productivity in \nthe service sector has been taken as indirect evidence of poor information \n’’ According to government statistics, from 1953 to 1968, labor productivity growth in \nservices averaged 2.56% versus 2.61% in manufacturing. For 1973 to 1979, the figures are \n0.68% versus 1.53%, respectively (Baily, 1986b). However, Gordon and Baily (1989) and \nGriliches (1994,1995) suggest that measurement errors in US. statistics systematically under- \nstate service productivity growth relative to manufacturing. More recently, computers defi- \nnitely have caused some divergence in the statistics on manufacturing and service productivity, \nbut for a very different reason. Because of the enormous quality improvements attributed to \nthe computers, the nonelectrical machinery category (containing the computer-producing \nindustry) has shown tremendous growth. Partly, as a result, overall manufacturing productivity \ngrowth has rebounded from about IS% in the 1970s to 3.5% in the 1980s. TABLE 111 \nINDUSTRY-LEVEL STUDIES \nFindings Study Sector Data Source \nBrand (1982) Services \nRoach (1987, 1989a, 1991) Services \nMorrison & Berndt (1991) Manufacturing \nBerndt etnl. (1992), Berndt & Manufacturing \nSiegel & Griliches (1992) Manufacturing Morrison (1995) \nSiegel (1994) Manufacturing BLS\" \nPrincipally BLS, BEAU \nBEA \nBEA, BLS \nMultiple government sources \nMultiple government sources Productivity growth of 1.3%/yr in banking \nVast increase in IT capital per information worker \nand a decrease in measured output per worker \nIT marginal benefit is 80 cents per dollar invested \nIT not correlated with higher productivity in most \nof industries, but correlated with more labor \nIT-using industries tend to be more productive; \ngovernment data are unreliable \nA multiple-indicators and multiple-causes model \ncaptures significant MFP effects of computers \na BLS, U.S. Bureau of Labor Statistics; BEA, U.S. Bureau of Economic Analysis 194 ERIK BRYNJOLFSSON AND SHINKYU YANG \nTABLE IV \nINVESTMENT IN COMPUTERS (OCAM) IN THE \nUS. ECONOMY (PERCENTAGE OF TOTAL IN \nCURRENT DOLLARS) \n1979 1989 1992 \nIndustry (%) (%) (%) \nAgriculture 0.1 0.1 0.1 \nMining 2.4 1.1 0.9 \nManufacturing 29.4 20.3 20.2 \nConstruction\" 0.1 0.3 0.2 \nNonservice Total 32.0 21.8 21.4 \nCommunication 1.5 1.4 1.5 \nUtilities 1.2 2.8 2.8 \nTrade\" 19.9 16.3 20.0 \nFinance\" 32.5 38.7 37.8 \nOther Services\" 11.6 17.0 13.9 \nServices Total 68.0 78.2 78.6 \nUnmeasurable Sectors\' 64.1 72.3 71.9 \nPlus consumer and 67.7 77.6 77.0 \nUnmeasurable sector output 63 69 70 \nSource: BEA, adapted from Griliches (1995). \nUnmeasurable sectors: construction, trade, fi- \nnance and other services; in these sectors outputs are \ndifficult to measure, relative to measurable sectors. Transportation 1.3 2.0 1.0 \ngovernment purchases \ntechnology productivity. Roach\'s research (1987, 1989a, 1989b, 1991) on \nwhite collar productivity, discussed earlier, focused principally on IT\'S per- \nformance in the service sector. He argued that IT is an effective substitute \nfor labor in most manufacturing industries, but has been associated with \nbloating white collar employment in services, especially finance. He attrib- \nuted this to relatively keener competitive pressures in manufacturing, and \nhe foresees a period of belt-tightening and restructuring in services as they \nbegin to face international competition. \nHowever, studies of manufacturing also found evidence that computers \nmay not increase productivity. Berndt and Morrison analyzed a broader \ndata set from the U.S. Bureau of Economic Analysis (BEA) that encom- \npasses the whole U.S. manufacturing sector. In their first paper (Morrison \nand Berndt, 1991), they examined a series of parameterized models of \nproduction and found evidence that every dollar spent on IT delivered, on \naverage, only about $0.80 of value on the margin, indicating a general \noverinvestment in IT. Their later paper (Berndt and Morrison, 1995) exam- INFORMATION TECHNOLOGY AND PRODUCTIVITY 195 \nined broad correlations of IT investment with labor productivity and multi- \nfactor productivity. This approach did not find a significant difference be- \ntween the productivity of IT capital and other types of capital for a majority \nof the 20 industry categories examined. They did find that investment in \nIT was correlated with increased demand for skilled labor. \nSiegel and Griliches (1992) used industry and establishment data from \na variety of sources to examine several possible biases in conventional \nproductivity estimates. They found a positive simple correlation between an \nindustry’s level of investment in computers and its multifactor productivity \ngrowth in the 1980s. They did not examine more structural approaches, in \npart because of troubling concerns about the reliability of the data and \ngovernment measurement techniques. Their findings contrast with those \nof Berndt and Morrison (1995). However, Berndt and Morrision (1995) \nalso document positive correlations between IT capital and some measures \nof economic performance in the specifications where cross-sectional effects \nwere emphasized. In addition, Berndt and Morrison’s level of aggregation \n(two-digit SIC code) is broader than that of Siegel and Griliches’ (four- \ndigit SIC code). \nMany researchers working on industry-level data express concerns about \ndata problems, which are often caused by aggregation. For example, the \nBEA data are mainly used for industry-level analyses, but it is subject to \nsubtle biases due to the techniques used to aggregate and classify establish- \nments. One of Siegel and Griliches’ (1992) principal conclusions was that \n“after auditing the industry numbers, we found that a non-negligible num- \nber of sectors were not consistently defined over time.” \nSiegel (1994) attempts to tackle the data problems that arise from two \npossible sources of measurement error. The first kind of error occurs when \ncomputer price and quantity are measured with error. The second source \nof error is more subtle: Firms invest in computers not only for cost reduction \nbut also for quality impr~vement.‘~ Because the quality improvement is \nnot fully taken into account in traditional statistics, the errors in output \nmeasurement are correlated with computer investment. These two kinds \nof errors cause bias and inefficiency in estimation. After controlling these \nerrors using a “multiple-indicators and multiple-causes’’ model, Siegel \nfound a significant positive relationship between multifactor productivity \ngrowth and computer investment. He also found that computer investment \nis positively correlated with both product quality and labor quality, a result \nthat is consistent with Brynjolfsson (1994), Berndt and Morrison (1995), \nand Berman et al. (1994). \nl4 See also Brynjolfsson (1994) 196 ERIK BRYNJOLFSSON AND SHINKYU YANG \n4. Firm-Level Studies of Information \nTechnology Productivity \nDuring the past 10 years, many studies examined the relationship between \nfirms’ IT investment and their performance. Interestingly, studies that have \nused larger and more recent data sets have found evidence that IT positively \naffects firm performance. Research results in manufacturing often show \nstronger effects than studies of services, probably because of better mea- \nsurement. \n4.1 Service Sector Studies \nStrassmann (1985) reports disappointing evidence in several studies (see \nTable V for a list of service sector studies). In particular, he found that \nthere was no correlation between IT and return on investment in a sample \nof 38 service sector firms: Some top performers invest heavily in IT, others \ndo not. In his later book (1990), Strassmann concludes that “there is no \nrelation between spending for computers, profits and productivity.” \nSeveral studies have examined IT’s impact on the performance of finan- \ncial services firms. Parsons et al. (1990) estimated a production function \nfor banking services in Canada. They found that the impact of IT on \nmultifactor productivity was quite low between 1974 and 1987. They specu- \nlated that IT has positioned the industry for greater growth in the future. \nSimilarly, Franke (1987) found that IT was associated with a sharp drop \nin capital productivity and stagnation in labor productivity, but remained \noptimistic about the future potential of IT, citing the long time lags associ- \nated with previous “technological transformations” such as the conversion \nto steam power. In contrast, Brand and Duke (1982) used Bureau of Labor \nStatistics (BLS) data and techniques and found that moderate productivity \ngrowth had already occurred in banking. \nHarris and Katz (1991) and Bender (1986) examined data on the insur- \nance industry from the Life Office Management Association Information \nProcessing Database. They found positive but sometimes weak relationships \nbetween IT expense ratios and various performance ratios. Aipar and Kim \n(1991) studied 759 banks and found that a 10% increase in IT capital is \nassociated with a 1.9% decrease in total costs. Several case studies of IT’s \nimpact on performance have also been done. Weitzendorf and Wigand \n(1991) developed a model of information use in two service firms; and \nPulley and Braunstein (1984) studied an information services firm and found \nan association between IT investment and increased economies of scope. \nEstimating a production function, Brynjolfsson and Hitt (1993) found \nthat for the service firms in their sample, gross marginal product averaged TABLE V \nSTUDIES OF FIRMS IN THE SERVICE SECTOR \nStudy Data Source Findings \nPulley & Braunstein (1984) \nClarke (1985) \nStrassmann (1985, 1990) \nBender (1986) \nFranke (1987) \nHarris & Katz (1991) \nNoyelle (1990) \nParsons er al. (1990) \nAlpar and Kim (1991) \nWeitzendorf & Wigand (1991) \nDiewert & Smith (1994) \nBrynjolfsson & Hitt (1995) An info service firm \nCase study \nComputerworld survey of 38 \nLOMA insurance data on \nFinance industry data companies \n132 firms \nLOMA insurance data for 40 \nU.S. and French industry \nInternal operating data from \nLarge number of banks \nInterviews at two companies \nA large Canadian retail firm \nIDG, Compustat, BEA two large banks Significant economies of scope \nMajor business process redesign needed to reap benefits in investment firm \nNo correlation between various IT ratios and performance measures \nWeak relationship between IT and various performance ratios \nIT was associated with a sharp drop in capital productivity and stagnant \nWeak positive relationship between IT and various performance ratios \nSevere measurement problems in services \nIT coefficient in translog production function small and often negative labor productivity \nIT is cost saving, labor saving, and capital using \nInteractive model of information use \nMultifactor productivity grows 9.4% per quarter over six quarters \nMarginal products of IT do not differ much in services and in the \nmanufacturing; firm effects account for 50% of the marginal product \ndifferential 198 ERIK BRYNJOLFSSON AND SHINKYU YANG \nmore than 60% per year. Their 1995 study reports that IT contributes as \nmuch output in the service sector as in the manufacturing sector (Brynjolfs- \nson and Hitt, 1995). Because they used firm-level data, this result suggests \nthat the productivity “slowdown” in the service sector may be an artifact \nof the mismeasurement of output in aggregate data sets. Indeed, even when \nfirms were classified into “measurable” and “unmeasurable” sectors as \ndefined by Griliches (1994), no noticeable difference in IT productivity \nbetween the sectors was found using this firm-level data. \nDiewert and Smith (1994) provide an interesting case study of a large \nCanadian retail distribution firm. They found that the firm experienced an \nastounding 9.4% quarterly multifactor productivity growth for six consecu- \ntive quarters starting at the second quarter of 1988. They argue that “these \nlarge productivity gains are made possible by the computer revolution \nwhich allows a firm to track accurately its purchase and sales of inventory \nitems and to use the latest computer software to minimize inventory hold- \ning costs.” \nMeasurement problems are more acute in services than in manufacturing, \npartly because many service transactions are idiosyncratic, and therefore \nnot amenable to statistical aggregation. Even when data are abundant, \nclassifications sometimes seem arbitrary. For instance, in accordance with \none standard approach, Parsons et al. (1990) treat time deposits as inputs \ninto the banking production function and demand deposits as outputs. The \nlogic for such decisions is sometimes tenuous, and subtle changes in deposit \npatterns or classification standards can have disproportionate impacts. \nThe importance of variables other than IT is also particularly apparent \nin some of the service sector studies. In particular, researchers and consul- \ntants have increasingly emphasized the need to reengineer work when \nintroducing major IT investments.” As Wilson (1995) suggests, it would \nbe interesting to know whether reengineering efforts are the main explana- \ntion for Brynjolfsson and Hitt’s (1993, 1995) findings that IT is correlated \nwith increased output. A recent survey found that, in fact, firms that had \nreengineered were significantly more productive than their competitors \n(B rynjolfsson, 1994). \n4.2 Studies of Manufacturing Sector \nand Cross-Sector Studies \nThere have been several firm-level studies of IT productivity in the \nmanufacturing sector. Some of the important results are summarized in \nIs See, for example. Davenport (1990), Davenport and Short (1993), Hammer (1990). \nHammcr and Champy (1YY3). and Champy (19%). INFORMATION TECHNOLOGY AND PRODUCTIVITY 199 \nTable VI. A study by Loveman (1994) provided some of the first economet- \nric evidence of an IT productivity shortfall, when he examined data from \n60 business units using the Management Productivity and Information Tech- \nnology (MPIT) subset of the Profit Impact of Market Strategy (PIMS) \ndatabase. As is common in productivity literature, he used an ordinary \nleast squares regression and assumed that production functions could be \napproximated by a Cobb-Douglas function. Loveman estimated that the \ncontribution of information technology capital to final output was approxi- \nmately zero over the 5-year period he studied in almost every subsample. \nHis findings were fairly robust to a number of variations on his basic formu- \nlation. \nBarua et al. (1991) traced Loveman’s results back a step by looking at \nIT’S effect on intermediate variables such as capacity utilization, inventory \nturnover, quality, relative price, and new product introduction. Using the \nsame data set, they found that IT was positively related to three of these \nfive intermediate measures, but that the effect was generally too small to \naffect final output measurably. Dudley and Lasserre (1989) also found \neconometric support for the hypothesis that better communication and \ninformation reduce the need for inventories, without explicitly relating this \nto bottom-line performance measures. Using a different data set, Weill \n(1992) disaggregated IT by use and found that significant productivity could \nTABLE VI \nSTUDIES OF MANUFACTURING FIRMS AND CROSS-SECTOR FIRMS \nStudy Data Source Findings \nLoveman (1994) \nDudley & Lasserre \n( 1989) \nWeill (1992) \nBarua et al. (1991) \nBrynjolfsson & \nHitt (1993) \nBrynjolfsson & \nHitt (1995) \nLichtenberg (1995) \nKwon & Stoneman \n(1995) PIMS/MPIT \nUS. and Canadian \nAggregate Data \nValve manufacturers \nPlMSiMPIT \n1DG; Compustat: BEA \nIDG: Compustat: BEA \nIDG; Informationweek \nUK survey (cross sector) IT investments added nothing to output \nIT and communication reduces invcntories \nContextual variables affect IT performance: \ntransaction processing IT produce \npositive results \nnecessarily final output \nover 50% per year in manufacturing \nproductivity benefits of earlier study \neffect is large \ncomputer use, has a positive impact on \noutput and productivity IT improved intermediate outputs, if not \nThe gross marginal product of IT capital is \nFirm effects account for half of the \nIT has excess return; IT staff‘s substitution \nNew technology adoption, cspccially 200 ERIK BRYNJOLFSSON AND SHINKYU YANG \nbe attributed to transactional types of information technology (e.g., data \nprocessing), but was unable to identify gains associated with strategic sys- \ntems (e.g., sales support) or informational investments (e.g., e-mail infra- \nstructure). \nIn a series of studies utilizing large firm-level surveys by International \nData Group (IDG), Brynjolfsson and Hitt report that IT improves produc- \ntivity. Their 1993 study found that while the gross marginal product of \nnoncomputer capital ranges from 4.14 to 6.86%, that of computer capital \naverages 56 to 68%. The results of this and their later study (Hitt and \nBrynjolfsson, 1994) imply that the following three null hypotheses can \nbe rejected: \nH1: IT capital has a zero gross marginal product. \nH2: IT capital has zero net marginal benefit, after all costs have been sub- \nH3: IT capital’s marginal product is not different from that of other tracted. \ncapital. \nTheir point estimates of gross marginal products indicate that at the margin \ncomputer capital generates 10 times more output than other capital of \nequal value. Brynjolfsson and Hitt (1995) show that up to half of the excess \nreturns imputed to IT could be attributed to firm-specific effects. \nIf gross marginal product of information technology capital is really so \nlarge, what friction or market failure prevents firms from investing in more \ncomputers, until the marginal products of all capital goods become equal?I6 \nOne reason is that computer capital has a higher user cost. According to \nOliner and Sichel (1994), from 1970 to 1992 the user cost of computer \ncapital averaged 36.6% per year, while that of other types of capital was \n15.4%.” The remaining portion of the answer may come from adjustment \nor hidden costs of information technology investment, such as the comple- \nmentary organizational investments required to realize the benefits of IT.’’ \nLichtenberg (1995) confirms the results of Brynjolfsson and Hitt, using \nsimilar data and methods. He also analyzes Informationweek survey data \nand uncovers essentially the same results. His formal tests reject the above \nnull hypotheses. Importantly, Lichtenberg extends his study to report the \nI‘ See, for example, Robert J. Gordon’s comment on Oliner and Sichel (1994). \n’* Take 60% per year as Brynjolfsson and Hitt’s (1993) estimate of gross marginal product \nof information technology capital. IT’S marginal product is more than 50% higher than that \nof other types of capital. About 20% (36.6-15.4%) is explained by the user costs of capital \ndifferential. Because the unexplained portion is large, we may expect a considerable amount \nin adjustment costs when implementing IT investment-annual 30% of computer capital stock. The differential is largely due to the rapid decline in computer prices. INFORMATION TECHNOLOGY AND PRODUCTIVITY 20 1 \nmarginal rate of substitution between IT and non-IT workers. At the sample \nmean, one IT worker can apparently be substituted for six non-IT workers. \nResearch in manufacturing generally finds higher returns to IT invest- \nment than in the services, probably because of better measurement. Yet \nthe MPIT data, which both Loveman (1994) and Barua et al. (1991) use, \nmust be scrutinized. Although the point estimates for IT’S contribution \nwere quite low, the standard errors were very high so that the 95% confi- \ndence interval often exceeded 2200% for Loveman’s estimates. These stud- \nies may also be unrepresentative, since the period covered by the MPIT \ndata, 1978-83, was unusually turbulent. \nThe IDG data set, which is among the largest data sets used in this \nresearch area, substantially mitigates data problems, although it contains \ndata on large firms only, and so may not be a representative random sample. \nIndeed, Brynjolfsson and Hitt (1993) attribute the statistical significance \nof their findings partly to the large size of the IDG data set, which enables \nthem to more precisely estimate returns for all factors. Utilizing comprehen- \nsive surveys of the UK engineering industry undertaken in 1981, 1986, and \n1993, Kwon and Stoneman (1995) also find that the use of computers and \nnumerical control machines has increased output and productivity. \n5. Contribution to Consumer Surplus \nand Economic Growth \nSome researchers have identified sizable contributions of IT to consumer \nsurplus and to economic growth. Some important studies are summarized \nin Table VII. Growth accounting and consumer surplus analysis are tech- \nniques to identify and measure “pecuniary externalities,” which Griliches \n(1992,1994) distinguishes from “non-pecuniary externalities of spill-overs.’’ \nPecuniary externalities arise when the price of some input declines. For \nexample, when computer prices are declining exogenously, profit-maximiz- \ning firms substitute computer systems for other input factors, such as labor \nor warehouse space. Lowered prices of computers and other inputs shift \nmarginal cost curves downward. These marginal cost curves result in higher \noutput and lower prices. The output increase is a measure of the pecuniary \nexternality; the benefits created by the computer sector are reflected in \ngreater output of computer-using industries. A second measure of the pecu- \nniary externality is consumer surplus. As computer prices fall, many firms \nand customers that could not afford computers become able to purchase \nthem, whereas the customers who were willing to pay higher prices enjoy \na windfall of price reduction. 202 ERIK BRYNJOLFSSON AND SHINKYU YANG \nTABLE VII \nSTUDIES ON CONTRIBUTION TO CONSUMER SURPLUS AND ECONOMIC GROWTH \nStudy Data Source Findings \nBresnahan (1986) Financial service Large gains in imputed consumer welfare \nLau & Tokutsu \n(1992) sources growth \nBrynjolfsson & \nHitt (1994) \nOliner & Sichel Principally BEA\" Growth contribution of computers is \n(1994) firms \nMultiple government \nIDG,\" Compustat Computer capital contributes half of output \nGrowth contribution of computers is 1% per \nyear among 367 US. large firms \n0.16-0.38% per year varying by different \nassumptions \nJorgenson & Stiroh Principally BEA Growth contribution of computers for the \n1979-92 period is 0.38-0.52% per year \nBrynjolfsson (1995) BEA $70 billion consumer surplus is generated \nannually in the late 1980s. (1995) \nIDG, International Data Group; BEA, US. Bureau of Economic Analysis. \nPecuniary externalities directly increase labor productivity, yet they do \nnot necessarily increase multifactor productivity. Pecuniary externalities \ndo not change the production function, rather they change the input mix. \nIn contrast, nonpecuniary externalities, or spill-overs, arise from technical \nchange; people may have found smarter ways of making goods and services \nusing information techn~logy.\'~ The production possibility frontier shifts \nout; both labor productivity and multifactor productivity should go up. \nBresnahan (1986) estimated the benefits to consumers of declining com- \nputer prices. Using the hedonic price index method?\' he calculates that \nthe consumer surplus was five or more times that of computer expenditures \nin the late 1960s financial sector. Adopting similar assumptions, Brynjolfs- \nson (1995) estimates that, in 1987, between $69 billion and $79 billion \nconsumer surplus was generated by $25 billion in expenditures on informa- \ntion technology capital. \nNow we turn to several growth accounting results. Jorgenson and Stiroh\'s \n(1995) comprehensive growth accounting found that from 1979 to 1985 \ncomputers and peripherals contributed to output growth by 0.52% per year, \nand that from 1985 to 1992, the contribution was 0.38% per year (see Table \n\'\' Bresnahan and Trajtenberg (1995) argue that \"general purpose technologies,\" like com- \nputers, engender waves of smaller and complementary innovations. This creates the potential \nfor positive externalities from IT, and thus the possibility that IT investment is too low, \ncompared to the socially optimal level. \'\" The hedonic price index method is an attempt to incorporate quality changes when \nconstructing price indices using the regression technique. See Chapter 4 in Berndt (1991). INFORMATION TECHNOLOGY AND PRODUCTIVITY 203 \nVIII).21 Because they assume that computers maintain their full ability \nuntil retirement, their estimation of computer capital’s contribution be- \ncomes larger than that of Oliner and Sichel (1994). \nOliner and Sichel(l994) carefully examine how the various excess return \nhypotheses of computer capital affect growth. As a baseline they estimate \nthat the contribution of computer capital to output growth is 0.16% per \nyear for the 1970-92 period. Using Romer’s (1986, 1987) assumption that \nphysical capital provides a positive externality, the contribution goes up to \n0.32%. Brynjolfsson and Hitt’s (1993) higher estimate for the return on \ncomputer capital raises the contribution to 0.35%. They also try to incorpo- \nrate Alan Krueger’s (1993) result of return on workers’ computer use. If \nthe return is equal to the difference in the marginal product between \ncomputer-using workers and nonusing workers, the contribution is 0.38%. \nOliver and Sichel claim that an annual contribution of up to 0.38% is not \nlarge enough to offset the approximately 1% drop in output growth since \nthe 1970~~~ \nThe following rough calculation may provide some intuition about the \nsize of the contribution of computers to national output. From Jorgenson \nand Stiroh (1995), we take the simple average contribution for the 1979-92 \nperiod or 0.45%. We compare it with the 0.72% contribution of other capital. \nThe share of computers in total capital stock was 1.6% in 1993, implying \nthat 1 unit of computer capital contributes as much to the growth of output \nas 98 units of other forms of capital. In 1993, GDP grew by $173 billion.23 \nComputers contributed $29 billion; other capital contributed $46 billion. \nThe unexplained residual (MFP) contribution is $40 billion. A rough esti- \nmate shows that the implicit marginal product of computer capital in Jorgen- \nson and Stiroh’s study is more than 60%.24 \nUsing data from 367 large firms that together generated $1.8 trillion in \noutput per year from 1982 to 1992, Brynjolfsson and Hitt (1994) provide \n*’ The contribution dropped because the growth rate of real computer capital is lower for \nthe 1079-85 period than for the 1985-92 period; nominal investment of computers did not \nincrease much during the 1985-92 period. \n22 However, an alternative view is that the glass is half-full; Jorgenson calls 0.38% “a pretty \nhefty contribution” (personal letter, Feb. 7, 1995). \n23 Survey of Current Business, March 1994, Table 1-1, nominal dollars. \n24 One of the standard growth accounting assumptions is that factors are paid according \nto their marginal product. Jorgenson and Stiroh report 0.38% growth contribution for the \nperiod 1985-92. The 0.38% is computers’ nominal income share times computer capital’s \ngrowth rate. By their data, we can also estimate computer capital’s growth rate during the \n1985-87 period (24%). Now computers’ nominal income share is equal to (computers capital’s \nmarginal product X computer capitaliGDP). In 1987, computer capital stock amounted to \n$1 13.24 billion and GDP was $4.5399 trillion, thus the implicit marginal product of computers \nis estimated to 63% = (0.38%)* ($4539.9/$113.24)/(24%). TABLE VIII \nGROWTH RATES OF AGGREGATE OUTPUT AND CONTRIBUTION OF FACTORS (1947-92) \nValue Added Growth Contribution \nVariable Annual Noncomp Noncomp Multifactor \nPeriod Growth Share Computer Share Capital Share Computer Share Labor Productivity \n47-92 3.42 3.33 0.09 1.47 1.26 0.21 0.92 1.03 \n47-53 5.46 5.46 0.00 1.92 1.92 0.00 1.26 2.27 \n53-57 2.14 2.14 0.00 1.42 1.42 0.00 0.19 0.53 \n57-60 2.39 2.37 0.02 0.83 0.83 0.00 -0.01 1.57 \n60-66 5.38 5.30 0.08 1.46 1.36 0.10 1.44 2.48 \n66-69 2.61 2.54 0.07 1.93 1.74 0.20 1.16 -0.49 \n69-73 3.67 3.60 0.08 1.64 1.40 0.24 0.74 1.29 \n73-79 2.63 2.50 0.12 1.45 1.19 0.26 1.28 -0.10 \n79-85 2.89 2.65 0.24 1.28 0.76 0.52 0.83 0.78 \n85-92 2.49 2.38 0.12 1.26 0.88 0.38 0.76 0.47 \n~ ~ ~ \nSource: Adapted from Jorgenson and Stiroh (1995). INFORMATION TECHNOLOGY AND PRODUCTIVITY 205 \nan interesting growth accounting result. For their sample of firms, IT capital \ncontributes about 1% per annum to output growth-a larger growth contri- \nbution than that of ordinary capital in absolute value. Lau and Tokutsu \n(1992) calculate an even bigger contribution to growth, attributing approxi- \nmately half of the real output growth (1.5% growth per annum) during the \npast three decades to computer capital. They also argue that the annual \nrate of inflation dropped by 1.2% per year because of the rapid decline \nin computer prices. In line with these studies, Roy Radner suggests that \n“productivity growth has slowed down for other reasons, unrelated to the \nIT story. Without IT, things would have been worse, and output growth \nwould have been lower” (Griliches, 1995). \nIn summary, the weight of evidence from various studies indicates that \ninformation technology capital generates billions of dollars annually for \nthe U.S. economy, both in terms of output growth and consumer surplus. \nMeanwhile, the recent firm-level analyses of Brynjolfsson and Hitt (1993, \n1995) and Lichtenberg (1995) have begun to remedy the shortfall of evi- \ndence regarding the productivity contribution of IT. \n6. Conclusion: Where Do We Go from Here? \nSections 2, 3, 4, and 5 reviewed the principal empirical literature on the \nproductivity of information technology. Looking at the simple relationship \nbetween the productivity slowdown of the whole U.S. economy and the \nrapid growth of computer capital is too general an approach. Poor data \nquality for IT outputs and inputs has exacerbated this problem. Due to \nthe application of improved methodologies and the identification of more \nreliable and larger data sets, researchers have made some progress with \nindustry-level and firm-level studies. Recently, some researchers have found \npositive effects of IT. Careful growth accounting exercises and estimation \nof production and cost functions for specific sectors or industries can provide \nsharper insights. Consumer surplus analyses are useful exercises for identify- \ning alternative ways to triangulate IT value. These studies suggest that \nwithout IT, the U.S. economy would probably be in a worse situation than \nit is. This section proposes further research questions and methodologies. \nThe first priority is to improve the data and the measurement techniques. \nGovernment statistics, especially in services and for information workers, \nhave not kept up with the growing importance and complexity of these \nsectors. Therefore, researchers may have to perform their own corrections \non the data, turn to private sources of secondary data, or gather data \nthemselves. Researchers should make their data available to other research- \ners so that a cumulative tradition can be maintained. The studies of Weill 206 ERIK BRYNJOLFSSON AND SHINKYU YANG \n(1992), Dos Santos et al. (1993), and Brynjolfsson and Hitt (1993, 1995) \nare examples of new data identification and development. \nOne effective way to identify possible gaps in the data is to compare \nthem with the benefits that managers and customers expect from IT, such \nas quality, timeliness, customer service, flexibility, innovation, customiza- \ntion, and variety. In principle, many of these benefits are quantifiable. In \nfact, some firms already attempt such an analysis in their capital budgeting \nand justification processes. In addition, many companies have developed \nelaborate measurement programs, for example, as part of total quality \nmanagement. These programs augment or even supersede financial ac- \ncounting measures and can serve as a foundation for more refined metrics \n(Kaplan and Norton, 1992). \nMany economists also have tried various methods to overcome the short- \nfall of government statistics, and to incorporate quality changes when esti- \nmating price indices. The long history of hedonic price index method is a \ngood example, but some economists argue that even the hedonic method \ndoes not capture all the benefits associated with product innovation and \ndifferentiation. Trajtenberg (1990) devises a new method of quality- \nadjusted price index calculation, adopting the discrete choice model.2s \nFisher and Griliches (1995) argue that if new inexpensive (quality-adjusted) \ngoods are introduced and gain market share at the expense of existing \ngoods, the official statistics by the BLS will seriously overestimate infla- \ntion.26 Hausman (1994) also reports a 20 to 25% overestimation of the \nconsumer price index for ready-to-eat cereals, based on his analysis of \nApple Cinnamon Cheerios. \nUnfortunately, for many services, even basic output measures must be \ncreated, because government and accounting data records only inputs. Baily \nand Gordon (1988) and Noyelle (1990), among others, have done much to \nimprove measurement in areas such as banking and retailing, while rela- \ntively good statistics can be compiled from private sources in areas such as \npackage delivery. Unfortunately, the individualized nature of many services \ndefies aggregation. The output of a lawyer, manager, or doctor cannot be \nextrapolated from the number of meetings attended, memoranda written, \nor medications provided. The complexity of the “diagnostic-related group” \napproach to valuing medical care is both a step in the right direction \nand a testament to these difficulties. A researcher who seeks to measure \n*’ For the period of 1973-82, Trajtenberg’s price deflator for the computed tomography \nscanner industry averages minus 55&; in contrast, the hedonic price index shows a 13% decline \nand government price statistics indicate a 9% increase. ’‘ Empirical evidence for their argument is presented in Griliches and Cockburn (1994). \nThey show that the adjusted price index for the cephalexin drug during the 1987-91 period \ndropped by 30 to 53%; the official figure records a 14% increase. INFORMATION TECHNOLOGY AND PRODUCTIVITY 207 \nrigorously the productivity of service industries generally must undertake \nthis detailed work before jumping to conclusions based on input-based \nstatistics. Similarly, disaggregating heterogeneous types of IT by use, as \nWeill (1992) did in a manufacturing study, can increase the resolution of \nstandard statistical techniques. \nBecause so many factors affect firm performance, it is generally impossi- \nble to distinguish the impact of IT using simple bivariate correlations, It is \nessential to control for other factors such as other inputs and their prices, \nthe macroeconomic environment, demand schedules for output, and the \nnature of competition. Because many unobservable factors affect either \nthe whole industry or one firm persistently, examining a panel consisting \nof both time series and cross-sectional data is the best approach, where fea- \nsible. \nImportantly, we must remember that our tools are still blunt. Managers \ndo not always recognize this and tend to rely too much on any one study \nof IT and productivity. While the studies usually state the limitations of \nthe data and methods, sometimes only the surprising conclusions are re- \nported by the media. Because significant investment decisions are based \non these  conclusion^,^^ researchers must be doubly careful to communicate \nthe limitations of their work. \nResearchers might also look to business for profitable research questions. \nA recurrent theme in the business press is the idea that information technol- \nogy should not so much help us produce more of the same things as allow \nus to do entirely new things in new ways.28 For instance, Watts (1986) \nfinds that information technology investments cannot be justified by cost \nreductions alone, but that instead managers should look to increased flexi- \nbility and responsiveness, whereas Brooke (1992) writes that information \ntechnology leads to greater variety but lower productivity as traditionally \nmeasured. Diewert and Smith’s (1994) study makes another interesting \npoint with respect to variety. They show that while IT facilitates great \nefficiency in inventory management, aggregate inventory level of the US. \neconomy did not shrink during the past 40 years, as reported by Blinder \nand Maccini (1991). Diewert and Smith argue that “a wide spread prolifera- \ntion of new products into the world economy” results in no macro-level \ninventory change even when great micro-level improvements have been \nmade. \n27 For instance. the stock prices of major IT vendors appeared to change significantly in \nresponse to a Wall Street Journal article on IT productivity (Dos Santos et al., 1991). \n” See, for example, Applegate and Mills (1988). Benjamin era/. (1984), Champy (1995). \nCecil and Hall (1988) Davenport (lYY3), Hammer and Champy (19Y3), Malone and Rockart \n(1991), Porter and Miller (1985), and Watts (1986). 208 ERIK BRYNJOLFSSON AND SHINKYU YANG \nThis literature highlights how difficult and perhaps inappropriate it would \nbe to tr', 'raytos.bsinfotech@gmail.com', 'ERIK BRYNJOLFSSON AND SHINKYU YANG ', '', '../pdf_files/674d4f90c9645-Information Technology and Productivity - A Review of the Literature.pdf', 2304654, 36, 12896, 88071, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(60, '8325508083', '51', 5, 5, ' Information technology and lender competition', '2024-12-02 14:22:49.088515', '2024', 'We study how information technology (IT) affects lender competition, entrepreneurs’ investment, and welfare in a spatial model. The effects of an IT improvement depend on whether it weakens the influence of lender borrower distance on monitoring costs. If it does, it has a hump-shaped effect on entrepreneurs’ investment and social welfare. If not, competition intensity does not vary, improving lender profits, entrepreneurs’ investment, and social welfare. When entrepreneurs’ moral hazard problem is severe, IT-induced competition is more likely to reduce investment and welfare. We also find that lenders’ price discrimination is not welfare-optimal. Our results are consistent with received empirical work on lending to SMEs.', 'Credit,Monitoring,FinTech,Price discrimination,Moral hazard,Regulation', 'Contents lists available at ScienceDirect\nJournal of Financial Economics\njournal homepage: www.elsevier.com/locate/finec\nInformation technology and lender competition✩\nXavier Vivesa,∗,Zhiqiang Yeb\naIESE Business School, Av. de Pearson, 21, Barcelona, 08034, Spain\nbSchool of Economics, Zhejiang University, 866 Yuhangtang Rd, Hangzhou, 310058, China\nA R T I C L E I N F O\nDataset link: Information Technology and Lend\ner Competition (Original data)\nJEL classification:\nG21\nG23\nI31\nKeywords:\nCredit\nMonitoring\nFinTech\nPrice discrimination\nMoral hazard\nRegulationA B S T R A C T\nWe study how information technology (IT) affects lender competition, entrepreneurs’ investment, and welfare\nin a spatial model. The effects of an IT improvement depend on whether it weakens the influence of lender–\nborrower distance on monitoring costs. If it does, it has a hump-shaped effect on entrepreneurs’ investment and\nsocial welfare. If not, competition intensity does not vary, improving lender profits, entrepreneurs’ investment,\nand social welfare. When entrepreneurs’ moral hazard problem is severe, IT-induced competition is more likely\nto reduce investment and welfare. We also find that lenders’ price discrimination is not welfare-optimal. Our\nresults are consistent with received empirical work on lending to SMEs.\n1. Introduction\nThe banking  industry  is undergoing  a digital  revolution.  A grow-\ning number  of financial  technology  (FinTech)  companies  and BigTech\nplatforms  are engaging  in traditional  banking  businesses  using their in-\nnovative  information  and automation  technologies.1Incumbent  banks\nare also moving  from reliance  on physical  branches  to adopting  infor-\nmation  technology  (IT) and Big Data in response  to the availability\nof technology  and to changes  in consumer  expectations  of service,\nwhich are two main drivers  of digital  disruption  (FSB,2019 ). Such\na transformation  spurs the banking  sector’s  increasing  investment  in\nIT, allowing  financial  intermediaries  to offer personalized  services  and\n✩Philipp  Schnabl  was the editor for this article.  We thank the editor and two anonymous  referees  for their helpful  comments.  We are also grateful  to\nparticipants  at the CEBRA  2021 Annual  Meeting,  EARIE 2021 Annual  Conference,  EFA 2021 Annual  Meeting,  ESEM Virtual  2021, Finance  Forum 2022, FIRS\n2021 Conference,  MADBAR  2020 Workshop,  Bocconi-CEPR  2023 Fintech  conference,  and the Annual  Conference  of the Central  Bank of Brazil 2024 (and especially\nto our discussants  Toni Ahnert,  David Martinez-Miera,  Cecilia Parlatore,  David Rivero and Lin Shen) and at seminars  sponsored  by the Bank of Canada,  Banque\nde France,  SaMMF  Johns Hopkins  and Swiss Finance  Institute  at EPFL– in particular,  to Tobias Berg, Hans Degryse,  Andreas  Fuster, Zhiguo  He, Julien Hugonnier,\nRobert Marquez,  Gregor Matvos,  Sofia Priazhkina,  Uday Rajan, Amit Seru, Laura Veldkamp,  Chaojun  Wang, Pierre-Olivier  Weill, David Xiaoyu  Xu and Liyan\nYang. Giorgia  Trupia provided  excellent  research  assistance.  Xavier Vives acknowledges  the financial  support  of Grant Ref. PID2021-123113NB-I00  funded  by\nMCIN/AEI/  10.13039/501100011033  and ‘‘ERDF A way of making  Europe’’  by the European  Union.\n∗Corresponding  author.\nE-mail addresses: xvives@iese.edu (X. Vives) ,zhiqiangye@zju.edu.cn (Z. Ye).\n1Prominent  examples  can be seen in China, where Alibaba  and Tencent  – the two largest BigTech  companies  – are active in a wide range of financial  services\nthat include  payments,  wealth management,  and lending.  In the United States, almost one-third  of small and medium  firms that sought financing  applied  with a\nFinTech  firm or online lender,  up from 19% in 2016 (US Federal  Reserve’s  Small Business  Credit Survey 2019). The annual growth  rate of the volume  of FinTech\nbusiness  lending  in the United States was greater  than 40% from 2016 to 2020 (Berg et al.,2022 ). See alsoVives (2019 ).to price discriminate.  The COVID-19  pandemic  has accelerated  this\ndigitalization  process  and fostered  remote  loan operations  and the\ndevelopment  and diffusion  of IT in the credit market  (Carletti  et al.,\n2020 ).\nHow do the development  and diffusion  of information  technology\naffect lending  competition?  What are the welfare  implications  of IT\nprogress?  In particular,  does the type of IT matter  for competition  and\nwelfare?  Is there a welfare  loss from price discrimination?  To answer\nthose questions,  we build a model of spatial  competition  in which\nlenders  compete  to provide  entrepreneurs  with loans. Lenders  in our\nmodel refer to institutions  that can provide  loans in the credit mar-\nket, including  commercial  banks,  shadow  banks,  fintechs,  or BigTech\nhttps://doi.org/10.1016/j.jfineco.2024.103957\nReceived  22 July 2022; Received  in revised  form 7 October  2024; Accepted  11 October  2024Journal  of Financial  Economics  163 (2025)  103957  \nAvailable  online  25 October  2024  \n0304-405X/©  2024  The Authors.  Published  by Elsevier  B.V. This is an open access  article  under  the CC BY-NC-ND  license  ( http://creativecommons.org/licenses/by-  \nnc-nd/4.0/  ). X. Vives and Z. Ye\nplatforms. Our model will help to illuminate the following empirical\nresults:\n•Business lending by banks with better IT adoption is less affected\nby the distance between banks and their borrowers (Ahnert et al.,\n2024 ).\n•Borrowers with better access to bank financing request loans at\nlower interest rates on a fintech’s platform (Butler et al.,2017 ). A\nbank will charge its borrowers higher loan rates if the borrowers\nget geographically closer to the bank or/and farther away from\ncompeting banks (Herpfer et al.,2022 ).\n•Increased bank/branch industry specialization (e.g., in export/\nSME) lending curtails bank competition (Paravisini et al.,2023 ;\nDuquerroy et al.,2022 ). Broadband internet implementation in-\ntensifies bank competition and reduces banks’ loan prices\n(D’Andrea et al.,2021 ).\n•Banks with superior IT adoption have higher loan growth\n(Dadoukis et al.,2021 andBranzoli et al.,2024 ). Entrepreneur-\nship is stronger in US counties that are more exposed to IT-\nintensive banks (Ahnert et al.,2024 ).\n•The relationship between bank competition and bank credit sup-\nply is hump-shaped (Di Patti and Dell’Ariccia ,2004 ).\nThe lending market is modeled as a linear city à laHotelling (1929 )\nwhere two lenders located at the two extremes of the city compete for\nentrepreneurs who are distributed along the segment. Entrepreneurs\ncan undertake scalable risky investment projects, which may succeed\nor fail, and have no initial capital. Hence, they require funding from\nlenders. Lenders have no direct access to investment projects and\ncompete in a Bertrand fashion by simultaneously posting their discrim-\ninatory loan rate schedules. We take it as given that IT is advanced\nenough for lenders to price flexibly. An entrepreneur can shirk and de-\nrive a private benefit, which is ex-ante random and unobservable, after\nobtaining loans from the lender; if she shirks, her investment project\nwill fail for sure. A critical lender function is monitoring entrepreneurs\nto reduce their private benefits of shirking (see, e.g., Holmstrom and\nTirole ,1997 ). Monitoring is more costly for a lender if there is a\nlarger distance between the lender and the monitored entrepreneur.\nThis distance can be physical2or in the characteristics space from the\nlender’s expertise in certain sectors or industries.3After an entrepreneur\nhas chosen a lender for funding, her private benefit of shirking becomes\nobservable to the lender, which will then adjust credit availability –\nmodeled as the maximum size of the loan available to the entrepreneur\n– based on the observed private benefit. For simplicity, we assume that\nlenders can provide loans at a given marginal funding cost and do not\nmodel how lenders compete to develop relationships with investors or\ndepositors.4\n2There is evidence that firm–lender physical distance matters for lending.\nSeeDegryse and Ongena (2005 ),Petersen and Rajan (2002 ) andBrevoort and\nWolken (2009 ).\n3Blickle et al.(2023 ) find that a bank ‘‘specializes’’ by concentrating\nits lending disproportionately on one industry where it has better knowl-\nedge. Paravisini et al.(2023 ) document that exporters to a given country are\nmore likely to be financed by a bank with better expertise. Duquerroy et al.\n(2022 ) find that in local markets, there exist specialized bank branches that\nconcentrate their SME lending on certain industries.\n4We admit that this is a limitation. Drechsler et al.(2021 ) emphasize\nthe importance of the deposit franchise for banks to increase their market\npower over retail deposits, allowing them to borrow at rates that are low and\ninsensitive to market interest rates. Matutes and Vives (1996 ) andCordella\nand Yeyati (2002 ) study bank competition for deposits within a similar spatial\ncompetition framework, but in their models, banks can directly invest in risky\nassets.The model has two important ingredients: First, lender monitoring\nmatters for welfare since it enables entrepreneurs with moral hazard\nproblems to obtain credit and invest. Second, lenders cannot credi-\nbly commit to monitoring effort ex ante since they can adjust credit\navailability later (after observing entrepreneurs’ private benefits).\nWe distinguish two types of information technology: (a) infor-\nmation collection/processing technology (IT-basic for short) and (b)\ndistance friction-reducing technology (IT-distance for short). Improve-\nments in the two types of IT generate different outcomes. Specifically,\nan improvement in IT-basic lowers evenly the costs of monitoring en-\ntrepreneurs in different locations. Such an improvement in the lending\nsector does not affect lenders’ relative cost advantage in different loca-\ntions – for example, by improving the ability to collect more valuable\ndata and process them with better computer hardware or informa-\ntion management software (e.g., desktop applications). In contrast,\nimproving IT-distance reduces the negative effect of lender–borrower\ndistance on monitoring costs. Such an improvement lowers more signif-\nicantly the costs of monitoring entrepreneurs located farther away. For\nexample, better internet connectivity and communication technology\n(e.g., video conferencing) reduce the physical distance friction.5The\nimprovement in remote learning devices, search engines, and artificial\nintelligence (AI) makes it easier to extend expertise, thereby reduc-\ning the expertise distance friction. Big Data and machine learning\ntechniques may improve both IT-basic and IT-distance.6\nUnder the set-up described, we study how information technol-\nogy affects lender competition and obtain results consistent with the\navailable empirical evidence. The equilibrium consequences of im-\nprovements in the two types of technology (IT-basic v.s. IT-distance)\nare compared. We find that by adopting more advanced IT, whatever its\ntype, a lender can charge higher loan rates and provide more loans. This\nis so because a lender’s IT progress increases its competitive advantage\nover its rival.\nWhen both lenders make technological progress, that progress will\nnot increase the overall competitive advantage of either lender. In\nthis case, different types of IT progress can yield different results.\nIf IT progress reduces the costs of monitoring an entrepreneur with-\nout altering lenders’ relative cost advantage (i.e., IT-basic improves),\nlenders’ competition intensity will not be affected. In this case, the loan\nrates that lenders offer to entrepreneurs do not vary; lenders become\nmore profitable and provide more loans because monitoring is now\ncheaper (i.e., monitoring efficiency is higher). However, if IT progress\ninvolves a weakening in the influence of lender–borrower distance\non monitoring costs (i.e., IT-distance improves), lenders’ competition\nintensity will increase because their differentiation becomes smaller.\nThen, the loan rates offered to entrepreneurs decline for both lenders.\nSuch a differentiation-reducing effect decreases lenders’ profits despite\nthe fact that IT progress makes monitoring cheaper.\nThe effect of IT-distance progress on lenders’ credit supply is ‘‘hump-\nshaped’’. IT-distance progress generates three effects on loan supply:\nFirst, it improves lenders’ monitoring efficiency, tending to increase\ntheir credit supply. Second, lenders’ differentiation and loan rates de-\ncrease, increasing entrepreneurs’ skin in the game and alleviating moral\nhazard; this effect also tends to increase credit supply. Finally, lenders’\nskin in the game decreases, reducing their monitoring incentives and\nwillingness to supply credit. The first two effects dominate and increase\nlenders’ credit supply and entrepreneurs’ investment when IT-distance\nis not sufficiently advanced (i.e., when lender differentiation is high),\nwhile the last effect – the decrease in lenders’ monitoring incentives\n5Jiang et al.(2023 ) finds that 3G mobile networks significantly reduce\ndistance friction for banks, geographically expanding their lending.\n6There are many companies (e.g., Zestfinance, Scienaptic systems,\nDatarobot, Underwrite.ai) that help the financial industry improve information\nprocessing via Big Data and machine learning techniques, thus transforming\nsoft data into hard data. See alsoBoot et al.(2021 ).Journal  of Financial  Economics  163 (2025)  103957  \n2 X. Vives and Z. Ye\n– dominates and reduces lenders’ credit supply and entrepreneurs’\ninvestment when IT-distance is sufficiently advanced. Moreover, as\nentrepreneurs’ moral hazard problem becomes more severe, the last\neffect will be more likely to dominate the first two. The reason is that a\nmore severe moral hazard problem increases the need for monitoring,\nhence making the provision of monitoring incentives (determined by\nlenders’ skin in the game) more important to credit supply. In contrast,\nIT-basic progress unambiguously increases lenders’ credit supply since\nit has no differentiation effect.\nOur model can shed light on the competition between a traditional\nbank – which has better access to firm data and hence an advantage in\nIT-basic – and a fintech lender with better IT-distance and lack of firm\ndata. With its better IT-basic, the bank can ensure a positive market\nshare because it has higher monitoring efficiency than the fintech when\nserving firms sufficiently close to the bank. The implication is that\nalthough fintechs, with their advantage in IT-distance, can bring com-\npetitive pressure to banks, the latter will not be completely replaced.\nMoreover, if the bank has a cheaper funding source (e.g., deposits) than\nthe fintech, then the bank will offer lower loan rates and volumes than\nthe fintech when serving entrepreneurs of similar characteristics.\nNext, we analyze the welfare effects of information technology\nprogress. We find that more intense competition does not always favor\nsocial welfare. When lender competition is not intense, increasing com-\npetition intensity improves welfare because it increases entrepreneurs’\nskin in the game from excessively low levels and substantially alleviates\ntheir moral hazard problem. Yet ‘‘too much’’ competition reduces social\nwelfare because high competition intensity decreases lenders’ skin in\nthe game and their monitoring incentives, thereby reducing lenders’\nwillingness to extend credit supply. Hence, an improvement in IT-\ndistance – which decreases lender differentiation – may or may not\nbenefit social welfare owing to the consequent increased lender compe-\ntition. IT-distance progress will be more likely to reduce social welfare\nwhen entrepreneurs’ moral hazard problem is more severe because the\nneed for monitoring will increase in this case, making lenders’ monitor-\ning incentives more crucial. In contrast, improving lenders’ IT-basic has\nno differentiation effect and hence improves welfare unambiguously.\nFrom the social point of view, the welfare-maximizing loan rate does\nnot depend on lenders’ IT. This rate represents the socially optimal way\nto share the project value between an entrepreneur and her lender.\nAlthough a lender’s IT determines the value of a project it finances\n(i.e., the size of the pie), the welfare-maximizing way to share the\npie must balance the severity of the entrepreneur’s moral hazard and\nthe lender’s monitoring incentive, which is a trade-off independent of\nthe lender’s IT. The implication is that lenders’ price discrimination\nwill generate inefficient equilibrium outcomes: A lender will price\naggressively at far-away locations – where the lender’s IT advantage\nis low – to gain as much business as possible while at locations close\nto the lender’s area of specialization it will price very high to exploit\nits high IT advantage. Such a strategy does not balance the severity\nof moral hazards well with the lender’s monitoring incentive at each\nlocation. Regulators can improve welfare by setting a proper reference\nloan rate for lenders and limiting their ability to price discriminate.\nRelated literature. Our work builds on the spatial competition mod-\nels ofHotelling (1929 ) andThisse and Vives (1988 ) but focuses on\nlenders’ competition to finance entrepreneurs’ projects. Villas-Boas and\nSchmidt-Mohr (1999 ) build a spatial model studying how lending com-\npetition affects the collateral requirements of bank contracts. Several\npapers have emphasized the importance of monitoring in lending.7\nAlmazan (2002 ) studies how lender capitalization, interest rates, and\n7See, e.g., Diamond (1984 ) and Holmstrom and Tirole (1997 ) for\npioneering work.regulatory shocks affect monitoring efficiency in a spatial competi-\ntion model where lenders have no market power over entrepreneurs.\nMartinez-Miera and Repullo (2019 ) examine the effectiveness of mon-\netary and macroprudential policies in addressing a financial system’s\nrisks within a framework where lender monitoring can increase the\nprobability that investing in an entrepreneur yields a positive return.8\nDifferent from the aforementioned papers, our model focuses on how\ndifferent types of IT progress (IT-basic v.s. IT-distance) generate dif-\nferent effects on lenders’ monitoring, market power, entrepreneurs’\ninvestment, and welfare.\nOur paper also belongs to the literature studying information tech-\nnology and lending competition. Hauswald and Marquez (2006 ) extend\nthe adverse selection model inHauswald and Marquez (2003 ) and show\nthat the equilibrium loan rates received by borrowers are decreasing\nin the lender–borrower distance and in the intensity of lender com-\npetition (measured by the number of lenders), similar to our model\nprediction. However, our model builds on a different mechanism –\nentrepreneurs’ moral hazard and lender monitoring (as inHolmstrom\nand Tirole ,1997 ) – and we analyze the relationship between the\nseverity of entrepreneurs’ moral hazard and the equilibrium effects of\nIT progress. Furthermore, our results differ from those ofHauswald\nand Marquez (2006 ), in which an improvement in the lending sector’s\nIT will soften lender competition, and social welfare increases in the\nintensity of lender competition if competition is already very intense.\nIn contrast, we find that lender competition is either intensified or\nunaffected by the lending sector’s IT improvements, depending on the\ntype of improved IT, and that social welfare decreases in the intensity\nof lender competition if competition is very intense.\nIn a model where a traditional bank and a fintech lender compete to\nextend loans, He et al.(2023 ) analyze the effects of ‘‘open banking’’ –\nan information sharing mechanism that enables borrowers to share\ntheir customer data stored in a bank with a fintech that has advanced\ninformation processing technology but less access to customer data.\nThey find that open banking increases the fintech’s screening ability but\nthat it can soften lending competition and hurt borrowers if the fintech\nis ‘‘over-empowered’’ by the data sharing mechanism. Our work has\na different focus: we distinguish two types of information technology\nand compare their different equilibrium consequences. In addition, we\nshow that one lender’s IT progress and the entire lending sector’s IT\nprogress generate quite different equilibrium outcomes.\nOur theoretical framework is relevant to the empirical literature\non information technology adoption in the lending market, which has\nthrived owing to the rise of FinTech in recent years.9To start with,\nthere is considerable evidence showing that IT makes non-traditional\ndata useful for assessing the quality of borrowers.10Moreover, a wide\nstream of research documents the lending efficiency increase brought\n8Bouvard et al.(2022 ) study lending and monitoring in a market where a\nbigtech and competitive banks can provide loans and monitor entrepreneurs.\nIn addition to providing loans, the bigtech itself is a monopolistic platform\ncharging participation fees from entrepreneurs (i.e., merchants).\n9Philippon (2016 ) claims that the existing financial system’s inefficiency\ncan explain the emergence of new entrants that bring novel technology to the\nsector. Gopal and Schnabl (2022 ) show that most of the increase in fintech\nlending to SMEs after the 2008 financial crisis substituted for a bank lending\nreduction.\n10The non-traditional data include soft information (Iyer et al.,2016 ),\nfriendships and social networks (Lin et al.,2013 ), applicants’ description text\n(Dorfleitner et al.,2016 ;Gao et al.,2023 ;Netzer et al.,2019 ), contract\nterms (Kawai et al.,2022 ;Hertzberg et al.,2018 ), mobile phone call records\n(Björkegren and Grissen ,2020 ), digital footprints (Agarwal et al.,2023 ;Berg\net al.,2020 ), and cashless payment information (Ghosh et al.,2022 ;Ouyang ,\n2023 ).Journal  of Financial  Economics  163 (2025)  103957  \n3 X. Vives and Z. Ye\nFig. 1.The economy.\nabout by information  technology.11Several  papers  provide  evidence\nconsistent  with our results. Branzoli  et al.(2024 ) andDadoukis  et al.\n(2021 ) find that banks with higher  IT adoption  have larger loan growth;\nthis is consistent  with our finding  that an improvement  of a lender’s  IT\nincreases  its lending  volume. D’Andrea  et al.(2021 ) find that broad-\nband internet  implementation  intensifies  bank competition  and reduces\nbanks’  loan prices,  which is consistent  with the effect of IT-distance\nprogress  in our model. Ahnert  et al.(2024 ) document  that small\nbusiness  lending  by banks with higher  IT adoption  is less affected  by\nthe distance  between  the bank headquarters  and their borrowers.  Our\nmodel aligns with this finding. Ahnert  et al.(2024 ) also find that job\ncreation  by young enterprises,  a proxy for entrepreneurship,  is stronger\nin US counties  that are more exposed  to IT-intensive  banks;  consistent\nwith this finding,  our model shows that IT-basic  progress  in the lending\nsector spurs credit supply  and entrepreneurial  investment.  However,  IT-\ndistance  progress  intensifies  lender  competition,  so its effect on lenders’\ncredit supply  is hump-shaped,  which is consistent  with Di Patti and\nDell’Ariccia (2004 ).12\nThe rest of our paper proceeds  as follows.  Section 2presents  the\nmodel setup. Section 3examines  the lending  market  equilibrium,  and\nSection 4examines  the effects  of information  technology.  Section 5\nprovides  a welfare  analysis  of information  technology  progress.  We\nconclude  in Section 6with a summary  of our findings. Appendix  A\npresents  the proofs  while other appendices  deal with model extensions.\n2. The model\nThe economy  and players. The economy  is represented  by a linear\n‘‘city’’,  of length  1, that is inhabited  by entrepreneurs  and lenders.\nAt each location,  there is one penniless  entrepreneur.  A point on the\ncity represents  the characteristics  of the entrepreneur  (type of project,\ntechnology,  geographical  position,  industry,  . . .) at this location,  and\ntwo close points mean that the entrepreneurs  in those locations  are\nsimilar.\nThere are two lenders,  labeled  by𝑖∈ {1,2}, located  at the two\nextremes  of the city. Hence,  a lender  is closer to some entrepreneurs\nthan to others.  This means,  for example,  that lenders  are specialized  in\ndifferent  sectors  of the economy  (seeParavisini  et al.,2023 for export-\nrelated  lending, Duquerroy  et al.,2022 for SME lending  andGiometti\n11Buchak  et al.(2018 ) find that lenders  with advanced  technology  can\noffer more convenient  services  to borrowers  and hence charge higher loan\nrates in the US mortgage  market  than traditional  banks. Frost et al.(2019 )\nreport that, in Argentina,  credit assessment  based on Big Data (e.g., platform\ntransactions  and the reputation  of sellers)  and processed  with machine  learning\ntechniques  has outperformed  credit bureau  ratings in terms of predicting  the\nloss rates of small businesses. Fuster et al.(2019 ) estimate  that technology-\nbased lenders  process  mortgage  applications  20% faster than traditional  banks\nwithout  incurring  greater  default  risk. Liu et al.(2024 ) find that a BigTech\nlender has superior  information  about entrepreneurs  in its ecosystem,  so it\ncan extend loans to borrowers  underserved  by banks without  incurring  greater\nrisks.\n12The literature  on the Paycheck  Protection  Program  (PPP) launched  by\nthe US Small Business  Administration  (SBA) also highlights  the importance  of\ntechnology.  However,  we will refrain from explaining  those findings  within\nour framework  because  PPP loans - when properly  used by borrowers  - are\nforgivable  and carry a uniform  loan rate of 1%, which drastically  diminishes\nthe space for lenders’  monitoring  and strategic  pricing.and Pietrosanti ,2023 for syndicated  corporate  loans).  If the distance\nbetween  an entrepreneur  and lender  1 is𝑧, we say that the entrepreneur\nis located  at (location)𝑧. As a result,  the distance  between  the en-\ntrepreneur  at𝑧and lender  2 is1 −𝑧.Fig. 1gives an illustration  of the\neconomy.\nEntrepreneurs  and investment  projects. Each entrepreneur  has no\ninitial capital  and is endowed  with a scalable  risky investment  project;\nhence,  entrepreneurs  require  funding  from lenders  to undertake\nprojects.\nAn entrepreneur’s  project  return  depends  on (a) whether  the en-\ntrepreneur  shirks and (b) the entrepreneur’s  investment  size. If the\nentrepreneur  at𝑧invests𝐼(𝑧)and does not shirk, her project  yields\nthe following  risky return  (where𝑅 >0):\ñ𝑅(𝐼(𝑧)) ={\n𝐼(𝑧)𝑅with probability 𝑝,\n0 with probability 1 −𝑝.\nIn the event of success  (resp. failure)  – which happens  with probability\n𝑝(resp. 1 −𝑝) – the entrepreneur’s  project  yields𝐼(𝑧)𝑅(resp. 0).\nThe success  probability 𝑝∈ (0,1)is a constant.13Project  returns  are\nindependent  for entrepreneurs  who do not shirk. Lenders  post loan rates\nand provide  credit to entrepreneurs.  If the entrepreneur  at𝑧borrows\n𝐼𝑖(𝑧)units of funds from lender𝑖(𝑖∈ {1,2}) at loan rate𝑟𝑖(𝑧), the\nentrepreneur  must promise  to repay𝐼𝑖(𝑧)𝑟𝑖(𝑧).\nThe funding  costs of lenders. We assume  lenders  can provide  loans\nat a given marginal  funding  cost,𝑓.14Appendix  Banalyzes  the case\nwhere the two lenders  have different  marginal  funding  costs. We let\n𝑝𝑅−𝑓 >0hold, meaning  that entrepreneurs’  projects  can generate\npositive  expected  returns  net of funding  cost.\nShirking  opportunity  and lender  monitoring. An entrepreneur  can\nshirk and derive  a private  benefit  from investment.  Following Holmstrom\nand Tirole (1997 ), we assume  that shirking  brings the entrepreneur\n(at𝑧) a total private  benefit  of𝐼𝑖(𝑧)̃𝐵(𝑧)if she invests𝐼𝑖(𝑧)units of\nfunds without  being monitored,  wherẽ𝐵(𝑧)>0is the random  marginal\nprivate  benefit  derived  from a unit of investment.  If the entrepreneur\nshirks,  her investment  project  fails (i.e., returns  0) for sure.\nBefore  the entrepreneur  at𝑧determines  which lender  to borrow\nfrom,̃𝐵(𝑧)is random  and unobservable  to entrepreneurs  and lenders.\nThe random  variablẽ𝐵(𝑧)is independent  across locations𝑧and follows\na binary  distribution:\n𝑃 𝑟𝑜𝑏.(̃𝐵(𝑧) =𝐵) =𝑘and𝑃 𝑟𝑜𝑏.(̃𝐵(𝑧) =𝑏) = 1 −𝑘, (1)\nwith𝐵 > 𝑏and𝑘∈ [0,1]. From lenders’  perspective,  the shirking\nopportunity  gives rise to the entrepreneurs’  moral hazard  problem,\nwhich is more severe  wheñ𝐵(𝑧) =𝐵than wheñ𝐵(𝑧) =𝑏. Therefore,\na higher𝑘implies  a higher  ex-ante  severity  of entrepreneurs’  moral\nhazard  problem.  We assume𝐵 < 𝑓, implying  that shirking  is always\n13We could also allow the entrepreneur  to influence  the success  probability\nby exerting  effort. Then, an additional  effect is introduced,  but our results are\nrobust to this extension.\n14Similar  assumptions  are adopted  inHolmstrom  and Tirole (1997 ),\nHauswald  and Marquez (2003 ,2006 ), andHe et al.(2023 ). An alternative\nassumption  is that lenders  have no capital and attract deposits  or debt from\ncompetitive  risk-neutral  investors,  who require  a break-even  expected  funding\nunit’s return of𝑓.Journal  of Financial  Economics  163 (2025)  103957  \n4 X. Vives and Z. Ye\nsocially undesirable since it cannot generate a non-negative return net\nof funding costs.\nAfter the entrepreneur at𝑧builds her lending relationship with\nlender𝑖,̃𝐵(𝑧)realizes and becomes observable to both the entrepreneur\nand the lender. Then, lender𝑖can monitor the entrepreneur and\ndecrease her private benefit of shirking by𝑚𝑖(𝑧), the lender’s monitoring\nintensity at𝑧. As a result, the entrepreneur will not shirk if and only if\nthe following incentive compatibility (IC) condition holds:\n𝑝𝐼𝑖(𝑧)(𝑅−𝑟𝑖(𝑧))≥𝐼𝑖(𝑧)̃𝐵(𝑧) −𝑚𝑖(𝑧)[IC]. (2)\nIf the entrepreneur does not shirk, her expected utility (i.e., profit) is\nthe left-hand side of (2): she receives𝐼𝑖(𝑧)(𝑅−𝑟𝑖(𝑧))in the event of\nsuccess, which happens with probability 𝑝. If she shirks, her utility\nbecomes𝐼𝑖(𝑧)̃𝐵(𝑧) −𝑚𝑖(𝑧)since the project returns 0.\nCredit limit. After observing ̃𝐵(𝑧), lender𝑖can set a loan size upper-\nbound𝐼𝑖(𝑧)(‘‘credit limit’’) for the entrepreneur at𝑧to control moral\nhazard by capping her investment scale. Since the entrepreneur’s fund-\ning comes from the lender, the entrepreneur’s investment scale cannot\nexceed𝐼𝑖(𝑧)(i.e.,𝐼𝑖(𝑧) ∈ [0,𝐼𝑖(𝑧)]).\nIn our model, lender𝑖manages its borrowers’ moral hazard through\ntwo channels: (a) monitoring (represented by𝑚𝑖(𝑧)), and (b) controlling\ncredit availability (represented by𝐼𝑖(𝑧)). Our setup is consistent with\nthe theory and evidence ofAcharya et al.(2014 ), in which banks\ndiscipline borrowers by combining monitoring and the capacity to\nadjust credit lines based on future information.15\nNon-trivial moral hazard. Throughout the paper, we assume that the\nmarginal private benefit̃𝐵(𝑧)is sufficiently large such that the moral\nhazard problem is not trivial:\ñ𝐵(𝑧)≥2(𝑝𝑅−𝑓), (3)\nwhich is equivalent to𝐵 > 𝑏≥2(𝑝𝑅−𝑓). Inequality ( 3) implies that,\nwithout monitoring, an entrepreneur’s per-unit expected pledgeable\nincome cannot make lenders break even.16To see this, consider that\nthe entrepreneur at𝑧borrows from lender𝑖with the loan rate𝑟𝑖(𝑧).\nWithout monitoring, she will not shirk if and only if𝑝(𝑅−𝑟𝑖(𝑧))≥̃𝐵(𝑧),\nimplying𝑝𝑟𝑖(𝑧)≤𝑝𝑅−̃𝐵(𝑧); that is, the entrepreneur can at most\npledge an expected marginal return of𝑝𝑅−̃𝐵(𝑧)to lender𝑖. However,\nInequality ( 3) implies𝑝𝑟𝑖(𝑧)≤𝑝𝑅−̃𝐵(𝑧)< 𝑓, so the entrepreneur’s\nexpected pledgeable income cannot cover lender𝑖’s funding costs if\nthere is no monitoring. As a result, lenders must monitor borrowers\nwhen lending.\nMonitoring and information technology. If the entrepreneur at𝑧\nborrows from lender𝑖and is monitored with intensity𝑚𝑖(𝑧), the lender\nincurs the monitoring cost:\n𝐶𝑖(𝑚𝑖(𝑧), 𝑧) =𝑐𝑖\n2(1 −𝑞𝑖𝑠𝑖)(𝑚𝑖(𝑧))2. (4)\nHere𝑐𝑖>0,𝑞𝑖∈ [0,1), and𝑠𝑖is the distance between lender𝑖and\nlocation𝑧; hence, we have𝑠𝑖=𝑧(resp.𝑠𝑖= 1 −𝑧) if𝑖= 1(resp.\n𝑖= 2). The parameters 𝑐𝑖and𝑞𝑖are inverse measures of the efficiency of\nlender𝑖’s information technology. Parameter𝑐𝑖is the slope of marginal\nmonitoring costs when lender–borrower distance is zero, and hence\nrepresents lender𝑖’s basic monitoring efficiency (IT-basic ). Parameter\n𝑞𝑖(IT-distance of lender𝑖) measures the negative effect of lender–\nborrower ‘‘distance friction’’ on the lender’s information collection and\n15Sufi (2009 ) finds that firms do not treat banks’ credit lines as a cash-\nlike liquidity commitment because credit lines are adjustable. Chodorow-Reich\nand Falato (2022 ) show that banks can reduce loan commitment following\nborrowers’ covenant violations.\n16In addition, Inequality ( 3) implies that an entrepreneur’s ex-ante expected\nutility (to be specified later by Eq. (10)) is a concave function of the loan rate\nshe borrows with, which ensures that all equilibrium outcomes are continuous\nfunctions of parameters and simplifies our analysis.data analysis.17The cost function ( 4) captures the idea that a lender\nhas a greater capacity to discipline nearby borrowers and must expend\nmore effort to monitor entrepreneurs who are more distant from the\nlender’s expertise or geographic location.18\nRemark. The cost function ( 4) has two crucial properties when𝑞1=\n𝑞2=𝑞and𝑐1=𝑐2=𝑐. First, the ratio of the two lenders’ monitoring\ncosts at location𝑧(i.e.,𝐶1(𝑚1, 𝑧)∕𝐶2(𝑚2, 𝑧)) is independent of𝑐for any\ngiven𝑚1and𝑚2:\n𝐶1(𝑚1, 𝑧)\n𝐶2(𝑚2, 𝑧)=1 −𝑞(1 −𝑧)\n1 −𝑞 𝑧(𝑚1\n𝑚2)2\n.\nThis property implies that increasing𝑐does not affect a lender’s relative\ncost advantage, although it makes monitoring more costly for both\nlenders. The second property is\n𝜕2(𝐶1(𝑚1,𝑧)\n𝐶2(𝑚2,𝑧))\n𝜕 𝑧𝜕 𝑞=2(1 −𝑞(1 −𝑧))\n(1 −𝑞 𝑧)3(𝑚1\n𝑚2)2\n>0, (5)\nwhich means that the sensitivity of the relative cost advantage to𝑧\nis increasing in𝑞. Note that𝐶1(𝑚1, 𝑧)∕𝐶2(𝑚2, 𝑧)is increasing in𝑧.\nTherefore, a higher𝑞not only makes monitoring more costly but also\nmagnifies the importance of lender specialization by increasing the\nimportance of distance in determining the relative cost advantage of\na lender’s monitoring.\nInterpretation of monitoring . Lenders typically monitor their borrow-\ners through information collection and analysis (Minnis and Sutherland ,\n2017 ;Gustafson et al.,2021 ;Branzoli and Fringuellotti ,2022 ). Specif-\nically, lenders can collect entrepreneurs’ data (e.g., by onsite visits\nor frequently requesting information) and assess whether funds are\ndiverted toward private benefits. If borrowers are not acting appropri-\nately, lenders can provide warnings and threats, disciplining borrowers\nand potentially improving their behavior.19Eq. ( 4) captures the fact\nthat a lender’s efficiency of information acquisition and processing\ndepends on not only its basic capability but also the distance friction.\nThe distance friction can be interpreted in two ways. First, we\ncan view𝑠𝑖as the ‘‘physical distance’’ between location𝑧and lender\n𝑖. Physical distance matters because first-hand borrower information\noften contains soft information that is hard to convey to distant loan\nofficers, incurring informativeness loss in the process of remote infor-\nmation transmission (seeLiberti and Petersen ,2019 ). The second way\nis to view𝑠𝑖as the “expertise distance’’ between an entrepreneur’s\ncharacteristics and lender𝑖’s s specialization. The effectiveness of an in-\nformation analysis framework will be lower when it is used to deal with\nfirms beyond the framework’s intended scope of application (e.g., a\nframework for a food company or a real estate company).\nDistance friction can be weakened by some technologies. The diffu-\nsion of the internet and the development of communication technology\n(like smartphones, mobile apps, social media, or video conferencing)\nfacilitate remote information collection and exchange, reducing the\nfriction caused by physical distance. The friction of the expertise dis-\ntance can be weakened if an IT improvement facilitates human capital’s\n17A similar classification of technology can be found inBoot et al.(2021 ).\n18This is consistent with Giometti and Pietrosanti (2023 ) who document that\nlenders specialize in lending to specific industries because of their information\nadvantages in monitoring those industries.\n19If the collected information shows a breach of covenants, lenders can\nobtain control rights and directly intervene to fix borrowers’ behavior. Such\nintervention is easier for BigTech lenders since they have advantages in\ninformation collection and contract enforcement in their ecosystems (Liu\net al.,2024 ); in addition, they can threaten to exclude misbehaving borrowers\nfrom future use of their platforms (Frost et al.,2019 andLi and Pegoraro ,\n2023 ). With advanced information technology (such as the abundance of\ncomprehensive transactional and locational data on borrowers’ online activities\nand machine learning techniques), this kind of monitoring process can be\nconducted almost on a real-time basis (Chen et al.,2022 ).Journal  of Financial  Economics  163 (2025)  103957  \n5 X. Vives and Z. Ye\nFig. 2.Timeline.\nTable 1\nTechnology  improvements  and monitoring  efficiency.\nImprovement  of efficiency Related technology\nDecreasing 𝑐𝑖(improvement  in\ncollecting  or/and processing\ninformation)ML with big/unconventional  data\nadvances  in cloud storage and computing,\ninformation  management  software\nDecreasing 𝑞𝑖(physical  distance\nfriction)\n(improvement  in communication)Diffusion  of internet,  video conferencing,\nsmartphone,  mobile apps, social media\nDecreasing 𝑞𝑖(expertise  distance\nfriction)\n(extending  competence  of human\ncapital/hardening  soft information)ML with big/unconventional  data, remote\nlearning  and AI\nexpansion  of specialized  areas. For example,  improvements  in remote\nlearning,  search  engines,  and AI (like GPT) make it easier for loan\nofficers  to process  the information  of firms they do not specialize  in,\nthereby  decreasing 𝑞𝑖.\nTechnologies  that decrease𝑐𝑖are related  to improvements  in\nlenders’  basic efficiency  of information  acquisition  and/or  processing,\nsuch as advances  in chip technology  and cloud computing/storage,\nadopting  better software  (e.g., desktop  applications,  seeHe et al.,\n2022 ), and exploiting  new sources  of information  (like transaction  data\nand digital  footprints)  with machine  learning  (ML) techniques.20\nOne consequence  of technological  progress  is the increased  avail-\nability  of cheap but imprecise  data (seeDugast  and Foucault ,2018 ).\nIn this case, information acquisition becomes  easier but the decrease  in\ndata quality  increases  the difficulty  of information processing . The net\nchange  of𝑐𝑖depends  on which effect dominates.\nSome technologies  decrease  both𝑐𝑖and𝑞𝑖: ML with Big Data\ndecreases𝑐𝑖by improving  lender𝑖’s ability  to acquire  and process  infor-\nmation.  It also helps to harden  soft information  (e.g., digital  footprints)\nand hence reduces  the reliance  on lenders’  expertise  in certain  areas,\nwhich lowers𝑞𝑖.Table 1summarizes  the technology  improvements  and\nthe corresponding  effects  on monitoring  efficiency.\nCompetition  with discriminatory  loan pricing. Lenders  compete  in\na localized  Bertrand  fashion  to attract  entrepreneurs.  Lender𝑖follows\na discriminatory  pricing  policy in which the loan rate𝑟𝑖(𝑧)varies as a\nfunction  of the entrepreneurial  location𝑧.21\nThe timing  of the duopoly  lending  game is shown  inFig. 2. First,\nlenders  (without  observing ̃𝐵(𝑧)) post loan rate schedules  simulta-\nneously.  Once the loan rate schedules  are chosen  and posted,  en-\ntrepreneurs  (without  observing̃𝐵(𝑧)) decide  which lender  to approach\nfor credit.  Then, lender–borrower  relationships  are established,  and\n20ML can process  real-time  borrower  data quickly  at large volumes  and\nlow operating  costs (Huang et al.,2020 ).Mester et al.(2007 ) find that\ntransaction  information  in borrowers’  accounts  – which provides  ongoing  data\non borrowers’  activities  – is useful for lenders’  monitoring. Dai et al.(2023 )\nshow that monitoring  borrowers’  digital footprints  can increase  the repayment\nlikelihood  on delinquent  loans by 26.5% because  digital footprints  (e.g., cell\nphone, email or/and  apps footprints)  reveal borrowers’  social networks  and\nphysical  locations,  thereby  increasing  lenders’  ability to intervene  and enforce\nthe repayment  of borrowers.\n21Degryse  and Ongena (2005 ) document  spatial discrimination  in loan\npricing.  See alsoAgarwal  and Hauswald (2010 ) andHerpfer  et al.(2022 ).̃𝐵(𝑧)realizes  and becomes  observable  to both the entrepreneur  at𝑧and\nher lender.  Next, lender𝑖determines  its optimal  monitoring  intensity\n𝑚𝑖(𝑧)and credit limit𝐼𝑖(𝑧)depending  on its entrepreneurs’  locations.\nEntrepreneurs  choose  their investment  based on available  credit limits,\nthat is,𝐼𝑖(𝑧) ∈ [0,𝐼𝑖(𝑧)]. Finally,  entrepreneurs  determine  whether  to\nshirk.\nKey ingredients. Compared  with a traditional  (Hotelling ,1929 ) model\n(where  sellers  with heterogeneous  production  costs compete  for con-\nsumers),  our model has two additional  ingredients.  The first ingredient\nis that lenders’  effort (monitoring)  matters  for welfare  since it enables\nentrepreneurs  to invest.22The second  ingredient  is that lenders  cannot\ncommit  to effort ex ante (lenders  can set their monitoring  intensities\nand credit limits based on the new information ̃𝐵(𝑧)after entrepreneurs\nhave chosen  lenders).\n3. Equilibrium\nIn this section,  we first derive  some optimal  decisions  of lenders\nand entrepreneurs  and then solve for the equilibrium  loan rates. Since\nlenders’  loan rates can vary with entrepreneurial  locations,  there is\nlocalized  Bertrand  competition  between  lenders  at each location.  With-\nout loss of generality,  we concentrate  on location𝑧and analyze  how\nlenders  set loan rates to compete  for the entrepreneur  at𝑧.\n3.1. Optimal  monitoring  intensity,  credit limit, and entrepreneurs’  decisions\nIt is easy to see that the entrepreneur  at𝑧always  uses up her\ncredit limit for investment  (i.e.,𝐼𝑖(𝑧) =𝐼𝑖(𝑧)holds when she is served\nby lender𝑖). After𝑟𝑖(𝑧),𝑚𝑖(𝑧), and𝐼𝑖(𝑧)have been determined,  the\nentrepreneur’s ex-post expected  utility is as follows:\nmax\n𝐼𝑖(𝑧)∈[0,𝐼𝑖(𝑧)]{𝐼𝑖(𝑧)𝑝(𝑅−𝑟𝑖(𝑧)), 𝐼𝑖(𝑧)̃𝐵(𝑧) −𝑚𝑖(𝑧)}, (6)\nso𝐼𝑖(𝑧) =𝐼𝑖(𝑧)is obviously  her optimal  choice.\nOptimal  monitoring  intensity. Lender𝑖can anticipate𝐼𝑖(𝑧) =𝐼𝑖(𝑧)\nwhen determining  its monitoring  intensity𝑚𝑖(𝑧)at𝑧. Since an en-\ntrepreneur’s  shirking  implies  the failure  of her project  and a zero return\nto the lender,  lenders  must prevent  their entrepreneurs  from shirking\nwhen providing  loans, yielding  the following  lemma.\nLemma  1.If lender𝑖provides  loans to the entrepreneur  at𝑧with loan\nrate𝑟𝑖(𝑧)and observes̃𝐵(𝑧), its optimal  monitoring  intensity  is:\n𝑚𝑖(𝑧) =𝐼𝑖(𝑧)(̃𝐵(𝑧) −𝑝(𝑅−𝑟𝑖(𝑧))), (7)\nwhere𝐼𝑖(𝑧)is the lender’s  credit limit at𝑧.\nWith𝐼𝑖(𝑧) =𝐼𝑖(𝑧),Lemma  1means  Condition (2) holds  with\nequality.  For lenders,  the only benefit  of costly monitoring  is to prevent\nentrepreneurs’  shirking.  Hence,  lender𝑖will choose𝑚𝑖(𝑧)as low as\npossible,  subject  to Condition (2), which ensures  that the entrepreneur\nwill not shirk.\n22Without  monitoring,  entrepreneurs  cannot implement  their projects  be-\ncause of the moral hazard problem.  Then, both entrepreneurs  and lenders  make\na zero profit.Journal  of Financial  Economics  163 (2025)  103957  \n6 X. Vives and Z. Ye\nAccording to Eq. (7), a higher monitoring intensity is needed as the\ncredit limit (which equals investment) increases. The reason is that a\nlarger credit size implies private benefits must be reduced more (by\nmonitoring) to ensure Condition ( 2). Consistent with the result, Heitz\net al.(2023 ) document that a bank will monitor a borrower more\nfrequently if the loan amount is larger.\nIn addition, note that𝑚𝑖(𝑧)is increasing iñ𝐵(𝑧) −𝑝(𝑅−𝑟𝑖(𝑧)), which\nreflects the severity of the entrepreneur’s moral hazard. To see this,\nrecall that𝑝(𝑅−𝑟𝑖(𝑧))is the marginal expected return (i.e., skin in the\ngame) to the entrepreneur at𝑧if she does not shirk. Thus,̃𝐵(𝑧) −𝑝(𝑅−\n𝑟𝑖(𝑧))measures the potential net benefit she can derive from a unit of\ninvestment by shirking. As̃𝐵(𝑧) −𝑝(𝑅−𝑟𝑖(𝑧))increases, shirking becomes\nmore attractive, so a higher monitoring intensity is needed to prevent\nshirking. Obviously, increasing𝑟𝑖(𝑧)will reduce the entrepreneur’s skin\nin the game𝑝(𝑅−𝑟𝑖(𝑧)), thereby increasing ̃𝐵(𝑧) −𝑝(𝑅−𝑟𝑖(𝑧))) and the\nneed for monitoring.\nOptimal credit limit. According to the timeline, an entrepreneur has\ndecided which lender to borrow from before lenders determine credit\nlimits. If the entrepreneur at𝑧approaches lender𝑖, then the lender’s\nexpected profit from financing the entrepreneur can be written as\n𝜋𝑖(𝑧)=𝐼𝑖(𝑧)(𝑝𝑟𝑖(𝑧) −𝑓) −𝑐𝑖\n2(1 −𝑞𝑖𝑠𝑖)(𝑚𝑖(𝑧))2. (8)\nThe first term of𝜋𝑖(𝑧)is the entrepreneur’s expected loan repayment\nminus the funding costs. Specifically, if monitoring prevents shirking,\nlender𝑖will receive the entrepreneur’s full loan repayment 𝐼𝑖(𝑧)𝑟𝑖(𝑧)\nwith probability 𝑝(i.e., in the event of project success). The fund-\ning costs are𝐼𝑖(𝑧)𝑓. The second term of𝜋𝑖(𝑧)represents lender𝑖’s\nmonitoring costs.\nLender𝑖chooses its optimal credit limit𝐼𝑖(𝑧)to maximize its ex-\npected profit𝜋𝑖(𝑧), taking𝑟𝑖(𝑧)as given; the result is presented in\nLemma  2.\nLemma 2.If lender𝑖provides loans to the entrepreneur at𝑧with loan\nrate𝑟𝑖(𝑧)and observes̃𝐵(𝑧), its optimal credit limit is:\n𝐼𝑖(𝑧) =1 −𝑞𝑖𝑠𝑖\n𝑐𝑖𝑝𝑟𝑖(𝑧) −𝑓\n(̃𝐵(𝑧) −𝑝(𝑅−𝑟𝑖(𝑧)))2.\nThe entrepreneur’s investment size𝐼𝑖(𝑧)equals𝐼𝑖(𝑧).\nRecall that a larger credit limit or more severe moral hazard needs\na higher monitoring intensity (Lemma  1). Hence,𝐼𝑖(𝑧)is determined by\nhow much moral hazard lender𝑖’s monitoring can alleviate. There are\nthree factors affecting𝐼𝑖(𝑧): (a) lender𝑖’s information technology at𝑧,\nwhich is represented by(1 −𝑞𝑖𝑠𝑖)∕𝑐𝑖, (b) the lender’s skin in the game\n𝑝𝑟𝑖(𝑧) −𝑓, and (c) the entrepreneur’s potential net benefit of shirking,\nwhich is̃𝐵(𝑧)minus the entrepreneur’s skin in the game𝑝(𝑅−𝑟𝑖(𝑧)).\nFirst,𝐼𝑖(𝑧)is increasing in(1 −𝑞𝑖𝑠𝑖)∕𝑐𝑖because better IT implies a higher\nmonitoring efficiency (i.e., monitoring becomes cheaper). Second,𝐼𝑖(𝑧)\nis increasing in𝑝𝑟𝑖(𝑧) −𝑓because a higher lender𝑖’s skin in the game\nincreases its willingness to provide credit and monitoring. Finally,𝐼𝑖(𝑧)\nis increasing in𝑝(𝑅−𝑟𝑖(𝑧))because a higher entrepreneur’s skin in the\ngame makes the moral hazard problem less severe (i.e.,̃𝐵(𝑧) −𝑝(𝑅−\n𝑟𝑖(𝑧))becomes smaller), reducing the need for monitoring. Note that\nincreasing𝑟𝑖(𝑧)increases lender𝑖’s skin in the game but decreases the\nentrepreneur’s, so the net effect of changing𝑟𝑖(𝑧)on𝐼𝑖(𝑧)is ambiguous\n(to be analyzed later in detail).\nEntrepreneurs’ decisions . After observing the loan rates posted by\nlenders, an entrepreneur will approach the lender that can provide\nhigher ex-ante expected entrepreneurial utility. If lender𝑖offers loan\nrate𝑟𝑖(𝑧)at𝑧, then its expected credit limit𝐸[𝐼𝑖(𝑧)](based onLemma  2\nand the distribution of̃𝐵(𝑧)) is as follows:\n𝐸[𝐼𝑖(𝑧)] =1 −𝑞𝑖𝑠𝑖\n𝑐𝑖(\n𝑘(𝑝𝑟𝑖(𝑧) −𝑓)\n(𝐵−𝑝(𝑅−𝑟𝑖(𝑧)))2+(1 −𝑘)(𝑝𝑟𝑖(𝑧) −𝑓)\n(𝑏−𝑝(𝑅−𝑟𝑖(𝑧)))2)\n.(9)As a result, the entrepreneur’s ex-ante expected utility is:\n𝑈(𝑞𝑖, 𝑐𝑖, 𝑠𝑖, 𝑟𝑖(𝑧))≡𝐸[𝐼𝑖(𝑧)]\n⏟⏞⏟⏞⏟\ngiven in Eq. (9)×𝑝(𝑅−𝑟𝑖(𝑧)), (10)\nwhich takes into consideration that lender monitoring will prevent\nshirking. Inequality ( 3) ensures that𝑈(𝑞𝑖, 𝑐𝑖, 𝑠𝑖, 𝑟𝑖(𝑧))is a concave func-\ntion of𝑟𝑖(𝑧). Note that the entrepreneur’s expected utility depends not\nonly on her skin in the game𝑝(𝑅−𝑟𝑖(𝑧))but also on the expected\ncredit limit𝐸[𝐼𝑖(𝑧)], which is her expected investment. The latter is\naffected by lender𝑖’s IT and skin in the game. Therefore, the en-\ntrepreneur does not simply choose the lender with a lower loan rate. If\n𝑈(𝑞1, 𝑐1, 𝑧, 𝑟1(𝑧))> 𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟2(𝑧)), obviously the entrepreneur will\napproach lender 1 for loans.\n3.2. Equilibrium loan rates\nIn this section, we study how lenders determine their loan rates.\nBest loan rate and monopoly loan rate. Before proceeding, we define\ntwo notable loan rates of lender𝑖.\nDefinition 1.Lender𝑖’s best loan rate at𝑧is the loan rate that\nmaximizes the ex-ante expected utility of the entrepreneur at𝑧. Lender\n𝑖’s monopoly loan rate at𝑧is the loan rate lender𝑖would choose if it\nfaced no competition at𝑧.\nThe best loan rate determines how much utility a lender can provide\nin the Bertrand competition, while the monopoly loan rate deter-\nmines the maximum profit a lender can earn. The following lemma\ncharacterizes the two loan rates.\nLemma 3. At any location, a lender’s best loan rate, denoted by𝑟,\nis increasing in𝑘and independent of𝑞𝑖,𝑐𝑖, and𝑠𝑖, and satisfies𝑓∕𝑝 <\n𝑟< 𝑅. Hence, the maximum expected utility lender𝑖can provide to the\nentrepreneur at𝑧is𝑈(𝑞𝑖, 𝑐𝑖, 𝑠𝑖, 𝑟). A lender’s monopoly loan rate is𝑅.\nLenders will offer loan rates within the interval [𝑟, 𝑅].\nIf lender𝑖faces no competition at𝑧, it always prefers a higher\nloan rate. Hence, its profit-maximizing strategy is to offer the highest\npossible loan rate𝑅and monitor the entrepreneur at𝑧to prevent\nshirking. Under this strategy, the lender extracts the entire project\nvalue, leaving zero surplus to the entrepreneur.\nWhen𝑟𝑖(𝑧) =𝑟, the utility𝑈(𝑞𝑖, 𝑐𝑖, 𝑠𝑖, 𝑟𝑖(𝑧))reaches its maximum.\nThe best loan rate𝑟is higher than𝑓∕𝑝, implying that lowering𝑟𝑖(𝑧)\nmay not always increase a lender’s attractiveness to entrepreneurs. The\nreason is that entrepreneurs care about not only the loan rate but also\nthe expected credit limit (see Eq. (9)). If𝑟𝑖(𝑧)is lower than𝑟, lender\n𝑖’s skin in the game and the monitoring incentive will be very small. In\nthis case, further reducing𝑟𝑖(𝑧)will decrease𝐸[𝐼𝑖(𝑧)]rapidly, thereby\nhurting the entrepreneur at𝑧. As𝑟𝑖(𝑧)approaches 𝑓∕𝑝, the lender’s skin\nin the game𝑝𝑟𝑖(𝑧) −𝑓will decrease to 0, implying𝐸[𝐼𝑖(𝑧)]→0(see\nLemma  2). Hence,𝑟> 𝑓∕𝑝must hold.\nNote that𝑟is unaffected by lender𝑖’s monitoring efficiency (i.e., is\nindependent of𝑞𝑖,𝑐𝑖, or𝑠𝑖). The reason is that𝑟represents the en-\ntrepreneurial utility-maximizing way to allocate the project net value\nbetween an entrepreneur and her lender. Although parameters 𝑞𝑖,𝑐𝑖,\nand𝑠𝑖affect the project net value (i.e., the size of the pie), the utility-\nmaximizing allocation rule (i.e., the sharing of the pie) is independent\nof them.\nWhen𝑘is higher, the potential marginal private benefit̃𝐵(𝑧)is more\nlikely to be high. In this case, entrepreneurs’ moral hazard problem is\nexpected to be more severe, generating a higher need for lenders’ mon-\nitoring to alleviate the problem. This means that a lender’s expected\ncredit limit will be very low if its skin in the game – which determines\nthe lender’s monitoring incentive – is small. As a result, allocating\na higher share of the pie to lenders (i.e., raising their monitoring\nincentives) is aligned with entrepreneurs’ interests, leading to a higher\nbest loan rate𝑟.Journal  of Financial  Economics  163 (2025)  103957  \n7 X. Vives and Z. Ye\nIn a competition of the Bertrand type, lender𝑖’s loan rate is always\nwithin the interval [𝑟, 𝑅]. If𝑟𝑖(𝑧)< 𝑟, decreasing 𝑟𝑖(𝑧)hurts the lender\nwithout increasing its attractiveness, so neither lender will offer a loan\nrate below𝑟. In the interval [𝑟, 𝑅], increasing 𝑟𝑖(𝑧)implies a higher\nlender𝑖’s profit at𝑧, but it implies lower entrepreneurial utility, thereby\nreducing the lender’s attractiveness in the competition.\nEquilibrium loan rates . We posit some standard assumptions in our\nBertrand competition model. (i) When𝑈(𝑞1, 𝑐1, 𝑧, 𝑟1(𝑧)) =𝑈(𝑞2, 𝑐2,1 −\n𝑧, 𝑟2(𝑧))holds, we assume that the entrepreneur at𝑧will approach\nthe lender that can potentially provide a higher maximum expected\nentrepreneurial utility (i.e., will approach lender 1 if𝑈(𝑞1, 𝑐1, 𝑧, 𝑟)>\n𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟)).23(ii) If both𝑈(𝑞1, 𝑐1, 𝑧, 𝑟1(𝑧)) =𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟2(𝑧))and\n𝑈(𝑞1, 𝑐1, 𝑧, 𝑟) =𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟)hold, then we assume the entrepreneur\nwill randomly approach a lender with probability 1∕2; different en-\ntrepreneurs’ random choices are independent.\nUsing Lemmas  1to3, we can solve for lenders’ equilibrium loan\nrates. If lender 1 wants to attract the entrepreneur at𝑧, it must offer a\nloan rate weakly more attractive than the best loan rate𝑟of lender 2\n(i.e., ensure𝑈(𝑞1, 𝑐1, 𝑧, 𝑟1(𝑧))≥𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟)). If lender 1 cannot do\nso, then the entrepreneur will be served by lender 2 instead. Reasoning\nin this way yields the equilibrium loan rates inProposition  1.24\nProposition 1.Let\ñ 𝑥≡1 −𝑐1∕𝑐2+𝑐1𝑞2∕𝑐2\n𝑐1𝑞2∕𝑐2+𝑞1.\nWhen 0< ̃ 𝑥 <1, there exists a unique equilibrium in which en-\ntrepreneurs located in[0, ̃ 𝑥)(resp. (̃ 𝑥,1]) are served by lender 1 (resp. lender\n2). At𝑧=̃ 𝑥, the entrepreneur is served by lender𝑖∈ {1,2}with probability\n1∕2. At𝑧∈[0, ̃ 𝑥], lender 1’s equilibrium loan rate schedule,𝑟∗\n1(𝑧), is the\nunique solution (in interval [𝑟, 𝑅]) of\n𝑈(𝑞1, 𝑐1, 𝑧, 𝑟∗\n1(𝑧))\n⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟\nentrepreneurial utility provided by𝑟∗\n1(𝑧)=𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟)\n⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟\nmaximum utility lender 2 provides. (11)\nAt𝑧∈[̃ 𝑥,1], lender 2’s equilibrium loan rate schedule𝑟∗\n2(𝑧)is determined\nin a symmetric way.\nProposition  1shows the existence and uniqueness of the equilib-\nrium. The restriction 0< ̃ 𝑥 <1guarantees that both lenders can attract\na positive mass of entrepreneurs in equilibrium. If this restriction does\nnot hold (which occurs when the difference between the two lenders’\nIT is sufficiently large), then one lender will drive the other lender out;\nin this case, lenders’ pricing policy displayed inProposition  1is still\nrobust for the dominant lender.25For convenience, we focus on the case\n0< ̃ 𝑥 <1for the rest of the paper.\nProposition  1implies that lender–borrower distance matters for\nlending if𝑞𝑖>0holds for some𝑖(i.e., if distance friction exists in\nthe market). Attracting an entrepreneur will be harder for a lender\nif the entrepreneur is located farther away because then the lender’s\nrelative cost advantage in monitoring is smaller. As a result, lender 1\n(resp. lender 2) can originate loans only in the region [0, ̃ 𝑥](resp. [̃ 𝑥,0]),\nand so must give up entrepreneurs who are sufficiently distant. The\n23If𝑈(𝑞1, 𝑐1, 𝑧, 𝑟)> 𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟)holds, lender 1 can provide utility\n𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟2(𝑧)) +𝜀(with𝜀small) no matter how lender 2 sets𝑟2(𝑧).\n24In our model, a lender’s profit at𝑧is discontinuous in the two lenders’\nloan rates. A pure-strategy Nash equilibrium still exists because Bertrand\nlending competition in our model is abetter-reply secure game. SeeDasgupta\nand Maskin (1986 ) andReny (1999 ).\n25For example, if𝑐2is much larger than𝑐1, theñ 𝑥≥1will hold; in this\ncase, lender 1 is the dominant lender. The monitoring efficiency and the\ncorresponding expected credit limit of lender 2 are so low that it cannot attract\nany entrepreneur even if its best loan rate𝑟is offered. The equilibrium loan\nrate of lender 1 at𝑧still equals𝑟∗\n1(𝑧)because lender 2’s competitive pressure\nstill exists even though it serves no locations.location𝑧=̃ 𝑥is theindifference location where neither lender has a cost\nadvantage in monitoring, that is:(1 −𝑞1̃ 𝑥)∕𝑐1= (1 −𝑞2(1 −̃ 𝑥))∕𝑐2. The\ntwo lenders offer the same maximum utility at this location, and the\nentrepreneur randomly chooses a lender with a probability of1∕2. Note\nthat̃ 𝑥is decreasing in𝑞1and𝑐1; this means lender 1 can reach farther\nlocations if its information technology develops. This result is consistent\nwith Ahnert et al.(2024 ) who document that small business lending\nby banks with higher IT adoption is less affected by bank–borrower\ndistance.\nNext, we characterize lenders’ pricing strategies.\nCorollary 1.Let𝑞𝑖>0for some𝑖∈ {1,2}and𝑧∈ [0, ̃ 𝑥]. Lender 1’s\nequilibrium loan rate𝑟∗\n1(𝑧)is decreasing in𝑧. A symmetric result holds for\n𝑟∗\n2(𝑧)at𝑧∈ [̃ 𝑥,1]. At the indifference location𝑧=̃ 𝑥,𝑟∗\n1(𝑧) =𝑟∗\n2(𝑧) =𝑟\nholds.\nWith distance friction (i.e.,𝑞𝑖>0for some𝑖∈ {1,2}), the schedule\n𝑟∗\n1(𝑧)displays a ‘‘perverse’’ pattern (see Panel 1 ofFig. 3): As lender\n1’s monitoring efficiency goes down (i.e., as an entrepreneur is farther\naway), the loan rate offered to that entrepreneur decreases. Such a\npattern results from the optimal pricing strategy of lender 1 at𝑧∈ [0, ̃ 𝑥]:\nmaximizing the lender’s profit while ensuring that entrepreneurial util-\nity is no less than the maximum utility the rival can provide. Based on\nthis strategy, at𝑧∈ [0, ̃ 𝑥]the entrepreneurial utility implied by lender\n1’s equilibrium loan rate𝑟∗\n1(𝑧)should exactly match the maximum\nutility𝑈(𝑞2, 𝑐2,1 −𝑧, 𝑟)lender 2 can provide.\nAs𝑧increases in the region [0, ̃ 𝑥], lender 1’s monitoring efficiency\ndecreases relative to lender 2’s. Hence, lender 1 must offer a lower\n𝑟∗\n1(𝑧)to match the maximum utility provided by lender 2, implying\nthe perverse loan rate pattern. The implication of the result is that\nentrepreneurs in the region [0, ̃ 𝑥]cannot benefit from lender 1’s advan-\ntageous monitoring efficiency; instead, lender 1 itself extracts the entire\nbenefit of its IT advantage over lender 2.Corollary  1is consistent with\nthe findings ofHerpfer et al.(2022 ): a bank will charge its borrowers\nhigher loan rates if the borrowers geographically get closer to the bank\nor/and farther away from competing banks.\nAt the indifference location𝑧=̃ 𝑥, neither lender has a cost advan-\ntage in monitoring, so the intensity of lender competition is maximal\nthere. Therefore, a lender must offer its best loan rate𝑟to match\nthe utility provided by the rival lender. Panel 1 ofFig. 3graphically\nillustrates lenders’ equilibrium rates when𝑞𝑖>0.\nThe case with no distance friction (𝑞1=𝑞2= 0). If𝑐1=𝑐2holds,\nthe two lenders have the same monitoring efficiency at all locations,\nmeaning that competition intensity is unboundedly high everywhere. In\nthis case, every location is an indifference location with both lenders\noffering the best loan rate𝑟, and, by assumption, every entrepreneur\nwill randomly choose a lender with probability 1∕2. Then, each lender\ncan obtain half of the market, which is consistent with the limit by\nletting𝑞1=𝑞2tend to0. Note that in this case,𝑟∗\n1(𝑧) =𝑟∗\n2(𝑧) =𝑟is also\nconsistent with the pricing strategies displayed inProposition  1.26\nInvestment. The investment 𝐼𝑖(𝑧)of the entrepreneur at𝑧is random\nand depends oñ𝐵(𝑧). However, the randomness will disappear if we\naverage the investment of a positive mass of entrepreneurs, in which\ncase the expected investment 𝐸[𝐼𝑖(𝑧)]at𝑧(based on the distribution of\ñ𝐵(𝑧)) matters. The following corollary characterizes how𝐸[𝐼𝑖(𝑧)]varies\nwith location.\nCorollary 2. Let𝑞𝑖>0for some𝑖∈ {1,2}and𝑧∈ [0, ̃ 𝑥]. The\nentrepreneur’s expected investment𝐸[𝐼1(𝑧)]– which equals𝐸[𝐼1(𝑧)]– is\ndecreasing in𝑧when𝑧is sufficiently close tõ 𝑥. A symmetric result holds\nfor𝐸[𝐼2(𝑧)]at𝑧∈ [̃ 𝑥,1].\n26If𝑞1=𝑞2= 0and𝑐1≠𝑐2hold, then the lender with better IT-basic\n(i.e., higher monitoring efficiency) will drive out the other lender. In this case,\nthe equilibrium loan rate of the dominant lender still follows the pricing policy\ninProposition  1and is invariant to𝑧because locations do not affect a lender’s\ncompetitive advantage when distance friction is absent.Journal  of Financial  Economics  163 (2025)  103957  \n8 X. Vives and Z. Ye\nFig. 3.Equilibrium  loan rates and expected  loan volumes  for different  locations.  This figure plots the equilibrium  loan rate and expected  loan volume against the entrepreneurial\nlocation.  The parameter  values are𝑅= 2.4,𝐵= 0.9,𝑏= 0.4,𝑘= 0.5,𝑝= 0.5,𝑓= 1,𝑐1= 1,𝑐2= 1,𝑞1= 0.6, and𝑞2= 0.6.\nAs𝑧increases  in the region [0, ̃ 𝑥], several  competing  effects  work on\nlender  1’s credit limit and hence expected  entrepreneurial  investment.\nFirst, if𝑞1>0, the direct effect of increasing𝑧is to decrease  lender\n1’s monitoring  efficiency  (because  of the longer  lending  distance),\nwhich tends to reduce𝐸[𝐼1(𝑧)]. Second,  the indirect  effect is that𝑟∗\n1(𝑧)\ndecreases  (seeCorollary  1), which in general  has an ambiguous  effect\non𝐸[𝐼1(𝑧)]. On the one hand, a lower𝑟∗\n1(𝑧)increases  the entrepreneur’s\nskin in the game, making  the moral hazard  problem  less severe  and\nhence tending  to increase𝐸[𝐼1(𝑧)]; on the other hand, it reduces  lender\n1’s skin in the game and monitoring  incentive,  tending  to decrease\n𝐸[𝐼1(𝑧)]. When𝑧is close tõ 𝑥, lender  competition  is very intense\n(i.e.,𝑟∗\n1(𝑧)is very close to𝑟), so the dominant  effect of decreasing 𝑟∗\n1(𝑧)\nis to reduce  lender  1’s monitoring  incentive,  which,  together  with the\ndirect effect, leads to a lower𝐸[𝐼1(𝑧)]. Panel 2 ofFig. 3illustrates  the\nresult.27\n4. Information  technology  and lender  competition\nIn this section,  we first derive  comparative  statics  of monitoring\nparameters  on loan rates, lending  volumes,  and lender  profits.  Then,\nwe study the competition  between  a fintech  and a bank.\n4.1. Comparative  statics of monitoring  parameters\nWe analyze  the comparative  statics  of (a) an individual  lender’s\n(e.g., lender𝑖’s) IT and (b) the lending  sector’s  IT, with a focus on the\nlatter. Table 2summarizes  the results.  When looking  at the lending\nsector (instead  of an individual  lender),  we let𝑐1=𝑐2=𝑐and\n𝑞1=𝑞2=𝑞hold and use𝑞and𝑐to represent  the sector’s  IT-distance\nand IT-basic,  respectively.\nInformation  technology  and loan rates. The following  corollary\nanalyzes  how equilibrium  loan rates vary with', 'raytos.bsinfotech@gmail.com', ' Xavier Vivesa, Zhiqiang Ye', '', '../pdf_files/674d52370f641-Information technology and lender competition.pdf', 2749477, 19, 18447, 127872, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(61, '5992067688', '51', 5, 5, ' Revisiting the effect of information and communication  technologies on employment growth in Ghana: The role of  enterprise formality', '2024-12-02 14:24:21.414187', '2024', 'The employment effect of information and communication technologies (ICT) on firm perfor mance remains a critical topic for policy and academic research. However, our understanding of the ICT-employment growth relationship in both informal and formal sectors in developing countries remains limited. Based on repeated cross-sectional data collected in 2013 and 2015 on 483 Ghanaian manufacturing enterprises and estimating a Feasible Generalised Least Squares (FGLS) regression model, the findings show that access to the internet leads to employment growth in enterprises, while the adoption of mobile phone technologies reduces the number of workers in enterprises. The positive effect of internet access on employment growth tends to be greater in enterprises with a higher degree of formality, while informal enterprises appear to remain small in terms of employment by using internet technology. We discuss these findings and their implications for digital technology policy in developing countries.', 'Information and communication technologies,Employment,Small enterprises,Informality,Ghana Africa', 'Revisiting the effect of information and communication \ntechnologies on employment growth in Ghana: The role of \nenterprise formality\nXiaolan Fua, Elvis Korku Avenyoa,b,*\naTechnology and Management Centre for Development, Oxford Department of International Development, University of Oxford, UK\nbCentre for Competition, Regulation and Economic Development and DSI/NRF South African Research Chair in Industrial Development, University \nof Johannesburg, South Africa\nARTICLE INFO\nEditor: DR B Gyampoh\nJEL Codes:\nO17\nO33\nO55\nQ55\nJ40 \nKeywords:\nInformation and communication technologies\nEmployment\nSmall enterprises\nInformality, Ghana\nAfricaABSTRACT\nThe employment effect of information and communication technologies (ICT) on firm perfor -\nmance remains a critical topic for policy and academic research. However, our understanding of \nthe ICT-employment growth relationship in both informal and formal sectors in developing \ncountries remains limited. Based on repeated cross-sectional data collected in 2013 and 2015 on \n483 Ghanaian manufacturing enterprises and estimating a Feasible Generalised Least Squares \n(FGLS) regression model, the findings show that access to the internet leads to employment \ngrowth in enterprises, while the adoption of mobile phone technologies reduces the number of \nworkers in enterprises. The positive effect of internet access on employment growth tends to be \ngreater in enterprises with a higher degree of formality, while informal enterprises appear to \nremain small in terms of employment by using internet technology. We discuss these findings and \ntheir implications for digital technology policy in developing countries.\nIntroduction\nInformation and communication technologies (ICT) are at the heart of today ’s global digital technology revolution [15,26,34]. As a \nresult, there is a wealth of literature examining the effect of ICT on growth and development, particularly in developing countries. The \nemerging evidence suggests that ICT drive economic growth and enhance various dimensions of development such as capabilities \nbuilding and access to information, education, finance, and health services [25,27,33].\nHowever, the evidence is mixed in Africa. ICT are found to boost inclusive human development and poverty alleviation in the \nregion [4,26,51]. ICT such as mobile phones, for instance, are also found to have an appealing complementary role for some business \ndimensions [2] and positive net effects on value added to the service sector [3]. Gaglio et al. [28] found similar results, indicating that \nselected digital communication technologies have a positive effect on innovation, and a subsequent positive effect on labour pro-\nductivity in micro and small enterprises in South Africa. On the contrary, the evidence also suggests that the ICT revolution is biased \n*Corresponding author at: DSI/NRF South African Research Chair in Industrial Development (SARChI-ID), Johannesburg Business School Park, \n69 Kingsway Avenue, Auckland Park, Johannesburg, 2092, South Africa.\nE-mail address: elvisa@uj.ac.za (E.K. Avenyo). \nContents lists available at ScienceDirect\nScientific African\nu{�~zkw! s{yo|kro>! ÐÐÐ1ow�o�t o~1m{y2w{m k�o2�mtkq\nhttps://doi.org/10.1016/j.sciaf.2024.e02394\nReceived 12 May 2024; Received in revised form 3 September 2024; Accepted 16 September 2024  Scientiϧc  African  26 (2024)  e02394  \nAvailable  online  18 September  2024  \n2468-2276/©  2024  The Author(s).  Published  by Elsevier  B.V. This is an open access  article  under  the CC BY license  \n( http://creativecommons.org/licenses/by/4.0/  ). towards large enterprises, threatens the survival of local and informal SMEs, and it is yet to transform African SMEs [23,42]. The \nenhancement of mobile phone and internet penetrations, for instance, are also found to have net negative effects on value added in the \nagricultural and manufacturing sectors Asongu, et al. [3].\nDespite the growing empirical evidence examining the effect of ICT on various measures of firm performance, the ICT - employment \ngrowth relationship is under-researched in Africa [37]. Majority of the available research is concentrated on developed countries (see, \nfor instance [12,19,22]). Also, the available literature is found to focus mainly on productivity and innovation effects of ICT [28] or the \nrole of ICT in bridging the digital divide [34,39].1\nGiven the nature of ICT and its potential disruption to the labour market, understanding the employment effects of ICT is critical for \npolicy, specifically in Africa. This is important given that ICT is a process innovation with direct cost-saving and efficiency effects on \nenterprises [38,52 ], and may generate ambiguous effects on employment in Africa. Also, given that ICT are skill biased [13], its \nadoption in firms may lead to lower growth in total employment in developing countries. Finally, given the high level of informality \nand the evidence that the diffusion of ICT is uneven [33], particularly in Africa, there may be substantial differences in the adoption \nand use of ICT within and across formal and informal enterprises, leading to heterogenous effects on employment growth.\nBased on the foregoing, this paper investigates the effect of ICT on employment growth in Ghanaian manufacturing enterprises. \nSpecifically, we examine the relationship between ICT adoption and employment growth in Ghanaian manufacturing by posing two \nmain questions: (1) Does the adoption of ICT- access to the internet and mobile phone use - affect the manufacturing employment \ngrowth of both formal and informal enterprises in Ghana? (2) Does the formality status of enterprises influence ICT’s effect on \nmanufacturing employment growth? To answer these questions, we employ a balanced repeated cross-sectional data collected as part \nof the Diffusion of Innovation in Low-Income Countries (DILIC) project in Ghana, covering the period 2011-2015.2Estimating Feasible \nGeneralised Least Squares (FGLS) panel regression, our results show that internet use enhances the employment growth of enterprises, \nwhile the use of mobile phones displaces workers. These effects are much stronger for firms that are closer to the formality end of the \nscale on the informality-formality continuum.\nThe paper and its findings contribute to the literature in several ways. Firstly, it contributes to the firm growth literature by \nproviding rare quantitative evidence on the ICT-employment growth nexus from a developing country context. Secondly, the informal \neconomy is a major sector in developing countries. Given that the informal economy is significant in Africa, and ICT have been \nidentified as key in transforming the performance of informal enterprises [18,30], it is crucial to examine enterprises’ ICT adoption \nbehaviours, and how they differ across formality status of firms. However, this ‘dualist’ structure of African economies – registered \n(formal) and unregistered (informal) - is under-researched in the literature. This study contributes to the literature by providing a \ncomparative evidence of the employment effects of ICT on the informal versus the formal sectors; and offers useful policy implications \nfor technology policy in a developing country context. Thirdly, the study uses two repeated cross-sectional data sets which allows us to \nexamine the dynamic effects of ICT on the employment growth of enterprises. The use of similar data is absent in the literature (see \n[46], for a rare exception).\nThe rest of the paper is structured as follows. Section 2 presents and discusses the literature on the effect of ICT on employment in \ndeveloping countries. Sections 3 and 4 discuss the methodology and empirical findings from the econometric regressions respectively. \nSection 5 concludes the paper with some key policy directions emerging from the paper.\nICT and employment growth in developing countries – role of formality status\nThe emerging fourth industrial revolution (4IR) technologies promise to generate growth for economies and firms that successfully \nadopt and leverage the benefits of ICT-based digital technologies. As a result, developing countries are implementing policies that aim \nto close the technological gap through the acceleration of ICT-based digital learning and upgrade in firms.\nAt the firm level, ICT are an important driver of value creation and success in firms. In particular, ICT adoption is found to enhance \norganisational and production processes [13], drive productivity [14], and the innovativeness of firms [26,38]. The literature, \ntherefore, shows a strong positive relationship between ICT and the performance of firms, although largely focusing on the produc -\ntivity and innovation effects of ICT.\nHowever, the dominant positive effects of ICT in the productivity and innovation literature may not be easily extrapolated to the \nICT-employment literature for three reasons. Firstly, the effect of ICT on employment may be ambiguous given that ICT are a process \ninnovation that may have direct cost-saving and efficiency effects on enterprises [28,38,52 ]. The efficiency gains from process \ninnovation may also lead to lower prices, thereby incentivising demand and leading to positive net employment growth [6]. Secondly, \naccording to skill-biased technical change theory, ICT are skill-biased [13] and as a result, may lead to lower growth in total \nemployment in developing countries. Thirdly, given that the diffusion of ICT is uneven [33], there may be substantial differences in the \nadoption and use of ICT, and subsequently, their effect on the employment performance of informal enterprises compared with their \nformal counterparts.\nIn the empirical literature, there is growing research on the effect of ICT on employment. Bresnahan et al. [13] highlight the critical \nimportance of indirect mechanisms in explaining how ICT affect the demand for labour in the United States of America. Aubert-Tarby, \n1In exception, Hjort and Poulsen [33] found that fast internet appears to have a positive impact on employment rates in African countries.\n2The Diffusion of Innovation in Low-Income Countries (DILIC) project was an international project to study the innovation activities and diffusion \nof technologies in developing countries. DILIC was funded by the UK’s Economic and Social Research Council and Department for International \nDevelopment.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n2 et al. [5] found ICT to be employment neutral in Europe [10]. In the context of developing economies, using industry level data from \nChina, Wang et al. [49] found that internet directly promotes employment within an industry, and indirectly through inter-industry \nspillovers on employment in other industries and positively affects employment within industry. In Latin America, Garcia-Murillo [29] \nfound conflicting results, with the use of mobile phones having a significantly negative influence on employment.\nPresenting a rare example, Hjort and Poulsen [33] analysed the impact of the internet on employment across twelve African \ncountries. The authors found a significantly positive effect of fast internet speeds on the probability of employment. Further analysis by \nthe authors showed that the positive employment impacts of ICT are driven mainly by the growth in skilled employment, an increase in \nemployment of less-educated workers, increase in entry by new firms, and the enhancement of productivity and the exporting activities \nof firms. Related studies by Tshukudu [47] and Khan, et al. [37] also found mixed effects of ICT on employment. The authors found \ninternet use to have a negligible effect on the probability of employment, while mobile phone ownership tends to have a positive effect \non the probability of employment only in certain countries.\nThe foregoing literature suggests that there is non-convergence in the empirical literature, in terms of the relationship between ICT \nand employment growth. More importantly, the available evidence focuses only on the formal economy and the activities of formal \nenterprises.\nThere is a growing literature on the importance of the informal economy in developing countries [7,40,43,44]. The evidence also \nsuggests that these informal enterprises operate along a continuum where they have varying degrees of informality [11,36,48,50]. The \nempirical evidence from the informality literature shows that the level of employment and output of the informal sector is critical to \nthe economies of most developing countries, and that ICT are key in transforming the performance of informal enterprises [18,30]. \nThis is because ICT are general-purpose technologies that could influence the formalisation (transition) of informal enterprises, or \notherwise, through reductions in transaction costs and general efficiency gains. For instance, Garcia-Murillo and Velez-Ospina [30] \nexamined the role of ICT in transitioning informal activities to the formal sector. Using country-level data from 170 countries, the \nauthors found that mobile phone use leads to the growth of the informal economy (transition to informality). Access to broadband \ninternet reduces the size of the informal economy (transition to formality).\nHowever, the ICT-employment literature in Africa has largely ignored these ICT adoption behaviours of informal enterprises and \ntheir effects on employment growth. Recognising the possible differences in the ICT adoption behaviours of informal enterprise \ncompared with formal firms,3and in how ICT adoption may affect the employment performance of informal enterprises compared with \ntheir formal counterparts, we pose two main questions: How will the level of formality affect the impact of ICT adoption on jobs in the \nfirms in Africa? Would informal enterprises respond different to the opportunities offered by ICT? This paper provides evidence on \nthese relationships.\nMethodology\nData\nAs noted, we use two repeated cross-sectional data sets collected as part of the ‘Diffusion of Innovation in Low-Income Countries’ \n(DILIC) project in Ghana: cross-section 1 conducted at the end of 2013 (covering 2011-2013), and cross-section 2 conducted at the end \nof 2015 (covering 2013-2015).4The data sets were collected by the University of Oxford’s Technology Management Centre and \nDevelopment (TMCD) and the Science and Technology Policy Research Institute (STEPRI-Ghana). This novel enterprise-level data \ncover formal and informal Ghanaian manufacturing enterprises across all major regions of Ashanti, Central, Eastern, Western, Greater \nAccra, and the then designated Northern Regions.\nInformal enterprises do not appear in official databases, therefore the survey employed different sampling procedures for formal \nand for informal enterprises. For formal enterprises, the sampling frame (population of enterprises) was used on three main sources: \nthe 2003 National Industrial Census; the Micro, Small, and Medium Enterprises database; and the register of the Association of Ghana \nIndustries (AGI). The population of informal enterprises was based on a random sample of 25 enterprises in 10 clusters across pur-\nposively selected sub-sectors and regions. The sampling frame comprised 4,658 enterprises. Random sampling was conducted to select \nenterprises by stratifying enterprises into industry, size, and region. For cross-section 2, for instance, a total of 502 enterprises con-\nsisting of 321 informal enterprises and 181 formal enterprises were sampled and surveyed (see Table 1).5\nBoth cross-sections of the data contain detailed information on enterprises’ characteristics, including sales, employment, etcetera in \nboth the formal and informal economies. The data contain two main ICT variables of interest: access to the internet, and access to \nmobile phones that we use in this paper to examine the effect of access to ICT on employment growth.\nA major advantage of using the DILIC data is that the survey collected information on enterprises by stratifying them into different \nstatus based on their registration and the nature of their main economic activities. In both cross-sections of the DILIC survey, the status \nof an enterprise is defined by registration with the Registrar General’s Department. The law in Ghana considers all enterprises without \na business registration certificate to be an informal enterprise, while all registered enterprises are formal enterprises. For the DILIC data \ncollection all participants were asked to indicate based on their operations how they define the nature of their enterprise. This enables \n3Ilavarasan [35], for instance, found that the use of ICT is limited in informal enterprises in India.\n4Although the data were collected about nine years ago, the use of this repeated cross-sectional data is unique in the literature and provides useful \ninsights to understand the correlation between ICT adoption and jobs in the firms in Africa.\n5See Table 1for the list of enterprises by manufacturing industries for cross-section 2.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n3 us to classify formal and informal enterprises into different spectrums, and to examine the varying employment growth generated \nacross these groups.\nTable 2below presents the descriptive statistics of all the variables we employ in the paper for the balanced repeated cross-sectional \ndata.6The table shows that, over the period, the average employment growth is 3.4 % in our data. The average proportion of en-\nterprises with access to the internet is about 25 %, while the average share of enterprises with access to mobile phones is about 92 %. \nThe descriptive statistics of our formality status variable suggest that enterprises operate in a continuum, with informal enterprises \ndominating in the data (about 50 %).\nThe empirical model\nThe econometric model used in the paper attempts to explain the extent to which employment growth is driven by ICT in Ghanaian \nenterprises. Based on this, we formulate a model as follows: \nEmployment growth itαitβICT itγStatus itρZiCtδiδjϑtεit (1) \nwhere t1C…CTi, and i1C…CNBEmployment growth it is the employment growth of enterprises across i and t. ICTit refers to a vector \nof ICT indicators: access to the internet and access to mobile phones across i and t. Status it is a categorical variable indicating the \nregistration status and the nature of operations of enterprises across i and t. ZiCt is a vector of all other explanatory variables. Finally, δi \nand δj are the enterprise and industry fixed effects, ϑt is the year effect, and εit is the idiosyncratic error term.\nA key econometric issue in estimating Eq. 1is the possible reverse causality between ICT adoption and employment growth. This is \nbecause employment growth could be as a result of the use of internet and telephones, it could also be that successful (growing) \ncompanies access and use ICT more than unsuccessful enterprises. To resolve this econometric issue, we employ ICT variables at the \nbeginning of each cross-section, that is as lags. This way, we allow enterprises to adopt ICT before making employment decisions. The \nuse of lags, while useful, may not completely solve the reverse causality problem. As a result, we interpret only the signs of our co-\nefficients and the findings as correlations.\nEq. (1)therefore models the employment growth of enterprises as explained by our ICT proxies, the dynamic transition status of \nenterprises, and other explanatory variables including time and industry dummies. Zit includes the age of the enterprise and its square, \nboth in logs, to capture the non-linearity in age. Besides age, we include the lagged size of the enterprise, and lagged domestic market \nshare of the enterprise, both in logs and lagged, to take care of possible simultaneity bias between age, market share, and employment \ngrowth, as well as dummies capturing the level of education of the owner, and whether the enterprise undertakes formal and informal \njob training of workers. We also capture variables such as whether or not the enterprise is a sub-contractor, is part of a company group, \nin a network, have a foreign investor, is owned by a group of people, is male-owned, and the city of where the enterprise is located, as \nwell as the industry in which the enterprise operates. Given the diverse nature of enterprises in terms of size, sector, and location in our \npanel, we employ the FGLS regression to estimate Eq. 1to allow for cross-sectional autocorrelation and heteroskedasticity across the \nerror terms. Modelling this underlying structure of our panel using FGLS is found to generate efficiency gains compared to OLS [32].\nVariable justification\nBased on the literature, we use employment growth as our dependent variable (see, for instance [16,38,41]). It is constructed as Table 1 \nList of enterprises in the sample by industry.\nIndustries Full sample Informal Formal\nManufacture of food products 124 90 34\nManufacture of beverages 2 0 2\nManufacture of textiles 23 15 8\nManufacture of wearing apparel 102 52 50\nManufacture of leather and related products 1 1 0\nManufacture of wood and of products of wood and cork 51 36 15\nManufacture of paper and paper products 10 0 10\nPrinting and reproduction of recorded materials 9 4 5\nManufacture of chemicals and chemical products 1 1 0\nManufacture of basic pharmaceutical products 1 0 1\nManufacture of rubber and plastics products 8 0 8\nManufacture of fabricated metal products 65 45 20\nManufacture of electrical equipment 2 2 0\nManufacture of machinery and equipment 1 0 1\nManufacture of furniture 74 51 23\nOther manufacturing 5 4 1\nRepair and installation of machinery 21 20 1\nConstruction of buildings 2 0 2\n6Table 3shows the list and definition of all variables.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n4 logarithm (log) differences between total employment at the end of each cross-section (2013 and 2015) and the total employment at \nthe beginning of each cross-section (2011 and 2013).7In both cross-sections of the DILIC survey, enterprises were asked to state the \ntotal employment in the enterprise in the last fiscal year and in the fiscal year three years prior the survey. For instance, in cross-section \n1, the data set contains information on the employment level of enterprises in 2011 and 2013, while for cross-section 2, the data \ncontain employment information in 2013 and 2015. Employment growth is then generated as the logarithm difference between the \nappended employment levels in 2011 and 2013 and that of 2013 and 2015.\nOur study gives insight into the link between employment growth and ICT using access to the internet and access to mobile phones \nas proxies, following Khan et al. [37], and Garcia-Murillo and Velez-Ospina [30]. Enterprises that use the internet are more innovative \nand sell more innovative products [26]. Internet use enhances the effectiveness of relations by reducing the cost of establishing and \nmaintaining social and business relations [15,20,33]. This leads to radical changes to and in the distribution networks of goods and \nservices, and how products are priced and exchanged [15]. Given the above and the evidence that the expansion of internet infra-\nstructure is key to Africa ’s employment creation potential [33], we expect access to the internet to have a positive employment growth \neffect due to its market expansion effects.\nAccess to business mobile phones may enhance communication within the enterprise and with other enterprises, customers, and \nsuppliers [34]. This is found to lead to immediacy, thereby resulting in the reduction in transaction cost leading to competitiveness in \nmedium and small-scale enterprises (MSEs)[ 21]. This cost and time effective medium of communication may replace certain kinds of \nworker, specifically unskilled workers such as messengers employed to undertake routine tasks. In the DILIC data, access to the internet \ntakes the value 1 if the enterprise uses the internet in its daily operations and 0 if otherwise. Access to mobile phones is also a dummy \nindicating whether the enterprise has a dedicated mobile phone for daily use and operations of the enterprise and 0 if otherwise. As \nnoted, we use the lag of ICT to control for possible endogeneity between our ICT and employment variables.\nAs noted, the literature on formality and informality shows that all enterprises in developing countries operate along a continuum \nwhere they have varying degrees of informality [11,36,48,50]. Examining the determinants of the varying levels of informality of \ninformal enterprises in Lahore, Pakistan, using the survey data of 300 micro-enterprises and constructing an index of informality based \non three proxies, Williams et al. [50] find that informal enterprises operate at different levels of informality, which are determined by \nthe characteristics of entrepreneurs and enterprises. Maloney [40] also find similar results in Latin America arguing that the informal \nand formal sectors are intertwined, while Kawooya [36] find ‘symbiotic ’ linkages between informal and formal sectors in Kampala, \nUganda. Bohme and Thiele [11] in their study of informal enterprises in West Africa also found formal-informal linkages depend on the \ndegree of informality (Table 3).\nBased on one-step transition probabilities obtained from the Markov chain analysis for the two repeated cross-sections, 2013 (t \01) \nand 2015 (t), the formality status of enterprises is defined as a categorical variable based on whether the enterprise is legally registered \nor not, and on the nature of the economic activity of the business, and defined as 0 if the enterprise is unregistered and operates entirely \nin the informal sector (informal), 1 if the enterprise is informal and operates in the formal sector (semi-informal), 2 if the enterprise is \nregistered and operates in the informal sector (semi-formal), and 3 if the enterprise is registered and operates entirely in the formal \nsector (formal). The descriptive statistics suggest that about 68 % and 53 % of informal and formal enterprises remained in their initial Table 2 \nDescriptive statistics.\nMean S.D. Overall S.D. Between S.D. Within\nVariables\nDependent variable ​ ​ ​ ​\nGrowth of employment (log) 0.034 0.530 0. 414 0. 341\nExplanatory variables ​ ​ ​ ​\nAccess to internet (Yes1) 0.248 ​ ​ ​\nAccess to mobile phone (Yes1) 0.917 ​ ​ ​\nFormality status of enterprises ​ ​ ​ ​\nInformal 0.491 ​ ​ ​\nSemi-informal 0.056 ​ ​ ​\nSemi-formal 0.145 ​ ​ ​\nFormal 0. 308 ​ ​ ​\nAge of enterprise 18.04 11.076 10.179 4.426\nDomestic market sharea0.168 0.257 0.211 0.173\nOwnership (Multiple owners1) 0.141 ​ ​ ​\nGender (Male1) 0. 661 ​ ​ ​\nFormal job training (Yes1) 0.176 ​ ​ ​\nInformal job training (Yes1) 0.478 ​ ​ ​\nSub-contractor (Yes1) 0.164 ​ ​ ​\nPart of a company group (Yes1) 0.139 ​ ​ ​\nPart of a network (Yes1) 0.120 ​ ​ ​\nForeign investor (Yes1) 0.062 ​ ​ ​\nNote: a ln (total sales/total sales in the industry).\n7For robustness, we employ other constructions of employment growth. See Table 8for estimation results.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n5 status (see Table 4). For instance, the table shows that about 56 %, 43 %, and 28 % of enterprises that were in 2013 semi-informal, \nsemi-formal and formal enterprises became informal in 2015, respectively. These figures suggest that enterprises experienced \ndifferent levels of transition between statuses over the period under consideration (see Tables 5 and 6).8\nThe empirical evidence suggests that informal enterprises transitioning to formality expend large financial and time resources on \npre-formalisation costs. In other words, they face a ‘transformation cost’[1]. While the transformation cost is temporary, it may serve \nas a barrier to formality and could also lead to a substantial negative effect on the employment growth of semi-informal enterprises, for \ninstance. Enterprises at the informal end of the continuum may employ informal workers with lower wages as they do not have formal \ncontracts and social security benefits [48]. Also, the empirical literature suggests that mobile phone use drives informality while fixed \nbroadband reduces informality [30]. In an extension to our basic model, we introduced interaction terms to capture these indirect \nmechanisms. We expect more ‘formal ’ enterprises to increase employment with access to internet, and more ‘informal ’ enterprises to \ndecrease employment with access to the internet.\nWe use a host of other enterprise-level, location, and industry-level explanatory variables to explain an enterprise ’s employment \ngrowth.The pairwise correlation of all explanatory variables is reported in Table 7. We explain employment growth by the age of the \nenterprise, its lagged size, its lagged domestic market share, the educational level of the owner, if the enterprise has a group of owners, \nthe gender of the owner, if the enterprise undertakes formal and informal job training for workers, if the enterprise is a sub-contractor, \nbeing part of a company group, being part of a network, having a foreign investor, the city of location of the enterprise, and industry, \nand time dummies. Several theoretical and empirical studies identify an inverse relationship between firm growth and the size and age \nof the firm [16,31 ].\nContrary to Gilbrat ’s law, empirical studies have shown that employment growth and size are negatively related [16]. Gebreyeesus \n[31] argues that smaller firms tend to lack the ‘indivisibility of resources and availability of slack resources ’ and as a result, tend to \ngrow faster than larger enterprises. Measuring size by the lag of the total number of employees, we expect a negative relationship \nbetween size and employment growth. An enterprise ’s incentive to grow decreases with age as older enterprises tend to be conser -\nvative with routinised activities and they tend to prefer their older ways of doing things than otherwise [16,41]. Younger enterprises \nlearn and adapt quickly and can grow faster [6,31]. Age is measured as the number of years from the establishment of the enterprise to Table 3 \nVariables ’ description and definition.\nVariable Description\nGrowth of employment This is generated as the logarithm (log) difference between the appended employment levels in 2011 and 2013 and that of \n2013 and 2015 respectively.\nFirm status Categorical variable indicating if the firm is informal (54.36 %), semi-informal (5.97 %), semi-formal (2.63 %) or formal \n(27.03 %). These are further classified as formal margin and informal margin.\nInformal margin Enterprises that operate in the informal and semi-formal spectrum of the informality-formality continuum.\nFormal margin Enterprises that operate in the formal and semi-informal spectrums of the informality-formality continuum.\nAccess to mobile phone This refers to whether the enterprise has access to mobile phones, with 1 indicating yes and 0 indicating no at the beginning \nof the period (2011 and 2013).\nAccess to internet connectivity Refers to whether the enterprise during the last three years has access to internet connectivity, with 1 indicating yes and \n0 indicating no at the beginning of the period (2011 and 2013).\nLagged total employees Refers to the total number of employees at the beginning of the period.\nAge enterprise and Age of \nenterprise squareThis refers to how old the enterprise is from the year it was established, and its square term.\nLagged domestic market share Refers to the domestic market share of enterprises, constructed as the total sales divided by the total sales of the industry.\nOwnership This refers to whether the enterprise has multiple owners (1) or owned by an individual (0).\nGender (Male) Refers to the gender of the owner of the enterprise, with 1 representing male-owned enterprises and 0 representing female- \nowned enterprises.\nFormal job training Indicates whether the enterprise undertakes formal training for its employees, with 1 indicating yes and 0 indicating no.\nInformal job training Indicates whether the enterprise undertakes informal training for its employees, with 1 indicating yes and 0 indicating no.\nSub-contractor Indicates whether the enterprise subcontracts for other enterprises, with 1 indicating yes and 0 indicating no.\nCompany group This indicates whether the enterprise is part of a group of companies, with 1 indicating yes and 0 indicating no.\nNetwork This indicates whether the enterprise belongs to a network, with 1 indicating yes and 0 indicating no.\nForeign investor This indicates whether the enterprise has foreign investors, with 1 indicating yes and 0 indicating no.\nEducation Refers to five education of owner dummies: No education, Primary school, Secondary School, Vocational Training, Graduate \ndegree\nIndustry Refers to the eighteen manufacturing industry dummies based on ISIC Revision 3.1.\nCity Refers to ten city dummies: Accra, Tema, Kumasi, Sekondi-Takoradi, Sunyani, Cape Coast, Koforidua, Techiman, \nBolgatanga, and Others.\nYear Years of data collection.\n8Tables 5 and 6show the one-step transition probabilities obtained from the Markov chain analysis for the two repeated cross-sections for our ICT \nvariables. Table 5shows that, about 13 % of enterprises that had no access to the internet in 2013 gained access in 2015. About 50 % of enterprises \nthat had access to the internet in 2013 lost access to the internet in 2015. In contrast, Table 6shows that only about 5 % of enterprises that had \naccess to mobile phones in 2013 lacked access in 2015. On the contrary, about 60 % of enterprises moved from no access in 2013 to access of mobile \nphones in 2015. These suggest across our data that enterprises tend to access and use mobile phones more easily over the period, while access to the \ninternet is more difficult.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n6 the year of the survey [6,41]. In our estimation, age and size are log-transformed. Enterprises with a higher domestic market size grow \nfaster [6,38,45]. Koellinger ’s [38] study of e-business enterprises in Europe finds domestic market share has a positive effect on \nemployment growth.\nSeveral other dummies that take the value 1 if the enterprise responded ‘yes’ and 0 if the enterprise responded ‘no’ are introduced \nas controls. Female-owned businesses tend to grow less than their male counterparts due to family ties and risk averseness [41]. \nEnterprises that invest in their human capital through activities such as training are expected to grow faster [24,31,41], while en-\nterprises with multiple owners may tend to have more financial resources leading to the expansion in employment [41]. Financial Table 4 \nTransition probabilities – Persistence in formality status.\nPeriod t \01 (2013) Period t (2015)\nFormality status Informal Semi-informal Semi-formal Formal\nInformal 0.678 0.051 0.096 0.175\nSemi-informal 0.564 0.077 0.128 0.231\nSemi-formal 0.434 0.105 0.250 0.211\nFormal 0.277 0.071 0.124 0.529\nPearson chi2 (9) 101.0056 (0.000)\nLikelihood-ratio chi2 (9) 96.8238 (0.000)\nNote: Markov chain analysis - one-step transition.\nTable 5 \nTransition probabilities – Persistence in access to the internet.\nPeriod t\01 (2013) Period t (2015)\nAccess to the internet Yes No\nYes 0.496 0.504\nNo 0.133 0.867\nPearson chi2 (9) 78.968 (0.000)\nLikelihood-ratio chi2 (9) 68.836 (0.000)\nNote: Markov chain analysis - one-step transition.\nTable 6 \nTransition probabilities – Persistence in access to mobile phone.\nPeriod t\01 (2013) Period t (2015)\nAccess to mobile phone Yes No\nYes 0.953 0.047\nNo 0.595 0.405\nPearson chi2 (9) 75.155 (0.000)\nLikelihood-ratio chi2 (9) 42.555 (0.000)\nNote: Markov chain analysis - one-step transition.\nTable 7 \nPairwise correlation matrix of all explanatory variables.\nAccess to internet 1\nAccess to mobile phone 0.110* 1\nStatus 0.459* 0.191* 1\nAge (log) 0.215* 0.156* 0.371* 1\nAge squared 0.217* 0.158* 0.373* 0.99* 1\nTotal employees 0.625* 0.224* 0.552* 0.418* 0.420* 1\nDomestic mkt size 0.345* 0.134* 0.349* 0.195* 0.196* 0.426* 1\nOwnership 0.439* 0.084* 0.299* 0.194* 0.196* 0.475* 0.113* 1\nGender 0.198* 0.262* 0.249* 0.255* 0.256* 0.316* 0.119* 0.231* 1\nEducation 0.548* 0.289* 0.410* 0.269* 0.272* 0.565* 0.366* 0.304* 0.262* 1\nFormal job training 0.567* 0.077 0.328* 0.140* 0.142* 0.546* 0.301* 0.415* 0.168* 0.460* 1\nInformal job training 0.016 -0.003 0.203* 0.081* 0.082* 0.120* 0.159* 0.056 0.108* 0.145* 0.004 1\nSub-contractor -0.006 -0.448* -0.038 -0.167* -0.168* -0.075 -0.063 -0.027 -0.196* -0.166* 0.003 0.085* 1\nCompany group 0.163* -0.386* 0.020 -0.131* -0.131* 0.073 -0.022 0.185* -0.187* -0.072 0.136* -0.0182 0.452* 1\nNetwork 0.142* 0.094* 0.057 0.095* 0.096* 0.208* 0.067 0.28* 0.173* 0.103* 0.209* 0.077 -0.047 -0.018 1\nForeign investor 0.434* 0.067 0.323* 0.057 0.059 0.457* 0.137* 0.469* 0.137* 0.329* 0.317* 0.0414 0.044 0.326* 0.112* 1\nNote: * p D0.05.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n7 constraint is a major obstacle most enterprises face in developing countries [8]. Enterprises that have foreign investors tend to have \nexternal sources of funding and are expected to perform and grow more than otherwise. La Porta and Shleifer [43] find formal en-\nterprises use external finance more than informal enterprises. Enterprises that sub-contract for others tend to perform better and grow \nas they are required to prove their technical know-how for specific subcontracts. However, Maloney [40] finds limited subcontracting \nbehaviour in informal enterprises. Networks lead to collective efficiency gains in small and micro enterprises [9,17] that may result in \nlower employment growth. Finally, enterprises that are part of a bigger company group lack legal and financial autonomy [45], and as \na result, are less likely to hire more workers. We also control for location, industry, and year dummies in line with McPherson [41].\nResults and discussion\nThe effect of ICT on employment growth in manufacturing enterprises\nAs noted in earlier sections, this paper examines the relationship between employment growth and ICT in Ghana, using two \nrepeated cross-sections of the DILIC data. Table 8reports the results of the random effects Generalised Least Squares and the FGLS \npanel regressions.9Our preferred FGLS estimates are reported in Table 8columns 3 and 4.\nThe results across different specifications are consistent and show that access to the internet has a significantly positive effect on \nemployment growth, while we observe that access to mobile phones has a significantly negative effect on the employment growth of \nenterprises. This result may be explained by the reasoning that access to the internet exposes enterprises to new knowledge and \nproduction processes thereby enhancing their efficiency, leading to relative price reductions. The relative drop in price may be driving \nan increase in demand and the compensation effect on employment. Also, internet access could lead to marketing innovation in en-\nterprises that may drive increases in demand and employment growth. The compensation effect of access to the internet on the \nemployment growth of enterprises is also observed in the wider literature that analyses the effect of the internet on the employment \ngrowth performance of the enterprise [33,38]. Koellinger [38], for instance, found internet-based technologies drive employment \ngrowth in European e-business enterprises. Conversely, the displacement effect due to the use of mobile phones may be explained by \nthe reduction in transaction costs leading to the replacement of ‘unskilled’ workers such as messengers. This result corroborates Khan, \net al. [37] who found a negative effect for mobile phone use in other countries.\nIn general, our status variable indicates that informal enterprises grow more than their formal counterparts. Also, the growth in \nemployment declines as firms move along the spectrum towards complete formality. These may be due to the differences in the types of \nlabour employed, with different costs associated with different types of labour along the continuum. In fact, there is evidence sug-\ngesting that the more an enterprise operates closer to the informality continuum, the more it employs ‘off the book’[ 48]. This cost \ndifference between informal employment and formal employment may explain this result.\nThe extended specifications also report the effect of other enterprise characteristics on employment growth. Lagged total em-\nployees (in log) is our size variable and the result suggests that larger enterprises grow less in line with the extant literature [31]. The \ncoefficients of age and its square term are insignificant but suggest a U-shaped relationship between age and employment growth in \nline with the empirical literature [6,31]. The gender and company group coefficients are insignificant suggesting that there is no \nstatistical difference between male and female-owned enterprises and enterprises that are part of a group. A positive relationship is \nobserved with employment growth for domestic market share, ownership, and for enterprises that are sub-contractors, or engage in \ninformal job training, in networking, and have foreign investors. More specifically, enterprises with a larger domestic market share \nemploy more workers and this may be due to the reasoning that new market entries aimed at expanding domestic dominance may \nrequire enterprises to employ more workers [6,45]. Multiple ownership tends to lead to higher growth in employees than enterprises \nowned by single individuals. The coefficient of informal training is statistically significant indicating the importance of on-the-job \ntraining and learning-by-doing in supporting employment growth. Enterprises that are in networks such as local associations and \nchambers of commerce show more employment growth than enterprises that are not demonstrating a positive effect of social capital. \nFinally, enterprises that have foreign investors may not be affected by constraints such as lack of finance and as a result, may tend to \nshow more employment growth than enterprises that do not have foreign investors.\nThe effect of ICT on the employment growth: Role of formality status\nTable 9reports the estimation results when we extend our model in Eq. (1)by interacting access to the internet and formality status \ndummies to analyse any possible indirect mechanisms using the data.\nColumns (1) – (5) add interaction terms between access to the internet and our enterprise status dummies. The results in columns \n(1) – (5) indicate that enterprises that operate informally with access to the internet tend to grow less on average (column 1) than \notherwise. On the contrary, enterprises with formal status on average grow more with access to the internet than all other enterprises. \nThese findings suggest that, compared with other enterprises, internet use enables informal enterprises to remain small to avoid \ndrawing attention to their activities. This allows them to keep labour costs low and enjoy some flexibility from being informal. This \nresult may also be explained by the higher cost associated with the use of the internet or the complementarity between labour and \n9Despite the attempt to control for the possible bidirectional relationship between ICT and employment growth using lags of ICT, we expect this \neconometric problem to persist due to the weak instruments used. As a result, an important caveat is that we consider our results as correlations and \ninterpret only the signs of coefficients obtained in our econometric analyses.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n8 internet use, leading enterprises to reduce employment. All other explanatory variables remain qualitatively similar to our earlier \nresults in terms of sign and significance.10\nThe estimates in Table 10allow us to go a step further to assess the determinants of employment growth at the informal and formal \nmargins. The informal margin comprises of enterprises that operate in informal and semi-formal spectrums, while the formal margin \ncomprises of enterprises that operate in the formal and semi-informal spectrums. Our main result is in line with [48], suggesting that \nenterprises that are more informal tend to avoid been caught by remaining small. Our results reported in column (2) show that en-\nterprises that operate at the informal margin tend to ‘hide ’ by growing less in employment with access to the internet, buttressing our \nearlier findings and the empirical literature. Also, following the evidence from other studies, this result may be due to the reasoning \nthat enterprises that operate at the formal margin tend to have the capacity to better adapt knowledge sourced from the internet, and as \na result, can perform and grow more than otherwise. A similar indirect effect of ICT is also found by Bresnahan et al. [13].Table 8 \nEmployment growth, ICT and formality status of enterprises.\nRandom-effects GLS Panel regression FGLS Panel regression\nDependent variable (1) (2) (3) (4)\nICT Log of employment growth\nAccess to internet (lagged) 0.287 *** 0.160 ** 0.228 *** 0.130 ***\n(3.88) (2.16) (9.43) (4.26)\nAccess to mobile phone (lagged) -0.605 *** -0.207 -0.583 *** -0.196 ***\n(-5.78) (-1.50) (-10.43) (-3.25)\nFormality status ​ ​ ​ ​\nSemi-informal -0.142 ** -0.051 -0.146 *** -0.035\n(-2.00) (-0.67) (-5.37) (-0.97)\nSemi-formal -0.148 *** -0.097 -0.141 *** -0.051 *\n(-2.90) (-1.55) (-9.37) (-1.90)\nFormal -0.064 -0.151 -0.0575 *** -0.077 **\n(-1.21) (-1.63) (-4.81) (-2.03)\nLagged total employees (in log) -0.117 *** -0.145 *** -0.075 *** -0.120 ***\n(-4.89) (-4.31) (-9.74) (-9.67)\nAge of enterprise (in log) ​ -1.493 ​ -1.102\n​ (-0.88) ​ (-1.41)\nAge of enterprise squared (in log) ​ 0.764 ​ 0.570\n​ (0.89) ​ (1.44)\nLagged domestic market share (in log)a​ 0.0476 ​ 0.037 **\n​ (1.07) ​ (2.22)\nOwnership ​ 0.205 *** ​ 0.140 ***\n​ (3.09) ​ (4.13)\nGender (Male) ​ -0.0245 ​ -0.024\n​ (-0.43) ​ (-1.06)\nFormal job training ​ 0.026 ​ 0.015\n​ (0.41) ​ (0.49)\nInformal job training ​ 0.182 *** ​ 0.132 ***\n​ (3.58) ​ (6.86)\nSub-contractor ​ 0.286 *** ​ 0.262 ***\n​ (3.36) ​ (7.01)\nCompany group ​ -0.060 ​ -0.014\n​ (-0.57) ​ (-0.33)\nNetwork ​ 0.121 ** ​ 0.125 ***\n​ (2.12) ​ (4.46)\nForeign investor ​ 0.341 *** ​ 0.272 ***\n​ (3.30) ​ (5.32)\nConstant 0.781 *** 0.343 * 0.686 *** 0.200 **\n(7.90) (1.88) (12.26) (2.29)\nWald chi2100.21 202.21 395.50 1320.47\nProb Fchi20.000 0.000 0.000 0.000\nN 598 483 598 483\nt statistics in parentheses.\n*p D0.10.\n**p D0.05.\n***p D0.01; Note: Two time dummies, eighteen industry dummies, ten city and five level of education of owner dummies are included in all \nextended regressions. a log (total sales/total sales of industry). Formality status is defined as: informal is unregistered enterprises who hire informal \nlabour and operate solely in the informal sector; semi-informal is unregistered enterprises who hire informal workers but operate in both the formal \nand informal sectors; semi-formal are registered enterprises who hire informal workers or engage with other informal enterprises, and formal are \nregistered enterprises and operate solely in the formal sector.\n10We failed to observe similar indirect mechanisms for mobile phone use (results are not reported but are available upon request).X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n9 Table 9 \nEmployment growth, ICT and formality status of enterprises with interaction terms.\nFGLS Panel regression\n(1) (2) (3) (4) (5)\nDependent variable: Log of employment growth\nICT ​ ​ ​ ​ ​\nAccess to internet (lagged) 0.218 *** 0.112 *** 0.103 *** 0.094 *** 0.069 **\n(5.76) (3.72) (3.07) (2.61) (2.12)\nAccess to mobile phone (lagged) -0.213 *** -0.211 *** -0.201 *** -0.208 *** -0.183 ***\n(-3.07) (-3.59) (-3.17) (-3.32) (-3.15)\nStatus ​ ​ ​ ​ ​\nInformal 0.102 *** ​ ​ ​ ​\n(4.18) ​ ​ ​ ​\nAccess to internet*Informal -0.309 *** ​ ​ ​ ​\n(-5.92) ​ ​ ​ ​\nSemi informal ​ -0.016 ​ ​ ​\n​ (-0.40) ​ ​ ​\nAccess to internet*Semi informal ​ 0.046 ​ ​ ​\n​ (0.46) ​ ​ ​\nSemi-formal ​ ​ -0.049 * ​ ​\n​ ​ (-1.82) ​ ​\nAccess to internet*Semi formal ​ ​ 0.068 ​ ​\n​ ​ (1.09) ​ ​\nSemi informal and formal ​ ​ ​ -0.050 ** ​\n​ ​ ​ (-2.10) ​\nAccess to internet* Semi informal and formal ​ ​ ​ 0.086 ​\n​ ​ ​ (1.50) ​\nFormal ​ ​ ​ ​ -0.159 ***\n​ ​ ​ ​ (-3.29)\nAccess to internet*Formal ​ ​ ​ ​ 0.254 ***\n​ ​ ​ ​ (3.95)\nLagged total employees (in log) -0.123 *** -0.128 *** -0.125 *** -0.125 *** -0.129 ***\n(-9.22) (-10.45) (-9.74) (-9.92) (-10.37)\nAge enterprise (in log) -0.911 -1.072 -0.892 -0.921 -1.114\n(-1.35) (-1.41) (-1.17) (-1.22) (-1.48)\nAge of enterprise squared (in log) 0.468 0.552 0.460 0.475 0.574\n(1.36) (1.43) (1.19) (1.24) (1.50)\nLagged domestic market share (in log)a0.027 * 0.030 ** 0.028 * 0.031 ** 0.023\n(1.67) (2.01) (1.77) (2.02) (1.48)\nOwnership 0.108 *** 0.149 *** 0.146 *** 0.142 *** 0.130 ***\n(3.19) (4.24) (4.04) (4.04) (3.54)\nGender (Male) -0.028 -0.026 -0.024 -0.022 -0.039 *\n(-1.26) (-1.14) (-1.08) (-1.00) (-1.73)\nFormal job training 0.001 0.001 -0.008 -0.001 -0.008\n(0.01) (0.01) (-0.26) (-0.02) (-0.24)\nInformal job training 0.124 *** 0.119 *** 0.121 *** 0.123 *** 0.126 ***\n(5.99) (6.08) (6.22) (6.35) (6.43)\nSub-contractor 0.240 *** 0.268 *** 0.270 *** 0.264 *** 0.249 ***\n(6.59) (6.25) (6.24) (6.33) (6.43)\nCompany group -0.024 0.004 -0.003 0.006 -0.039\n(-0.55) (0.09) (-0.06) (0.12) (-0.90)\nNetwork 0.107 *** 0.124 *** 0.127 *** 0.122 *** 0.122 ***\n(3.90) (4.60) (4.76) (4.65) (4.35)\nForeign investor 0.241 *** 0.249 *** 0.253 *** 0.256 *** 0.243 ***\n(4.77) (5.03) (4.90) (4.95) (4.80)\nConstant 0.198 ** 0.255 *** 0.260 *** 0.268 *** 0.216 **\n(2.01) (2.86) (2.85) (2.96) (2.46)\nWald chi21184.62 836.09 567.63 1161.96 589.47\nProb Fchi20.000 0.000 0.000 0.000 0.000\nN 483 483 483 483 483\nNote: t statistics in parentheses.\n*p D0.10.\n**p D0.05.\n***p D0.01. \nTwo time dummies, eighteen industry dummies, and ten city and five level of education of owner dummies are included in all regressions. a log \n(total sales/total sales of industry). Formality status is defined as: informal is unregistered enterprises who hire informal labour and operate solely in \nthe informal sector; semi-informal is unregistered enterprises who hire informal workers but operate in both the formal and informal sectors; semi- \nformal are registered enterprises who hire informal workers or engage with other informal enterprises, and; formal are registered enterprises and \noperate solely in the formal sector.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n10 In columns (3) and (4), the estimates show access to the internet as a significant determinant of employment growth for enterprises \noperating at both the formal and informal margins, while access to mobile phones has no significant effect in both models. Large \nenterprises operating at both margins show little employment growth. In line with [50], we find a U-shaped relationship between the \nage and employment growth of enterprises, suggesting that older enterprises ’ employment growth is greater at the formal margin. \nDomestic market size and multiple ownership matter significantly for enterprises operating at the informal margin. Male-owned and \nsubcontracting enterprises at the formal margin tend to show significantly more employment growth. Subcontracting is insignificant \nfor enterprises at the informal margin, corroborating with the findings of Maloney [40]. Informal on-the-job-training leads to \nemployment growth in enterprises at the informal margin while it leads to displacement effects in enterprises at the formal margin: this \nsuggests the importance of apprenticeship in enterprises. On the contrary, enterprises at the informal margin that are part of a company \ngroup lack autonomy that characterises informality, and as result employment grows less, while the reverse holds for enterprises at the \nformal margin who may be taking advantage of the financial resources the bigger group offers. Network effects matter positively for \nboth groups of enterprises, despite the drop in statistical significance in column 4.Table 10 \nEmployment growth, ICT and informality margin.\nFGLS Panel regression\n(1) (2) (3) (4)\nFull sample Informal margin Formal margin\nDependent variable: Log of employment growth\nICT ​ ​ ​ ​\nAccess to internet (lagged) 0.130 *** 0.246 *** 0.106 *** 0.135 ***\n(4.40) (5.29) (3.10) (2.93)\nAccess to mobile phone (lagged) -0.217 *** -0.220 *** -0.001 -0.034\n(-3.90) (-3.92) (-0.01) (-0.15)\nInformal margin 0.0315 0.087 *** ​ ​\n(1.22) (2.66) ​ ​\nAccess to internet*Informal margin ​ -0.198 *** ​ ​\n​ (-3.59) ​ ​\nLagged total employees (in log) -0.125 *** -0.125 *** -0.205 *** -0.076 ***\n(-10.27) (-10.03) (-12.82) (-4.85)\nAge enterprise (in log) -1.179 -1.080 -0.912 -5.142 *\n(-1.56) (-1.43) (-1.40) (-1.78)\nAge of enterprise squared (in log) 0.606 0.557 0.472 2.586 *\n(1.58) (1.45) (1.40) (1.77)\nLagged domestic market share (in log)a0.033 ** 0.021 0.083 ** -0.008\n(2.21) (1.40) (2.52) (-0.48)\nOwnership 0.139 *** 0.119 *** 0.200 *** 0.0716\n(4.10) (3.33) (4.27) (1.59)\nGender (Male) -0.029 -0.036 0.026 0.120 ***\n(-1.26) (-1.60) (0.92) (3.96)\nFormal job training 0.012 -0.002 -0.074 -0.002\n(0.38) (-0.05) (-1.62) (-0.06)\nInformal job training 0.124 *** 0.122 *** 0.234 *** -0.125 ***\n(6.39) (6.17) (9.68) (-3.71)\nSub-contractor 0.262 *** 0.255 *** -0.021 0.165 ***\n(6.64) (6.58) (-0.22) (3.42)\nCompany group -0.007 -0.019 -0.949 *** 0.0747 *\n(-0.16) (-0.45) (-6.11) (1.84)\nNetwork 0.127 *** 0.116 *** 0.123 *** 0.102 *\n(4.65) (4.21) (4.28) (1.74)\nForeign investor 0.264 *** 0.226 *** - 0.057\n(5.31) (4.54) - (0.88)\nConstant 0.214 ** 0.165 * 0.097 -0.246\n(2.35) (1.67) (0.91) (-0.95)\nWald chi21362.33 5726.02 914.40 3118.33\nProb Fchi20.000 0.000 0.000 0.000\nN 483 483 307 176\nNote: t statistics in parentheses.\n*p D0.10.\n**p D0.05.\n***p D0.01. Two time dummies, eighteen industry dummies, and ten city and five-level of education of owner dummies are included in all re-\ngressions. a log (total sales/total sales of industry). Informal margin refers to enterprises that operate in the informal and semi-formal spectrum; \nFormal margin refers to enterprises that operate in the formal and semi-informal spectrums.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n11 Conclusion\nThe creation of new and quality employment opportunities has become a critical policy priority in many developing countries. The \ndiscussion recognises that the ICT revolution lies at the heart of today’s global digital transformation and could play a critical role in \ngenerating new and quality job opportunities. This paper contributes to the ICT- employment literature by examining the role of ICT on \nemployment growth across formal and informal manufacturing enterprises in Ghana. Specifically, it addresses the following questions: \n(1) Does the adoption of ICT influence employment growth in Ghana’s manufacturing enterprises?; (2) Does the formality status of \nenterprises influence the effect of ICT on manufacturing employment growth?\nEstimating a feasible generalised least squares (FGLS) regression using repeated data collected in 2013 and 2015, our results \nshowed that access to the internet has a positive effect on employment growth while access to mobile phones leads to a negative effect \non employment growth. Also, our results showed that the more informal an enterprise is, the less it grows with access to the internet. In \nother words, the employment gains from internet access mainly occur for formal enterprises and enterprises that are more formal. \nEnterprises with mobile phone access are more likely to pursue smallness in labour employment to benefit from the flexibility and \nefficiency gains. The key determinants of employment growth are also identified to vary depending on the specific formality status of \nthe enterprise. The results strongly indicate that other factors such as domestic market size, multiple ownership, and informal training \nmatter for the employment growth of enterprises at the informal margin (informal and semi-formal), while male-ownership, sub-\ncontracting, and being part of a group of companies positively determine the employment performance of enterprises at the formal \nmargin (formal and semi-informal).\nOverall, the findings suggest that informal enterprises with access to the internet actively pursue smallness by substituting the use \nof internet for labour. Conversely, the use of mobile phones reduces the number of workers, most of which transition into the informal \nsector. Our findings confirm the growing evidence that indicates most enterprises in developing countries are interconnected and \noperate at varying degrees on the informality-formality continuum, and the ICT technology revolution has brought new changes into \nthe transition dynamics.\nThe emerging findings from this paper have significant policy and practical implications in Ghana. Firstly, the ILO’s ‘Transition \nfrom the Informal to the Formal Economy Recommendation (No. 204)’ aims to formalise enterprise. The understanding of some of the \nsubtle nuances of how enterprises operate and how ICT are transforming the operations and business models of enterprises in \ndeveloping countries, especially among small and micro enterprises at the borderline of formality and informality, could help Ghana to \ndevelop effective policies to incentive the transition of enterprises to the formal economy. Secondly, our findings have useful impli -\ncations for the digital transformation of enterprises in Ghana. Our findings indicate that the use of ICT decreases transaction costs and \nentry barriers. To achieve optimal digital transformation enterprises still need technologies and capabilities that can facilitate \ntransformation in production processes, marketing strategies, and supply chain management systems. The rise of the platform \neconomy in recent years may change the digital technology-formality-employment nexus.\nThere are limitations to our research. Despite the paper’s innovation and contribution to the wider literature, our analysis employs \nICT proxies that are dummies, thereby, for example, not examining differences in investment in ICT, and intensive and extensive \nmargins of ICT. Our analysis focuses on selected manufacturing enterprises in Ghana and does not consider the sector, skill level, and \nstatus of jobs and workers as well as other country contexts. These are mainly due to data limitations. Also, our data would benefit from \nan update and an extensive longitudinal study: our data comprises only two relatively short periods. The use of other better-measured \nICT and employment variables and cross-country panel data would be natural extensions of the paper. Lastly, while we employ lagged \nvariables to address endogeneity concerns, a more formal method could be used in future studies once data become available.\nCompliance with Ethical Standards\nFunding\nThis work was supported by the ESRC/DFID Grants (ES/J008699/1 and ES/S001336/1).\nEthical Statement\nThis manuscript is the authors’ own original work, which is not currently being considered for publication elsewhere and has not \nbeen previously published elsewhere.\nData Availability Statement\nThe dataset generated during the current study is not publicly available as it contains sensitive information. Further information on \nhow to obtain it and reproduce the analysis is available on request from the corresponding author.\nCRediT authorship contribution statement\nXiaolan Fu: Conceptualization, Formal analysis, Investigation, Project administration, Software, Validation, Visualization, Writing \n– original draft, Writing – review & editing. Elvis Korku Avenyo: Conceptualization, Data curation, Formal analysis, Investigation, \nMethodology, Project administration, Software, Validation, Visualization, Writing – original draft, Writing – review & editing.X. Fu and E.K. Avenyo                                                                                                                                                                                               Scientiϧc  African  26 (2024)  e02394  \n12 Declaration of competing interest\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to \ninfluence the work reported in this paper.\nAcknowledgements\nWe would like to thank Marc Ventresca, Pierre Mohnen, George Essegbey, Anne Miroux and Pervez Ghauri for helpful comments \nand suggestions. We are also grateful for comments from participants at the SBS-TMCD joint workshop at the Oxford University and the \n2015 Globelics Conference. Useful comments and directions from two anonymous reviewers helped to improve the paper. Views \nexpressed in this paper are those of the authors.\nReferences\n[1]M. Amin, A. Islam, Are large informal firms more productive than the small informal firms? Evidence from firm-level surveys in Africa, World Dev. 74 (2015) \n374–385.\n[2]Simplice A. Asongu, Jacinta C. Nwachukwu, Stella-Maris I. Orim, Mobile phones, institutional quality and entrepreneurship in Sub-Saharan Africa, Technol. \nForecast. Social Change 131 (2018) 183–203, https://doi.org/10.1016/j.techfore.2017.08.007 .\n[3]Simplice A. Asongu, Mushfiqur Rahman, Joseph Nnanna, Mohamed Haffar, Enhancing information technology for value added across economic sectors in Sub- \nSaharan Africa, Technol. Forecast. Social Change 161 (2020), https://doi.org/10.1016/j.techfore.2020.120301 .\n[4]Simplice A. Asongu, Sara Le Roux, Enhancing ICT for inclusive human development in Sub-Saharan Africa, Technol. Forecast. Social Change 118 (2017) 44–54.\n[5]Cl˘emence Aubert-Tarby, Octavio R. Escobar, Thierry Rayna, The impact of technological change on employment: The case of press digitisation, Technol. \nForecast. and Social Change 128 (2018) 36–45, https://doi.org/10.1016/j.techfore.2017.10.015 .\n[6]E.K. Avenyo, M. Konte, P. Mohnen, The employment impact of product innovations in sub-Saharan Africa: Firm-level evidence, Res. Policy 48 (9) (2019) \n103806 .\n[7]E.K. Avenyo, M. Konte, P. Mohnen, Product innovation and informal market competition in sub-Saharan Africa, J. Evolut. Econ. (2020) 1–33, https://doi.org/ \n10.1007/s00191-020-00688-2 .\n[8]M. Ayyagari, A. Demirgüç-Kunt, V. Maksimovic, Firm innovation in emerging markets: The role of finance, governance, and competition, J. Financial and \nQuantitative Analysis 46 (6) (2011) 1545 –1580 .\n[9]A. Barr, Do SMEs network for growth? in: K. King, S. McGrath (Eds.), Enterprise in Africa – Between poverty and growth Practical Action, Rugby, UK, 1999, \npp. 121–131.\n[10] F. Biagi, M. Falk, The impact of ICT and e-commerce on employment in Europe, J. Policy Model. 39 (1) (2017) 1–18.\n[11] M.H. Bohme, R. Thiele, Informal –formal linkages and informal enterprise performance in urban West Africa, Eur. J. Developm. Res. 26 (4) (2014) 473–489.\n[12] David Brougham, Jarrod. Haar, Technological disruption a', 'raytos.bsinfotech@gmail.com', ' Xiaolan Fu, Elvis Korku Avenyo', '', '../pdf_files/674d5294a64cb-Revisiting the effect of information and communication technologies on employment growth in Ghana - The role of enterprise formality.pdf', 857800, 14, 10635, 72798, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(62, '5010932210', '51', 5, 5, 'LLM technologies and information search', '2024-12-02 14:25:53.447085', '2024', 'With the booming of LLM technologies (e.g., ChatGPT), people’s goals and behaviors in in formation search have been reshaped significantly. This paper attempts to conceptually discuss how LLM technologies might revolutionize these important aspects in information search and provides a comprehensive analysis of the technological advancements and capabilities of ChatGPT, highlighting its potential to disrupt traditional search engines like Google. In addition, this paper contrasts ChatGPT’s conversational approach with Google’s link-based search model, offering a detailed examination of the implications for online search advertising and user behavior and explaining why Google is concerned about ChatGPT as well as its potential reactions.', 'LLM technologies,Information search,Google,Online advertising', 'Journal of Economy and Technology 2 (2024) 269–277\nContents lists available at ScienceDirect\nJournal of Economy and Technology\njournal homepage: www.keaipublishing.com/JET\nResearch article \nLLM technologies and information search\nLin Liua,⁎, Jiajun Menga, Yongliang Yangb\na School of Economics and Management, Beihang University, China \nb Department of Computer Science, University of Bass, UK \nARTICLE INFO\nKeywords: \nLLM technologies\nInformation search\nGoogle\nOnline advertisingABSTRACT\nWith the booming of LLM technologies (e.g., ChatGPT), people’s goals and behaviors in in-\nformation search have been reshaped significantly. This paper attempts to conceptually discuss \nhow LLM technologies might revolutionize these important aspects in information search and \nprovides a comprehensive analysis of the technological advancements and capabilities of \nChatGPT, highlighting its potential to disrupt traditional search engines like Google. In addition, \nthis paper contrasts ChatGPT’s conversational approach with Google’s link-based search model, \noffering a detailed examination of the implications for online search advertising and user be-\nhavior and explaining why Google is concerned about ChatGPT as well as its potential reactions.\n1. Introduction\nChatGPT, a conversational AI chatbot from the generative pre-trained transformer (GPT) family of language models, was de-\nveloped by OpenAI and released in November 2022.1It is based on OpenAI’s GPT-3.5, GPT-4, and GPT-4o large language models \n(LLMs) and has been fine-tuned through both supervised and reinforcement learning techniques. ChatGPT can engage in con-\nversational interactions and provide clear, straightforward answers across various domains of knowledge, unlike traditional search \nengines that simply list links.\nGoogle, the world’s leading search engine, for the first time ever, has issued a “code red” in response to the rise of ChatGPT, \nviewing it as a potential threat to its core business—online search advertising—and its future.2Google’s CEO Sundar Pichai has \nredirected some teams to focus on AI product development, planning to unveil more than 20 new products this year. Google also has \nits own chatbot called Gemini, which is similar to ChatGPT and was developed by Google researchers. However, Google may be \nreluctant to deploy this new technology in online search, as this might cannibalize its core business (online search advertising), which \naccounts for most of Google’s revenue.3\nThe emergence of ChatGPT and other chatbots (e.g., Claude, Bing Copilot, Perplexity) signifies a major technological shift that \ncould disrupt the tech industry and transform how people access information on the Internet. This development also raises ethical and \nhttps ://doi.org/10.1016/j.ject.2024.08.007 \nReceived 23 June 2024; Received in revised form 23 August 2024; Accepted 27 August 2024 \nAvailable online 29 August 2024\n2949-9488/© 2024 The Author(s). Published by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC \nBY license (http://creativecommons.org/licenses/by/4.0/ ). \n]]]] \n]]]]]]\n⁎ Corresponding author.\nE-mail address: linliubh@buaa.edu.cn (L. Liu).\n1 OpenAI is a research lab that aims to create and promote beneficial AI for humanity (see openai.com).\n2 See ChatGPT and Other Chat Bots Are a ‘Code Red’ for Google Search - The New York Times (nytimes.com) and Google Management Issues \'Code \nRed\' Over ChatGPT: Report (businessinsider.com).\n3 For more details about Google’s reluctance, see https://www.bloomberg.com/news/articles/2024–04-03/google-considers-charging-for-ai- \nfueled-search-features-ft-says .social questions about AI’s impact on human communication, privacy, security, and creativity. While ChatGPT and similar chatbots \nare still in the early stages of development and face numerous limitations and challenges, they also present new opportunities for \ninnovation and collaboration.\nThis paper makes several key contributions to the understanding of how LLM technologies, such as ChatGPT, are revolutionizing \ninformation search. First, it provides a comprehensive analysis of the technological advancements and capabilities of ChatGPT, \nhighlighting its potential to disrupt traditional search engines like Google. Second, the paper contrasts ChatGPT’s conversational \napproach with Google’s link-based search model, offering a detailed examination of the implications for online search advertising and \nuser behavior. Third, it explores the broader economic and social impacts of ChatGPT, considering both the opportunities for in-\nnovation and the challenges related to ethics, privacy, and security. Lastly, it contextualizes these developments within relevant \neconomic literature on information search, deliberation, digital platforms, and consumer perception and engagement, thereby \ncontributing to ongoing academic discourse in these fields.\nThe remainder of this paper is organized as follows. Section 2introduces the detailed functionality of ChatGPT and other con-\nversational chatbots, explaining how they process information and interact with users. Section 3discusses the specific concerns that \ntraditional search engines (e.g., Google, Microsoft, Baidu) have regarding ChatGPT and the strategic responses they have initiated. \nSection 4reviews the relevant economic literature, linking the theoretical frameworks to the practical developments discussed. \nFinally, Section 5explores the future of information search in light of generative AI technologies, considering potential scenarios and \ntheir implications.\n2. LLM technologies: ChatGPT and other conversational chatbots\nChatGPT is a chatbot built on GPT-3.5/4/4o (Generative Pre-trained Transformer 3.5/4/4omni) technology, designed to com-\nmunicate with humans in natural language. It operates using a large neural network with 1.8 trillion parameters, trained on vast \namounts of text data from the internet. This extensive training allows ChatGPT to simulate a conversation with a human user through \ntext or voice on almost any topic, given some input words or sentences. In addition to ChatGPT, there are a few other popular \nconversational products on the market nowadays, such as Claude, Bing Copilot, Perplexity, and Gemini. A brief comparison of these \nproducts is summarized in Table 1.\nChatGPT\'s dialogue format enables users to iteratively refine their queries and explore topics in depth. It can handle various types \nof conversations, from casual chat to complex problem-solving, and can even generate creative content like poems or code. While \nChatGPT offers many advantages, it\'s important to note its limitations, such as potential inaccuracies (i.e., AI Hallucinations), and \noccasional inconsistencies in responses.\nThe emergence of LLM technologies like ChatGPT marks a significant shift in how people access information. Unlike traditional \nsearch engines that provide lists of links, ChatGPT engages in conversational interactions, offering direct answers across various \nknowledge domains. This technological leap has profound implications for the search industry, particularly for established players \nlike Google. The potential disruption to Google\'s core business model – online search advertising – has prompted a strategic re-\nevaluation within the company, including redirecting resources towards AI product development.\nSpecifically, LLM technologies like ChatGPT have the following advantages in information search over traditional search engines. \nFirst, ChatGPT offers a conversational interface that allows users to ask questions in natural language and receive detailed, context- \naware responses. This contrasts with traditional search engines, which typically return a list of links. Users can engage in follow-up \nquestions, making the search process more interactive and efficient. Second, Recent updates have enabled ChatGPT to search the web \nfor current information, enhancing its ability to provide answers that are not limited to its training data.4This capability allows it to \nsummarize content from various websites, potentially offering a more cohesive answer than traditional search engines, which present \nfragmented information across multiple sources.\nIn addition to the information search aspect, ChatGPT may revolutionize traditional online advertising on search engines. As users are \nincreasingly looking for direct answers rather than browsing through ads and links, it could diminish the effectiveness of traditional pay- \nper-click advertising models.5Advertisers may need to adapt their strategies to engage users in a more conversational manner. In addition, \nOpenAI\'s partnership with Microsoft Bing suggests a potential integration of ChatGPT capabilities into advertising platforms, allowing for \nmore personalized ad experiences.6This could lead to more targeted advertising based on user interactions with AI, providing advertisers \nwith richer data on consumer preferences and behaviors. Furthermore, the rise of AI-driven search tools like ChatGPT may necessitate a \nreevaluation of search engine optimization (SEO) strategies. Businesses may need to focus more on creating content that is easily un-\nderstood and relevant to conversational queries, rather than solely optimizing for keyword-based searches.\n3. Impact on traditional search engines: Google\'s concerns and reactions\nGoogle is concerned about ChatGPT because it threatens its core business—online search advertising—and its future. Google \ngenerates the majority of its revenue from selling ads on its own platforms, such as Google Search, YouTube, Gmail, and Google Maps, \n4 For more details, see https://openai.com/index/searchgpt-prototype/ .\n5 For example, consumers may be able to purchase products directly through ChatGPT without having to visit a brand\'s or retailer\'s website.\n6 ChatGPT has been integrated with Bing, Microsoft’s search engine. Users can join a waitlist to use Bing with ChatGPT and get personalized and \nconversational search results. Bing with ChatGPT can also help users with tasks such as booking flights, finding restaurants, or learning languages.L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n270as well as on third-party websites and apps that use Google’s advertising services, such as Google Ads and Google AdSense. According \nto its 2023 annual report, Google’s advertising revenue was $237.9 billion, accounting for 77 % of its total revenue.7\nFor example, users can use Google Search to find information on the Internet by entering keywords or queries. Google’s search \nengine returns a list of links to web pages that are relevant to the user’s query, ranked by their popularity and authority. At the top of \nthese links, Google displays ads, which generate income for Google and its advertisers. Fig. 1illustrates Lenovo’s sponsored ads (after \nentering “laptop”) on Google.\nAI chatbots like ChatGPT, however, offer a new way to search for information on the internet, which may challenge Google’s \nsearch engine. Instead of entering keywords or queries, users could interact with AI chatbots in natural language and receive in-\nformation in clear and simple sentences. AI chatbots could also provide more personalized and engaging responses than Google’s \nsearch engine, by adapting to the user’s preferences, interests, and emotions. In addition, the chatbot could also generate new \ninformation or content that Google’s search engine may not have access to or be able to provide. Figs. 2 and 3illustrate the dialogue \nformat of information interaction of Perplexity and ChatGPT (offered by Microsoft’s New Bing).\nFrom Figs. 1–3, one can have the following evident observations about several key differences between AI chatbots and Google’s \nsearch engine. First, AI chatbots offer a dialogue-based interaction process whereas Google provides a list of relevant links based on \nthe users’ query, ranked by their popularity and authority. Second, users can easily use AI chatbots’ conversational interactions to \ndeliberate their information needs and evaluate the value of information, while they have to costly click and read various web pages \nin Google’s search results. Third, although sponsored ads appear on both Microsoft’s New Bing (backed by GPT) and Google, the \nsponsored ads on Microsoft’s New Bing appear after multiple iterations of information exchange when the AI chatbot collects suf-\nficient information from the author and knows him better (i.e., entering “laptop”, “which laptop is best for gaming?”, and “how much \ndo these laptops cost?”). However, sponsored ads show up on the very top of Google’s search results right after the author enters the \nkeyword “laptop”.\nWith these advantages, AI chatbots like ChatGPT may become widely adopted and preferred by users over Google’s search engine, \npotentially causing Google to lose market share and revenue in the online search industry. Google could also lose its competitive edge \nand influence in the tech industry and society at large.\nGoogle is aware of the potential threat posed by ChatGPT and other chatbots, and it is taking steps to actively respond to the \nchallenge. Google’s CEO Sundar Pichai has issued a “code red” over the rise of ChatGPT, indicating an emergency that requires \nimmediate action. Google has redirected some teams to focus on developing AI products that can compete with or complement \nChatGPT. In particular, Google has introduced Bard, a conversational AI service initially limited in availability, which has since \nevolved into Gemini. This AI system is designed to provide users with conversational responses and is integrated into Google\'s search \nengine. Google aims to combine traditional search results with AI-generated summaries to improve the relevance and immediacy of \ninformation presented to users. Fig. 4illustrates how Gemini interacts with the author. Obviously, Gemini also adopts a form of \nconversational interaction similar to ChatGPT, and it also makes full use of its own Google ecological advantages to integrate Google \nweb links into the conversations, which is exactly the same as Perplexity.\nIn addition to Google, other traditional search engine companies have also responded quickly to the rise of LLM technologies like \nChatGPT. Microsoft has taken a proactive approach by launching Bing Chat, later rebranded as Copilot, which utilizes OpenAI\'s \ntechnology. This integration has led to a notable increase in Bing\'s search ad revenue, which is expected to grow significantly faster \nthan Google\'s as more users adopt AI tools for search.8The company is leveraging its existing platforms, including Microsoft 365, to \nembed AI functionalities that enhance user interaction with search. Besides, Baidu, the leading search engine in China, has also \nentered the AI space with its service called Ernie. This AI-powered chat service aims to provide similar functionalities to those of \nGoogle and Microsoft, reflecting a global trend among search engines to adopt AI technologies to meet user demands for more \nefficient information retrieval.Table 1 \nComparison of conversational chatbots. \nProduct Company LLM technology Key Strength\nChatGPT OpenAI GPT 3.5/4/4o Versatility, general knowledge\nClaude Anthropic Claude 3 (Opus, Sonnet, Haiku) Strong performance on complex tasks\nBing Copilot Microsoft GPT 3.5/4/4o Combination of search and AI capabilities\nPerplexity Perplexity GPT 3.5/4/4o, Claude 3 Online, up-to-date answers\nGemini Google Gemini 1.5 Integration with Google ecosystem\n7 Google also has other businesses that contribute to its revenue and growth, such as cloud computing, hardware, and other bets. Google’s cloud \ncomputing business includes Google Cloud Platform, which offers infrastructure and data analytics services, and Google Workspace, which offers \nproductivity and collaboration tools. Google’s hardware business includes devices such as Pixel phones, Nest smart home products, Chromebooks, \nand Chromecast. Google’s other bets are long-term, risky, and potentially disruptive projects that aim to create new markets and technologies, such \nas Waymo (self-driving cars), Verily (life sciences), Loon (internet balloons), and Wing (drone delivery).\n8 For more details, see https://www.impressiondigital.com/blog/bing-differ-google/ .L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n2714. Relevant literature\nThe above discussions are generally related to four key streams of economic literature: search, deliberation, digital platform, and \nconsumer perception and engagement.\nFirst, the paper is related to the literature on information search (Wolinsky, 1986, Anderson and Renault, 1999, Liu and Dukes, \n2013, Liu and Wang, 2023, Zhang et al., 2024 ). Specifically, there are two types of mainstream search models: parallel search and \nsequential search, which differ in how people collect and evaluate information. Under parallel search, individuals first select a \nsampling plan, doggedly evaluate all alternatives in the plan, and then select the best alternative after evaluation (provided that \ndoing so is better than choosing the no-select option which is usually assumed to provide zero utility). Many studies use parallel \nsearch model to capture people’s search behavior (e.g., Morgan and Manning, 1982 , Chade and Smith, 2006 , Kircher, 2009 , Liu and \nDukes, 2013, 2016 , Dukes and Liu, 2016 , Liu and Wang, 2021 ).9\nDifferent from parallel search, under sequential search, people evaluate alternatives one by one until finding a desirable alter-\nnative and thus quitting the search process (e.g., Wolinsky, 1986 , Anderson and Renault, 1999 , Armstrong et al., 2009 , Menzio and \nTrachter, 2015 , Liu et al., 2022 , Jin et al., 2022 , Liu and Wang, 2023 ). Specifically, in the sequential search process, a person’s search \nbehavior is guided by an optimal stopping rule which dictates whether she should pick the alternative immediately (and thus quit \nsearching) or keep on searching the next alternative.10\nLLM technologies like ChatGPT might fundamentally reshape the landscape of information search. In the context of search theory, \nLLMs introduce a novel paradigm that challenges traditional models of both parallel and sequential search. Unlike conventional \nsearch engines that require users to sift through multiple results, LLMs offer a conversational interface that can provide direct, \nsummary answers. This approach potentially reduces search costs and alters the optimal search strategy for users. In addition, the \nconversational interaction form of LLM may transform the previously common sequential search based on web links into the parallel \nsearch based on the consideration set formed by the dialogue.\nThe second related strand of literature is deliberation, which examines how people make choices when they must invest sig-\nnificant time and resources to understand their own tastes (Shugan, 1980, Kahn and Meyer, 1991, Wathieu and Bertini, 2007, Guo \nand Zhang, 2012, Xiong and Chen, 2013, Guo, 2016, Li et al., 2019, Xu and Zhou, 2021 ). The key difference between deliberation and \nsearch is as follows. Under deliberation, people do not know their inherent tastes and thus must costly invest effort to understand \nFig. 1. Sponsored Ads from Lenovo on Google. \n9 Notably, parallel search is often used in explore people’s consideration set formation (Morgan and Manning, 1985, Dukes and Liu, 2016 ). For \nexample, when buying a mid-size SUV, a consumer might consider all models of Mercedes and BMW before making her purchase. In this example, \nall mid-size SUV models of these two German brands constitute the consumer’s consideration set (i.e., sampling plan). When forming the con-\nsideration set, the consumer will balance the expected benefits of evaluating all mid-size SUV models of the two brands and the associated search \ncosts. That is, all benefits and costs are current when the consideration set is formed.\n10 Notably, parallel search is often used in explore people’s consideration set formation (Morgan and Manning, 1985, Dukes and Liu, 2016 ). For \nexample, when buying a mid-size SUV, a consumer might consider all models of Mercedes and BMW before making her purchase. In this example, \nall mid-size SUV models of these two German brands constitute the consumer’s consideration set (i.e., sampling plan). When forming the con-\nsideration set, the consumer will balance the expected benefits of evaluating all mid-size SUV models of the two brands and the associated search \ncosts. That is, all benefits and costs are current when the consideration set is formed.L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n272their own nature. In contrast, under search, people know their inherent tastes but face uncertainty about the attributes of alternatives \nand thus have to costly evaluate the nature of alternatives.\nFor example, consider a consumer buying a car. She might have uncertainty about her tastes and the value of different vehicle models, \nand thus, her purchase process is a series of interactions between deliberation and search. Specifically, she might not know about what \nkind of car she likes, an SUV or a sedan. After visiting different car dealers and test-driving various cars, she figures that a sporty car is her \ntaste (deliberation—figuring tastes), and then focuses her search on SUVs. She knows that a mid-size car fits her needs but she is uncertain \nwhich brand provides a mid-size SUV, and thus, she needs to costly search this information through Google (search—figuring attributes ). \nAfter narrowing down to several brands (e.g., Mercedes and BMW), she might be uncertain about what color she loves the most. After \ntrying different models, she figures that the white color is her taste (deliberation—figuring tastes). She then focuses on evaluating and \ncomparing white mid-size SUVs of Mercedes and BMW and buys the one that best fits her tastes (search—figuring attributes ).\nObviously, LLMs can act as intelligent intermediaries in the deliberation process, potentially helping users clarify their own tastes \nand preferences through iterative conversations. This connection is particularly prominent in complex decision-making scenarios \nFig. 2. Sponsored Ads from Dell on Perplexity. L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n273Fig. 3. Sponsored Ads from Xoticpc on ChatGPT (by Microsoft’s New Bing). L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n274where users might be uncertain about their own needs or desires. By offering contextual information, suggestions, and clarifications, \nLLMs could significantly reduce the cognitive load associated with deliberation, potentially leading to more informed and satisfying \ndecisions.\nThe third related strand of literature is the digital platform. Digital platforms are online structures that enable the exchange of \ngoods, services, and information between users and providers (Rochet and Tirole, 2003, Laffont et al., 2003, Caillaud and Jullien, \n2003, Baye and Morgan, 2001, Zhang et al., 2022, Zhong, 2023, Leong et al., 2024 ). Digital platforms have dramatically transformed \nthe landscape of information search and retrieval, impacting both economic models and user behavior. Traditional digital platforms \nlike Google have dominated the market by leveraging network effects and data-driven personalization, creating an efficient yet \ntraditional search experience where users input queries and receive a ranked list of links. Nevertheless, LLMs introduce a new \ndimension to this ecosystem by offering highly personalized, conversational interactions that could create novel forms of user en-\ngagement and loyalty. This shift could alter the nature of competition among digital platforms, potentially creating new winners and \nlosers based on the quality and capabilities of their LLM integrations. Moreover, LLMs could change the way platforms monetize user \ninteractions, particularly in the field of online advertising, by offering more nuanced and context-aware opportunities for user- \nadvertisement matching.\nSpecifically, compared to Google, ChatGPT’s conversational interactions provide a healthier information discovery process in \nwhich users can easily conduct multiple iterations to deliberate their inherent needs for information and evaluate the value of \ninformation (including attributes). That is, if users are rational decision-makers whose choices are made based on the maximization \nof the difference between expected benefits and costs, they are likely to use ChatGPT’s dialogue format of interactions over Google’s \nstuff list of links like traditional search results.\nThe fourth related strand of literature is consumer perception and engagement. Consumer perception, as studied by Zeithaml \n(1988) , Parasuraman et al. (1985) , and Fatma and Rahman (2017), focuses on how consumers interpret and evaluate information and \nexperiences. In the process of information search, perception plays a key role in how users assess the credibility, relevance, and \nquality of information sources. Consumer engagement, on the other hand, has been extensively studied in the context of digital \nplatforms and social media. Brodie et al. (2013) define consumer engagement as a psychological state that occurs through interactive \nexperiences with a focal agent or object. In the digital age, engagement often manifests as user-generated content, feedback, and \nactive participation in online communities (Van Doorn et al., 2010 ).\nFig. 4. Sponsored Ads from Dell and ASUS on Gemini. L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n275LLM technology introduces novel dimensions to both consumer perception and engagement.11In terms of perception, LLMs \nfundamentally alter how users interact with and perceive information sources. Unlike traditional search engines that present a list of \npotentially relevant links, LLMs offer direct, conversational responses. This shift may influence users\' perceptions of information \ncredibility and relevance, as they interact with an AI that appears to \"understand\" their queries and provide contextual responses. The \nconversational nature of LLMs may also affect users\' perception of the search process itself, potentially making it feel more intuitive. \nRegarding engagement, LLMs create unprecedented opportunities for users to contribute to and shape the information landscape. \nEvery interaction with an LLM can be seen as a form of engagement that potentially improves the system\'s responses for future \nqueries. Moreover, the iterative nature of LLM interactions allows for a depth of engagement not typically seen in traditional search, \npotentially leading to more satisfied users. This dynamic engagement could have significant implications for how digital platforms \ndesign their user experiences and build user loyalty in the age of LLM-powered information search.\n5. ChatGPT and the future of information\nThe future of information will likely be significantly influenced by ChatGPT and other generative AI technologies in various ways. \nFor example, ChatGPT could revolutionize the economy by automating many tasks that require human creativity and reasoning, such \nas writing, data analysis, customer service, education, and entertainment. It could transform healthcare by providing accurate di-\nagnoses, personalized treatments, and health education to patients and providers. ChatGPT could enhance communication by sup-\nporting multiple languages, generating summaries and translations, and creating engaging content for social media and marketing. \nHowever, the integration of ChatGPT also poses challenges and risks, including ethical issues, social implications, data quality, \nsecurity, and accountability.\nChatGPT has a wide range of applications and influences in various industries. ChatGPT’s dialogue format has enabled scientists to \nconverse with AI to generate potential drug targets.12For example, drug discovery companies are customizing ChatGPT to interact \nwith their other AI and machine learning tools, such as target discovery platforms, knowledge graphs, and computational chemistry \nmodels. ChatGPT can also answer medical questions using Med-PaLM, a chatbot designed by Google and DeepMind. In addition, the \nAI chatbot can also assist lawyers by identifying themes, patterns, or topics in large sets of documents, prioritizing and categorizing \ndocuments based on their relevance to the case, finding key concepts, entities, and relationships within documents, summarizing \ndocuments, generate queries, and more.13\nWhile debates continue over the pros and cons of ChatGPT versus Google,14and despite the limitations and uncertainties of these \ndeveloping technologies, generative AI holds great potential to transform the way we access, produce, and consume information in \nthe future. The following propositions outline potential future research directions to explore the impact of LLMs in business contexts: \ni. LLMs will significantly reduce search costs, leading to more efficient information markets. Future research could examine how \nthese reduced costs affect consumer surplus and firms’ strategies.\nii. LLMs will alter the nature of consumer deliberation, potentially leading to more informed and less costly decision-making. An \ninteresting area for further study is how LLM-assisted deliberation impacts consumer choices and firms’ strategic responses.\niii. LLMs will reshape online advertising competition on digital platforms. Future research might explore how firms use LLMs for \npersonalized advertising and pricing strategies.\niv.LLM-powered information search will change consumers’ perception of information credibility and relevance compared to tra-\nditional methods. A potential research direction could investigate how interactions with LLMs affect users’ trust and evaluation of \ninformation sources.\nv.LLMs will increase consumer engagement by enabling more interactive and personalized information experiences. Further re-\nsearch could assess the extent to which LLM-powered interactions enhance user engagement compared to traditional digital \ninterfaces.\nFuture research is necessary to test the theoretical and empirical validity of these propositions, which will deepen our under -\nstanding of the transformative potential of LLMs like ChatGPT in business and beyond. Moreover, future research can also focus on a \nseries of key role of ChatGPT and generative AI on information, such as information accessibility and understandability for users who \n11 Traditional user engagement can be measured by tracking metrics such as average session duration, bounce rate, page views, user retention \nrates, and interaction with content like clicks, likes, and shares.\n12 See https://www.sciencedaily.com/releases/2024/02/240207195142.htm .\n13 See https://rankings.io/blog/chat-gpt-for-lawyers .\n14 For example, ChatGPT and Google have different goals and use cases. ChatGPT may be more suitable for creative or personal tasks, such as \nwriting poems, jokes, or stories, while Google may be more suitable for factual or professional tasks, such as finding news, data, or products. \nChatGPT can produce human-like text that is engaging and entertaining, but it can also make up facts or be inconsistent. Google can provide \naccurate and reliable information from various sources, but it can also be biased or incomplete. ChatGPT may be more appealing for users who want \nto have fun or explore ideas, while Google may be more appealing for users who want to get answers or solve problems. In addition, ChatGPT is a \nrelatively new product that is still in development and has limited access. Google is a well-established product that is widely used and integrated \nwith other services and platforms. ChatGPT may face challenges in scaling up, ensuring safety and quality, and gaining user trust and loyalty. Google \nmay face challenges in innovating, adapting, and competing with new technologies and competitors.L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n276have low literacy skills or language barriers; personalized and engaging responses for users by adapting to their preferences, interests \nand emotions; new information or content generation for poems, stories, code and images; creativity and innovation facilitation \namong users by inspiring them with new ideas and suggestions; communication and collaboration among users by connecting them \nwith people who share similar interests or goals; education and learning enhancement among users by providing them with ex-\nplanations, feedback and guidance; dealing with the privacy violation and security concerns of users; the quality and reliability \nimprovement of information for users by producing texts that are accurate, relevant or unbiased; authority and credibility of in-\nformation sources selection for users; texts generation that are indistinguishable from human-written texts; avoiding AI manipulation \nor deception on humans.\nDeclaration of Competing Interest\nYongliang Yang is an Associate Editor and Lin Liu is the Editor-in-Chief for the Journal of Economy and Technology and were not \ninvolved in the editorial review or the decision to publish this article. All the authors declare that they have no known competing \nfinancial interests or personal relationships that could have appeared to influence the work reported in this paper.\nAcknowledgements\nLiu’s work is supported in part by National Natural Science Foundation of China, Projects (72271014, 72242101).\nReferences\nAnderson, S., Renault, R., 1999. Pricing, product diversity, and search costs: a bertrand-chamberlin-diamond model. Rand J. Econ. 30 (4), 719–735 . https://doi.org/ \n10.2307/2556072\nArmstrong, M., Vickers, J., Zhou, J., 2009. Prominence and consumer search. Rand J. Econ. 40 (2), 209–233 . https://doi.org/10.1111/j.1756-2171.2009.00062.x\nBaye, M., Morgan, J., 2001. Information gatekeepers on the internet and the competitiveness of homogenous product markets. Am. Econ. Rev. 91, 454–474 . https:// \ndoi.org/10.1257/aer.91.3.454\nBrodie, R.J., Ilic, A., Juric, B., Hollebeek, L., 2013. Consumer engagement in a virtual brand community: an exploratory analysis. J. Bus. Res. 66 (1), 105–114 . https:// \ndoi.org/10.1016/j.jbusres.2011.07.029\nCaillaud, B., Jullien, B., 2003. Chicken and egg; competing matchmakers. Rand J. Econ. 34 (2), 309–328 . https://doi.org/10.2307/1593720\nChade, H., Smith, L., 2006. Simultaneous Search. Econometrica 74 (5), 1293–1307 . https://doi.org/10.1111/j.1468-0262.2006.00705.x\nDukes, A., Liu, L., 2016. Online shopping intermediaries: the strategic design of search environment. Manag. Sci. 62 (4), 1064–1077 . https://doi.org/10.1287/mnsc. \n2015.2176\nGuo, L., 2016. Contextual deliberation and preference construction. Manag. Sci. 62 (10), 2977–2993 . https://doi.org/10.1287/mnsc.2015.2290\nGuo, L., Zhang, J., 2012. Consumer deliberation and product line design. Mark. Sci. 31 (6), 995–1007 . https://doi.org/10.1287/mksc.1120.0736\nJin, Q., Zhu, M., Yang, Y., Liu, L., 2022. Consumer search with anticipated regret. Prod. Oper. Manag. 31 (8), 3337–3351 . https://doi.org/10.1111/poms.13767\nKahn, B., Meyer, R., 1991. Consumer multiattribute judgments under attribute-weight uncertainty. J. Consum. Res. 17, 508–522 . https://doi.org/10.1086/208574\nKircher, P., 2009. Efficiency of simultaneous search. J. Political Econ. 117 (5), 861–913 . https://doi.org/10.1086/644791\nLaffont, J.J., Marcus, S., Rey, P., Tirole, J., 2003. Internet interconnection and the off-net-cost pricing principle. Rand J. Econ. 34 (2), 370–390 . https://doi.org/10. \n2307/1593723\nLeong, C., Lin, S., Tan, F., Yu, J., 2024. Coordination in a digital platform organization. Inf. Syst. Res. 35 (1), 363–393 . https://doi.org/10.1287/isre.2023.1226\nLi, X., Li, Y., Shi, M., 2019. Managing consumer deliberations in a decentralized distribution channel. Mark. Sci. 38 (1), 170–190 . https://doi.org/10.1287/mksc.2018.1120\nLiu, L., Dukes, A., 2013. Consideration set formation with multiproduct firms: the case of within-firm and across-firm evaluation costs. Manag. Sci. 59 (8), 1871–1886 . \nhttps://doi.org/10.1287/mnsc.1120.1659\nLiu, L., Dukes, A., 2016. Consumer search with limited product evaluation. J. Econ. Manag. Strategy 25 (1), 32–55 . https://doi.org/10.1111/jems.12131\nLiu, L., Wang, X.H., 2021. Product differentiation and equilibrium price with partial product search (Article). Econ. Lett. 205, 109932 . https://doi.org/10.1016/j. \neconlet.2021.109932\nLiu, L., Wang, X.H., 2023. Partial sequential search and product differentiation.  Article 111066.. Econ. Lett. 225https://doi.org/10.1016/j.econlet.2023. . 111066.\nLiu, L., Wang, X.H., Yu, H., 2022. Sequential search with partial depth (Article). Econ. Lett. 216, 110624 . https://doi.org/10.1016/j.econlet.2022.110624\nMenzio, G., Trachter, N., 2015. Equilibrium price dispersion with sequential search. J. Econ. Theory 160, 188–215 . https://doi.org/10.1016/j.jet.2015.09.004\nMorgan, P., Manning, R., 1982. Search and consumer theory. Rev. Econ. Stud. 49, 203–216 . https://doi.org/10.2307/2297270\nMorgan, P., Manning, R., 1985. Optimal Search. Econometrica 53 (4), 923–944 . https://doi.org/10.2307/1912661\nParasuraman, A., Zeithaml, V.A., Berry, L.L., 1985. A conceptual model of service quality and its implications for future research. J. Mark. 49 (4), 41–50 . https://doi. \norg/10.2307/1251430\nRochet, J.C., Tirole, J., 2003. Platform competition in two-sided markets. J. Eur. Econ. Assoc. 1 (4), 990–1029 . https://doi.org/10.1162/154247603322493212\nShugan, S.M., 1980. The cost of thinking. J. Consum. Res. 7 (2), 99–111 . https://doi.org/10.1086/208799\nVan Doorn, J., Lemon, K.N., Mittal, V., Nass, S., Pick, D., Pirner, P., Verhoef, P.C., 2010. Customer engagement behavior: theoretical foundations and research \ndirections. J. Serv. Res. 13 (3), 253–266 . https://doi.org/10.1177/1094670510375599\nWathieu, L., Bertini, M., 2007. Price as a stimulus to think: the case for willful overpricing. Mark. Sci. 26 (1), 118–129 . https://doi.org/10.1287/mksc.1060.0222\nWolinsky, A., 1986. True monopolistic competition as a result of imperfect information. Q. J. Econ. 101 (3), 493–512 . https://doi.org/10.2307/1885694\nXiong, H., Chen, Y.J., 2013. Product line design with deliberation costs: a two-stage process. Decis. Anal. 10 (3), 225–244 . https://doi.org/10.1287/deca.2013.0273\nXu, H., Zhou, P., 2021. Balancing product differentiation and cost saving in the presence of consumer deliberation. Int. Trans. Oper. Res. 28 (6), 3577–3594 . https:// \ndoi.org/10.1111/itor.12701\nZeithaml, V.A., 1988. Consumer perceptions of price, quality, and value: a means-end model and synthesis of evidence. J. Mark. 52 (3), 2–22. https://doi.org/10. \n1177/002224298805200302\nZhang, C., Chen, J., Raghunathan, S., 2022. Two-sided platform competition in a sharing economy. Manag. Sci. 68 (12), 2793–2806 . https://doi.org/10.1287/mnsc.2022.4302\nZhang, Z., Liu, L., Yang, Y., 2024. Monetizing showrooming. Prod. Oper. Manag (forthcoming).\nZhong, Z., 2023. Platform search design: the roles of precision and price. Mark. Sci. 42 (2), 293–313 . https://doi.org/10.1287/mksc.2022.1370L. Liu, J. Meng and Y. Yang                                                                                                              Journal of Economy and Technology 2 (2024) 269–277\n277', 'raytos.bsinfotech@gmail.com', 'Yongliang Yang,  Lin Liu, Jiajun Meng', '', '../pdf_files/674d52f11a2e9-LLM technologies and information search.pdf', 4186123, 9, 5607, 40309, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(63, '8103123931', '51', 5, 5, 'Tech + touch: A pilot study to facilitate access to health information technology for Spanish-speaking parents', '2024-12-02 14:27:40.648679', '2024', 'Objectives: As Spanish-speaking parents face many barriers to care, we sought to: (1) understand HIT experiences and preferences; (2) pilot test a tablet/navigator intervention; (3) understand HIT uses and barriers. Methods: Prospective, uncontrolled, non-randomized, pilot intervention examining facilitated access to a patient portal for Spanish-speaking parents. Parents were recruited from pediatric specialty clinics in an academic center. Parents received an electronic tablet pre-populated with health resources, plus 2 telephone calls from a navigator. Surveys assessed HIT perceptions/use; portal activation was assessed through electronic records. Results: Twenty-five Spanish-speaking parents were enrolled. All parents wished they knew more about their child’s health and that doctors knew them better. Most parents endorsed interest in HIT, however only 12% activated portals. Post-intervention, there were non-significant increases in using portals to make appointments, receive reminders, send/receive messages, and view labs/instructions. Uses of study tablets included video visits (56%), health/COVID information (16%), and schoolwork (16%). Innovation: Spanish-speaking parents express high interest in HIT. Provision of tablets may augment electronic capacity and facilitate video visits. Greater Spanish-language support is needed for Spanish-speaking parents to meaningfully use portals', 'Spanish-speaking,Health information technology,Patient portal', 'Tech touch: A pilot study to facilitate access to health information \ntechnology for Spanish-speaking parents\nJennifer C. Gutierrez-Wua,b, Jennifer Pilotos McBridea, Allison Pittmana, Yumei Yangc,  \nFeng-Chang Linc, Kori B. Flowera,*\naDepartment of Pediatrics, University of North Carolina, Chapel Hill, North Carolina, USA\nbCecil G. Sheps Center for Health Services Research, University of North Carolina, Chapel Hill, North Carolina, USA\ncDepartment of Biostatistics, University of North Carolina, Chapel Hill, North Carolina, USA\nARTICLE INFO\nKeywords:\nSpanish-speaking\nHealth information technology\nPatient portalABSTRACT\nObjectives: As Spanish-speaking parents face many barriers to care, we sought to: (1) understand HIT experiences \nand preferences; (2) pilot test a tablet/navigator intervention; (3) understand HIT uses and barriers.\nMethods: Prospective, uncontrolled, non-randomized, pilot intervention examining facilitated access to a patient \nportal for Spanish-speaking parents. Parents were recruited from pediatric specialty clinics in an academic \ncenter. Parents received an electronic tablet pre-populated with health resources, plus 2 telephone calls from a \nnavigator. Surveys assessed HIT perceptions/use; portal activation was assessed through electronic records.\nResults: Twenty-five Spanish-speaking parents were enrolled. All parents wished they knew more about their \nchild ’s health and that doctors knew them better. Most parents endorsed interest in HIT, however only 12% \nactivated portals. Post-intervention, there were non-significant increases in using portals to make appointments, \nreceive reminders, send/receive messages, and view labs/instructions. Uses of study tablets included video visits \n(56%), health/COVID information (16%), and schoolwork (16%).\nInnovation: Spanish-speaking parents express high interest in HIT. Provision of tablets may augment electronic \ncapacity and facilitate video visits. Greater Spanish-language support is needed for Spanish-speaking parents to \nmeaningfully use portals.\n1.Introduction\nApproximately 13% of the United States (U.S.) population speaks \nSpanish as their primary or secondary language [1]. Spanish-speaking \nfamilies experience communication barriers [2] that contribute to dis-\nparities in healthcare access, quality, and health outcomes [3-8]. Na-\ntional health objectives aim to improve communication for individuals \nusing a language other than English (LOE) who experience health dis-\nparities [9]. Health information technology (HIT), namely electronic \nhealth record (EHR) patient portals, has the potential to serve as a tool to \naddress these disparities by improving access to care, encouraging \npatient-provider communication, and improving quality of healthcare. \nHIT may provide an additional method for accessing healthcare, and \ncould reduce barriers such as transportation, which can contribute to \nhealth disparities [10]. EHR patient portals have become the primary digital touchpoint utilized by healthcare systems to facilitate online \ncommunication between patients and their healthcare teams [11].\nDespite widespread adoption of portals, prior studies demonstrate \nlower rates of patient portal interaction among patients using a LOE \n[12,13]. Spanish-speaking parents endorse interest in HIT, including \npatient portals, to communicate about their children ’s health; however, \nSpanish-speaking parents ’ HIT preferences and experiences are not well \nunderstood [4]. Additionally, relatively little is known about how access \nto portals can be facilitated for patients who face language barriers to \nhealth care. Currently, one of the most obvious barriers to portal use is a \nlack of widespread availability of Spanish-language patient portals by \nhealth systems. Additionally, barriers to HIT use may include limited \naccessibility to household devices [4], low digital literacy, and lack of \nlinguistically and culturally appropriate HIT resources [14]. We hy-\npothesized that providing an electronic tablet customized with Spanish- \nAbbreviations: HIT, health information technology; IRB, institutional review board; EHR, electronic health record; VBN, volunteer bilingual navigator; LEP, \nlimited English proficiency.\n*Corresponding author at: 231 MacNider CB 7220, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA.\nE-mail address: kflower@unc.edu (K.B. Flower). \nContents lists available at ScienceDirect\nPEC Innovation\nu{�~zkw! s{yo|kro>! ÐÐÐ1ow�o �to~1m{y2w{m k�o2|omtzz\nhttps://doi.org/10.1016/j.pecinn.2024.100358\nReceived 18 February 2024; Received in revised form 3 November 2024; Accepted 15 November 2024  PEC Innovation  5 (2024)  100358  \nAvailable  online  17 November  2024  \n2772-6282/©  2024  The Authors.  Published  by Elsevier  B.V. This is an open access  article  under  the CC BY-NC-ND  license  ( http://creativecommons.org/licenses/by-  \nnc-nd/4.0/  ). language resources, and paired with individual assistance in Spanish \nwould: 1) increase parent use of an electronic patient portal, and 2) \nresult in more positive parent perceptions of HIT and patient portals. \nThus, we conducted a prospective, uncontrolled, non-randomized pilot \nintervention of facilitated access to an EHR patient portal for Spanish- \nspeaking parents to (1) understand Spanish-speaking parents ’ HIT \npreferences and experiences, (2) pilot test a tablet/navigator interven -\ntion to address potential barriers and increase HIT access/use and (3) \nunderstand HIT uses and barriers to successful HIT use among Spanish- \nspeaking parents.\n2.Materials and methods\n2.1. Study population\nParents were recruited from pediatric specialty clinics in a single \nacademic center from August 2020 to January 2021. Spanish-speaking \nresearch assistants identified potentially eligible patients by reviewing \nclinic schedules. Phone contact was attempted for all potentially eligible \npatients. Parents were eligible if (1) their preferred language was \nSpanish; (2) they had never activated the institutional patient portal; (3) \nthey had internet service in their home or the ability to easily access \ninternet service; (4) their child was under the age of 13 years (given \nproxy portal access needed for youth age 13 and older); (5) they antic-\nipated that their child would need at least 1 follow-up appointment \nwithin 1 year. Parents were excluded if they did not meet any of the \ndefined inclusion criteria.\nParents ’ consent to participate was documented using a verbal \nconsent form; additionally, for children ages 7 to 12 years, assent to \nparticipate was documented using a verbal assent form. This study was \napproved by the Institutional Review Board (IRB) at the University of \nNorth Carolina at Chapel Hill.\n2.2. Intervention\nIn the institution studied, we previously described low patient portal \nuse by Spanish-speaking parents, and limited household technology \ndevices [4]; we had also implemented navigators to improve patient \nexperience [15]. We theorized that several elements may be needed to \naddress barriers to HIT and portal use, including: 1) availability of \nappropriate electronic devices (hardware); 2) electronic health infor-\nmation and resources in Spanish; 3) language-concordant support and \nassistance with use of technology and devices. Thus, we designed an \nintervention, Estudio Triple T (Tableta, Tecnología, y Toque) that \ncombined these 3 elements: an electronic tablet, information technology \nin Spanish, and a human touch. The intervention consisted of receiving \nan electronic tablet by mail which was pre-populated with Spanish \nlanguage health resources (Appendix 1), plus two follow-up phone or \nvideo calls per parent preference from a culturally and linguistically \nappropriate navigator. Our team also created a printed user’s guide that \nprovided step by step instructions in Spanish to using the tablet and the \npre-populated Spanish-language health information resources and \nincluded instructions to activating the patient portal using the pre- \ninstalled application on the tablet; the printed guide was mailed to \nparents with the tablet. The patient portal application was available at \nour institution only in English; therefore, navigators provided Spanish- \nlanguage instructions in using it to perform simple tasks such as \nviewing future appointments and requesting medication refills. The \noriginal study design planned recruitment and intervention delivery in \nperson at clinic visits; due to the COVID-19 pandemic, the protocol was \nmodified to recruit and deliver the intervention virtually.\nVolunteer bilingual navigators (VBNs) are certified in English and \nSpanish and were implemented in the study setting previously to sup-\nport families with wayfinding and nonmedical communication [15]. \nThree VBNs received an additional 30-min standard training specific to \nthis intervention in how to assist families in accessing electronic resources through the study tablet and activate the patient portal. \nApproximately one week after parents received the tablet, the VBN \ncalled parents to assist with orientation to the tablet, provide informa -\ntion about health information resources available through the pre-\nprogrammed tablet, provide virtual assistance with activating their \npatient portal, and describe the process for patient video visits. Two \nweeks later the navigator attempted a 2nd phone call to answer any \nquestions about the tablet use or functioning. The tablet also served as \nan incentive for study participants.\n2.3. Pre-intervention measures\nBaseline measures were obtained at enrollment by a bilingual \nresearch assistant in Spanish via telephone interviews, which included \ndemographics, and baseline HIT access, use, and interest. Demographics \nincluded caregiver sex (female, male), caregiver age (continuous), \ncountry of origin (U.S., Mexico, Honduras, El Salvador, Guatemala, \nColumbia, Ecuador, other), number of years in the U.S. (continuous), \neducation level (elementary/primary school, middle school, high \nschool, trade/vocational school, and college, dichotomized as middle \nschool or less, high school or more), employment status (full time, part \ntime, homemaker, not working), annual household income (D$10,000, \n$10,000 –$19,000, $20,000 –$39,000, $40,000 –$59,000), and house -\nhold size (continuous). HIT questions were adapted from the Consumers \nand Health Information Technology National Survey [16], and trans -\nlated into Spanish by bilingual research assistants. HIT baseline ques-\ntions addressed the following domains: 1) general information technology \nuse (5 items); 2) previous HIT use (3 items); 3) familiarity with HIT (3 \nitems); 4) interest in HIT (2 items); 5) communication needs (7 items); 6) \ncommunication preferences (3 items); 7) perceptions of HIT (3 items); 8) \nperceptions of patient portals (3 items).\n2.4. Post-intervention measures\nA post-intervention questionnaire was conducted by telephone by \nbilingual research assistants 1 month after parents received the tablet \nand assistance from navigators and included the same items used in the \nbaseline questionnaire to reevaluate parents ’ communication preferences, \nperceptions of HIT, and perceptions of patient portals. Overall scores for \nparent perceptions of HIT and parent perceptions of patient portals were \ncalculated by summing the Likert responses for the three items in each of \nthese domains (score range 3–12). Study tablet use by household \nmembers, study tablet use by activity on a Likert scale (dichotomized as \nnever/very little vs. moderately/very often/almost always), and an \nopen-ended question about barriers to portal use were also evaluated. \nSince virtual visit availability expanded greatly during the study period \ndue to the COVID-19 pandemic, we also inquired about electronic de-\nvices used for video visits. Activation of the patient portal was assessed \nthrough the electronic medical record review of portal activity at 6 \nmonths.\n2.5. Statistical analysis\nDemographic characteristics were summarized using medians and \ninterquartile range for continuous variables and proportions for cate-\ngorical variables. Descriptive baseline statistics for individual items \nwithin each HIT domain were examined using proportions. Pre- \nintervention vs post-intervention HIT perceptions and uses were \ncompared for each individual item using the Wilcoxon test (for medians) \nand the McNemar test (for proportions) as appropriate; median pre- and \npost-intervention scores for parent perception of HIT and parent \nperception of patient portals were also compared using the Wilcoxon \ntest. Wilcoxon signed-rank test was used for comparing the score ranks \nof pre- and post-HIT perception and usage, given that the scores were \nordinal and we could not assume normal distributions.J.C. Gutierrez-Wu et al.                                                                                                                                                                                                                       PEC Innovation  5 (2024)  100358  \n2 3.Results\nOf caregivers who were screened (N 314), 79 were potentially \neligible and phone contact was attempted; 25 caregivers, all of whom \nwere parents, consented and were enrolled. All parents participated in at \nleast 1 navigator call; 76% participated in 2 calls. Parents were mostly \nmothers (96%) from Mexico (64%) with a household income D$40,000 \n(76%) (Table 1). Before receiving the study tablet, 84% of participants \nreported having an electronic device; smart phones were the most \nfrequently reported device in the home (Fig. 1). At baseline, all parents \nreported wishing they knew more about their child ’s health care and \nthat their doctor knew more about them/their child ’s health, and most \n(90%) agreed that keeping track of all their child ’s health information \nwas difficult (Table 1).\nRegarding HIT use at baseline, most parents reported having used an \nelectronic device for health-related reasons (64%) such as searching a \nwebsite for nutrition, weight, and exercise information (60%), while \nfewer reported searching online for information about a disease or \nmedical problem (24%) (Table 2). Few reported being very familiar with \nHIT such as mobile applications (16%), websites for personal health \ninformation (12%), or use of electronic medical files by doctors and \nhealth care systems (16%). Most reported being very interested in using \nHIT via a smartphone or tablet (84%) and a patient portal (78%).\nTwenty parents completed the post-intervention questionnaire. \nThere was no difference observed in parents ’ communication prefer -\nences, perceptions of HIT, or perceptions of patient portals before and \nafter the intervention (Table 3). After the intervention, there were in-\ncreases in the proportion of parents who reported using the patient \nportal to make appointments, receive reminders, send/receive messages from doctors/nurses, view labs, and view instructions; these increases \nwere not statistically significant. On examination of free-text responses \nto an open-ended question about barriers to patient portal use, the most \nfrequently endorsed reasons for lack of portal use were lack of aware -\nness/ understanding of the portal, lack of access to internet, no \nperceived need for the portal, and preference for in-person communi -\ncation. Based on electronic health record review, 12% of parents acti-\nvated the patient portal.\nParents reported that study tablets were mostly used for video visits, \nentertainment, news, health/COVID information, and children ’s \nschoolwork (Fig. 2). The study tablet was equally and most often used by \na parent or child (75%). Fifty-six percent of families reported having a \nvideo visit; 50% of them reported using the study tablet for the video \nvisit. Of those who did not use the study tablet for the video visit, 38% \nreported using a phone and 12% reported using another device.\n4.Discussion and conclusion\n4.1. Discussion\nIn this HIT pilot intervention providing Spanish-speaking parents \nwith customized tablets and language-concordant assistance from pa-\ntient navigators, we sought to understand Spanish-speaking parents ’ HIT \npreferences and experiences and increase patient use of a patient portal \nthat was accessible in English only. This intervention did not lead to \nchanges in perceptions of HIT, and only 12% of parents activated the \npatient portal despite the linguistically tailored resources and support \nthat were provided. While activation of the patient portal was modest \nfollowing this intervention, we learned about the ways in which \nlanguage-specific support combined with technology provision may \nbenefit Spanish-speaking families, and gained insight into remaining \nchallenges to having more Spanish-speaking parents meaningfully \nengage in patient portal use.\nWhile the overall proportion of parents who activated the patient \nportal for their children was low, more parents reported using the pa-\ntient portal for specific health communication needs following the \nintervention. This is notable because patient portal activation is an \ninitial step that is necessary but not sufficient to enable parents to \nbenefit from the functionalities of patient portals, and parent report of \nusing specific functionalities indicates active engagement beyond basic \nactivation. Specifically, more parents reported use of the patient portal \nto make an appointment, receive reminders about exams, vaccines, and \nradiology studies, send/receive messages, view laboratory or other re-\nsults, and view physicians ’ instructions. Parent-reported uses in this \nstudy provide insight into the patient portal functions that may be most \naccessible and initially beneficial and could be emphasized when par-\nents are introduced to portals. In contrast, we observed no change in Table 1 \nBaseline characteristics of parents (N 25).\nCharacteristics N (%)/ Median \n(IQR)\nSex\nFemale 24 (96%)\nAge (years) 38 (32–40)\nNumber of people in household 3 (3–4)\nCountry of origin\nMexico 16 (64%)\nHonduras 6 (24%)\nGuatemala 3 (12%)\nEducation level\nMiddle school or less 9 (36%)\nHigh school or less 16 (64%)\nEmployment status\nWorking full time 6 (24%)\nWorking part time 4 (16%)\nNot working 5 (20%)\nHomemaker 10 (40%)\nAnnual household income\nD$10,000 6 (29%)\n$10,000 –19,999 6 (29%)\n$20,000 –39,999 7 (33%)\n$40,000 –59,999 2 (9.5%)\nHealth communication preferencesa\nKeeping track of child ’s health information is difficult 18 (90%)\nI wish the doctor knew me and my child ’s health better 25 (100%)\nI wish I knew more about my child ’s health care 25 (100%)\nHealth communication needs in past yearb\nSchedule an appointment 23 (92%)\nReceive a reminder when child needs an exam 22 (88%)\nKeep up to date with child ’s health records 22 (88%)\nSee the doctor ’s instructions for taking care of child ’s \nhealth20 (80%)\nSend/receive an email from a doctor or nurse 17 (68%)\nRefill a prescription 16 (64%)\nView the results of labs or other tests 15 (60%)\na% agree shown (strongly agree/agree); response options were 4-point Likert \nscale from 1 (strongly agree) to 4 (strongly disagree).\nb% of parents responding “yes” to having need within past year.\nFig. 1.Percent of parents with electronic devices in home at baseline.J.C. Gutierrez-Wu et al.                                                                                                                                                                                                                       PEC Innovation  5 (2024)  100358  \n3 parent report of use of the patient portal for other functions, such as \nrenewing medications, and staying up to date with a child ’s health and \nvaccines. It is possible that functions such as renewing medications \nthrough the patient portal are less readily accessible, and therefore \nrequire some additional orientation in Spanish to increase engagement. \nSimilarly, staying up to date with a child ’s health may be challenging \nwhen the health record is primarily in English. Having accessible, \nvisible, brief health summary information in Spanish via patient portals \nis one strategy that could support parents in making fuller use of portals for staying up to date with their child ’s health, and meeting the need \nthat parents expressed in this study to know more about their child ’s \nhealth.\nWe found that all Spanish-speaking parents in our study desired more \ncommunication than they currently receive about their children ’s care. \nThis is consistent with previously described differences in communica -\ntion patterns by language [ 2] and previous findings that medical teams \ndisplayed less respect and partnership with Spanish-speaking Latino \ncaregivers [17]. Prior studies of families using a LOE have also been \nfound to receive less information and support during inpatient family \nconferences [18]. In addition to language, Spanish-speaking caregivers \nmay also face access barriers that prevent them from receiving optimal \ninformation about their children ’s care [3,4].\nPatient portals are one potential avenue to improve access and Table 2 \nBaseline parent health information technology use and interest (N 25).\nTechnology use and interest N (%)\nParent current technology use\nCheck bank account online or pay bill online\nAlmost never 21 \n(84%)\nOften 4 (16%)\nUse social media apps or websites, such as Facebook, Instagram, or \nLinkedIn\nAlmost never 5 (20%)\nOften 20 \n(80%)\nRead the news online\nAlmost never 8 (32%)\nOften 17 \n(68%)\nWatch the videos online, like on YouTube\nAlmost never 6 (24%)\nOften 19 \n(76%)\nShop online\nAlmost never 24 \n(96%)\nOften 1 (4%)\nParent health information technology use (ever)\nSearched online for information about a disease or medical problem 6 (24%)\nTyped information on a website about eating, exercise, or weight 15 \n(60%)\nUsed an application on a cell phone or tablet for any health-related \nreasons16 \n(64%)\nParent familiarity with health information technology\nFamiliar with mobile applications to save/keep up-to-date with health \ninformation\nNot at all 7 (28%)\nA little 14 \n(56%)\nVery 4 (16%)\nFamiliar with websites where you can get, save, or update your health \ninformation\nNot at all 13 \n(52%)\nA little 9 (36%)\nVery 3 (12%)\nFamiliar with doctors and health care systems using electronic medical \nfiles\nNot at all 15 \n(60%)\nA little 6 (24%)\nVery 4 (16%)\nParent interest in health information technology\nLevel of interest in health programs on a smartphone or tablet\nNot at all interested 0 (0%)\nA little interested 4 (16%)\nVery interested 21 \n(84%)\nLevel of interest in using a patient portal\nNot at all interested 1 (4%)\nA little interested 4 (17%)\nVery interested 18 \n(78%)Table 3 \nParents ’ interest in and use of health information technology (HIT) before and \nafter tablet and navigator intervention (N 20).a\nPre- \ninterventionbPost- \ninterventionbP \nvalue\nParent communication preferencesc\nKeeping track of all their health \ninformation is difficult2 1.5 0.38\nI wish the doctor knew me and my \nchild ’s health better1 1 0.78\nI wish I knew more about my child ’s \nhealth care1 1 0.97\nPerceptions of health information technologyc\nOverall scored7 6 0.45\nThings like electronic health \nrecords – even sending emails back \nand forth – can improve your \nrelationship with your doctor.2 1 0.15\nTechnology can make it easier for \nyou to schedule a doctor visit, look \nat results, renew your medicine, \nand talk with your doctor.2.5 3 0.64\nWith more technology and \ninformation, you could feel more in \ncontrol of your health and the type \nof health care you receive.2 2 0.69\nPerceptions about patient portal usec\nOverall scoree3 3 0.85\nI don’t need this to handle my \nhealth needs1 1 0.71\nI don’t like using computers or the \nInternet1 1 0.86\nIt would take too much time 1 1 0.93\nReported uses of patient portalf\nMake an appointment 0 0.05 1\nRenew medications 0 0 –\nStay up to date with your child ’s \nhealth records, like vaccines dates0 0 –\nReceive a reminder when your \nchild needs an exam/vaccine/xray0.05 0.1 1\nSend or receive a message from the \ndoctor or nurse0 0.15 0.25\nView lab or other results 0.05 0.2 0.25\nView instructions from your doctor \nabout your child ’s health0 0.1 0.48\naPre and post-intervention responses provided for N 20 participants who \ncompleted both surveys.\nbMedians displayed and paired Wilcoxon tests used to compare pre- and post- \nintervention values for all items except “Reported Uses of Patient Portal ” for \nwhich proportions are displayed and McNemar test was used for comparison.\ncResponse options: 4-point Likert scale from 1 (strongly agree) to 4 (strongly \ndisagree).\ndScore calculated from sum of Likert responses from 3 items shown. Lower \nscores indicate more positive perceptions.\neScore calculated from sum of Likert responses from 3 items shown. Higher \nscores indicate more positive perception.\nfResponse options: Yes/No. Proportion responding “Yes” is displayed.J.C. Gutierrez-Wu et al.                                                                                                                                                                                                                       PEC Innovation  5 (2024)  100358  \n4 communication with Spanish-speaking families. We found that Spanish- \nspeaking patients may have the necessary means (access via smart -\nphones), background (high use of phone apps, tablet use for video visits \nand health information), and interest in HIT and patient portals. How-\never, we did not observe an increase in HIT preferences or interest in and \nuse of patient portals. This may be due to several challenges Spanish- \nspeaking parents faced to successful patient portal use. Like many \nhealth systems, the portal in our study was only available in English for \nparents to access independently or with the assistance of VBNs via \nphone, presenting a barrier to set-up and navigation. Spanish-language \npatient portals are available, (e.g., Epic ’s MyChart) however, are not yet \nuniversally used by health care systems [19]. HIT preferences may \nshaped by larger systemic and societal factors, may be difficult to \nimpact, and may require a longer intervention period to change. Low \ndigital literacy, concerns regarding privacy and confidentiality of HIT, \nconcerns related to reliability of web-based information, and a prefer -\nence for in-person interaction may also explain why we did not observe a \nchange in HIT preferences [14].\nIn addition to patient-facing barriers, healthcare providers have \nexpressed concerns related to time and reimbursement for care provided \nthrough patient portals [20]. Adoption of Spanish-language portals will \nlikely need policy makers, product makers, healthcare organizations, \nand providers to work together to expand federal policies and funding \nfor language accessibility to include digital communication, continue \ndevelopment of language accessible portals, integrate language services \ninto portal messaging workflows, and engage patients and caregivers in \nportal use and awareness as part of standard of care. Currently, the \nliterature on non-English language patient portals is sparse. To ensure \nHIT is accessible to populations using a LOE, it is vital that healthcare \norganizations and investigators continue to measure and evaluate portal \nuse, quality, cost, and outcomes for patients using a LOE and caregivers \n[19]. Additionally, parents lacked familiarity with patient portals and \nother HIT for personal health information, and that may also contribute \nto concerns about confidentiality and reliability [4,21]. Efforts to improve digital literacy among patients using a LOE, including famil -\niarity and safety of patient portals, through collaborations with com-\nmunity organizations (e.g., libraries) and linguistically tailored support \nfrom community health workers may improve familiarity with and use \nof patient portals and HIT [19].\nFurthermore, due to restrictions related to the COVID-19 pandemic, \nwe modified the original intervention to enable it to be conducted \nremotely. Testing the use of remote technologies was especially salient \nduring the pandemic when many families did not have sufficient elec-\ntronic devices to meet new technology needs such as online school and \nvideo visits. This enabled us to learn how families used the study- \nprovided tablet. Our findings that more than half of families used the \ntablet for video visits, and that 16% used it for children ’s education, \nthough that was not the intended purpose, suggests unmet technology \nneeds that can be addressed through the provision of electronic re-\nsources. However, due to pandemic restrictions, navigators had to use \nthe very technologies that families may have found challenging, such as \nvideo calls, to assist families with use of the tablet and patient portal. \nProviding assistance regarding HIT while relying on information tech-\nnology to communicate was a significant challenge; and could partially \nexplain our low portal activation rate. A preference for in-person in-\nteractions [14] may also explain our low activation rates and it is \npossible that in-person assistance, as was originally planned for this \nstudy, would be more effective in enabling families to activate the pa-\ntient portal. Additionally, families expressed uncertainty about the \nadded value of the portal; Spanish-language materials to highlight its \nbenefits could address this. Concerns regarding privacy and confiden -\ntiality related to HIT may also present a barrier to activation and use of \npatient portals [14], and efforts to improve digital literacy and confi -\ndence should be addressed as previously discussed. Finally, since patient \nportal activation required navigating a multi-step process in English, we \nanticipate that this may have deterred caregivers from activating the \nportal, even with assistance. The challenges we encountered in remote \ndelivery of a HIT intervention are not surprising as other studies have \nFig. 2.Uses of study-provided electronic tablet (n 19).J.C. Gutierrez-Wu et al.                                                                                                                                                                                                                       PEC Innovation  5 (2024)  100358  \n5 found that Spanish-speaking patients experienced difficulties with tel-\nehealth visits and HIT, and many expressed a preference for in-person \nvisits [10,22]. Future interventions might address these barriers \nthrough greater in-person assistance, making all aspects of the patient \nportal available in Spanish, and providing clear, low-literacy, Spanish- \nlanguage information about confidentiality.\nThis was a small pilot study, which may have limited the ability to \ndetect a true difference before and after the study intervention. Our \nsample (N 20) had only 29% power to detect a 1-point change in the \nPerceptions of Health Technology score, and 55% power to detect a 1- \npoint change in the Perceptions about Patient Portal Use score; a \nlarger sample size (N 98) would be needed to detect these changes \nwith 80% power. While the small sample size limited power, it was \nnecessary at this stage to refine intervention delivery, given the inno-\nvative, multi-component nature of the intervention, and conduct pre-\nliminary testing to inform larger studies. Our study also used self-report \nmeasures that are subject to recall bias. Our study population consisted \nof parents at specialty clinics potentially limiting generalizability to \nthose presenting to a primary care setting. Despite these limitations, \nliterature examining HIT interventions is limited, and our study provides \nvaluable insight into characteristics of HIT interventions that may be \nneeded to increase access and use of HIT and patient portals among \nSpanish-speaking patients, and may be used to inform a larger study \nwith more power.\n4.2. Innovation\nThis pilot study introduces a novel approach to engaging primarily \nSpanish-speaking caregivers with HIT by providing multiple supports \naimed at reducing reported barriers to patient portal use, namely \nappropriate access to electronic devices, access to electronic HIT and \nresources in Spanish, and personal support from a language-concordant \nnavigator. Of interventions to increase electronic patient portal use, ours \nis one of the few developed specifically to address the gap in electronic \npatient portal use by Spanish-speaking caregivers and was uniquely \ndesigned to holistically address both linguistic and cultural barriers. \nWhile our pilot intervention did not lead to an increase in patient portal \nuse or activation, our findings highlight the need for the translation of \nHIT resources into Spanish, increased support with portal activation and \nnavigation to facilitate caregiver engagement with these tools, and the \npotential role for in-person support.\n4.3. Conclusion\nSpanish-speaking caregivers express high interest in HIT and patient \nportals. While provision of electronic tablets may augment electronic \ncapacity and facilitate connecting to video visits, Spanish-speaking \ncaregivers also reported barriers with portal set-up and navigation. \nThese findings highlight the need for greater Spanish-language infor-\nmation, support, and resources to facilitate portal use, and the need for \nstudies to determine what types of assistance are most effective in \nengaging Spanish-speaking parents in setting up and using patient por-\ntals meaningfully. Since patient portals have become a major method of \nhealth communication, institutions should make efforts to ensure that \nthis technology is accessible to populations using a LOE, including those \nwho speak Spanish. To facilitate equitable access, healthcare institutions \nshould provide plain language, low literacy-adapted information about \npatient portals, simplify and clarify activation steps to make them \nmaximally accessible in all languages, and consider providing in-person \nassistance to assist patients in activating and using HIT, including pa-\ntient portals. Healthcare organizations may also need clear, effective, \nmultilingual communication about the value and benefit of activating \nand using patient portals. More broadly, community-level investments \nin internet access are needed to address the barrier of limited internet \naccess that was identified by parents in this study.Funding/Support\nFunding to support this study was provided by the Oak Foundation.\nDr. Jennifer C. Gutierrez-Wu was supported by a NRSA Post-Doctoral \nTraineeship from the Health Resources and Services Administration \nsponsored by The Cecil G. Sheps Center for Health Services Research, \nUniversity of North Carolina at Chapel Hill, Grant No. 2-T32-HP14001- \n34-00 The funding agencies had no role in the design and conduct of the \nstudy.\nClinical Trial Registration\nThis study is registered as NCT04410380 . Data Sharing: Research \ndata may be shared in a de-identified data set to protect subject privacy; \nplease contact the investigators with an analytic proposal and request.\nCRediT authorship contribution statement\nJennifer C. Gutierrez-Wu: Writing – review & editing, Writing – \noriginal draft, Methodology, Formal analysis, Data curation. Jennifer \nPilotos McBride: Writing – review & editing, Formal analysis. Allison \nPittman: Writing – review & editing, Formal analysis, Data curation. \nYumei Yang: Writing – review & editing, Formal analysis, Data cura-\ntion. Feng-Chang Lin: Writing – review & editing, Supervision, Meth -\nodology, Formal analysis. Kori B. Flower: Writing – review & editing, \nWriting – original draft, Formal analysis, Data curation, \nConceptualization.\nDeclaration of competing interest\nThe authors declare that they have no known competing financial \ninterests or personal relationships that could have appeared to influence \nthe work reported in this paper.\nAppendix A.Supplementary data\nSupplementary data to this article can be found online at https://doi. \norg/10.1016/j.pecinn.2024.100358 .\nReferences\n[1]U.S. Census Bureau. American Community Survey. 1-Year Estimates Data Profiles: \nSelected social characteristics in the United States. https://data.census.gov/table? \ntidACSDP1Y2021.DP02 ; 2021 [accessed 10 Sep 2023].\n[2]Flower KB, Skinner AC, Yin HS, et al. Satisfaction with communication in primary \ncare for Spanish-speaking and English-speaking parents. Acad Pediatr. May-Jun \n2017;17(4):416 –23. https://doi.org/10.1016/j.acap.2017.01.005 .\n[3]Timmins CL. The impact of language barriers on the health care of Latinos in the \nUnited States: a review of the literature and guidelines for practice. J. Midwifery \nWomens Health Mar-Apr 2002;47(2):80 –96. https://doi.org/10.1016/s1526-9523 \n(02)00218-0 .\n[4]Flower KB, Wurzelmann S, Tucker C, Rojas C, Díaz-Gonz ˘alez de Ferris ME, \nSylvester F. Spanish-speaking parents ’ experiences accessing academic medical \ncenter care: barriers, facilitators and technology use. Acad Pediatr Jul 2021;21(5): \n793–801. https://doi.org/10.1016/j.acap.2020.10.008 .\n[5]Flores G, Olson L, Tomany-Korman SC. Racial and ethnic disparities in early \nchildhood health and health care. Pediatrics Feb 2005;115(2):e183 –93. https:// \ndoi.org/10.1542/peds.2004-1474 .\n[6]Eneriz-Wiemer M, Sanders LM, Barr DA, Mendoza FS. Parental limited English \nproficiency and health outcomes for children with special health care needs: a \nsystematic review. Acad. Pediatr. Mar-Apr 2014;14(2):128 –36. https://doi.org/ \n10.1016/j.acap.2013.10.003 .\n[7]DeCamp LR, Choi H, Davis MM. Medical home disparities for Latino children by \nparental language of interview. J. Healt. Care Poor Underserv. Nov 2011;22(4): \n1151 –66. https://doi.org/10.1353/hpu.2011.0113 .\n[8]Cordova-Ramos EG, Tripodis Y, Garg A, Kalluri NS, Flores G, Parker MG. Linguistic \ndisparities in child health and presence of a medical home among United States \nLatino children. Acad Pediatr. Jul 2022;22(5):736 –46. https://doi.org/10.1016/j. \nacap.2021.09.011 .\n[9]Office of Disease Prevention and Health Promotion. Health Communication. \nHealthy People 2030. U.S. Department of Health and Human Services; 2023. htt \nps://health.gov/healthypeople/objectives-and-data/browse-objectives/health \n-communication [accessed 10 Sep 2023].J.C. Gutierrez-Wu et al.                                                                                                                                                                                                                       PEC Innovation  5 (2024)  100358  \n6 [10] Chaet AV, Morshedi B, Wells KJ, Barnes LE, Valdez R. Spanish-language consumer \nhealth information technology interventions: a systematic review. J. Med. Internet \nRes. Aug 10, 2016;18(8):e214. https://doi.org/10.2196/jmir.5794 .\n[11] U.S. Government Accountability Office. Health Information Technology: HHS \nShould Assess the Effectiveness of Its Efforts to Enhance Patient Access to and Use \nof Electronic Health Information. Washington, D.C: U.S. Government \nAccountability Office; 2017. https://www.gao.gov/assets/gao-17-305.pdf . 2017 \n[accessed 10 Sep 2023].\n[12] Garrido T, Kanter M, Meng D, et al. Race/ethnicity, personal health record access, \nand quality of care. Am. J. Manag. Care Feb 1, 2015;21(2):e103 –13.\n[13] Ancker JS, Barr˘on Y, Rockoff ML, et al. Use of an electronic patient portal among \ndisadvantaged populations. J. Gen. Intern. Med. Oct 2011;26(10):1117 –23. \nhttps://doi.org/10.1007/s11606-011-1749-y .\n[14] Whitehead L, Talevski J, Fatehi F, Beauchamp A. Barriers to and facilitators of \ndigital health among culturally and linguistically diverse populations: qualitative \nsystematic review. J. Med. Internet Res Feb 28, 2023;25:e42719. https://doi.org/ \n10.2196/42719 .\n[15] Flower KB, Wurzelmann S, Rojas C, et al. Improving satisfaction and appointment \nattendance through navigation for Spanish-speaking families. J. Healt. Care Poor \nUnderserv. 2020;31(2):810 –26. https://doi.org/10.1353/hpu.2020.0062 .\n[16] Lake Research Partners. Consumers and Health Information Technology: A \nNational Survey. California Health Foundation; 2010. https://www.chcf.org/w \np-content/uploads/2017/12/PDF-ConsumersHealthInfoTechnologyNationalSur \nvey.pdf [accessed 10 Sep 2023].[17] Parente VM, Reid HW, Robles J, et al. Racial and ethnic differences in \ncommunication quality during family-centered rounds. Pediatrics Dec 1, 2022;150 \n(6). https://doi.org/10.1542/peds.2021-055227 .\n[18] Thornton JD, Pham K, Engelberg RA, Jackson JC, Curtis JR. Families with limited \nEnglish proficiency receive less information and support in interpreted intensive \ncare unit family conferences. Crit. Care Med. Jan 2009;37(1):89 –95. https://doi. \norg/10.1097/CCM.0b013e3181926430 .\n[19] Rodriguez JA, Casillas A, Cook BL, Marlin RP. The language of equity in digital \nhealth: prioritizing the needs of limited English proficient communities in the \npatient portal 2.0. J. Health Care Poor Underserv. 2021;32(2):211. https://doi. \norg/10.1353/hpu.2021.0059 .\n[20] Ochoa A, Kitayama K, Uijtdehaage S, et al. Patient and provider perspectives on the \npotential value and use of a bilingual online patient portal in a Spanish-speaking \nsafety-net population. J. Am. Med. Inform. Assoc. Nov 1, 2017;24(6):1160 –4. \nhttps://doi.org/10.1093/jamia/ocx040 .\n[21] Reuland CJ, Godage SK, Wu L, et al. Information and communication technology \naccess and use among low-income Latino immigrant parents. Matern. Child Health \nJ. Dec 2021;25(12):1807 –13. https://doi.org/10.1007/s10995-021-03265-6 .\n[22] Samuels-Kalow ME, Chary AN, Ciccolo G, et al. Barriers and facilitators to pediatric \ntelehealth use in English- and Spanish-speaking families: a qualitative study. \nJ. Telemed. Telecare 2024;30(3):527 –37. https://doi.org/10.1177/ \n1357633x211070725 .J.C. Gutierrez-Wu et al.                                                                                                                                                                                                                       PEC Innovation  5 (2024)  100358  \n7 ', 'raytos.bsinfotech@gmail.com', 'Jennifer C. Gutierrez-Wu, Feng-Chang Lin, Jennifer Pilotos McBride , Kori B. Flower, Allison Pittman, Yumei Yang', '', '../pdf_files/674d535b91875-Tech + touch - A pilot study to facilitate access to health information.pdf', 608281, 7, 5863, 42138, '2024-12-03 04:43:00', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(67, '9693078778', '6745cf4203d9a', 1, 1, 'Density-Functionalized QM/MM Delivers Chemical Accuracy For Solvated Systems', '2024-12-02 17:37:12.746994', '2024', 'In recent years, the relationship between information technology (IT) and productivity has become a source of debate. In the 1980s and early 1990s, empirical research on IT productivity generally did not identify significant productivity improvements. More recently, as new data are identified and more sophisticated methodologies are applied, several researchers have found evidence that IT is associated not only with improvement in productivity, but also in intermediate measures, consumer surplus, and economic growth. Nonetheless, new questions emerge as old puzzles fade. This survey reviews the literature, identifies remaining questions, and concludes with recommendations for applications of traditional methodologies to new data sources, as well as alternative, broader metrics of welfare to assess and enhance the benefits of IT.', 'Quantum,Computational,Modular,Mechanics', 'Density-Functionalized QM/MM Delivers\nChemical Accuracy For Solvated Systems\nXin Chen,,†Jessica A. Martinez B.,,‡Xuecheng Shao,,¶Marc Riera,,§Francesco\nPaesani,,§Oliviero Andreussi,,∥and Michele Pavanello∗,,†\nE-mail: m.pavanello@rutgers.edu\nAbstract\nWe present a reformulation of QM/MM as a fully quantum mechanical theory of\ninteracting subsystems, all treated at the level of density functional theory (DFT). For\nthe MM subsystem, which lacks orbitals, we assign an ad hoc electron density and\napply orbital-free DFT functionals to describe its quantum properties. The interaction\nbetween the QM and MM subsystems is also treated using orbital-free density function-\nals, accounting for Coulomb interactions, exchange, correlation, and Pauli repulsion.\nConsistency across QM and MM subsystems is ensured by employing data-driven,\nmany-body MM force fields that faithfully represent DFT functionals. Applications to\nwater-solvated systems demonstrate that this approach achieves unprecedented, very\nrapid convergence to chemical accuracy as the size of the QM subsystem increases.\nWe validate the method with several pilot studies, including water bulk, water clusters\n(prism hexamer and pentamers), solvated glucose, a palladium aqua ion, and a wet\nmonolayer of MoS 2.\n1arXiv:2411.17844v1  [physics.chem-ph]  26 Nov 2024Significance\nQM/MM is a powerful computational method used to model a critical, small portion of a\ncomplex molecular system—such as a protein’s active site–using quantum mechanics, while\ntreating the surrounding environment with classical force fields. While QM/MM has ad-\nvanced our understanding of enzymes and biological systems, it often struggles with accu-\nracy, even when the QM and MM regions are not covalently bonded. A notable challenge is\nthe slow convergence of system-environment interaction energies as the size of the QM region\nincreases. This work demonstrates that incorporating quantum mechanics in the description\nof the MM subsystem leads to dramatically improved models. By assigning the MM subsys-\ntem a physically meaningful electron density, and using ab-initio density functionals for the\nQM-MM interaction (accounting for exchange, correlation, and Pauli repulsion), chemical\naccuracy in QM/MM models of aqueous solutions is achieved for the first time.\nIntroduction\nQM/MM (standing for quantum mechanics/molecular mechanics) has revolutionized com-\nputational biochemistry.1Since the pioneering work of Honig and Karplus,2the combination\nof a quantum mechanical (QM) description for a subsystem with a classical point-charge de-\nscription of its environment has led to major breakthroughs in fields such as enzymatics,3,4\ndrug development,5,6and materials design.7Since its conception, methods handling the QM\nand MM subsystems have dramatically evolved. Today’s MM force fields can integrate data-\ndriven potentials,8polarizable models,9–15and even machine learning techniques.16,17QM\nmethods have also evolved dramatically, from DFT methods to wavefunction theory methods\nroutinely used in conjunction with QM/MM.18\nThe nature of the QM-MM interaction has also evolved. Initially, these were handled\nmechanically,3with Coulomb interactions calculated a posteriori , influencing only the forces\nand total energy, but without affecting the QM wavefunction or density. The advent of\n2electrostatic embedding improved accuracy by incorporating MM partial charges directly\ninto the QM Hamiltonian.19Ultimately, mutual QM-MM polarization was achieved using\npolarizable force fields,9,13a concept anticipated in early QM/MM work.20\nThe computational cost of QM/MM simulations is greatly reduced compared to fully\nquantum mechanical treatments. However, incorporating QM / polarizable-MM interac-\ntions in an efficient manner remains challenging. Methods based on judicious partitioning\nof the induction response have demonstrated excellent scalability.14,21Additionally, algorith-\nmic advances have been supported by steady progress in software development.17,22–28To\nextend QM/MM simulations to condensed phases, periodic boundary conditions (PBC) have\nbeen implemented. Ewald summation techniques are commonly used, and adaptations for\nmolecular condensed phases29–32and material systems26,28,33,34are now widely available.\nHow accurate are QM/MM models? A common way to address this question is to evaluate\nthe convergence of the results with respect to the size of the QM subsystem. Unfortunately,\ngenerally such a convergence is slow. Protein environments, for example, are exceptionally\ncomplex, and the search for effective ways to include relevant protein regions in QM/MM\nsimulations continues.35–38Particularly challenging has been capturing charge transfer inter-\nactions on larger scales.37,39\nA slow convergence of the QM/MM setup has also affected those systems where partition-\ning in QM and MM subsystems involves no bond breaking. For example, water solvation.40\nIronically, independent QM-only or MM-only treatments of liquid water can provide ac-\ncurate results, but their combination in QM/MM workflows results in an overall reduced\naccuracy.26,41Accurately modeling aqueous environments with QM/MM is essential due to\nthe need to consider large water environments to properly account for the static and dynamic\nresponses at water-material interfaces.42,43Therefore, representing these polarization effects\nin water bulk, which can extend for several nanometers, is crucial for capturing significant\neffects on the energetics of solvated species.44,45\nThe culprit is the difficulty to accurately capture QM-MM interactions with a compu-\n3tationally efficient method. The MM subsystem is typically described using methods that\nlargely (or completely) neglect its electronic structure. Point charges or, at times, point\npolarizable dipoles do not faithfully represent any electronic structure! The polarizable em-\nbedding method46tackles this problem by dividing the MM subsystem into two regions:\none near the QM subsystem is assigned a QM density derived from isolated fragment cal-\nculations, while the remaining MM atoms are treated using conventional point charge or\ndipole models. This embedding approach improves the accuracy of the QM Hamiltonian\nby capturing both electrostatic and non-electrostatic interactions, leading to better results\nthan traditional QM/MM setups.47Similar methods, such as QM/ESP,48QM/GEM,49and\nQXD,50as well as approaches in density embedding51and many-body expansions,52further\nexplore these concepts. While attempts to account for the purely quantum mechanical Pauli\nrepulsion within QM/MM have yielded mixed outcomes,53some methods address this by\nparametrizing the mechanical embedding interaction energy without introducing new terms\nin the QM Hamiltonian.54–56\nThus, our approach in this work is to treat QM and MM subsystems on a more equal\nbasis, aiming to reduce the impact of an imbalanced QM-MM interface and an imbal-\nanced treatment of the internal energy of QM and MM subsystems. We propose “density-\nfunctionalizing” the MM subsystem, assigning it an electron density such that it can be\nhandled like an electronic subsystem within the rigorous framework of subsystem DFT.57–61\nThis standardization of QM and MM subsystems allows for the use of first-principles density\nfunctionals for evaluating the QM-MM interaction, inherently capturing all relevant physical\neffects, such as exchange, correlation, Pauli repulsion, electrostatics, and charge penetration.\nThe next section details the theoretical framework for this density-functionalized QM/MM\napproach, with additional, less critical details provided in the supplementary materials.62\n4A density-functionalization of QM/MM\nThe central idea is to assign an electron density to both the QM subsystem, ρQM(r), and\nto the MM subsystem, ρMM(r), with the total electron density given by their sum and the\nenergy functional borrowed from rigorous subsystem DFT57–59(sDFT, hereafter),\nρ(r) =ρQM(r) +ρMM(r), (1)\nE[ρQM, ρMM] =E[ρQM] +E[ρMM] +Enad[ρQM, ρMM]. (2)\nAlthough formally the electronic energy is strictly a density functional, in practice, the\nexternal potential (electron-nuclear attraction) is known ahead of time and is thus specified\nfor the QM subsystem, vQM(r), and for the MM subsystem, vMM(r), such that the additive\npart of the energy is given by (disregarding for the time being the nuclear-nuclear repulsion)\nE[ρQM] =Ts[ρQM] +EH[ρQM] +Exc[ρQM] +Z\nvQM(r)ρQM(r)dr, (3)\nE[ρMM] =Ts[ρMM] +EH[ρMM] +Exc[ρMM] +Z\nvMM(r)ρMM(r)dr, (4)\nwhere Ts,EHandExcare the noninteracting kinetic energy, the classical electron-electron\nrepulsion (Hartree) and the exchange-correlation functionals, respectively. The nonadditive\nenergy is thus given by\nEnad[ρQM, ρMM] =Tnad\ns[ρQM, ρMM] +Enad\nxc[ρQM, ρMM]+ (5)\n+ZρQM(r)ρMM(r)\n|r−r′|drdr′+Z\nρMM(r)vQM(r)dr+Z\nρQM(r)vMM(r)dr\nwhere Tnad\ns[ρQM, ρMM] =Ts[ρQM+ρMM]−Ts[ρQM]−Ts[ρMM] and equivalently for Enad\nxc.\nThe equations above can be exploited for a variational minimization of the energy func-\ntional with respect to variations in both ρQMandρMM, provided that suitable approxima-\ntions for the relevant density functionals are available. When both subsystems are treated\n5at the Kohn-Sham DFT level, this approach yields sDFT, which was found to be accurate\nin the limit of weak inter-subsystem interactions. This is the case for systems such as wa-\nter molecules in liquid water63or CO 2molecules in fluid CO 2.64In fact, sub-1 kcal/mol\naccuracy is now routinely achieved in sDFT calculations either with Kohn-Sham subsys-\ntems,65–67orbital-free subsystems,68and proper multiscale simulations.69–72Inter-subsystem\ninteractions involving hydrogen bonds, are the focus of this work and are particularly well\ndescribed by the nonadditive PBE exchange-correlation and revAPBEk nonadditive kinetic\nenergy functionals65(and in general many GGA nonadditive functionals73).\nIn a QM/MM framework, Eq. (4) is usually replaced by a classical force-field expression,\nwhich involves electrostatic interactions between atom-centered point charges and possi-\nbly atom-centered polarizable dipoles, as well as (typically empirical) expressions for short\nrange dispersion-repulsion interactions and bonded terms. In common implementations of\nQM/MM approaches, the tool associated with the classical component is responsible for the\ncalculation of this energy term. However, the electrostatic multipoles present in the MM\nforce-field are also involved in the electrostatic terms of the QM-MM interaction energy term\nin Eq. (5). Usually, ad-hoc corrections to describe short-range dispersion-repulsion interac-\ntions and avoid unphysical behaviors when the QM and MM subsystems are too close are\nintroduced to approximate the first two terms of Eq. (5). Once the analytic dependence\nof Eq. (2) on the atomic positions of the MM subsystem is defined, the functional deriva-\ntive of Eq. (2) with respect to ρQM(r) allows the optimization of the QM subsystem via a\nself-consistent field (SCF) approach.\nPoint-charges and point-dipoles introduced in the definition of the MM part of the sys-\ntem can be tuned to fit empirical results for the MM system, or they can be optimized to\nreproduce properties connected to the electronic density of the MM components computed\nfrom first principles (e.g., binding energies or the behavior of the electrostatic potential).\nBecause the permanent charges in MM force fields are independent of the geometry of the\nsystem and of its surrounding environment, atomic polarizabilities may be included in the\n6force field in order to capture the system’s electrostatic response to external fields. The\nresulting polarizable force fields will, therefore, respond to the non-additive term in Eq. (5)\nas it contributes to the induced dipoles in the MM subsystem. This results in mutually\npolarized QM and MM subsystems.\nThe typical approximations in the above approach lead to significant inaccuracies when\nthe boundary between QM and MM regions varies systematically. Drawing from existing\nQM/MM methods that account for electron densities in the MM subsystem46,74and the\nsuccesses of the sDFT framework, we hypothesize that a QM/MM framework based on Eqs.\n(2–5) can accurately model solute-solvent systems. This extends to weakly interacting QM\nand MM subsystems, provided consistent forward and backward mappings between first-\nprinciples electronic densities and force field multipoles are established.\nFor the forward mapping between electronic-structure calculations and accurate classi-\ncal electrostatics, the many-body polarizable approach by Paesani and collaborators showed\nthat it is possible to effectively describe statistical properties of bulk systems by carefully\nparametrizing a classical force-field on a large database of accurate few-body first-principles\nsimulations.75,76While the initial developments of MB-Pol focused on high-accuracy coupled-\ncluster simulations of water dimers and trimers, the approach can be applied to DFT-based\ncalculations77giving rise to, e.g., the MB-PBE force field. The resulting force-fields describe\nelectrostatic interactions in terms of atomic charges and polarizabilities. As in similar ap-\nproaches in the literature, short-range corrections are introduced to avoid self-polarization\nand the unphysical divergence of the induced dipoles when different polarizable systems are\ntoo close to each other. In this work, we hypothesize that using an MM subsystem whose\nelectrostatic interactions are fully consistent with the level of theory of the QM component\nwill allow the seamless convergence of QM-MM calculations as the boundary between the\ntwo regions is varied.\nFor the backward mapping between the classical force-field used in the MM region and\nan effective electronic density to use in the density functionalized QM-MM interaction term,\n7we introduce the following approach. We treat each atomic nuclei and core electrons using\npseudopotentials. To keep the approach computationally efficient for large MM subsys-\ntems, we use the local part of the ultrasoft pseudopotentials from Garrity and Vanderbilt\n(GBRV),78which are designed for fast, high-throughput simulations that require low plane\nwave cutoffs. This assignment can be efficiently handled in a computationally linear scaling\nmanner using the particle-mesh Ewald method.79For the valence electrons, we convert the\npoint-like charge multipoles computed and used by the classical force-field into a smooth\nelectronic charge density. Namely, for each atom i, the valence electron density is rep-\nresented by a Gaussian centered at the ion’s position, Ri, with an adjustable width σi:\nρqi(r) = (Ni−qi)gσi(r−Ri), where gσiis a normalized Gaussian and the prefactor is crucial\nfor accurately representing the ion’s permanent charges, qi, while accounting for the isolated\natom’s number of valence electrons, Ni. If the force-field involves higher multipoles in the\ndescription of its electrostatic interactions, they can be included in the reconstructed elec-\ntron density by using derivatives of the normalized Gaussian. In particular, we can map\na point-like dipole into a corresponding smooth density using the gradient of a Gaussian\nfunction as ρµj(r) =−⃗ µj·⃗∇gσj(r−Rj), where ⃗ µjis the induced dipole at the dipole site j.\nSimilarly, higher-order multipoles can be mapped using higher-order derivatives. The total\nvalence electron density becomes\nρMM(r) =X\ni∈MM chargesρqi(r) +X\nj∈MM dipolesρµj(r). (6)\nWe stress that the proposed formulation relies on a set of element-specific widths (the σi)\nthat can significantly affect the final shape of the reconstructed electronic density (both\npermanent charges and polarization density due to the induced dipoles).\nFor the forward mapping, we hypothesize that using the Gaussian widths that provide\nthe best match between QM/MM vs QM/QM (sDFT) interaction energies will allow for\nthe accurate description of the mutual polarization effects and the seamless convergence of\n8QM/MM calculations as a function of an increasing size of the QM subsystem.\nThe functional derivatives of the non-additive interaction energy with respect to the QM\nor MM subsystem densities yields the embedding potentials\nvQM\nemb(r) =δEnad[ρQM, ρMM]\nδρQM(r)=vMM(r) +Z\ndr′ρMM(r′)\n|r−r′|+δTnad\ns\nδρQM(r)+δEnad\nxc\nδρQM(r), (7)\nvMM\nemb(r) =δEnad[ρQM, ρMM]\nδρMM(r)=vQM(r) +Z\ndr′ρQM(r′)\n|r−r′|+δTnad\ns\nδρMM(r)+δEnad\nxc\nδρMM(r), (8)\nthat can be used to optimize the QM or MM degrees of freedom. In particular, Eq. (8) enters\nthe Hamiltonian of the QM subsystem(s) at each SCF step and it is used for the calculation\nof the ground state QM electronic densities as well as for the optimization of QM atomic\npositions. The sDFT framework and the implementation of this approach in the eDFTpy\nsoftware80allows for the coupling of the QM/MM embedding potential into multiple QM\nsubsystems.\nEq. (7) instead can be used by the MM engine to compute the QM effects on the induced\ndipoles and on the interatomic forces. For the former, the gradient of the MM embedding\npotential needs to be added to the classical electric field used to compute induced dipoles.\nWhile all the terms in Eq. (7) would ideally be included in the embedding field that polarizes\nthe MM component, the current definition of atomic polarizabilities within polarizable force\nfields is only meaningful for a classical description of long-range polarization effects. Thus, in\nthe current implementation, we only keep the first two terms, which are related to classical\nelectrostatic interactions, and we neglect the effect of the non-additive kinetic and exchange-\ncorrelation terms, which are more relevant for short-range interactions.\nThe evaluation of the QM additive energy in (3) can utilize the sDFT implementation\nof eDFTpy with either a single QM subsystem or multiple QM subsystems. When NSQM\nsubsystems are involved, the QM electron density is represented as the sum of contributions\nfrom each subsystem, and the QM energy is decomposed into additive and nonadditive terms,\n9Figure 1: Workflow of the QM/MM method with emphasis on the software implementation.\nSee details in section .\nfollowing the structure of (2). Namely,\nρQM(r) =NSX\nI=1ρI(r), (9)\nE[ρQM] =NSX\nI=1E[ρI] +Enad[{ρI}]. (10)\nIn the results Section , we will refer to a one-subsystem treatment of the QM region as\nfragmentation type 1 (or Frag. 1) while a many-subsystem treatment as fragmentation type\n2 (or Frag. 2).\nDetails of the implementation\nWe now discuss the details of the implementation of the QM/MM algorithm in the eDFTpy\nsoftware.80Figure 1 illustrates the QM/MM workflow of the SCF cycle in the presence of a\nMM subsystem. It begins with initial guesses for the MM and QM density and wavefunctions.\nIn eDFTpy, we use QEpy81as QM solver (a python implementation of Quantum ESPRESSO\n7.282) and a python interface to MBX as the MM solver.83The initial guess density for the\n10QM subsystem is usually taken from the sum of atomic densities from the pseudopotential\nfiles. For the MM subsystem, a valence electron density consistent with the value of the\npermanent charges (which are fixed, independent of geometry) is used.\neDFTpy then directs QEpy, the QM solver, to solve for the electronic structure of the\nQM system. This is done either by a single QEpy instance when a single QM subsystem\nis considered, or by multiple QEpy instances when several QM subsystems are considered.\nThe QM subsystems require the computation of QM-in-QM embedding potentials which are\nhandled also by eDFTpy as indicated by the blue arrows connecting the QEpy solvers to\nthe eDFTpy circle in the figure. The QM electrostatic field formally given by the negative\ngradient of the MM embedding potential in Eq. (7), −⃗∇vMM\nemb(r) is then represented on the\nMM polarizable dipole sites. For large systems, representing the QM electric field on the\nMM sites is a task of non-negligible computational complexity.33,34,84,85The QM electric field\nis then represented on the grid point closest to each of the MM polarizable dipole sites. This\nis accurate enough given the exceptional smoothness of the QM field in the MM region34\nand saves the inconvenient step of splining the field on the exact position of the ions. Spline\nwould require an MPIGATHER operation which carries a high wall-time cost. In eDFTpy, the\nMM cell is spanned by a grid fine enough to properly represent the ionic pseudopotentials\ncentered on each QM ion and MM site. In our simulations, we use a 100 Ha cutoff for this\ngrid, which is fine enough to produce real-space grid points spaced by about 0.23 a0.\nOnce the electric field is represented on the MM sites, the MM solver is tasked with solving\nthe Coulomb problem in the MM cell to yield the MM polarizable dipoles. The MM density\nis then built using Eq. (6). Having the MM density and the density of all QM subsystems\nallows eDFTpy to compute the required embedding potentials for each subsystem, including\nthe MM subsystem. The SCF cycles then continue until convergence is achieved, which is\ncalibrated on the convergence of the QM density. At convergence, QM density and MM\ndipoles are fully mutually polarized.\nIn the eDFTpy implementation we take full advantage of plane wave reduction techniques\n11that were developed for sDFT.68,69,86–88Specifically, MM and QM subsystems are represented\nby different simulation cells, grids and thus plane wave basis sets. The QM simulation cell is\nsmaller compared to the physical cell which coincides with the MM cell. Coulomb fields and\nother long-ranged energy functionals are evaluated on the large, physical cell. Employing\nsuch a multi-cell/grid approach is crucial in the context of QM/MM simulations as the MM\nsubsystem is usually dramatically more extended than any of the QM subsystems. In the\nsupplementary materials62we further discuss our parallelization strategy.\nRO-O\nFigure 2: Water dimer energy curve (structure shown) for O–O distances ranging from 2.3\nto 7.7 ˚A. The black line represents the QM/QM result, where both the donor and acceptor\nmonomers are treated at the QM level. The shaded area represents the deviation of the\nQM/MM result from QM/QM. Green and blue lines correspond to the QM hydrogen bond\ndonor (QM/MM) and acceptor (MM/QM), respectively. The inset shows a correlation plot\nof QM/MM and MM/QM interaction energies. Yellow markers represent geometries in the\nrepulsive region of the curve ( RO-O<2.9˚A), while red markers correspond to those in the\nattractive region ( RO-O>2.9˚A).\nThe current implementation also features analytic energy gradients for the atoms in the\nQM region. In the supplementary materials we devote a section to the implementation of\nthe forces and results are shown in Tables ??and??.\n12Computational Details\nPseudopotentials, Density Functionals and Plane Wave Cutoffs\nGBRV pseudopotentials78are used for all elements considered of both the QM and MM\nsubsystems. The PBE exchange-correlation functional89and the revAPBEk noninteracting\nkinetic energy functional90are employed for approximating additive Excand nonadditive\nExcandTsfunctionals. All calculations include Grimme’s D3 correction.91We choose plane\nwave basis sets for the QM subsystems with a cutoff energy of 20 Ha for wavefunctions\nand 200 Ha for charge density and potential unless otherwise stated (see supplementary\nTable ??). The energy convergence threshold for the SCF was set to 10−8Ha/atom. The\nBrillouin zone was sampled by a 5 ×5×1 k-point mesh for MoS 2and the Γ point for all\nother calculations. MM calculations were conducted using the MBX package83using the\nMB-PBE and MB-Pol water models, which were developed to quantitatively reproduce PBE\nor CCSD(T) water,77,92respectively.\nAll inputs/output files, Jupyter notebooks needed to analyze the data and reproduce\nthe figures in this work, as well as links to tagged versions of the software (MBX, eDFTpy,\nQEpy, and DFTpy) used for the simulations, are available as reported in the supplementary\nmaterials.62\nParameters Defining the MM Density\nAs described in the sections above, the proposed framework relies on the conversion of\nclassical permanent charges and polarizable dipole sites into a smooth electronic density.\nFor each atomic charge and polarizable dipole, this involves the fit of the width, σ, of the\ncorresponding normalized Gaussian functions that contribute to the expansion in Eq. (6).\nIn our applications to solvated systems, MM sites only involve oxygen and hydrogen atoms,\nfor a total of 4 parameters that need to be fitted.\nWe also considered an additional MM-induced dipole self-energy correction. Although\n13the induced point-dipole self-energy is given by1\n2µ2α−1,93where αis the isotropic dipole\npolarizability, we recognize that the dipoles considered in our work are not point dipoles,\ne.g., their charge density overlaps with the QM density at the QM/MM interface. Thus, we\nadded an additional term to the self-energy for each site equal to kSE\ni|⃗ µ−⃗ µ′|2, where ⃗ µ′is\nthe induced dipole at the same site when only the MM subsystem is considered, and kSE\ni\nare element-dependent proportionality constants. Additional details about this correction\nand about how the permanent charge density was generated for the MB-PBE and MB-Pol\nforce fields (which use the so-called M-site) are available in the supplementary materials\ndocument.62\nThe parameters defining the MM density were fitted so as to reproduce the QM-QM\ninteraction energies for a single water molecule in bulk water. Ten snapshots of 64-water\nmolecule cubic systems were taken from Ref. 94. These provided 640 water-bulk interaction\nenergies. More details about this system will be given in the results section. The final values\nof the parameters for both MB-PBE and MB-Pol force fields are listed in Table ??.\nThe use of bulk simulations as a reference for the parametrization of the density func-\ntionalization approach provides a robust and general strategy that reduces the need for\napplication-specific benchmarks. Results on small water clusters and solvation effects on\nmolecules and materials (reported in the following) highlight the transferability of the ob-\ntained parameters.\nResults and Discussion\nWater Dimer\nWe start by comparing the QM/MM potential energy curves shown in Figure 2 and the\npolarization density depicted in Figure 3 for water dimers. The dimer structures, sourced\nfrom Ref. 95, were placed in a 20- ˚A cubic simulation cell and evaluated against benchmark\nQM/QM simulations performed using sDFT.\n14QM/QM\nQM/MM MM/QM\nH\nH\nOOH\nHOO\nHH\nOOH\nH\nOOMM/MM(a)\n(c) (d)\n(b)Figure 3: Polarization density, defined as ρ(r)−ρiso(r), where ρisois the sum of the elec-\ntron densities of the isolated water monomers, for the water dimer at the equilibrium O–O\ndistance. In each panel, we present isosurfaces (top) and contour plots (bottom) generated\nwith a cutoff of ±0.0007 e·a−3\n0.\nThe key aspect of this system lies in its asymmetry, as one monomer is a hydrogen\nbond donor, and the other is an acceptor. Even though both QM and MM monomers are\nmodeled by PBE (the MM subsystem is described by the MB-PBE model), the nature of\nthe QM-MM interface is dramatically different whether one considers a QM hydrogen bond\ndonor (QM/MM) or acceptor (MM/QM). Despite this, the curves are remarkably similar.\nThe QM/MM and MM/QM minima (at 2.90 ˚A O–O distance) are less than 0.15 kcal/mol\naway from each other, and both deviate from the reference by a similar measure. These\nresults show that the QM/MM interface is extremely well characterized by the nonadditive\nfunctionals. Crucially, the repulsive part of the curve is also well reproduced. Our ∼0.2\nkcal/mol error compares well with the ∼0.6 kcal/mol error for the dimer reported in Ref. 41\nfor their QM/MM (AMOEBA) method.\n15In the inset of Figure 2, we report the correlation between the interaction energies of the\nQM/MM and MM/QM systems, showing that they are in extremely good agreement. The\ninteraction energies in the attractive part of the curve follow the ideal trend, i.e., the points\nsit on the diagonal line. However, those in the repulsive part (yellow color coded markers)\nshow a slightly deviated trend. A behavior indicative of an asymmetry in accounting for\ncharge penetration effects of the H QM-OMMvs H MM-OQM. To ensure our results are not\naffected by possible artifacts due to the use of PBCs, we recalculated the interaction energy\nminima in a larger simulation cell with lattice constant a= 50 ˚A finding a shift of less than\n10−3kcal/mol.\nFigure 3 shows the polarization density (defined in the caption) of the water dimer system.\nIt is clear that the MM polarization is only qualitatively similar to the QM polarization.\nSpecifically, comparing the QM/QM (panel a) with the MM/MM (panel b) shows that the\nlatter misses several potentially important details near the ion’s core and along the O–O line.\nThese are well-known deficiencies in the electrostatic response of dipole-only polarizable force\nfields.96,97Interestingly, the QM/MM treatment improves the polarization of both monomers.\nPanels (c) and (d) show that the MM molecule polarization gains features that are prominent\nin the QM response of that monomer but that are absent (or weakly present) in the MM/MM\ncase. This shows that the handling of the QM/MM interface by our method is accurate not\nonly by the interaction energy measure (recall Figures 2) but also by the much more stringent\ntest of subsystem mutual polarization.\nWater Hexamer\nHexamer water structures play a crucial role in quantum chemistry due to their complex\nhydrogen-bond topologies. Accurately predicting their relative energies is often seen as a\nbenchmark for a model’s ability to represent water across its various stable phases.98Here,\nfollowing Ref. 8, we focus on the most stable hexamer, the prism hexamer, to examine the\neffect of the QM-MM boundary. In the prism hexamer all water monomers act as both\n16hydrogen bond donors and acceptors, with either 1/2 or 2/1 accepted/donated hydrogen\nbonds.\nThe root mean square errors (RMSEs) of the computed interaction energies defined as\nthe energy of the hexamer minus the energy of the 6 isolated water molecules are collected\nin Figures ??and??for the MM treated with MB-PBE and MB-Pol, respectively. When\nmultiple water molecules are treated at the QM level, the sDFT framework allows flexibility\nin how the QM waters are grouped: they can be combined into a single subsystem (Frag. 1\nin the figure) or divided into separate subsystems (Frag. 2). For each partition type with k\nQM or MM water molecules, there are\06\nk\npossible members of the partition (i.e., ways to\nsplit the hexamer into QM and MM subsystems).\nIdeally, all members of each partition should yield the same interaction energy. Therefore,\na larger RMSE for the predicted interaction energy indicates a lower accuracy of the method.\nRecognizing that no practical fragmentation method is perfect, we find a relation between\nthe RMSE for the k-th partition ( σQM/MM(k)) and the square root of the number of members\nin the partition99(q\06\nk\n). This relationship is confirmed by R2values of 0.99 for all QM/MM\nand fragmentation methods considered (see Figure ??). The slope of this linear relationship\nis proportional to the average error per QM/MM boundary in the partitions (error = slope\n·pπ\n2), yielding a predicted error per boundary ranging between 0.2 and 0.3 kcal/mol for the\nmethods considered. This error is consistent with the results for water dimers and, as we\nwill see in the next section, also aligns with the RMSEs for the pentamer clusters extracted\nfrom bulk liquid structures.\nBulk and First Solvation Shell Water Environment\nTo further assess our method, we consider the dipole moment and the molecule-environment\ninteraction energy of water molecules embedded in an MM environment of bulk liquid water.\nThe benchmark is once again sDFT. Dipole moments of embedded molecules are accessible\nin sDFT, calculated with the subsystem electron density. This procedure was found to be\n17accurate for a variety of embedded molecular species.57,94,100,101We consider 10 snapshots of\nan ab-initio dynamics trajectory of 64 independent water molecules in a cubic cell of lattice\nconstant 12.42 ˚A that was presented elsewhere63,94(also available in the supplementary\nmaterials62). We use the nomenclature n/m to denote a simulation where nmolecules are\ntreated at the QM level and mare treated at the MM level. In all cases, the reported quantity\nis the interaction of a single water molecule with the environment. For example, 1/63 means\nthere are 63 MM water molecules and one QM water, for a total of 64 water molecules.\nWe use sDFT to generate benchmark values for the water-environment interaction energy.\nWithin a sDFT framework, one may treat all 63 environment molecules as a single subsystem\nor as 63 coupled subsystems (for the 1/4 system we only consider 4 environment water\nmolecules). Owing to the accuracy of sDFT for bulk water simulations,45,63we employed\nboth approaches, which resulted in very similar trends, as reported in Figure ??of the\nsupplementary materials. For the discussion in the following, we consider the benchmark\nwhere all 63 molecules in the environment are grouped in a single subsystem. Leveraging\nthe available bulk configurations, inspired by Ref. 41, we also considered the performance\nof our QM-MM approach on “first shell” structures, where each water molecule of the bulk\nis embedded only by the nearest 4 water molecules of the environment, giving rise to a\ncollection of water pentamer structures (denoted by 1/4). We also test our QM/MM scheme\non a partition “minimal solvation” where each water molecule and the nearest 4 water\nmolecules of the environment are included in the QM subsystem and the remaining 59 water\nmolecules are kept in the MM subsystem (system 5/59). Because in each snapshot there\nare 64 water molecules and there are 10 snapshots, 640 total structures / data points are\navailable.\nPanels (a) and (b) of Figure 4 show that the interaction energy between water molecules\nand their environment in liquid water ranges from -35 to -7 kcal/mol for the bulk calculations\nand from -20 to -1 kcal/mol for the first shell calculations. Such energy scales are in line\nwith comparable calculations in the literature.41As indicated in the figure, the root mean\n18QM/MM (1/63) QM/MM (1/4) QM/MM (5/59)Figure 4: Panels (a), (b) and (c): correlation plots of the interaction energy (in kcal/mol) of\na single water molecule with its environment in a model of liquid water. (a) Bulk: QM/MM\nwith 1 QM water molecule and 63 MM water molecules. (b) First shell: 1 QM water\nmolecule and 4 MM water molecules (only the first solvation shell). (c) Minimal solvation: 5\nQM water molecules and 59 MM water molecules. Panels (d), (e), and (f): correlation plots\nof the dipole moment length of the embedded molecule (in Debye) for the same systems as\nfor panels (a–c).\n19square errors (RMSEs) of the QM/MM interaction energy compared to the QM/QM ones\nare 1.32 kcal/mol for the bulk and 1.05 kcal/mol for the first shell calculations. The minimal\nsolvation setup improves upon the bulk with an RMSE of 1.11 kcal/mol. The RMSE of\nthe first shell simulations compares well with 1.4 kcal/mol from a similar simulation from\nRef. 41 where MM was treated with the AMOEBA force field. To our knowledge, a similar\ncomparison for the bulk or minimal solvation results is not available.\nFigure 5: Polarization density (defined as the difference of the embedded and isolated\nmolecular electron density) of an embedded water molecule employing the methods indicated\nin the figure. Top panels: single water molecule polarization. Bottom panels: environment\npolarization. The isosurface value is set to ±0.0025 e ·a−3\n0.\nSuch RMSEs are also consistent with the accuracy of the hexamer structure discussed\nbefore. However, ∼1 kcal/mol accuracy for bulk systems is even more impressive. In the\nhexamer, the interaction energies (mbpol) average about 8.00 kcal/mol per water molecule.\nIn the bulk water, the QM–QM interaction energy averages to a much larger value ( ∼22.42\nkcal/mol) due to a stronger polarization. In fact, the ∼1 kcal/mol accuracy leads us to\nconclude that the QM-MM mutual polarization predicted by the QM/MM simulation in\nbulk and minimal solvation setups is well represented. As we can see in Figure 5, both\n20the polarization of the embedded water molecule (see panels a, b, and c) as well as of the\nenvironment (see panels e, f, and g) are fairly well represented by the QM/MM calculations.\nAn interesting aspect of the MM polarization in panels (e) and (d) of Figure 5 is that,\nin comparison to the QM/QM polarization they only feature a small component from the\nsecond solvation shell. An explanation for this effect is the fact that polarizable force fields\ntypically employ slightly damped atomic dipole polarizabilities compared to the reference\nQM value.102,103The damping is crucial to fend off overpolarization, which in our framework\nwould stems from the neglect of the nonadditive components of the embedding potentials,\nsee Eq. (7). In follow-up work, it will be interesting to analyze the effect of these additional\nterms on the MM polarization and the chosen values of the atomic dipole polarizabilities.\nPanels (d) (e) and (f) of Figure 4 present the dipole lengths of the central, embedded\nwater molecule. These range from 1.6 D to 4.5 D for both 1/63 and 5/59 bulk simulations,\nand from 1.3 D to 3.5 D for the 1/4 first-shell calculations. Generally, we notice that the\ndipole lengths are underestimated in the QM/MM treatment compared to the reference\nQM/QM. The QM/MM dipoles, however, correlate very well with the reference QM/QM\n(sDFT) dipoles showing Pearson’s correlation coefficients above 0.9. We also computed an\nRMSE for the dipoles of the 1/4 calculations of 0.29 D which compare well with the 0.62 D\nof Ref. 41. The dipole results and the results from the interaction energies sustain our claim\nthat our method is the most accurate QM/MM result for liquid water available to date.\nFigure 4 also shows (red diamonds) results labeled as “charge only,” which are from\nQM/MM simulations where the polarization of the MM subsystem is neglected (i.e., the\npolarizable dipoles are set to zero). While for the first shell systems the results are still\nacceptable (dipole correlation of 0.91, dipole RMSE of 0.42 D, and for the interaction energy\nof 1.73 kcal/mol), the results for the bulk system are qualitatively incorrect. In the bulk,\nthe RMSE for the interaction energy jumps to 7.33 kcal/mol. An unacceptable deviation is,\nhowever, in line with the expected accuracy of a typical electrostatic embedding QM/MM\nsimulation of condensed phases.104,105\n21When employing 63 coupled subsystems to represent the QM/QM benchmark, the inter-\naction energies and dipole moment correlations are consistent with what is presented above,\nsee supplementary Figure ??. We also note that MB-Pol provides us with a very accurate\nbenchmark for the interaction energies. We thus include a comparison of the computed\nQM/MM interaction energies for the 1/63 system against an MB-Pol reference in supple-\nmentary Figure ??.\nConvergence with respect to the QM size\nAn important test for QM/MM simulations of solvated species is the convergence with\nrespect to the number of water molecules included in the QM subsystem. As mentioned in\nthe introduction, having an accurate model for the QM-MM interface and employing an MM\nforce field that is consistent with the QM method (we use the MB-PBE force field) should\nallow us to showcase strong QM/MM convergence. The typical target is a ±2 kcal/mol from\nthe reference QM calculation.40In Figure 6, we present the interaction energies of glucose\n(left panel) and the [Pd(H 2O)4]2+aqua ion, counterbalanced by 2 Cl−ions (right panel),\nwith the water bulk environment as a function of the number of water molecules included\nin the QM subsystem. For glucose (a neutral molecule), the figure clearly shows that the\n±2 kcal/mol target is reached (in fact, a ±1 kcal/mol is achieved) already when only 14\nwater molecules are included in the QM subsystem. This amounts to including less than\nthe first solvation shell. Interestingly, the convergence for this system is much worse when\na charge-only MM model is used (i.e., as done before, we simply neglect the polarization\nof the MM subsystem) for which 26 QM water molecules are needed to reach convergence.\nFor PdCl 2, despite the presence of a doubly charged cation, we find an essentially identical\nbehavior with convergence being reached already with 13 QM water molecules. Conversely,\nthe charge only QM/MM method does not reach the ±2 kcal/mol goal even when 46 QM\nwater molecules are included. Therefore, we conclude that similar to the glucose system,\nincluding polarization in the MM subsystem dramatically improves the convergence of the\n22interaction energy with the size of the QM subsystem.\nOur results on the need to include polarization in the MM subsystem find justification\nin the fact that, for a condensed phase system, including the inductive response of the\nenvironment, is crucial to obtain a physical picture, particularly for charged solutes.41\nQMMM 14QM/193MM 26QM/181MM 49QM/158MM QM/QM(207QM)70\n60\n50\n40\n30\n20\nInteraction Energy (kcal/mol)\nQM/QM\npolarizable charge only\nQMMM 13QM/96MM 29QM/80MM 46QM/63MM QM/QM(109QM)420\n400\n380\n360\n340\n320\n300\nInteraction Energy (kcal/mol)\nQM/QM\npolarizable charge only\nFigure 6: Convergence of the glucose (left panel) and the [Pd(H 2O)4]2+aqua ion (coun-\nterbalanced by 2 Cl−ions, right panel) solute-water interaction energy with respect to the\nnumber of water molecules included in the QM subsystem. An orange bar representing the\nsDFT reference is labeled as QM/QM in each plot. The dot-dashed line marks ±2 kcal/mol,\nand the shade marks ±1 kcal/mol window from the sDFT reference.\nIn supplementary Figure ??, we also present the polarization density of glucose and\nits water environment, showing once again that the polarization of the QM/MM model\nreproduces fairly accurately the polarization of the reference QM/QM simulation.\nWet Surfaces\nIn the supplementary information document,62we also present a QM/MM calculation of a\nmonolayer MoS 2solvated by water, see Figures ??and??. The conclusions of that analysis\nare consistent with what has been presented so far. That is, QM/MM simulations reproduce\nwithin a reasonable error the QM/QM result for the interaction energy. For this system,\nwe record a QM/MM interaction energy of -0.11 kcal/mol ·˚A−2at the equilibrium distance\ncompared with a QM/QM reference of -0.23 kcal/mol ·˚A−2, and QM/MM polarization\ndensities very close to the QM/QM benchmark. The equilibrium water-MoS 2distance of 2.1\n23˚A is predicted by both QM/QM and QM/MM methods.\nConclusions\nWe introduced a novel QM/MM framework that incorporates density-functional theory\n(DFT) for the QM and the MM subsystems that leverages an orbital-free treatment for\nthe MM region and the QM-MM interaction. By assigning an electron density to the MM\nsubsystem and accurately capturing nonadditive interactions (such as exchange, correlation,\nCoulomb, and Pauli repulsion effects) our density-functionalized QM/MM approach achieves\nchemical accuracy in modeling complex solute-solvent systems. We validated the approach\nagainst a variety of water-based systems, including water clusters, bulk water, solvated ions,\nand a wet monolayer of MoS 2, demonstrating consistent accuracy and achieving unprece-\ndented fast convergence to chemical accuracy with respect to increasing size of the QM\nsubsystem. Reaching chemical accuracy with the proposed method requires only the inclu-\nsion of the first solvation shell in the QM region–a significant advancement over traditional\nQM/MM schemes.\nParticularly striking is the performance of our density functionalized QM/MM method\nfor H 2O in water. There we find that the excellent performance of the method for clusters\n(dimers, pentamers and hexamers) seamlessly translates to accurate models of bulk liquid\nwater. A prime example is given by the dipole of the solute molecule which we predict an\nRMSE with QM/MM of 0.29 D, or 12%, for both bulk and pentamers compared to 0.624 D\nfor pentamers from Ref. 41.\nOur results highlight the critical role of (1) employing ab-initio density functionals for\nthe QM-MM interactions instead of ad-hoc parametrizations; (2) properly accounting for\nmutual polarization at the QM-MM interface; and (3) employing MM force fields that are\nconsistent with the QM method employed (here we use MB-PBE for MM and DFT with the\nPBE exchange-correlation functional for QM). We found that following these three principles\n24significantly improves convergence with respect to the size of the QM region compared to\nstandard QM/MM methods. Our pilot simulations have showed that for both neutral and\ncharged solutes, the interaction energies reached the target accuracy of within ±2 kcal/mol\nusing a minimal QM region, with further refinement yielding sub-1 kcal/mol errors when\nmerely the first shell of solvent molecules is included in the QM subsystem. This level of\naccuracy, achieved even in bulk water systems, underscores the robustness of our method for\nsimulating condensed-phase environments.\nOverall, this work presents a significant step forward in extending the applicability of\nQM/MM methods to treat larger, more complex systems than typically approached by stan-\ndard QM methods while maintaining chemical accuracy. Future work will explore the impact\nof including beyond-Coulomb, ab-initio terms in the MM embedding potential, so that the\nMM dipole response can more closely resemble the true electronic response of the electrons\nin the MM subsystem. We plan to apply the density-functionalized QM/MM framework to\nchemical environments other than water, for example those provided by biomolecules and\nmaterials interfaces as well as non-aqueous solvents.\nAcknowledgements\nThis research was partially funded by the U.S. National Science Foundation grants No. CHE-\n2154760 (MP, JMB and XC), OAC-2321103 (MP, JMB and XC), OAC-2311260 (MR and\nFP) and CHE-2306929 and OAC-2321102 (OA). All computations were carried out on the\nPrice supercomputer of Rutgers University-Newark acquired through an NSF MRI grant\nNo. OAC-2117429 (MP) and managed by the Office of Advanced Research Computing at\nRutgers.\n25Authors contributions\nPavanello, Andreussi and Paesani conceived the work and co-wrote the manuscript. Pa-\nvanello managed the students and the project. Shao and Riera developed the software.\nMartinez B. and Chen carried out the simulations and co-wrote the manuscript.\nReferences\n(1) Karplus, M. Development of Multiscale Models for Complex Chemical Systems:\nFrom H+H 2to Biomolecules. Nobel Lecture, 2013; https://www.nobelprize.org/\nuploads/2018/06/karplus-lecture.pdf .\n(2) Honig, B.; Karplus, M. Implications of torsional potential of retinal isomers for visual\nexcitation. Nature 1971 ,229, 558–560.\n(3) Senn, H. M.; Thiel, W. QM/MM studies of enzymes. Current Opinion in Chemical\nBiology 2007 ,11, 182–187.\n(4) Kulik, H. J. Large-scale QM/MM free energy simulations of enzyme catalysis reveal\nthe influence of charge transfer. Phys. Chem. Chem. Phys. 2018 ,20, 20650–20660.\n(5) Raghavan, B.; Paulikat, M.; Ahmad, K.; Callea, L.; Rizzi, A.; Ippoliti, E.; Man-\ndelli, D.; Bonati, L.; De Vivo, M.; Carloni, P. Drug Design in the Exascale Era: A\nPerspective from Massively Parallel QM/MM Simulations. Journal of Chemical Infor-\nmation and Modeling 2023 ,63, 3647–3658, PMID: 37319347.\n(6) Lin, H.; Zhang, Y.; Pezeshki, S.; Duster, A. W.; Wang, B.; Wu, X.-P.; Zheng, S.-\nW.; Gagliardi, L.; Truhlar, D. G. QMMM 2023: A program for combined quantum\nmechanical and molecular mechanical modeling and simulations. Computer Physics\nCommunications 2024 ,295, 108987.\n26(7) Ma, C.; Martin-Samos, L.; Fabris, S.; Laio, A.; Piccinin, S. QMMMW: A wrapper for\nQM/MM simulations with Quantum ESPRESSO and LAMMPS. Computer Physics\nCommunications 2015 ,195, 191–198.\n(8) Lambros, E.; Lipparini, F.; Cisneros, G. A.; Paesani, F. A Many-Body, Fully Polariz-\nable Approach to QM/MM Simulations. Journal of Chemical Theory and Computation\n2020 ,16, 7462–7472.\n(9) Gresh, N.; Cisneros, G. A.; Darden, T. A.; Piquemal, J.-P. Anisotropic, Polarizable\nMolecular Mechanics Studies of Inter- and Intramolecular Interactions and Ligand-\nMacromolecule Complexes. A Bottom-Up Strategy. Journal of Chemical Theory and\nComputation 2007 ,3, 1960–1986.\n(10) Lu, Z.; Zhang, Y. Interfacing ab Initio Quantum Mechanical Method with Classical\nDrude Osillator Polarizable Model for Molecular Dynamics Simulation of Chemical\nReactions. Journal of Chemical Theory and Computation 2008 ,4, 1237–1248.\n(11) Ganguly, A.; Boulanger, E.; Thiel, W. Importance of MM Polarization in QM/MM\nStudies of Enzymatic Reactions: Assessment of the QM/MM Drude Oscillator Model.\nJournal of Chemical Theory and Computation 2017 ,13, 2954–2961.\n(12) Loco, D.; Lagard` ere, L.; Caprasecca, S.; Lipparini, F.; Mennucci, B.; Piquemal, J.-P.\nHybrid QM/MM Molecular Dynamics with AMOEBA Polarizable Embedding. Jour-\nnal of Chemical Theory and Computation 2017 ,13, 4025–4033.\n(13) Bondanza, M.; Nottoli, M.; Cupellini, L.; Lipparini, F.; Mennucci, B. Polarizable\nembedding QM/MM: the future gold standard for complex (bio)systems? Phys. Chem.\nChem. Phys. 2020 ,22, 14433–14448.\n(14) Reinholdt, P.; Kongsted, J.; Lipparini, F. Fast approximate but accurate QM/MM\ninteractions for polarizable embedding. J. Chem. Theory Comput. 2021 ,18, 344–356.\n27(15) Giovannini, T.; Puglisi, A.; Ambrosetti, M.; Cappelli, C. Polarizable QM/MM Ap-\nproach with Fluctuating Charges and Fluctuating Dipoles: The QM/FQF µModel.\nJournal of Chemical Theory and Computation 2019 ,15, 2233–2245, PMID: 30875213.\n(16) Zinovjev, K. Electrostatic embedding of machine learning potentials. J. Chem. Theory\nComput. 2023 ,19, 1888–1897.\n(17) Giese, T. J.; Zeng, J.; Lerew, L.; McCarthy, E.; Tao, Y.; Ekesan, S.; York, D. M.\nSoftware Infrastructure for Next-Generation QM/MM- ∆MLP Force Fields. J. Phys.\nChem. B 2024 ,\n(18) Ratcliff, L. E.; Mohr, S.; Huhs, G.; Deutsch, T.; Masella, M.; Genovese, L. Challenges\nin large scale quantum mechanical calculations. Wiley Interdisciplinary Reviews: Com-\nputational Molecular Science 2017 ,7, e1290.\n(19) Groenhof, G. Introduction to QM/MM simulations. Biomolecular simulations: meth-\nods and protocols 2013 , 43–66.\n(20) Warshel, A.; Levitt, M. Theoretical studies of enzymic reactions: dielectric, electro-\nstatic and steric stabilization of the carbonium ion in the reaction of lysozyme. Journal\nof molecular biology 1976 ,103, 227–249.\n(21) Lipparini, F. General linear scaling implementation of polarizable embedding schemes.\nJournal of Chemical Theory and Computation 2019 ,15, 4312–4317.\n(22) Bondanza, M.; Nottoli, T.; Nottoli, M.; Cupellini, L.; Lipparini, F.; Mennucci, B. The\nOpenMMPol library for polarizable QM/MM calculations of properties and dynamics.\nJ. Chem. Phys. 2024 ,160.\n(23) Olsen, J. M. H.; Bolnykh, V.; Meloni, S.; Ippoliti, E.; Bircher, M. P.; Carloni, P.;\nRothlisberger, U. MiMiC: a novel framework for multiscale modeling in computational\nchemistry. Journal of chemical theory and computation 2019 ,15, 3810–3823.\n28(24) Cruzeiro, V. W. D.; Manathunga, M.; Merz Jr, K. M.; G¨ otz, A. W. Open-source\nmulti-GPU-accelerated QM/MM simulations with AMBER and QUICK. Journal of\nChemical Information and Modeling 2021 ,61, 2109–2115.\n(25) Pederson, J. P.; McDaniel, J. G. PyDFT-QMMM: A modular, extensible software\nframework for DFT-based QM/MM molecular dynamics. J. Chem. Phys. 2024 ,161.\n(26) Dziedzic, J.; Mao, Y.; Shao, Y.; Ponder, J.; Head-Gordon, T.; Head-Gordon, M.;\nSkylaris, C.-K. TINKTEP: A fully self-consistent, mutually polarizable QM/MM ap-\nproach based on the AMOEBA force field. J. Chem. Phys. 2016 ,145.\n(27) Lu, Y.; Sen, K.; Yong, C.; Gunn, D. S.; Purton, J. A.; Guan, J.; Desmoutier, A.;\nNasir, J. A.; Zhang, X.; Zhu, L., et al. Multiscale QM/MM modelling of catalytic\nsystems with ChemShell. Phys. Chem. Chem. Phys. 2023 ,25, 21816–21835.\n(28) Dohn, A.; Jonsson, E. O.; Levi, G.; Mortensen, J. J.; Lopez-Acevedo, O.; Thyge-\nsen, K. S.; Jacobsen, K. W.; Ulstrup, J.; Henriksen, N. E.; Møller, K., et al. Grid-based\nprojector augmented wave (GPAW) implementation of quantum mechanics/molecular\nmechanics (QM/MM) electrostatic embedding and application to a solvated diplat-\ninum complex. J. Chem. Theory Comput. 2017 ,13, 6010–6022.\n(29) Nam, K.; Gao, J.; York, D. M. An Efficient Linear-Scaling Ewald Method for Long-\nRange Electrostatic Interactions in Combined QM/MM Calculations. J. Chem. Theory\nComput. 2005 ,1, 2–13, PMID: 26641110.\n(30) Holden, Z. C.; Richard, R. M.; Herbert, J. M. Periodic boundary conditions for\nQM/MM calculations: Ewald summation for extended Gaussian basis sets. J. Chem.\nPhys. 2013 ,139, 244108.\n(31) Bonfrate, S.; Ferr´ e, N.; Huix-Rotllant, M. Analytic Gradients for the Electrostatic\nEmbedding QM/MM Model in Periodic Boundary Conditions Using Particle-Mesh\n29Ewald Sums and Electrostatic Potential Fitted Charge Operators. J. Chem. Theory\nComput. 2024 ,20, 4338–4349.\n(32) Pederson, J. P.; McDaniel, J. G. DFT-based QM/MM with particle-mesh Ewald for\ndirect, long-range electrostatic embedding. J. Chem. Phys. 2022 ,156.\n(33) Laino, T.; Mohamed, F.; Laio, A.; Parrinello, M. An efficient linear-scaling electro-\nstatic coupling for treating periodic boundary conditions in QM/MM simulations. J.\nChem. Theory Comput. 2006 ,2, 1370–1378.\n(34) Laino, T.; Mohamed, F.; Laio, A.; Parrinello, M. An efficient real space multigrid\nQM/MM electrostatic coupling. J. Chem. Theory Comput. 2005 ,1, 1176–1184.\n(35) Brandt, F.; Jacob, C. R. Systematic QM region construction in QM/MM calculations\nbased on uncertainty quantification. J. Chem. Theory Comput. 2022 ,18, 2584–2596.\n(36) Pedraza-Gonz´ alez, L.; Mar´ ın, M. D. C.; Jorge, A. N.; Ruck, T. D.; Yang, X.; Valen-\ntini, A.; Olivucci, M.; De Vico, L. Web-ARM: a web-based interface for the automatic\nconstruction of QM/MM models of rhodopsins. J. Chem. Inf. Model. 2020 ,60, 1481–\n1493.\n(37) Kulik, H. J.; Zhang, J.; Klinman, J. P.; Mart´ ınez, T. J. How large should the QM\nregion be in QM/MM calculations? The case of catechol O-methyltransferase. J.\nPhys. Chem. B 2016 ,120, 11381–11394.\n(38) Karelina, M.; Kulik, H. J. Systematic quantum mechanical region determination in\nQM/MM simulation. J. Chem. Theory Comput. 2017 ,13, 563–576.\n(39) Kulik, H. J. Large-scale QM/MM free energy simulations of enzyme catalysis reveal\nthe influence of charge transfer. Phys. Chem. Chem. Phys. 2018 ,20, 20650–20660.\n(40) P´ erez-Barcia, ´A.; C´ ardenas, G.; Nogueira, J. J.; Mandado, M. Effect of the QM size,\n30basis set, and polarization on QM/MM interaction energy decomposition analysis. J.\nChem. Inf. Model. 2023 ,63, 882–897.\n(41) Dziedzic, J.; Head-Gordon, T.; Head-Gordon, M.; Skylaris, C.-K. Mutually polariz-\nable QM/MM model with in situ optimized localized basis functions. The Journal of\nChemical Physics 2019 ,150, 074103.\n(42) Moscato, D.; Mandelli, G.; Bondanza, M.; Lipparini, F.; Conte, R.; Mennucci, B.;\nCeotto, M. Unraveling Water Solvation Effects with Quantum Mechanics/Molecular\nMechanics Semiclassical Vibrational Spectroscopy: The Case of Thymidine. J. Am.\nChem. Soc. 2024 ,146, 8179–8188.\n(43) G´ omez, S.; Giovannini, T.; Cappelli, C. Multiple facets of modeling electronic absorp-\ntion spectra of systems in solution. ACS Physical Chemistry Au 2022 ,3, 1–16.\n(44) Coons, M. P.; Herbert, J. M. Quantum chemistry in arbitrary dielectric environments:\nTheory and implementation of nonequilibrium Poisson boundary conditions and ap-\nplication to compute vertical ionization energies at the air/water interface. Journal\nChem. Phys. 2018 ,148.\n(45) Martinez B, J. A.; Paetow, L.; Tolle, J.; Shao, X.; Ramos, P.; Neugebauer, J.; Pa-\nvanello, M. Which Physical Phenomena Determine the Ionization Potential of Liquid\nWater? J. Phys. Chem. B 2023 ,127, 5470–5480.\n(46) Olsen, J. M. H.; Steinmann, C.; Ruud, K.; Kongsted, J. Polarizable density embedding:\nA new QM/QM/MM-based computational strategy. J. Phys. Chem. A 2015 ,119,\n5344–5355.\n(47) Kvedaraviciute, S.; Carrasco-Busturia, D.; Møller, K. B.; Olsen, J. M. H. Polarizable\nEmbedding without Artificial Boundary Polarization. J. Chem. Theory Comput. 2023 ,\n19, 5122–5141.\n31(48) Viquez Rojas, C. I.; Slipchenko, L. V. Exchange repulsion in quantum mechani-\ncal/effective fragment potential excitation energies: Beyond polarizable embedding.\nJ. Chem. Theory Comput. 2020 ,16, 6408–6417.\n(49) Gokcan, H.; Kratz, E.; Darden, T. A.; Piquemal, J.-P.; Cisneros, G. A. QM/MM sim-\nulations with the Gaussian electrostatic model: A density-based polarizable potential.\nJ. Phys. Chem. Lett. 2018 ,9, 3062–3067.\n(50) Kuechler, E. R.; Giese, T. J.; York, D. M. Charge-dependent many-body exchange\nand dispersion interactions in combined QM/MM simulations. J. Chem. Phys. 2015 ,\n143.\n(51) Treß, R. S.; Hattig, C.; Hofener, S. Employing pseudopotentials to tackle excited-state\nelectron spill-out in frozen density embedding calculations. J. Chem. Theory Comput.\n2022 ,18, 1737–1747.\n(52) Gillan, M.; Alf` e, D.; Bygrave, P.; Taylor, C.; Manby, F. Energy benchmarks for water\nclusters and ice structures from an embedded many-body expansion. J. Chem. Phys.\n2013 ,139.\n(53) Ben-Nun, M.; Mart´ ınez, T. J. Direct evaluation of the Pauli repulsion energy using-\nclassical’wavefunctions in hybrid quantum/classical potential energy surfaces. Chem.\nPhys. Lett. 1998 ,290, 289–295.\n(54) Giovannini, T.; Lafiosca, P.; Cappelli, C. A General Route to Include Pauli Repulsion\nand Quantum Dispersion Effects in QM/MM Approaches. Journal of Chemical Theory\nand Computation 2017 ,13, 4854–4870, PMID: 28898079.\n(55) Bedrov, D.; Piquemal, J.-P.; Borodin, O.; MacKerell, A. D. J.; Roux, B.; Schr¨ oder, C.\nMolecular Dynamics Simulations of Ionic Liquids and Electrolytes Using Polarizable\nForce Fields. Chemical Reviews 2019 ,119, 7940–7995, PMID: 31141351.\n32(56) Hrˇ sak, D.; Olsen, J. M. H.; Kongsted, J. Optimization and transferability of non-\nelectrostatic repulsion in the polarizable density embedding model. Journal of compu-\ntational chemistry 2017 ,38, 2108–2117.\n(57) Krishtal, A.; Ceresoli, D.; Pavanello, M. Subsystem real-time time dependent density\nfunctional theory. J. Chem. Phys. 2015 ,142.\n(58) Jacob, C. R.; Neugebauer, J. Subsystem density-functional theory. WIREs: Comp.\nMol. Sci. 2014 ,4, 325–362.\n(59) Wesolowski, T. A.; Shedge, S.; Zhou, X. Frozen-density embedding strategy for mul-\ntilevel simulations of electronic structure. Chem. Rev. 2015 ,115, 5891–5928.\n(60) Mi, W.; Luo, K.; Trickey, S.; Pavanello, M. Orbital-free density functional theory:\nAn attractive electronic structure method for large-scale first-principles simulations.\nChem. Rev. 2023 ,123, 12039–12104.\n(61) Jacob, C. R.; Neugebauer, J. Subsystem density-functional theory (update). Wiley\nInterdisciplinary Reviews: Computational Molecular Science 2024 ,14, e1700.\n(62) Supplementary Materials. See supplementary materials document at [url-to-be-\ninserted].\n(63) Genova, A.; Ceresoli, D.; Pavanello, M. Avoiding fractional electrons in subsystem\nDFT based ab-initio molecular dynamics yields accurate models for liquid water and\nsolvated OH radical. J. Chem. Phys. 2016 ,144.\n(64) Mi, W.; Ramos, P.; Maranhao, J.; Pavanello, M. Ab initio structure and dynamics of\nCO2 at supercritical conditions. J. Phys. Chem. Lett. 2019 ,10, 7554–7559.\n(65) Shao, X.; Mi, W.; Pavanello, M. GGA-level subsystem DFT achieves Sub-kcal/mol ac-\ncuracy intermolecular interactions by mimicking nonlocal functionals. J. Chem. Theory\nComput. 2021 ,17, 3455–3461.\n33(66) Mi, W.; Pavanello, M. Nonlocal subsystem density functional theory. J. Phys. Chem.\nLett.2019 ,11, 272–279.\n(67) Schl¨ uns, D.; Klahr, K.; M¨ uck-Lichtenfeld, C.; Visscher, L.; Neugebauer, J. Subsystem-\nDFT potential-energy curves for weakly interacting systems. Phys. Chem. Chem. Phys.\n2015 ,17, 14323–14341.\n(68) Shao, X.; Mi, W.; Pavanello, M. Density embedding method for nanoscale molecule–\nmetal interfaces. J. Phys. Chem. Lett. 2022 ,13, 7147–7154.\n(69) Shao, X.; Lopez, A. C.; Khan Musa, M. R.; Nouri, M. R.; Pavanello, M. Adaptive\nsubsystem density functional theory. J. Chem. Theory Comput. 2022 ,18, 6646–6655.\n(70) Chen, X.; Cifuentes-Lopez, A.; Shao, X.; Lin, L.; Prokopchuk, D.; Pavanello, M.\nUnraveling the Hydration Shell Structure and Dynamics of Group 10 Aqua Ions. J.\nPhys. Chem. Lett. 2024 ,15, 5517–5528.\n(71) Schmitt-Monreal, D.; Jacob, C. R. Density-based many-body expansion as an efficient\nand accurate quantum-chemical fragmentation method: Application to water clusters.\nJournal of Chemical Theory and Computation 2021 ,17, 4144–4156.\n(72) Focke, K.; Jacob, C. R. Coupled-cluster density-based many-body expansion. The\nJournal of Physical Chemistry A 2023 ,127, 9139–9148.\n(73) Kevorkyants, R.; Dulak, M.; Wesolowski, T. A. Interaction energies in hydrogen-\nbonded systems: A testing ground for subsystem formulation of density-functional\ntheory. J. Chem. Phys. 2006 ,124.\n(74) Cisneros, G. A. Application of Gaussian Electrostatic Model (GEM) Distributed Mul-\ntipoles in the AMOEBA Force Field. J. Chem. Theory Comput. 2012 ,8, 5072–5080.\n(75) Babin, V.; Leforestier, C.; Paesani, F. Development of a “First Principles” Water\nPotential with Flexible Monomers: Dimer Potential Energy Surface, VRT Spectrum,\n34and Second Virial Coefficient. Journal of Chemical Theory and Computation 2013 ,9,\n5395–5403, PMID: 26592277.\n(76) Babin, V.; Medders, G. R.; Paesani, F. Development of a “First Principles” Water\nPotential with Flexible Monomers. II: Trimer Potential Energy Surface, Third Virial\nCoefficient, and Small Clusters. Journal of Chemical Theory and Computation 2014 ,\n10, 1599–1607, PMID: 26580372.\n(77) Riera, M.; Lambros, E.; Nguyen, T. T.; G¨ otz, A. W.; Paesani, F. Low-order many-\nbody interactions determine the local structure of liquid water. Chem. Sci. 2019 ,10,\n8211–8218.\n(78) Garrity, K. F.; Bennett, J. W.; Rabe, K. M.; Vanderbilt, D. Pseudopotentials for high-\nthroughput DFT calculations. Computational Materials Science 2014 ,81, 446–452.\n(79) Shao, X.; Mi, W.; Xu, Q.; Wang, Y.; Ma, Y. O(NlogN) scaling method to evaluate\nthe ion–electron potential of crystalline solids. J. Chem. Phys. 2016 ,145.\n(80) Shao, X.; Mi, W.; Pavanello, M. eDFTpy: An Object-Oriented Platform for Den-\nsity Embedding Simulations. available at http://edftpy.rutgers.edu, 2024; http:\n//edftpy.rutgers.edu , (Last accessed on: 04/25/2024).\n(81) Shao, X.; Andreussi, O.; Ceresoli, D.; Truscott, M.; Baczewski, A.; Camp-\nbell, Q.; Pavanello, M. QEpy: Quantum ESPRESSO in Python. Available at\nhttps://gitlab.com/shaoxc/qepy, 2024; https://gitlab.com/shaoxc/qepy , (Last ac-\ncessed on: 04/25/2024).\n(82) Giannozzi, P. et al. Advanced capabilities for materials modelling with QUANTUM\nESPRESSO. Journal of Physics: Condensed Matter 2017 ,29, 465901.\n(83) Riera, M.; Knight, C.; Bull-Vulpe, E. F.; Zhu, X.; Agnew, H.; Smith, D. G. A.;\nSimmonett, A. C.; Paesani, F. MBX: A many-body energy and force calculator for\n35data-driven many-body simulations. The Journal of Chemical Physics 2023 ,159,\n054802.\n(84) S. Nørby, M.; Magnus Haugaard Olsen, J.; Kongsted, J.; Aagard Jensen, H. J. Mul-\ntipole moments for embedding potentials: Exploring different atomic allocation algo-\nrithms. J. Comp. Chem. 2016 ,37, 1887–1896.\n(85) Ferr´ e, N.; ´Angy´ an, J. G. Approximate electrostatic interaction operator for QM/MM\ncalculations. Chem. Phys. Lett. 2002 ,356, 331–339.\n(86) Genova, A.; Ceresoli, D.; Krishtal, A.; Andreussi, O.; DiStasio Jr, R. A.; Pavanello, M.\neQE: An open-source density functional embedding theory code for the condensed\nphase. Int. J. Quantum Chem. 2017 ,117, e25401.\n(87) Mi, W.; Shao, X.; Genova, A.; Ceresoli, D.; Pavanello, M. eQE 2.0: Subsystem DFT\nBeyond GGA Functionals. Comp. Phys. Comm. 2021 ,269, 108122.\n(88) Genova, A.; Pavanello, M. Exploiting the locality of periodic subsystem density-\nfunctional theory: efficient sampling of the Brillouin zone. J. Phys.: Condens. Matter\n2015 ,27, 495501.\n(89) Perdew, J. P.; Burke, K.; Ernzerhof, M. Generalized Gradient Approximation Made\nSimple [Phys. Rev. Lett. 77, 3865 (1996)]. Phys. Rev. Lett. 1997 ,78, 1396–1396.\n(90) Laricchia, S.; Fabiano, E.; Constantin, L.; Della Sala, F. Generalized gradient ap-\nproximations of the noninteracting kinetic energy from the semiclassical atom theory:\nRationalization of the accuracy of the frozen density embedding theory for nonbonded\ninteractions. J. Chem. Theory Comput. 2011 ,7, 2439–2451.\n(91) Grimme, S. Supramolecular binding thermodynamics by dispersion-corrected density\nfunctional theory. Chemistry–A European Journal 2012 ,18, 9955–9964.\n36(92) Babin, V.; Leforestier, C.; Paesani, F. Development of a “first principles” water po-\ntential with flexible monomers: Dimer potential energy surface, VRT spectrum, and\nsecond virial coefficient. J. Chem. Theory Comput. 2013 ,9, 5395–5403.\n(93) B ¨OTT', 'm.pavanello@rutgers.edu', 'Xin Chen, Jessica A. Martinez B., Xuecheng Shao, Marc Riera, Francesco  Paesani, Oliviero Andreussi, and Michele Pavanello', '', '../pdf_files/674d7fc5a5863-Density-Functionalized QM-MM Delivers Chemical Accuracy For Solvated Systems.pdf', 5183270, 38, 10080, 67329, '2024-12-02 09:37:13', '2024-12-02', 'Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(73, '3630583576', '6745cf4203d9a', 12, 1, 'STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS ', '2024-12-03 01:33:37.396668', '2024', 'STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS ', 'IT,Technology,Information Technology', 'Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n INTRODUCTION TO INFORMATION TECHNOLOGY  \n \n \n \nSon T hai Tran, Le Ngoc Thanh, Nguyen Quoc Binh, Dang Binh Phuong , Le Hoai Bac   \n \nFaculty of Information Technology,  \nUniversity of Science, Hochiminh city, Vietnam  \n \n \nABSTRACT  \n \nWe present our experience in designing a  course of Introduction to Information Technology (IIT) \nfor the first -year students. The main purpose of this course is to introduce the concepts of \ncomputing and computer, and to present a hierarchy of information technology (IT)  knowledge \nfrom basic to a dvance through the introduction of syllabus system, research trends of our faculty, \nIT applications in society, ethics and career potentials in IT. The content of this course is set up \nto meet  the Standard 4 in CDIO. We divide the introduction into two cou rses and teach the first - \nyear students in  the first and second semesters.  The first course is the introduction of computer, \ncomputing, internet, ethics, and some technical skills of analysis, design, implementation, and \ntesting. This is an overview of IT from the outside rs. The second is a hierarchy of IT knowledge \nfrom basic to advance through education systems and research in our faculty. This is an \noverview of IT from inside viewpoint. We also present some experiences about the project -\nbased approach fo r labs an d explain how we train person al skills and professional attitude for \nour students. Finally, we conclude by providing  comments with  pros and cons in operating th e \ncourse s. \n \n \nKEYWORDS  \n \nStandard 4, Introduction to Information Technology , CDIO syllabu s, Project -based learning  \n \n \nINTRODUCTION  \nIn CDIO standard, the standard 4 [1] plays an important role to pro vide a general view about \ncurriculum , syllabus system, future  career  and beginning concepts of CDIO for the first -year \nstudents in our university. Many similar work s in engineering ha ve been published in the CDIO \nconference. Ramon Bragós , et. al. [2], presented a method that they have conceived, designed \nand implement ed \"Introduction to Engineering\" course at Telecom BCN, UPC, Barcelona using \nthe CDIO  syllabus and standards. The basic concepts  and professional  skills were  given to the \nstudents through lessons and simple  projects. From that, the students were  able to recognize  \nproblems of which solutions we were going to teach in the following courses o f the curriculum.   \nYingzi Wang , et. al. [3], introduced  the implementation of the cornerstone project. They \ntransform ed the name of “Introduction to Civil Engineering” into “Introduction to Civil Engineering \nDesign”. The difference is that students are put  into an environment where they could learn and \nuse knowledge and professional skills  to study design actively . Xiaohua Lu , et.al.  [4], introduced \none approach of multi -disciplinary project  for the introduction course.  In his class,  the students \nwere  divided into different disciplinary group s and join ed in project -based learning. That project \nrequired student s to design and build a computer -controlled tower crane at Shantou University. \nThis process help ed students  to understand the different modules and the  input/output of each \nmodule. As a result, the multi -disciplinary p roject i s a good approach to introduction  courses . Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n Goran Gustafsson, et. al. [5],  presented his work of engineering education program s. The  first-\nyear introductory course  was discussed and shared to improve and increase student motivation. \nThey have identified projects and teamwork as important parts of the first-year courses. With the \nCDIO approach, a new model for engineering education is developed to be able to implement \nthis projects and  professional  skills.  In many  previous work s, we rarely see the first-year \nintroductory course to information technology (IT). In this paper, w e present our experience in \ndesigning a course of Introduction to Information Technology (IIT) for the first -year students. On \none hand, t he main purpose of this course is to introduce the concepts of computing and \ncomputer, and to present a hierarchy of IT knowledge from basic to advance through the \nintroduction of syllabus system, research trends of our faculty, IT  applications in society, ethics \nand career potentials in IT.  On the other hand, the purpose of this course will introduce the \nrelationship between the contents of 4 year learning in the university with IT career after \ngraduation  to first -year students . The IIT course also shows students the social requirements to \nIT not only in Vietnam but also worldwide . After studying this course, the first -year student will \nhave another point of view  about their role in  the development of IT. From that starting point, it \nwill help student s to think and navigate  their future career in IT.  It also influences to students ’ \ndecision in course selections for undergraduate program at the current time or their intention to \nenter the graduate program in the future. This course wi ll also help the  students to identify the \nimportance of engineering skills and appropriate  attitudes for the success in their future career \npath. From the above mot ivation, the design and implementation  of this course have been \nconsidered seriously by our senior lecturers and professors in our faculty.  We have already \nspent more than one year to prepare the learning outcome, syllabus, teaching /learning  \ndocuments, and workspace for  this course  [6]. This paper will present our experiences in design, \nbuilding , teaching, and evaluation of this course to the first -year students in 2012.  \n  \nThe content of this paper is presented as follows; Section 2 presents the design and building of \ncourse goals  and learning outcomes for IIT course. Section 3 presents the appro ach of project -\nbased learning to embed CDIO concepts in teaching and training for students.  Section 4 \npresents the meeting and feedback between IT companies and the first -year students. Section 5 \npresents the assessments and some rubrics for this course. S ection 6 is our discussions  about \npros and cons in operating this course  at our faculty.  Section 7 is the conclusions.   \n \n \nCOURSE GOALS AND  LEARNING OUTCOME S \nDesign and building the course goals and learning outcome s of one course in CDIO system is  \nnot easy  because the scope of course goal s must be suitable to the learning outcome s of the \ncurriculum . Figure 1 presents our workflow in the design of course goals and learning outcome s \nfor o ne course by using CDIO approac h. In Fig. 1, we can see that the learnin g outcome s are \ndefined from the course goals while  the course goals are defined by the learning outcome s of \nour curriculum. In practice, the number of course goals is less than or equal to 8 and there are \nabout 2 to 4 learning outcomes corresponding  to eac h course goal.  We can see that t he content \nof course goals is presented more in details by the learning outcomes. Most important contents \nin the course goal s will be  the objectives of the assessment  corresponding to Source of \nEvidence in Fig.1 . It is notic ed that the course goals and the learning outcome will involve \ndirectly to the design of the course.  The solid lines in Fig.1 show the task order in workflow and \nthe dash lines show the revision and comparison. The total score is the final score of student s \nafter studying the course.  We divide the content  of IIT  into two courses and teach the first year \nstudents in the first and second semesters.  \n Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \nFigure 1: Workflow to build a CDIO syllabus  \n \nThe first course is the introduction of computer, computing, in ternet, ethics, and some technical \nskills of analysis, design, implementation, and testing.  This is an overview of IT from outside \nviewpoint. The second is a hierarchy of IT knowledge from basic to advance through systems of \neducation and research in our f aculty. This is an overview of IT from inside viewpoint  of our \nfaculty . The course goal of Introduction to Information Technology can be written into two stages \nas follows;  \na) The course goals of the first course  \n Explain general knowledge of IT include basic knowledge about counting system, \noperating system, internet, email, and office applications . \n Describe the basic values related to professional ethics of those working in IT \nsector . \n Describe the work  and job position  in a company, related to IT, which is one  IT \nstudent can undertake  after graduation.  \n Recognize the  importance of self study, team work, and communication skills.  \n Recognize the professional attitude, regulatory compliance, and reliability.  \n \nThe first course is taught in ten weeks with 15 hours in class, 20 hours in lab an d 15 hours of \nself studying at home  (Note that  details of weekly c lasses will be  provided by contacting the \nauthors ). \n \nb) The course goals of the second  course  \n Describe relationship between  the syllabus system , researches,  and the IT career \ndevelopment in the Department of Information Technology, University of Science, \nHoch iminh city, Vietnam.   \n Describe basic concepts related to the fields of Information Systems, Software \nEngineering, Computer Networking & Telecommunications, Knowledge \nEngineering , and Machine Vision & Robotics.  \nProceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 2 : The course outline of Introduction to Information Technology (IIT) 1 & 2.  \n \n Describe outline of jobs which directly and indirectly related to the above IT fields .  \n Recognize the importance of self study, team work, and problem solving.  \n Recognize the professional attitude, regulatory compliance, and reliability.  \n \nThe second course is similar to the first course. It also takes ten weeks with 15 hours in \nclass, 20 hours in lab and 15 hours of self studying at home.  Knowledge  \nGeneral introduction to IT  \nConcept / Basic knowledge of IT  \nOS / Network /Internet/ Virus  \nWord processor / Excel / \nPresentation  \nGeneral introduction to IT career  \nConcept of Analysis / Design / \nImplement  / Operation and Testing  \nIT professional ethics  Skills  \nPersonal skills:   \nteamwork, communication  \nProfessional skills  Attitudes  \nProfessional attitudes  \nRegulatory compliance \nand relia bility \nKnowledge  \nIT Career and IT Programs  \nInformation System Introduction  \nSoftware Engineering Introduction  \nComputer Network and \nTelecommunication Introduction  \nComput ing Science Introduction  \nKnowledge Engineering \nIntroduction  \nComputer Vision & Ro botic \nIntroduction  Skills  \nPersonal skills: \nteamwork, presentation  \nProfessional skills  Attitudes  \nProfessional attitudes  \nRegulatory compliance \nand reliability  - Search information using \ninternet . \n- Scan, detect and kill \nvirus on computer  \n- Use word proces sor, \nexcel, power point  \n- Present and explain one idea \nin front of the audiences  \n- … \nIT Integrated Field Introduction  - Think about problem, \nsystem, and solution  \n- Test and evaluate one \nsoftware  \n- Read and comprehend \nmanual book of one \nsystem  \n- Survey one gi ven \nproblem  \n- … Introduction to \nInformation \nTechnology 1  ( Theory: \n2 credits ; Lab: 3 \ncredits )  \nIntroduction to \nInformation \nTechnology 2  ( Theory: \n2 credits ; Lab: 3 \ncredits )  Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \nFigure 3: The concept of CDIO for  studying and training  in our IIT courses . \n \nBased on the course goal of the 1st and 2nd courses, the outline of two IIT courses is presented \nin Fig. 2. We can see that the content of the second course describes more in details about the \nsystem of research and education in our faculty.  It provides experiences and case study about \nthe influence and importance of advanced courses in the syllabus system to career selection of \nstudents. Through the content of this course, we also give students a general view of IT \napplications and potential fields, where IT can be integrated successfully.  \n \nBeside s providing knowledge, we apply  the project -based approach to embed skills and \nattitudes into the teaching/learning activities of two IIT courses. Here the CDIO concept s can be \nexplained easily to our students by using  a simple project first, and then the requirements  in the \nsecond project  are upgraded to higher level in order to give students a chance of thinking, \nrecognizing, and implementing their knowledge, skills and att itudes. Figure 3 presents the \nconcept of CDIO for studying and training in our two IIT course s. In the first course, one simple \nproject is proposed to introduce the first -year students about D -I-O. Meanwhile, the project in the \nsecond course is designed to  train the first -year students all stages of C -D-I-O.  \n \nPROJECT -BASED APPROACH  \nAs mentioned above, the project -based approach is appli ed in both two IIT courses in our IT \nprogram. When we design the project  system , our expectation is to present  the four st ages of C -\nD-I-O to students as soo n as possible. However, most first -year students cannot understand the \nconcept of conceives  when we give them a set of initial conditions to produce software . The \nlimitation of students to recognize and understand all stag es of C-D-I-O is describes as follows;  \n Limitation of knowledge and time.  \n Limitation of personal skills and professional skills.  \nAs a result, we propose one project , where students will study D -I-O instead of C -D-I-O. In the \ncontent of the first course, we see that there is a relation between the concept s of \nanalysis/design/implement/operation and testing to the concept s of D-I-O. In practice, it t akes  a \nshort time, around  2 classes, for the first -year students to understand D -I-O concepts.  We divide \nthe cla ss into many groups, with 5 members for each . \n \n \n \n \n \nProceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n    \nProject:  House Prototype Building    \n \nA. Build a prototype of house by using paper and bamboo stick such that  :  \na) It can be waterproof . \nb) Shape of house must  be stable when  we put 330 gram on  the roof for di agnostic load \ntest. \nc) Maximum size of house is 20 cm x 20 cm x 20 cm.  \nB. Material : \n3 daily papers, 250 bamboo sticks (0.2 cm x 5cm / stick), 3 glue bottles (50 ml / bottle) .   \nC. Outputs:  \n- House prototype . \n- Report  and documents  of design, solution, work load (time and position) , balance \nsheet, salary & price, and explanation  of testing result.   \n- Slide and presentation . \n \nSome of  first-year students wonder why we give them  the above project .  The question is why IT \nstudent s must study to build a house prototype instead of one software . The answer comes \nfrom the output of the projects, where using IT app lications such as Word processor, Excel, and \nPower point is one of the important requirements and the concepts of D -I-O must be reflected in \nthe report of students. Teamwo rk can be evaluated by the quality of house prototype and sheet \nof workload. We can also check students ’ communication skill through their slide s and \npresentation. Figure 4 presents some examples of house prototype from the above project.                         \n \n \n \nFigure 4: Some examples of house prototype.  \n \nIn the second course, the level of project is upgraded to present the concept  of C-D-I-O. We \ngroup the contents of Information System, Software Engineering, Network and \nTelecommunication  into one pro ject. Meanwhile,  those o f Computing Science, Knowledge \nEngineering, Computer Vision and Robotics are designed  in one other C -D-I-O project.  For \ninstances, a three -month project is to build a small social network where students must study \nand work with web design, web programming , database management, and network \nmanagement to release the first and second demo s. This project  asks student s work in team \nand gives them a large freedom to generate  ideas, make design, find solution, and implement  \nboth software an d hardware.  The lecturer and TA play a role of the end user s or customer s of \ntheir service.  The output of this project is evaluated  by checking  demo softwares , reports, and \npresentation s. One other kind of the project is to build a system  of data analysis for multimedia  \ndata such as video information retrieval or video / audio processing  by using free ware . \nAdditionally , we have also provided some projects related to research of our departments  by \nusing available  toolboxes  or open source s. \n \nProceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n MEETING OF COMPAN IES AND STUDENTS  \nBeside the course, we have organized a meeting between company and the first -year student s. \nThe purpose of the meeting is to give our students a chance to listen the  vision , tendency, and \ndemand  from companies. Through  the meeting, student s, our faculty  staffs,  and company  \nmembers  can share viewpoints  about the development of IT in Vietnam and in the world. After \nthe meeting, we can have some thoughts about  important demand s from IT companies  in \nVietnam  such as :  \n Personal skills , specifical ly team work and communication,  play an important role for the \nsuccess of one’s career path . \n Problem solving  capa bility is the key of admission to company . \n For most companies, r eliability and loyalty are the most precious characteristics.   \n \n \nASSESSMENT  AND FEEDBACKS  \nAssessment  is the main difference between CDIO approach and the conventional teaching \nmethods. We divide 70% of final exam and 30% of project in the first course. Meanwhile, the \nratio of final exam and project in the second course is 60% and 40%,  respectively. The \nassessment  of each  project is checked monthly in three months.  Figure 5 presents some rubrics \nof project and report evaluation . The detail of assessment has been shown to students at the \nbeginning of the course. During the course, studen ts have been reminded about the assessment \nand we have also encouraged them to provide a good strategy  of learning for each group s o that \nall members of the same group can receive a good result.  In practice, the peer review gives \nobjective  evaluation. It h elps students have a strong responsibility and a serious thinking about \ntheir contributions to the final results of their group.  \n \nOrder  Outputs  Evaluation \nmembers  Applicants  Ratio  \n1.  Hardcopy of report  Lecturer  Group  30% \n2.  Demo  software  Lecturer  Group  30% \n3.  Presentation  Lecturer  Group / member  10% \n4.  Member  \nperformance  Inside group \n(peer review)  Member  15% \n5.  Group  performance  Other group \n(peer review)  Group  15% \na) Project evaluation  \n \nOrder  Outputs  0 1 2 3 Ratio  \n1.  Introduction, \nmotivation and \nsurvey  None  \nUncle ar Clear  but not \nenough  Enough and logical  15% \n2.  Description of basic \nconcepts  None  Unclear  Clear but not \nenough  Enough and logical  15% \n3.  Formulation of \nproblem  None  Unclear  Clear but not \nenough  Enough and logical  15% \n4.  Experiment \nexplanation  None  Unclear  Clear but not \nenough  Enough and logical  15% Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n 5.  Description of  demo  \nsoftware  None  Unclear  Clear but not \nenough  Enough and logical  10% \n6.  Creativity  None  Unclear  Clear but not \nbetter  Clear and better  10% \n7.  Presentation  None  Unclear  Clear  Clear and logical  10% \n8.  Documentation  None  Not \nenough  Enough but \nnot logical  Enough and logical  5% \n9.  Reference  None  Not \ncorrect  Correct and \nnot enough  Enough and \ncorrect  5% \nb) Report evaluation  \n \nFigure 5: Some rubrics of project and report evaluation . \n \nAfter assessment, we make s ome QA to receive the feedbacks from students. There are 170  of \n450 students returning feedbacks.  The result of feedback is presented as the following table ; \n \nTable 1:  Feedback of students  \n 1 2 3 4 5 NC \nHomework/Project is evaluated fairly and positively.  65 74 25 4 1 1 \nHomework/Project is evaluated on the fixed schedule \nexactly.  48 72 45 4 0 4 \nSyllabus is well prepared.  44 86 31 6 0 3 \nSyllabus content is presented in a suitable order.  56 83 26 3 0 2 \nSyllabus content is easily understandable.  43 78 43 4 0 2 \nCourse slide and other resources are provided on time  to \nbe useful for teaching and learning.  50 80 34 4 1 1 \na) Theory  \n \n 1 2 3 4 5 NC \nHomework/Project is evaluated fairly and positively.  76 74 17 3 0 0 \nHomework/Project is evaluated on the fixed sch edule \nexactly.  59 71 36 3 0 1 \nLab’s documents are well prepared.  49 79 37 4 0 1 \nLab’s documents are presented in a suitable order.  48 93 25 2 1 1 \nLab’s documents are easily understandable.  38 82 45 4 0 1 \nSlide and other resources of Lab experiments ar e \nprovided on time to be useful for teaching and learning.  52 79 33 4 0 2 \nb) Lab \n \n \nTable 2: Benchmark  \n \nAbsolutely agree  Agree  Neutral  Object  Absolutely object  No comments  \n1 2 3 4 5 NC \n \nTable 1 presents the feedbacks of 170 students and Table 2 gives the benchmark  of score value. \nWe can see that most distribution of feedbacks stays on “Agree” corresponding to the score \nvalue of 2.  It means that the feedbacks of students are positive  toward  CDIO approach.  However , \nthere are still some complain ts about overloa ded and stressful because the first -year students \nhave got a lot of project and homework deadl ines from the first semester of the undergraduate \nprogram in the University.   Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n  \nDISCUSSIONS  \nAfter one year implementing CDIO  to IT  program, we found some interesti ng points and \ndifficulties  in CDIO implementation . The approach of CDIO  helps us to clarify the quality of the \nsyllabus easily.  By checking the learning outcome and course goal s, we can see an overview to \nour whole program and find whether there is any inconsisten ce or overlap  in the undergraduate \nprogram.  The introduction of IT  course provides  the students motivation, prospective view of \ntheir career , and important  concept s of IT. Besides the advantage s, this course still has some \ndifficult problems in tea ching and learning activities  \n Some s tudents feel stressful because of overloaded project s and homework . Most \ncourses designed in CDIO approach have a requirement of project -based learning. \nConsequently,  the number of projects that a student needs to work o n during one \nsemester  increas e considerably.  As a matter of fact , the requirements  of project become \nmore difficult because it will check both knowledge and skills in the learning  outcomes . It \ntakes students a lot of time  and effort  to catch  up projects ’ deadlines and requirements . \nOne solution of the above  is to design one big project which can be applied for  multiple \ncourses . However, there is always a limitation  about  time and the coverage of learning \noutcomes  in a project.  It is not easy to make  decisi on whether we should select  or not \none learning outcome from a bunch of multiple courses.   \n The number of lecture rs and teaching assistants (T As) are not enough to cover a class of \n450 students.  Originally , CDIO program has been developed from engineering school, \nwhere the number of students in each class is just a few dozen. Now the number of first-\nyear students in our IT faculty is around 450 a year.  As a result, w e need more space \nand more T As to organize Teaching  and Learning  activities  in class.  One s olution is to \ndivide into many small classes with a few dozen students. However, this also brings \nsome difficulties in  scheduling and funding for extra -hour payment.  \n Lecturer s and T As are still familiar with the conventional teaching  approach . It will take  \ntime to change their thinking  and teaching approach . We have already organized some \ntraining programs for lecturers to explain CDIO program  and enhance their professional \nskills.  \n The CDIO approach requires  students, lecturer s, and T As spend more time  in \npreparation . Hence w e need an efficient administration to support and encourage them in  \nlong run . As mentioned above, scheduling and workspace management play a very \nimportant role in our CDIO p rogram. If administration staff  could  be trained well, they will \nhelp us to save much time in learning and teaching activities.  \n We need a sufficient funding  to set up  the workspace , evaluate  the learning outcomes , \nand revise the program every year.  \n CDIO -based  program  is usually  applied for the first -year students and we must wait  until \nfour years later , when all the first -year students graduate,  in order  to receive the \nfeedbacks from the sta keholders to decide  the CDIO program  successful or not . \nAbsolutely, nobody wants to see it  failed after four years. Therefore, we must clarify what \nwe should evaluate and revise periodically (e.g. yearly) in order to  ensure that the CDIO \nprogram is develop ed with high efficiency . Since  we invest  more  time, money, and \nhuman resource  to follow the CDIO program, we really need the posit ive evidence  to \npersu ade our students, faculty staff , the university, and the society for supporting us to \nkeep it going on.  \n \n \n \nCONCLUSIONS  Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n We present  our experience of designing a course of Introduction to Information Technology (IIT) \nfor the first -year s tudents.  We design two courses for IT introduction: One is a general view from \noutsiders  to IT and the other is an introduction of research in IT. We have experiences to teach \nthose two courses for 450 students and receive both positive and negative feedba cks. Most  of \nthe students think  that those two courses are useful to motivate them to IT and give them a near \nvision of their career in the future. Students have been trained personal and professional skills. It \nmakes  them more confident than students of the conventional classes.  Although  most students \nthink  that CDIO -based approach is interestin g, it makes them a bit pressure with  deadlines. \nLecturer s and TAs also find it difficult in handling  a few hundred student  class . Last but not least, \nthe CDIO -base d program needs a sufficient and stable  fund to support it in the long run. In fact,  \nonce  we decide to start CDIO program, we  must k eep it going until the result  of our program \ncomes up  (i.e. feedback from stakeholders once student graduation ).   \n \n \nREFEREN CES \n \n[1]     Crawley, E. F. The CDIO Syllabus: A Statement of Goals for Undergraduate Engineering \nEducation,  MIT CDIO Report #1, 2001.  \n[2] Ramon Bragós, et. al., Conceiving and Designing an “Introduction To Engineering” Course \nwithin the New Curricula at T elecom BCN, UPC Barcelona , Proceedings of the 6th \nInternational CDIO Conference, École Polytechnique, Montréal, June 15 -18, 2010.  \n[3] Yingzi Wang, et.al., CDIO in Practice in Cornerstone Project for Civil Engineering Program , \nProceedings of the 4th Interna tional CDIO Conference, Hogeschool Gent, Gent, Belgium, \nJune 16 -19, 2008  \n[4] Xiaohua Lu, Yinghui Fan, Stephen Banzaert, Joshua Jacobs, Multi -Disciplinary Design -\nBuild PBL As An Introduction to Engineering , Proceedings of the 6th International CDIO \nConferen ce, École Polytechnique, Montréal, June 15 -18, 2010.  \n[5] Goran Gustafsson, et.al., First-Year Introductory Courses as a Means to Develop \nConceive – Design – Implement – Operate Skills in Engineering Education Programmes , \nPresented the SEFI Annual Conferenc e, Firenze, Italy, 08 -11 September 2002.  \n[6] Edward Crawley , Johan Malmqvist , Soren Ostlund , Doris Brodeur , Rethinking Engineering  \nEducation: The CDIO Approach , Springer, 2007.  \n \n \nBIOGRAPHICAL INFORMATION  \n \nSon Thai  Tran is lecturer at the Faculty of Information Technology  (FIT), University of Scie nce, \nHochiminh city, Vietnam. He is the Deputy H ead of Department  of Computer Vision and \nRobotics . He joined the CDIO program as a designer of I ntroduction to Information Technology  \ncourse  in 2012. His research interests are in Statistical Data Analysis, C omputer Vision, and \nDiscrete Optimization.   \n \nLe Ngoc Thanh  is the Deputy Head of Computer Science Department. He is also a member of \nthe CDIO project that implemented in FIT. With this promotion, he is responsible for evaluating \nand applying CDIO standard  into Introduction to Information Technology course. In addition, he \njoins in the construction of other course’s syllabus based on CDIO approach to ensure the \nstudents achieve learning outcomes thoroughly. Tha nh’s research interests are in Data Mining, \nSocial Network, and Graph T heory.  \nNguyen  Quoc Binh is teaching assistant at the Faculty of Information Technology  (FIT), \nUniversity of Science, Hochiminh city, Vietnam. He is at Department  of Knowledge Engineering . Proceedings of the 9th International CDIO Conference, Massachusetts Institute of Technology  and Harvard  University \n He joined the CDIO program as a teaching ass istant of Introduction to Information Technology \ncourse  in 2012 . His research interests are in Cryptography , Privacy, and Statistical Data \nAnalysis.  \n \nDang Binh Phuong is lecturer at the Faculty of Information Technology  (FIT), University of \nScience, Hochim inh city, Vietnam. He is at Department  of Software Engineering . He joined the \nCDIO program as a lecturer of Introduction to Information Technology course in 2012 and 2013. \nHis research interests are in Software Engineering and Mobile Programming.  \n \nLe Hoai Bac is associate professor at the Faculty of Information Technology  (FIT) , University of \nScience, Hochiminh city, Vietnam. He is the Vice Dean of the Facu lty of Information Technology, \nHead of Computer Science  Department . He is monitoring and controlling t he progress of the \nCDIO program at the FIT . He is an active member in adopting CDIO in FIT. Prof. Le Hoai Bac’s \nresearch interests are in Data Mining, Soft C ompu ting and Artificial  Intelligence . \n \nCorresponding Author   \n     \nSon Thai Tran  \nDeputy Head of Depa rtment of Computer Vision & Robotics  \nFaculty of Information Technology  \nUniversity of Science – HCMC Vietnam National University  \n227 Nguyen Van Cu, District 5TH, Hochiminh city, Vietnam  \nEmail: ttson@fit.hcmus.edu.vn  \n \n \nThis work is licensed under a  Creative Commons Attribution -NonCommercial -NoDerivs 3.0 \nUnported License . \n \n', 'test@gmail.com', 'Jiarui Gan, Abheek Ghosh, Nicholas Teh', '', '../pdf_files/674def70ddd32-INTRODUCTION TO INFORMATION TECHNOLOGY.pdf', 712615, 11, 5025, 31333, '2024-12-02 17:33:41', '', 'Not Accepted', 0, 0);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(75, '1127012173', '52', 12, 1, 'STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS ', '2024-12-03 12:48:45.130545', '2024', 'STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS ', 'IT,Technology,Information Technology', 'Information Technology and \nProductivity: A Review \nof the Literature \nERIK BRYNJOLFSSON AND SHINKYU YANG \nMIT Sloan School of Management \nCambridge, Massachusetts \nAbstract \nIn recent years, the relationship between information technology (IT) and pro- \nductivity has become a source of debate. In the 1980s and early 1990s, empirical \nresearch on IT productivity generally did not identify significant productivity \nimprovements. More recently, as new data are identified and more sophisticated \nmethodologies are applied, several researchers have found evidence that IT is \nassociated not only with improvement in productivity, but also in intermediate \nmeasures, consumer surplus, and economic growth. Nonetheless, new questions \nemerge as old puzzles fade. This survey reviews the literature, identifies remain- \ning questions, and concludes with recommendations for applications of tradi- \ntional methodologies to new data sources, as well as alternative, broader metrics \nof welfare to assess and enhance the benefits of IT. \n1. The “Productivity Paradox”-A Clash of Expectations and Statistics ...... 179 \n2. Research on Economy-wide Productivity and Information Worker \nProductivity ................................. 187 \n3. Industry-Level Studies of Information Technology Productivity. ........ 192 \n4. Firm-Level Studies of Information Technology Productivity .......... 196 \n4.1 Service Sector Studies. ........................ 196 \n4.2 Studies of Manufacturing Sector and Cross-Sector Studies. ........ 198 \n5. Contribution to Consumer Surplus and Economic Growth ........... 201 \n6. Conclusion: Where Do Wc Go from Here? .................. 205 \nBibliography. ................................ 209 \n1. The “Productivity Paradox”-A Clash of \nExpectations and Statistics \nDuring the past decade, both academics and the business press have \nperiodically revisited the so-called “productivity paradox” of computers: \n179 Copyright 0 1996 by Academic Pre%, Inc \nAll rights of reproductinn In any form rewved ADVANCES IN COMPUTERS. VOL 43 180 ERIK BRYNJOLFSSON AND SHINKYU YANG \nWhile delivered computing power in the United States has increased by \nmore than two orders of magnitude since the early 1970s (Fig. l), productiv- \nity, especially in the service sector, seems to have stagnated (Fig. 2). Despite \nthe enormous promise of information technology (IT) to effect “the biggest \ntechnological revolution men have known” (Snow, 1966), disillusionment \nand frustration with the technology are evident in headlines like “Computer \nData Overload Limits Productivity Gains” (Zachary, 1991). \nInterest in the “productivity paradox” has engendered a significant \namount of research. Although researchers analyzed statistics extensively \nduring the 1980s, they found little evidence that information technology \nsignificantly increased productivity. As Robert Solow quipped, “you can \nsee the computer age everywhere but in the productivity statistics.”’ \n80 \n70 \n20 \n10 \n0 \n1955 1960 1965 1970 1975 1980 1985 1990 1995 \nYear \nFIG. 1. Investment in information technology is growing at a rapid pace. [Note: Constant \ndollars (base year 1987) calculated by hedonic price method, see Dulberger (tYXY).] [Based \non data from BEA, National Income and Wealth Division, and adapted from Jorgenson and \nStiroh (1995).] \n’ Solow, Robert M., “We’d Better Watch Out,” New York Times Book Review, July 12, \n1987, p. 36. \nINFORMATION TECHNOLOGY AND PRODUCTIVITY 181 \n30‘ \n5 Mfg. \nNon Mfg. \n1945 1955 1965 1975 1985 1995 \nYear \nFIG. 2. Productivity in the service sector has not kept pace with that in manufacturing. \n(Based on data from Bureau of Labor Statistics, Productivity & Testing Division.) \nNow, after some researchers found firm-level evidence that IT invest- \nments earned hefty returns, the media pendulum has swung in the opposite \ndirection. Businessweek’s proclamation of “the productivity surge” due to \n“information technology,”2 and Fortune magazine’s headline heralding the \narrival of “technology payoff”-’ represent the latest trend. A growing num- \nber of academic studies also report positive effects of information technol- \nogy on various measures of economic performance. \nJust as the business media’s premature announcement of a “productivity \nparadox” was out of proportion to the more carefully worded academic \nresearch, the current cover stories on “productivity payoff” are often over- \nblown. A consensus on the relationship between IT investment and eco- \nnomic performance is still elusive. More than a decade ago, one of the \nearliest surveys concluded that we still had much to learn about measuring \nthe effects of computers on organizations (Attewell and Rule, 1984). A \nmore recent survey also reports a “sobering conclusion: our understanding \nof how information technology affects productivity either at the level of \nthe firm or for the economy as a whole is extremely limited” (Wilson, 1995). \n* Wildstrom, Stephen H. “The Technology Payoff,” Businessweek June 14, 1993, p. 56-68. \nMandel, Michael J., “The Digital Juggernaut,” Businessweek, The Information Revolution, \nMay 18,1994, Bonus Issue, pp. 22-31. Businessweek recently ran another cover story, “Produc- \ntivity to the Rescue,” October 9, 1995. \nMagnet, Myron, “Productivity Payoff Arrives,” Fortune, June 27, 1994, pp. 77-84. 182 ERIK BRYNJOLFSSON AND SHINKYU YANG \nAs more research is conducted, we are gradually developing a clearer \npicture of the relationship between IT and productivity. However, produc- \ntivity measurement is not an exact science; the tools are blunt, and the \nconclusions are not definitive. Thus, while one study shows a negative \ncorrelation between total factor productivity and high share of high-tech \ncapital formation during the 1968-86 period (Berndt and Morrison, 1995), \nanother study suggests that computer capital contributes to growth more \nthan ordinary capital (Jorgenson and Stiroh, 1995). More recently, Brynjolf- \nson and Hitt (1996) report positive effects of IT based on firm-level evi- \ndence. \nThis article seeks to summarize what we know; distinguish the central \nissues from peripheral ones; and clarify the questions that future research \nshould explore. Results and implications of different studies should be \ninterpreted in the context of specific research questions. The question of \naggregate economic performance differs from the question of firm-level \neconomic performance. Data sources and performance measures may also \ndepend on the level of aggregation. Even within one level of aggregation, \nresults may depend on the measure of performance or research method. \nIt is hoped that the process of reviewing studies of the productivity mystery \nwill serve as a useful springboard for examining alternative methodologies \nand the broader issues involved. \nAs a prelude to the literature survey, it is useful to define some of the \nterms used and to highlight some of the basic trends in the economics of IT. \nDefinitions: \n0 Information technology can be defined in various ways. In terms of \ncapital, among the most common is the BEA’s (U.S. Bureau of Eco- \nnomic Analysis) category “Office, Computing and Accounting Machin- \nery” (OCAM), which consists primarily of computers. Some research- \ners look specifically at computer capital, whereas others consider the \nBEA’s broader category, “Information Processing Equipment (IPE).” \nIPE includes communications equipment, scientific and engineering \ninstruments, photocopiers, and related equipment. In addition, soft- \nware and related services are sometimes included in the IT capital. \nRecent studies often examine the productivity of information systems \nstaff, or of workers who use computers. \n0 Labor productivity is calculated as the level of output divided by a \ngiven level of labor input. Multifactor productivity (sometimes more \nambitiously called total factor productivity) is calculated as the level \nof output for a given level of several inputs, typically labor, capital, \nand materials. In principle, multifactor productivity is a better measure INFORMATION TECHNOLOGY AND PRODUCTIVITY 183 \nof a firm or industry’s efficiency because it adjusts for shifts among \ninputs, such as substituting capital equipment for labor. However, the \ndata needed to calculate multifactor productivity are more complex. \n0 In productivity calculations, output is defined as the number of units \nproduced times their unit value, proxied by their real price. Determin- \ning the real price of a good or service requires the calculation of \nindividual price deflators to eliminate the effects of inflation. \nTrends: \nThe price of computing has dropped by half every 2-3 years (Figs. 3a \nand b).4 If progress in the rest of the economy had matched progress \nin the computer sector, a Cadillac would cost $4.98, while 10 minutes’ \nlabor would buy a year’s worth of groceries.’ \n0 There have been increasing levels of business investment in informa- \ntion technology equipment. These investments now account for more \nthan 10% of new investment in capital equipment by American firms \n(Fig. 4, Table II).6 \nInformation processing continues to be the principal task undertaken \nby America’s workforce. More than half the labor force is employed \nin information-handling activities (Fig. 5) \n0 Overall productivity growth appears to have slowed significantly since \nthe early 1970s and measured productivity growth has fallen especially \nsharply in the service sectors, which account for 80% of IT investment \n(Fig. 2, Table 4). \nWhite collar productivity statistics have been essentially stagnant for \n20 years (Fig. 6). \nThis relationship has been dubbed “Moore’s law” after John Moore, who first documented \nthe trend in microprocessors. It is widely projected to continue at least into the next century. \nIn the last 35 years, the quality-adjusted costs of computing have decreased over 6000-fold \nrelative to equipment prices outside the computer sector (Gordon, 1987b). ’ This comparison was inspired by the slightly exaggerated claim in Forbes Magazine 11980) \nthat “If the auto industry had done what the computer industry has done, . . . a Rolls-Royce \nwould cost $2.50 and get 2.000,OOO miles to the gallon.” The $4.98 Cadillac is based on a price \nof $30,890 for a 1991 Sedan de Ville divided by 6203, the relative deflator for computers. The \ngrocery comparison is based on a wage of $10 an hour and $10,000 worth of groceries, each \nin 1991 dollars. ’ Some studies estimate that as much as 50% of recent equipment investment is in informa- \ntion technology (Kriebel, 1989). This higher figure seems to be partly due to a broader \ndefinition of IT. A discrepancy also arises when recent investments are expressed in 1982 \ndollars, when IT was relatively more expensive. This has the effect of boosting IT’S real share \nover time faster than its nominal share grows. The recent change by BEA to a chain-weighted \nindex, instead of a fixed-weight index, will largely alleviate this problem. b 1ooO.O \nlW.0 \n10.0 \n1 .o \n0.1 \n1955 1960 1965 1970 1975 1980 1985 1990 \nYear \n52%/year \n42%iyear growth \ngrowth \nYear \n-#-Mcroprocessor A DRAM \nFIG. 3. (a) The cost of computing has declined substantially relative to other capital pur- \nchases. PDE, producer’s durable equipment. (Based on data from U.S. Department of Com- \nmerce, Survey of Current Business.) (b) Microchip performance has shown uninterrupted \nexponential growth. (P6, P7 microprocessors and 256M, lG, 4G DRAMS are estimated by \nIntel and the Semiconductor Industry Association.) [Based on data from Grove (1990), and \nIntel data. Trend lines are by authors’ estimations.] \nINFORMATION TECHNOLOGY AND PRODUCTIVITY 185 \n0.2 \n0.16 \n0.14 \n0.12 \nu f 0.1 \nr t \n0.08 \n0.06 \n0.04 \n0.02 \n0 \n1558 1963 1968 1973 1978 1983 1988 1993 1998 \nYear \nFIG. 4. Computers comprise about 10% of current-dollar investment in PDE. (Based on \ndata from BEA, National Income and Wealth Division.) \nThese trends suggest the two central questions of the productivity paradox: \n(1) Why would companies invest so heavily in information technology if it \ndid not add to productivity? (2) If information technology does contribute \nto productivity, why is its contribution so difficult to measure? \nThis article builds on a number of earlier literature surveys.’ This review \nconsiders more than 150 articles, but is not comprehensive. Rather, we aim \n’ Much of the material is adapted from a previous paper by Brynjolfsson (1993). Crowston \nand Treacy (1986) surveyed 11 articles from 1975 to 1985 on the impact of IT on enterprise- \nlevel performance and conclude that attempts to measure the impact of IT were surprisingly \nunsuccessful. They attribute this to poorly defined variables, a result of inadequate reference \ndisciplines and methodologies. A review of research combining information systems and \neconomics, by Bakos and Kemerer (1992), includes particularly relevant work. In addition, \nmany papers that seek to assess IT productivity directly begin with a literature survey: the \nreviews by Brooke (1992), Barua ef al. (1991), and Berndt and Morrison (1995) were particu- \nlarly useful. Most recently, the first part of Landauer (1995) details research on the productivity \npuzzle. Wilson (1995) also provides a useful survey of articles. \n186 ERIK BRYNJOLFSSON AND SHINKYU YANG \n120 \n.* P \n%I10 - \nY \ne \n:! Q \nPI 8 100 \n3 go \n80 50 \n- White Collar \nProductivity - Infomation \nAgricultum \nIndustry _c_ \n!bNb -+.-.. \n0 \n1850 1800 in50 2000 \nYear \nFic. 5. Information processing is the largest category of employment. The defining criterion \nfor information workers is whether the primary activity is knowledge creation, warehousing, \nor dissemination. [Based on data from Porat (1977).] INFORMATION TECHNOLOGY AND PRODUCTIVITY 187 \nto clarify the principal issues surrounding IT and productivity. We assimilate \nthe results of a computerized literature surrounding IT and productivity. \nWe assimilate the results of a computerized literature search of 30 leading \njournals in information systems and economics.8 In addition, many of the \nleading researchers in this area identified recent research that has not yet \nbeen published. \nThe productivity of IT can be measured using data on the whole economy, \non specified industries, or on individual firms. In the 1980s and early 1990s, \ndisappointment in information technology was chronicles in articles disclos- \ning broad negative correlations with economy-wide productivity. Several \neconometric estimates also indicated low IT capital productivity in a variety \nof manufacturing and service industries. More recently, researchers began \nto find positive relationships between IT investment and various measures \nof economic performance at the level of individual firms. The principal \nempirical research studies of IT and productivity are listed in Table I. \n2. Research on Economy-wide Productivity and \nInformation Worker Productivity \nEconomists have been unable to explain the slowdown in measured \nproductivity growth that began in the early 1970s. Labor productivity grew \nabout 2.5% per year from 1953 to 1968, but dropped to about 0.7% per \nyear from 1973 to 1979. Multifactor productivity growth declined from \n1.75% a year to 0.32% (Baily, 1986b). Even after accounting for factors \nsuch as the oil price shocks, changes in the quality of the labor force, and \npotential measurement errors, most researchers still find an unexplained \nresidual drop in productivity that roughly coincides with the rapid increase \nin the use of information technology. \nJorgenson and Stiroh\'s (1995) more recent growth accounting confirms \nthis correlation. They calculate that average multifactor productivity growth \ndropped from 1.7% per year for the 1947-73 period to about 0.5% for the \n\' The journals searched were American Economic Review, Bell (Rand) Journal of Econom- \nics, Brookings Papers on Economics and Accounting, Econometrica, Economic Development \nReview, Economica, Economics of Innovation and New Technology, Economics Journal, \nEconomist (Netherlands), In formation Economics & Policy, International Economics Review, \nJournal of Business Finance, Communications of the ACM, Database, Datamation, Decision \nSciences, Harvard Business Review, IEEE Spectrum, IEEE Transactions on Engineering Man- \nagement, IEEE Transactions on Software Engineering, Information & Management, Interfaces, \nJournal of MIS, Journal of Systems Management, Management Science, MIS Quarterly, Opera- \nrions Research, and Sloan Managemenr Review. Articles were selected if they indicated an \nemphasis on computers, information systems, information technology, decision support sys- \ntems, expert systems, or high technology combined with an emphasis on productivity. TABLE I \nPRINCIPAL EMPIRICAL STUDIES OF IT AND PRODUCT~VITY \nCross-sector Manufacturing Services \nAggregate-level studies \n(economy-wide and \nindustry-level) \nMicro-level studies \n(firm and workers) Jonscher (1983, 1994) \nBaily (1986b), Baily & Chakrabarti (1988). \nRoach (1987, 1989b) \nBrooke (1992) \nLau & Tokutsu (1992) \nOliner & Sichel (1994) \nJorgenson & Stiroh (1995) \nOsterman (1986) \nDos Santos er al. (1993) \nKrueger (1993) \nBrynjolfsson & Hitt (1994) \nHitt & Brynjolfsson (1994) \nLichtenberg (1995) \nBrynjolfsson & Hitt (1996) Baily & Gordon (1988) Morrison & Berndt (1991) \nBerndt et al. (1992) \nBerndt & Morrison (1995) \nSiegel & Griliches (1992) \nSiegel (1994) Brand & Duke (1982) \nBaily (1986a) \nRoach (1987, 1989a, 1991) \nLoveman (1994) \nWeill (1992) \nDudley & Lasserre (1989) \nBarua er al. (1991) \nBrynjolfsson & Hitt (1993, 1995, 1996) Cron & Sobol (1983) \nPulley & Braunstein (1984) \nBender (1986) \nBresnahan (1986) \nFranke (1987) \nStrassmann (1985, 1990) \nHarris & Katz (1991) \nParsons et al. (1990) \nDiewert & Smith (1994) INFORMATION TECHNOLOGY AND PRODUCTIVITY 189 \n1973-92 period. At the same time, OCAM capital as a percentage of all \nproducers’ durable equipment (PDE) investment rose from about 0.5% in \nthe 1960s to 12% in 1993. A broader category of IT capital, information \nprocessing equipment (IPE), now constitutes 34.2% of all PDE investment \n(Table 11). Although productivity growth, especially in manufacturing, has \nrebounded somewhat recently, the overall negative correlation between \nproductivity and the advent of computers underlies many arguments that \ninformation technology has not helped the United States’ productivity and \nthat information technology investments have been counterproductive. \n[see, for example, Baily (1986b)l. \nThis argument was made more explicitly by Stephen Roach (1987,1988) \nwho focused on the productivity of information workers. In the past, office \nwork was not very capital intensive, but recently the level of IT capital \nper “white collar” information worker has approached that of production \ncapital per “blue collar” production worker. Concurrently, the ranks of \ninformation workers have ballooned and the ranks of production workers \nhave shrunk. Roach shows that output per production worker grew by \n16.9% between the 1970s and 1986, while output per information worker \ndecreased by 6.6%. He concludes: “America’s productivity shortfall [is] \nconcentrated in that portion of the economy that is the largest employer of \nwhite-collar workers and the most heavily endowed with high-tech capital.” \nRoach’s analysis provided quantitative support for widespread reports of \nlow office productivity.’ \nBut the economy’s productivity record in the 1970s and 1980s cannot be \nblamed on the investment in information technology; many other factors \nalso affect productivity and, until recently, computers were not a major \nshare of the economy. Consider an order of magnitude estimate. In 1992, \nIT capital stock (OCAM) was equal to about 10% of GDP (with a base \nyear of 1987). If, hypothetically, IT’S marginal product were 50% (exceeding \nthe return to most other capital investments), then the level of gross domes- \ntic product (GDP) would be directly increased about 5% (10% X 50%) \nbecause of the current stock of IT. However, information technology capital \nstock did not jump to its current level in 1 year; rather, the increase must \nbe spread over about 30 years, suggesting an average annual contribution \nto aggregate GDP growth of 0.15%. This contribution would be very difficult \nto isolate because so many other factors affected GDP, especially in the \nrelatively turbulent 1970s and 1980s. Indeed, if the marginal product of IT \nFor instance, Lester Thurow (1987) has noted that “the American factory works, the \nAmerican office doesn’t,’’ citing examples from the auto industry indicating that Japanese \nmanagers are able to get more output from blue collar workers (even in American plants) \nwith up to 40% fewer managers. \'1 90 ERIK BRYNJOLFSSON AND SHINKYU YANG \nTABLE I1 \nSELECTED INVESTMENT COMPONENTS IN 1970 AND 1993 \n(CURRENT. DOLLARS) \nPercentage of Percentage of \nInvestment Fixed Investment Fixed \n1970 Investment PDE 1993 Investment PDE \nItem \\ Year ($ Billion) (910) (%) ($ Billion) (%) \nFixed investment 148.1 \nNonresidential 106.7 \ninvestment \nPDE 66.4 \n(nonresidential) \ninformation 14.3 \nprocessing \nOCAM 4.1 \nComputer 2.7 \nIndustrial 20.2 \nTransportation 16.1 equipment \nequipment 100.0 \n72.05 \n44.83 \n9.66 \n2.77 \n1.82 \n13.64 \n10.87 866.7 \n616.1 \n100.00 442.7 \n21.54 151.5 \n6.17 53.7 \n4.07 47 .O \n30.42 96.7 \n24.25 104.2 100.0 \n71.1 \n51.1 100.0 \n17.5 34.2 \n6.2 12.1 \n5.4 10.6 \n11.2 21.8 \n12.0 23.5 \nSources: Survey of Current Business, July 1994; U.S. Bureau of Economic Analysis (1992, \nNote: Information processing equipment: OCAM (office, computing and accounting machin- Vol. 2. Tables 5.4 and 5.8); adapted from Oliner and Sichel (1994). \nery), communication equipment, and scientific and engineering equipment. \ncapital were anywhere from 0 to +65%, it would still not have affected \naggregate GDP growth by more than about 0.2% per year.\" More compre- \nhensive growth accounting exercises confirm this estimate (see Section 5). \nThus, very large changes in capital stock are needed to change total \noutput measurably, although computers may have had significant effects \nin specific activities, such as transaction processing, and on other characteris- \ntics of the economy, such as employment shares, organizational structure, \nand product variety. However, as the information technology stock contin- \nues to grow and the share of the total economy accounted for by computers \nbecomes substantial, we should begin to find changes in the level of aggre- \n\'\" Each white collar worker is endowed with about $10,000 in IT capital, which at a 50% \nROI, would increase his or her total output by about $5000 per year over precomputer levels \nof output. In contrast, it costs about $100,000 or so in salary and overhead to employ a white \ncollar worker. INFORMATION TECHNOLOGY AND PRODUCTIVITY 191 \ngate GDP.” Some recent studies report a high contribution of computers \nto GDP growth [see, for example, Jorgenson and Stiroh (1995)l. \nJust as it is hard to isolate information technology’s effect on the econ- \nomy, white collar productivity cannot be directly inferred from the number \nof information workers per unit of output. For instance, if a new delivery \nschedule optimizer allows a firm to substitute one clerk for two truckers, \nthe increase in the number of white collar workers is evidence of an increase \nin their relative productivity as well as the firm’s productivity. Osterman \n(1986) suggests that such efficiency improvements can explain why firms \noften hire more clerical workers after they introduce computers, and Berndt \net al. (1992) confirm that information technology capital is, on average, a \ncomplement for white collar labor and is correlated with fewer blue collar \nworkers. Berman etal. (1994) also find that the “increased use of nonproduc- \ntion workers is strongly correlated with investment in computers and \nR&D.” Unfortunately, it is exceedlingly difficult to measure directly the \nproductivity of office workers. \nIndependent of its implications for productivity, growth in the white \ncollar workforce cannot be attributed solely to information technology. \nAlthough almost half of workers now use computers in their jobs (Katz \nand Kreuger, 1994), the ranks of information workers began to surge even \nbefore the advent of computers (Porat, 1977). In fact, Jonscher (1994) \nargues that the increased demand for information technology created econ- \nomies of scale and learning in the computer industry, thereby reducing the \ncost of computers. \nIn line with this argument, the unbalanced growth hypothesis may provide \na sensible economic explanation.’* Economic growth may slow down be- \ncause of intrinsically slow technical progress in the white colalr sector, since \nit is less subject to automation. Then why is the white collar sector’s share \nin the economy growing? One possible answer is the higher income elasticity \n(and lower price elasticity) of demand for services of this sector. As income \n” An important study of computer-using workers by Krueger (1993) indirectly supports \nthis view. He found that computer-using workers earned wages 10 to 18% higher than nonusers. \nIn 1984, 24.6% of workers were using computers at work. By 1989, this number had grown \nto 37.4%. Katz and Krueger (1994) also report that this share of workers had risen to 47% \nby 1993. Assuming that workers are paid according to their productivity, this implies that \ncomputers at work increase GDP level by 3% (3% = 0.7 X 0.1 X 37.4%. 0.1 is the excess \nmarginal product, and 0.7 is the labor share of GDP). Although this numbcr is not sufficient \nto compensate for the annual 1% productivity slowdown after the early 1970s. it indicates \nthat information technology may boost office worker productivity. ’’ Sce. for example, Baumol (1967), and Baumol et al. (1985). 192 ERIK BRYNJOLFSSON AND SHINKYU YANG \nincreases, people demand more services of white collar sectors. Thus, even \nif information technology does not add to productivity, companies in devel- \noped countries may be forced to invest in it. Since it is difficult to measure \nwhite collar sector output, the story becomes complicated. Companies in- \nvest in computers to produce “unmeasurables,” as argued in Griliches \n(1994). In short, the increased IT use may not be a source of the productivity \nslowdown, but simply a response to the overall transformation of the econ- \nomy. Furthermore, the main benefits from using computers appear to be \nin areas such as improved quality, variety, timeliness, and customization, \nwhich are not well-measured in official productivity statistics (Brynjolf- \nsson, 1994). \n3. Industry-Level Studies of Information \nTechnology Productivity \nThe preceding section has shown that contrasting the economy-wide \nproductivity slowdown with increasing IT investment is an obtuse ap- \nproach, because so many other factors may intervene. Going down to \nthe firm level helps to control many problems that arise from aggregation, \nbut it is often difficult to find data representative for the whole economy. \nIndustry-level studies may provide a middle-of-the-road alternative. Table \nI11 summarizes some of the important studies. We start with studies on \nservice sectors. \nIt has been widely reported that most of the productivity slowdown is \nconcentrated in the service sector (Schneider, 1987; Roach, 1987, 1991). \nBefore about 1970, service and manufacturing productivity growth rates \nwere comparable, but since then the trends have diverged significantly.I3 \nMeanwhile services have dramatically increased as a share of total employ- \nment and, to a lesser extent, as a share of total output. Because services use \nup to 80% of computer capital (Table IV), the slow growth of productivity in \nthe service sector has been taken as indirect evidence of poor information \n’’ According to government statistics, from 1953 to 1968, labor productivity growth in \nservices averaged 2.56% versus 2.61% in manufacturing. For 1973 to 1979, the figures are \n0.68% versus 1.53%, respectively (Baily, 1986b). However, Gordon and Baily (1989) and \nGriliches (1994,1995) suggest that measurement errors in US. statistics systematically under- \nstate service productivity growth relative to manufacturing. More recently, computers defi- \nnitely have caused some divergence in the statistics on manufacturing and service productivity, \nbut for a very different reason. Because of the enormous quality improvements attributed to \nthe computers, the nonelectrical machinery category (containing the computer-producing \nindustry) has shown tremendous growth. Partly, as a result, overall manufacturing productivity \ngrowth has rebounded from about IS% in the 1970s to 3.5% in the 1980s. TABLE 111 \nINDUSTRY-LEVEL STUDIES \nFindings Study Sector Data Source \nBrand (1982) Services \nRoach (1987, 1989a, 1991) Services \nMorrison & Berndt (1991) Manufacturing \nBerndt etnl. (1992), Berndt & Manufacturing \nSiegel & Griliches (1992) Manufacturing Morrison (1995) \nSiegel (1994) Manufacturing BLS\" \nPrincipally BLS, BEAU \nBEA \nBEA, BLS \nMultiple government sources \nMultiple government sources Productivity growth of 1.3%/yr in banking \nVast increase in IT capital per information worker \nand a decrease in measured output per worker \nIT marginal benefit is 80 cents per dollar invested \nIT not correlated with higher productivity in most \nof industries, but correlated with more labor \nIT-using industries tend to be more productive; \ngovernment data are unreliable \nA multiple-indicators and multiple-causes model \ncaptures significant MFP effects of computers \na BLS, U.S. Bureau of Labor Statistics; BEA, U.S. Bureau of Economic Analysis 194 ERIK BRYNJOLFSSON AND SHINKYU YANG \nTABLE IV \nINVESTMENT IN COMPUTERS (OCAM) IN THE \nUS. ECONOMY (PERCENTAGE OF TOTAL IN \nCURRENT DOLLARS) \n1979 1989 1992 \nIndustry (%) (%) (%) \nAgriculture 0.1 0.1 0.1 \nMining 2.4 1.1 0.9 \nManufacturing 29.4 20.3 20.2 \nConstruction\" 0.1 0.3 0.2 \nNonservice Total 32.0 21.8 21.4 \nCommunication 1.5 1.4 1.5 \nUtilities 1.2 2.8 2.8 \nTrade\" 19.9 16.3 20.0 \nFinance\" 32.5 38.7 37.8 \nOther Services\" 11.6 17.0 13.9 \nServices Total 68.0 78.2 78.6 \nUnmeasurable Sectors\' 64.1 72.3 71.9 \nPlus consumer and 67.7 77.6 77.0 \nUnmeasurable sector output 63 69 70 \nSource: BEA, adapted from Griliches (1995). \nUnmeasurable sectors: construction, trade, fi- \nnance and other services; in these sectors outputs are \ndifficult to measure, relative to measurable sectors. Transportation 1.3 2.0 1.0 \ngovernment purchases \ntechnology productivity. Roach\'s research (1987, 1989a, 1989b, 1991) on \nwhite collar productivity, discussed earlier, focused principally on IT\'S per- \nformance in the service sector. He argued that IT is an effective substitute \nfor labor in most manufacturing industries, but has been associated with \nbloating white collar employment in services, especially finance. He attrib- \nuted this to relatively keener competitive pressures in manufacturing, and \nhe foresees a period of belt-tightening and restructuring in services as they \nbegin to face international competition. \nHowever, studies of manufacturing also found evidence that computers \nmay not increase productivity. Berndt and Morrison analyzed a broader \ndata set from the U.S. Bureau of Economic Analysis (BEA) that encom- \npasses the whole U.S. manufacturing sector. In their first paper (Morrison \nand Berndt, 1991), they examined a series of parameterized models of \nproduction and found evidence that every dollar spent on IT delivered, on \naverage, only about $0.80 of value on the margin, indicating a general \noverinvestment in IT. Their later paper (Berndt and Morrison, 1995) exam- INFORMATION TECHNOLOGY AND PRODUCTIVITY 195 \nined broad correlations of IT investment with labor productivity and multi- \nfactor productivity. This approach did not find a significant difference be- \ntween the productivity of IT capital and other types of capital for a majority \nof the 20 industry categories examined. They did find that investment in \nIT was correlated with increased demand for skilled labor. \nSiegel and Griliches (1992) used industry and establishment data from \na variety of sources to examine several possible biases in conventional \nproductivity estimates. They found a positive simple correlation between an \nindustry’s level of investment in computers and its multifactor productivity \ngrowth in the 1980s. They did not examine more structural approaches, in \npart because of troubling concerns about the reliability of the data and \ngovernment measurement techniques. Their findings contrast with those \nof Berndt and Morrison (1995). However, Berndt and Morrision (1995) \nalso document positive correlations between IT capital and some measures \nof economic performance in the specifications where cross-sectional effects \nwere emphasized. In addition, Berndt and Morrison’s level of aggregation \n(two-digit SIC code) is broader than that of Siegel and Griliches’ (four- \ndigit SIC code). \nMany researchers working on industry-level data express concerns about \ndata problems, which are often caused by aggregation. For example, the \nBEA data are mainly used for industry-level analyses, but it is subject to \nsubtle biases due to the techniques used to aggregate and classify establish- \nments. One of Siegel and Griliches’ (1992) principal conclusions was that \n“after auditing the industry numbers, we found that a non-negligible num- \nber of sectors were not consistently defined over time.” \nSiegel (1994) attempts to tackle the data problems that arise from two \npossible sources of measurement error. The first kind of error occurs when \ncomputer price and quantity are measured with error. The second source \nof error is more subtle: Firms invest in computers not only for cost reduction \nbut also for quality impr~vement.‘~ Because the quality improvement is \nnot fully taken into account in traditional statistics, the errors in output \nmeasurement are correlated with computer investment. These two kinds \nof errors cause bias and inefficiency in estimation. After controlling these \nerrors using a “multiple-indicators and multiple-causes’’ model, Siegel \nfound a significant positive relationship between multifactor productivity \ngrowth and computer investment. He also found that computer investment \nis positively correlated with both product quality and labor quality, a result \nthat is consistent with Brynjolfsson (1994), Berndt and Morrison (1995), \nand Berman et al. (1994). \nl4 See also Brynjolfsson (1994) 196 ERIK BRYNJOLFSSON AND SHINKYU YANG \n4. Firm-Level Studies of Information \nTechnology Productivity \nDuring the past 10 years, many studies examined the relationship between \nfirms’ IT investment and their performance. Interestingly, studies that have \nused larger and more recent data sets have found evidence that IT positively \naffects firm performance. Research results in manufacturing often show \nstronger effects than studies of services, probably because of better mea- \nsurement. \n4.1 Service Sector Studies \nStrassmann (1985) reports disappointing evidence in several studies (see \nTable V for a list of service sector studies). In particular, he found that \nthere was no correlation between IT and return on investment in a sample \nof 38 service sector firms: Some top performers invest heavily in IT, others \ndo not. In his later book (1990), Strassmann concludes that “there is no \nrelation between spending for computers, profits and productivity.” \nSeveral studies have examined IT’s impact on the performance of finan- \ncial services firms. Parsons et al. (1990) estimated a production function \nfor banking services in Canada. They found that the impact of IT on \nmultifactor productivity was quite low between 1974 and 1987. They specu- \nlated that IT has positioned the industry for greater growth in the future. \nSimilarly, Franke (1987) found that IT was associated with a sharp drop \nin capital productivity and stagnation in labor productivity, but remained \noptimistic about the future potential of IT, citing the long time lags associ- \nated with previous “technological transformations” such as the conversion \nto steam power. In contrast, Brand and Duke (1982) used Bureau of Labor \nStatistics (BLS) data and techniques and found that moderate productivity \ngrowth had already occurred in banking. \nHarris and Katz (1991) and Bender (1986) examined data on the insur- \nance industry from the Life Office Management Association Information \nProcessing Database. They found positive but sometimes weak relationships \nbetween IT expense ratios and various performance ratios. Aipar and Kim \n(1991) studied 759 banks and found that a 10% increase in IT capital is \nassociated with a 1.9% decrease in total costs. Several case studies of IT’s \nimpact on performance have also been done. Weitzendorf and Wigand \n(1991) developed a model of information use in two service firms; and \nPulley and Braunstein (1984) studied an information services firm and found \nan association between IT investment and increased economies of scope. \nEstimating a production function, Brynjolfsson and Hitt (1993) found \nthat for the service firms in their sample, gross marginal product averaged TABLE V \nSTUDIES OF FIRMS IN THE SERVICE SECTOR \nStudy Data Source Findings \nPulley & Braunstein (1984) \nClarke (1985) \nStrassmann (1985, 1990) \nBender (1986) \nFranke (1987) \nHarris & Katz (1991) \nNoyelle (1990) \nParsons er al. (1990) \nAlpar and Kim (1991) \nWeitzendorf & Wigand (1991) \nDiewert & Smith (1994) \nBrynjolfsson & Hitt (1995) An info service firm \nCase study \nComputerworld survey of 38 \nLOMA insurance data on \nFinance industry data companies \n132 firms \nLOMA insurance data for 40 \nU.S. and French industry \nInternal operating data from \nLarge number of banks \nInterviews at two companies \nA large Canadian retail firm \nIDG, Compustat, BEA two large banks Significant economies of scope \nMajor business process redesign needed to reap benefits in investment firm \nNo correlation between various IT ratios and performance measures \nWeak relationship between IT and various performance ratios \nIT was associated with a sharp drop in capital productivity and stagnant \nWeak positive relationship between IT and various performance ratios \nSevere measurement problems in services \nIT coefficient in translog production function small and often negative labor productivity \nIT is cost saving, labor saving, and capital using \nInteractive model of information use \nMultifactor productivity grows 9.4% per quarter over six quarters \nMarginal products of IT do not differ much in services and in the \nmanufacturing; firm effects account for 50% of the marginal product \ndifferential 198 ERIK BRYNJOLFSSON AND SHINKYU YANG \nmore than 60% per year. Their 1995 study reports that IT contributes as \nmuch output in the service sector as in the manufacturing sector (Brynjolfs- \nson and Hitt, 1995). Because they used firm-level data, this result suggests \nthat the productivity “slowdown” in the service sector may be an artifact \nof the mismeasurement of output in aggregate data sets. Indeed, even when \nfirms were classified into “measurable” and “unmeasurable” sectors as \ndefined by Griliches (1994), no noticeable difference in IT productivity \nbetween the sectors was found using this firm-level data. \nDiewert and Smith (1994) provide an interesting case study of a large \nCanadian retail distribution firm. They found that the firm experienced an \nastounding 9.4% quarterly multifactor productivity growth for six consecu- \ntive quarters starting at the second quarter of 1988. They argue that “these \nlarge productivity gains are made possible by the computer revolution \nwhich allows a firm to track accurately its purchase and sales of inventory \nitems and to use the latest computer software to minimize inventory hold- \ning costs.” \nMeasurement problems are more acute in services than in manufacturing, \npartly because many service transactions are idiosyncratic, and therefore \nnot amenable to statistical aggregation. Even when data are abundant, \nclassifications sometimes seem arbitrary. For instance, in accordance with \none standard approach, Parsons et al. (1990) treat time deposits as inputs \ninto the banking production function and demand deposits as outputs. The \nlogic for such decisions is sometimes tenuous, and subtle changes in deposit \npatterns or classification standards can have disproportionate impacts. \nThe importance of variables other than IT is also particularly apparent \nin some of the service sector studies. In particular, researchers and consul- \ntants have increasingly emphasized the need to reengineer work when \nintroducing major IT investments.” As Wilson (1995) suggests, it would \nbe interesting to know whether reengineering efforts are the main explana- \ntion for Brynjolfsson and Hitt’s (1993, 1995) findings that IT is correlated \nwith increased output. A recent survey found that, in fact, firms that had \nreengineered were significantly more productive than their competitors \n(B rynjolfsson, 1994). \n4.2 Studies of Manufacturing Sector \nand Cross-Sector Studies \nThere have been several firm-level studies of IT productivity in the \nmanufacturing sector. Some of the important results are summarized in \nIs See, for example. Davenport (1990), Davenport and Short (1993), Hammer (1990). \nHammcr and Champy (1YY3). and Champy (19%). INFORMATION TECHNOLOGY AND PRODUCTIVITY 199 \nTable VI. A study by Loveman (1994) provided some of the first economet- \nric evidence of an IT productivity shortfall, when he examined data from \n60 business units using the Management Productivity and Information Tech- \nnology (MPIT) subset of the Profit Impact of Market Strategy (PIMS) \ndatabase. As is common in productivity literature, he used an ordinary \nleast squares regression and assumed that production functions could be \napproximated by a Cobb-Douglas function. Loveman estimated that the \ncontribution of information technology capital to final output was approxi- \nmately zero over the 5-year period he studied in almost every subsample. \nHis findings were fairly robust to a number of variations on his basic formu- \nlation. \nBarua et al. (1991) traced Loveman’s results back a step by looking at \nIT’S effect on intermediate variables such as capacity utilization, inventory \nturnover, quality, relative price, and new product introduction. Using the \nsame data set, they found that IT was positively related to three of these \nfive intermediate measures, but that the effect was generally too small to \naffect final output measurably. Dudley and Lasserre (1989) also found \neconometric support for the hypothesis that better communication and \ninformation reduce the need for inventories, without explicitly relating this \nto bottom-line performance measures. Using a different data set, Weill \n(1992) disaggregated IT by use and found that significant productivity could \nTABLE VI \nSTUDIES OF MANUFACTURING FIRMS AND CROSS-SECTOR FIRMS \nStudy Data Source Findings \nLoveman (1994) \nDudley & Lasserre \n( 1989) \nWeill (1992) \nBarua et al. (1991) \nBrynjolfsson & \nHitt (1993) \nBrynjolfsson & \nHitt (1995) \nLichtenberg (1995) \nKwon & Stoneman \n(1995) PIMS/MPIT \nUS. and Canadian \nAggregate Data \nValve manufacturers \nPlMSiMPIT \n1DG; Compustat: BEA \nIDG: Compustat: BEA \nIDG; Informationweek \nUK survey (cross sector) IT investments added nothing to output \nIT and communication reduces invcntories \nContextual variables affect IT performance: \ntransaction processing IT produce \npositive results \nnecessarily final output \nover 50% per year in manufacturing \nproductivity benefits of earlier study \neffect is large \ncomputer use, has a positive impact on \noutput and productivity IT improved intermediate outputs, if not \nThe gross marginal product of IT capital is \nFirm effects account for half of the \nIT has excess return; IT staff‘s substitution \nNew technology adoption, cspccially 200 ERIK BRYNJOLFSSON AND SHINKYU YANG \nbe attributed to transactional types of information technology (e.g., data \nprocessing), but was unable to identify gains associated with strategic sys- \ntems (e.g., sales support) or informational investments (e.g., e-mail infra- \nstructure). \nIn a series of studies utilizing large firm-level surveys by International \nData Group (IDG), Brynjolfsson and Hitt report that IT improves produc- \ntivity. Their 1993 study found that while the gross marginal product of \nnoncomputer capital ranges from 4.14 to 6.86%, that of computer capital \naverages 56 to 68%. The results of this and their later study (Hitt and \nBrynjolfsson, 1994) imply that the following three null hypotheses can \nbe rejected: \nH1: IT capital has a zero gross marginal product. \nH2: IT capital has zero net marginal benefit, after all costs have been sub- \nH3: IT capital’s marginal product is not different from that of other tracted. \ncapital. \nTheir point estimates of gross marginal products indicate that at the margin \ncomputer capital generates 10 times more output than other capital of \nequal value. Brynjolfsson and Hitt (1995) show that up to half of the excess \nreturns imputed to IT could be attributed to firm-specific effects. \nIf gross marginal product of information technology capital is really so \nlarge, what friction or market failure prevents firms from investing in more \ncomputers, until the marginal products of all capital goods become equal?I6 \nOne reason is that computer capital has a higher user cost. According to \nOliner and Sichel (1994), from 1970 to 1992 the user cost of computer \ncapital averaged 36.6% per year, while that of other types of capital was \n15.4%.” The remaining portion of the answer may come from adjustment \nor hidden costs of information technology investment, such as the comple- \nmentary organizational investments required to realize the benefits of IT.’’ \nLichtenberg (1995) confirms the results of Brynjolfsson and Hitt, using \nsimilar data and methods. He also analyzes Informationweek survey data \nand uncovers essentially the same results. His formal tests reject the above \nnull hypotheses. Importantly, Lichtenberg extends his study to report the \nI‘ See, for example, Robert J. Gordon’s comment on Oliner and Sichel (1994). \n’* Take 60% per year as Brynjolfsson and Hitt’s (1993) estimate of gross marginal product \nof information technology capital. IT’S marginal product is more than 50% higher than that \nof other types of capital. About 20% (36.6-15.4%) is explained by the user costs of capital \ndifferential. Because the unexplained portion is large, we may expect a considerable amount \nin adjustment costs when implementing IT investment-annual 30% of computer capital stock. The differential is largely due to the rapid decline in computer prices. INFORMATION TECHNOLOGY AND PRODUCTIVITY 20 1 \nmarginal rate of substitution between IT and non-IT workers. At the sample \nmean, one IT worker can apparently be substituted for six non-IT workers. \nResearch in manufacturing generally finds higher returns to IT invest- \nment than in the services, probably because of better measurement. Yet \nthe MPIT data, which both Loveman (1994) and Barua et al. (1991) use, \nmust be scrutinized. Although the point estimates for IT’S contribution \nwere quite low, the standard errors were very high so that the 95% confi- \ndence interval often exceeded 2200% for Loveman’s estimates. These stud- \nies may also be unrepresentative, since the period covered by the MPIT \ndata, 1978-83, was unusually turbulent. \nThe IDG data set, which is among the largest data sets used in this \nresearch area, substantially mitigates data problems, although it contains \ndata on large firms only, and so may not be a representative random sample. \nIndeed, Brynjolfsson and Hitt (1993) attribute the statistical significance \nof their findings partly to the large size of the IDG data set, which enables \nthem to more precisely estimate returns for all factors. Utilizing comprehen- \nsive surveys of the UK engineering industry undertaken in 1981, 1986, and \n1993, Kwon and Stoneman (1995) also find that the use of computers and \nnumerical control machines has increased output and productivity. \n5. Contribution to Consumer Surplus \nand Economic Growth \nSome researchers have identified sizable contributions of IT to consumer \nsurplus and to economic growth. Some important studies are summarized \nin Table VII. Growth accounting and consumer surplus analysis are tech- \nniques to identify and measure “pecuniary externalities,” which Griliches \n(1992,1994) distinguishes from “non-pecuniary externalities of spill-overs.’’ \nPecuniary externalities arise when the price of some input declines. For \nexample, when computer prices are declining exogenously, profit-maximiz- \ning firms substitute computer systems for other input factors, such as labor \nor warehouse space. Lowered prices of computers and other inputs shift \nmarginal cost curves downward. These marginal cost curves result in higher \noutput and lower prices. The output increase is a measure of the pecuniary \nexternality; the benefits created by the computer sector are reflected in \ngreater output of computer-using industries. A second measure of the pecu- \nniary externality is consumer surplus. As computer prices fall, many firms \nand customers that could not afford computers become able to purchase \nthem, whereas the customers who were willing to pay higher prices enjoy \na windfall of price reduction. 202 ERIK BRYNJOLFSSON AND SHINKYU YANG \nTABLE VII \nSTUDIES ON CONTRIBUTION TO CONSUMER SURPLUS AND ECONOMIC GROWTH \nStudy Data Source Findings \nBresnahan (1986) Financial service Large gains in imputed consumer welfare \nLau & Tokutsu \n(1992) sources growth \nBrynjolfsson & \nHitt (1994) \nOliner & Sichel Principally BEA\" Growth contribution of computers is \n(1994) firms \nMultiple government \nIDG,\" Compustat Computer capital contributes half of output \nGrowth contribution of computers is 1% per \nyear among 367 US. large firms \n0.16-0.38% per year varying by different \nassumptions \nJorgenson & Stiroh Principally BEA Growth contribution of computers for the \n1979-92 period is 0.38-0.52% per year \nBrynjolfsson (1995) BEA $70 billion consumer surplus is generated \nannually in the late 1980s. (1995) \nIDG, International Data Group; BEA, US. Bureau of Economic Analysis. \nPecuniary externalities directly increase labor productivity, yet they do \nnot necessarily increase multifactor productivity. Pecuniary externalities \ndo not change the production function, rather they change the input mix. \nIn contrast, nonpecuniary externalities, or spill-overs, arise from technical \nchange; people may have found smarter ways of making goods and services \nusing information techn~logy.\'~ The production possibility frontier shifts \nout; both labor productivity and multifactor productivity should go up. \nBresnahan (1986) estimated the benefits to consumers of declining com- \nputer prices. Using the hedonic price index method?\' he calculates that \nthe consumer surplus was five or more times that of computer expenditures \nin the late 1960s financial sector. Adopting similar assumptions, Brynjolfs- \nson (1995) estimates that, in 1987, between $69 billion and $79 billion \nconsumer surplus was generated by $25 billion in expenditures on informa- \ntion technology capital. \nNow we turn to several growth accounting results. Jorgenson and Stiroh\'s \n(1995) comprehensive growth accounting found that from 1979 to 1985 \ncomputers and peripherals contributed to output growth by 0.52% per year, \nand that from 1985 to 1992, the contribution was 0.38% per year (see Table \n\'\' Bresnahan and Trajtenberg (1995) argue that \"general purpose technologies,\" like com- \nputers, engender waves of smaller and complementary innovations. This creates the potential \nfor positive externalities from IT, and thus the possibility that IT investment is too low, \ncompared to the socially optimal level. \'\" The hedonic price index method is an attempt to incorporate quality changes when \nconstructing price indices using the regression technique. See Chapter 4 in Berndt (1991). INFORMATION TECHNOLOGY AND PRODUCTIVITY 203 \nVIII).21 Because they assume that computers maintain their full ability \nuntil retirement, their estimation of computer capital’s contribution be- \ncomes larger than that of Oliner and Sichel (1994). \nOliner and Sichel(l994) carefully examine how the various excess return \nhypotheses of computer capital affect growth. As a baseline they estimate \nthat the contribution of computer capital to output growth is 0.16% per \nyear for the 1970-92 period. Using Romer’s (1986, 1987) assumption that \nphysical capital provides a positive externality, the contribution goes up to \n0.32%. Brynjolfsson and Hitt’s (1993) higher estimate for the return on \ncomputer capital raises the contribution to 0.35%. They also try to incorpo- \nrate Alan Krueger’s (1993) result of return on workers’ computer use. If \nthe return is equal to the difference in the marginal product between \ncomputer-using workers and nonusing workers, the contribution is 0.38%. \nOliver and Sichel claim that an annual contribution of up to 0.38% is not \nlarge enough to offset the approximately 1% drop in output growth since \nthe 1970~~~ \nThe following rough calculation may provide some intuition about the \nsize of the contribution of computers to national output. From Jorgenson \nand Stiroh (1995), we take the simple average contribution for the 1979-92 \nperiod or 0.45%. We compare it with the 0.72% contribution of other capital. \nThe share of computers in total capital stock was 1.6% in 1993, implying \nthat 1 unit of computer capital contributes as much to the growth of output \nas 98 units of other forms of capital. In 1993, GDP grew by $173 billion.23 \nComputers contributed $29 billion; other capital contributed $46 billion. \nThe unexplained residual (MFP) contribution is $40 billion. A rough esti- \nmate shows that the implicit marginal product of computer capital in Jorgen- \nson and Stiroh’s study is more than 60%.24 \nUsing data from 367 large firms that together generated $1.8 trillion in \noutput per year from 1982 to 1992, Brynjolfsson and Hitt (1994) provide \n*’ The contribution dropped because the growth rate of real computer capital is lower for \nthe 1079-85 period than for the 1985-92 period; nominal investment of computers did not \nincrease much during the 1985-92 period. \n22 However, an alternative view is that the glass is half-full; Jorgenson calls 0.38% “a pretty \nhefty contribution” (personal letter, Feb. 7, 1995). \n23 Survey of Current Business, March 1994, Table 1-1, nominal dollars. \n24 One of the standard growth accounting assumptions is that factors are paid according \nto their marginal product. Jorgenson and Stiroh report 0.38% growth contribution for the \nperiod 1985-92. The 0.38% is computers’ nominal income share times computer capital’s \ngrowth rate. By their data, we can also estimate computer capital’s growth rate during the \n1985-87 period (24%). Now computers’ nominal income share is equal to (computers capital’s \nmarginal product X computer capitaliGDP). In 1987, computer capital stock amounted to \n$1 13.24 billion and GDP was $4.5399 trillion, thus the implicit marginal product of computers \nis estimated to 63% = (0.38%)* ($4539.9/$113.24)/(24%). TABLE VIII \nGROWTH RATES OF AGGREGATE OUTPUT AND CONTRIBUTION OF FACTORS (1947-92) \nValue Added Growth Contribution \nVariable Annual Noncomp Noncomp Multifactor \nPeriod Growth Share Computer Share Capital Share Computer Share Labor Productivity \n47-92 3.42 3.33 0.09 1.47 1.26 0.21 0.92 1.03 \n47-53 5.46 5.46 0.00 1.92 1.92 0.00 1.26 2.27 \n53-57 2.14 2.14 0.00 1.42 1.42 0.00 0.19 0.53 \n57-60 2.39 2.37 0.02 0.83 0.83 0.00 -0.01 1.57 \n60-66 5.38 5.30 0.08 1.46 1.36 0.10 1.44 2.48 \n66-69 2.61 2.54 0.07 1.93 1.74 0.20 1.16 -0.49 \n69-73 3.67 3.60 0.08 1.64 1.40 0.24 0.74 1.29 \n73-79 2.63 2.50 0.12 1.45 1.19 0.26 1.28 -0.10 \n79-85 2.89 2.65 0.24 1.28 0.76 0.52 0.83 0.78 \n85-92 2.49 2.38 0.12 1.26 0.88 0.38 0.76 0.47 \n~ ~ ~ \nSource: Adapted from Jorgenson and Stiroh (1995). INFORMATION TECHNOLOGY AND PRODUCTIVITY 205 \nan interesting growth accounting result. For their sample of firms, IT capital \ncontributes about 1% per annum to output growth-a larger growth contri- \nbution than that of ordinary capital in absolute value. Lau and Tokutsu \n(1992) calculate an even bigger contribution to growth, attributing approxi- \nmately half of the real output growth (1.5% growth per annum) during the \npast three decades to computer capital. They also argue that the annual \nrate of inflation dropped by 1.2% per year because of the rapid decline \nin computer prices. In line with these studies, Roy Radner suggests that \n“productivity growth has slowed down for other reasons, unrelated to the \nIT story. Without IT, things would have been worse, and output growth \nwould have been lower” (Griliches, 1995). \nIn summary, the weight of evidence from various studies indicates that \ninformation technology capital generates billions of dollars annually for \nthe U.S. economy, both in terms of output growth and consumer surplus. \nMeanwhile, the recent firm-level analyses of Brynjolfsson and Hitt (1993, \n1995) and Lichtenberg (1995) have begun to remedy the shortfall of evi- \ndence regarding the productivity contribution of IT. \n6. Conclusion: Where Do We Go from Here? \nSections 2, 3, 4, and 5 reviewed the principal empirical literature on the \nproductivity of information technology. Looking at the simple relationship \nbetween the productivity slowdown of the whole U.S. economy and the \nrapid growth of computer capital is too general an approach. Poor data \nquality for IT outputs and inputs has exacerbated this problem. Due to \nthe application of improved methodologies and the identification of more \nreliable and larger data sets, researchers have made some progress with \nindustry-level and firm-level studies. Recently, some researchers have found \npositive effects of IT. Careful growth accounting exercises and estimation \nof production and cost functions for specific sectors or industries can provide \nsharper insights. Consumer surplus analyses are useful exercises for identify- \ning alternative ways to triangulate IT value. These studies suggest that \nwithout IT, the U.S. economy would probably be in a worse situation than \nit is. This section proposes further research questions and methodologies. \nThe first priority is to improve the data and the measurement techniques. \nGovernment statistics, especially in services and for information workers, \nhave not kept up with the growing importance and complexity of these \nsectors. Therefore, researchers may have to perform their own corrections \non the data, turn to private sources of secondary data, or gather data \nthemselves. Researchers should make their data available to other research- \ners so that a cumulative tradition can be maintained. The studies of Weill 206 ERIK BRYNJOLFSSON AND SHINKYU YANG \n(1992), Dos Santos et al. (1993), and Brynjolfsson and Hitt (1993, 1995) \nare examples of new data identification and development. \nOne effective way to identify possible gaps in the data is to compare \nthem with the benefits that managers and customers expect from IT, such \nas quality, timeliness, customer service, flexibility, innovation, customiza- \ntion, and variety. In principle, many of these benefits are quantifiable. In \nfact, some firms already attempt such an analysis in their capital budgeting \nand justification processes. In addition, many companies have developed \nelaborate measurement programs, for example, as part of total quality \nmanagement. These programs augment or even supersede financial ac- \ncounting measures and can serve as a foundation for more refined metrics \n(Kaplan and Norton, 1992). \nMany economists also have tried various methods to overcome the short- \nfall of government statistics, and to incorporate quality changes when esti- \nmating price indices. The long history of hedonic price index method is a \ngood example, but some economists argue that even the hedonic method \ndoes not capture all the benefits associated with product innovation and \ndifferentiation. Trajtenberg (1990) devises a new method of quality- \nadjusted price index calculation, adopting the discrete choice model.2s \nFisher and Griliches (1995) argue that if new inexpensive (quality-adjusted) \ngoods are introduced and gain market share at the expense of existing \ngoods, the official statistics by the BLS will seriously overestimate infla- \ntion.26 Hausman (1994) also reports a 20 to 25% overestimation of the \nconsumer price index for ready-to-eat cereals, based on his analysis of \nApple Cinnamon Cheerios. \nUnfortunately, for many services, even basic output measures must be \ncreated, because government and accounting data records only inputs. Baily \nand Gordon (1988) and Noyelle (1990), among others, have done much to \nimprove measurement in areas such as banking and retailing, while rela- \ntively good statistics can be compiled from private sources in areas such as \npackage delivery. Unfortunately, the individualized nature of many services \ndefies aggregation. The output of a lawyer, manager, or doctor cannot be \nextrapolated from the number of meetings attended, memoranda written, \nor medications provided. The complexity of the “diagnostic-related group” \napproach to valuing medical care is both a step in the right direction \nand a testament to these difficulties. A researcher who seeks to measure \n*’ For the period of 1973-82, Trajtenberg’s price deflator for the computed tomography \nscanner industry averages minus 55&; in contrast, the hedonic price index shows a 13% decline \nand government price statistics indicate a 9% increase. ’‘ Empirical evidence for their argument is presented in Griliches and Cockburn (1994). \nThey show that the adjusted price index for the cephalexin drug during the 1987-91 period \ndropped by 30 to 53%; the official figure records a 14% increase. INFORMATION TECHNOLOGY AND PRODUCTIVITY 207 \nrigorously the productivity of service industries generally must undertake \nthis detailed work before jumping to conclusions based on input-based \nstatistics. Similarly, disaggregating heterogeneous types of IT by use, as \nWeill (1992) did in a manufacturing study, can increase the resolution of \nstandard statistical techniques. \nBecause so many factors affect firm performance, it is generally impossi- \nble to distinguish the impact of IT using simple bivariate correlations, It is \nessential to control for other factors such as other inputs and their prices, \nthe macroeconomic environment, demand schedules for output, and the \nnature of competition. Because many unobservable factors affect either \nthe whole industry or one firm persistently, examining a panel consisting \nof both time series and cross-sectional data is the best approach, where fea- \nsible. \nImportantly, we must remember that our tools are still blunt. Managers \ndo not always recognize this and tend to rely too much on any one study \nof IT and productivity. While the studies usually state the limitations of \nthe data and methods, sometimes only the surprising conclusions are re- \nported by the media. Because significant investment decisions are based \non these  conclusion^,^^ researchers must be doubly careful to communicate \nthe limitations of their work. \nResearchers might also look to business for profitable research questions. \nA recurrent theme in the business press is the idea that information technol- \nogy should not so much help us produce more of the same things as allow \nus to do entirely new things in new ways.28 For instance, Watts (1986) \nfinds that information technology investments cannot be justified by cost \nreductions alone, but that instead managers should look to increased flexi- \nbility and responsiveness, whereas Brooke (1992) writes that information \ntechnology leads to greater variety but lower productivity as traditionally \nmeasured. Diewert and Smith’s (1994) study makes another interesting \npoint with respect to variety. They show that while IT facilitates great \nefficiency in inventory management, aggregate inventory level of the US. \neconomy did not shrink during the past 40 years, as reported by Blinder \nand Maccini (1991). Diewert and Smith argue that “a wide spread prolifera- \ntion of new products into the world economy” results in no macro-level \ninventory change even when great micro-level improvements have been \nmade. \n27 For instance. the stock prices of major IT vendors appeared to change significantly in \nresponse to a Wall Street Journal article on IT productivity (Dos Santos et al., 1991). \n” See, for example, Applegate and Mills (1988). Benjamin era/. (1984), Champy (1995). \nCecil and Hall (1988) Davenport (lYY3), Hammer and Champy (19Y3), Malone and Rockart \n(1991), Porter and Miller (1985), and Watts (1986). 208 ERIK BRYNJOLFSSON AND SHINKYU YANG \nThis literature highlights how difficult and perhaps inappropriate it would \nbe to tr', 'raytos.r.bsinfotech@gmail.com', 'ERIK BRYNJOLFSSON AND SHINKYU YANG ', '', '../pdf_files/674e8da73e359-Information Technology and Productivity - A Review of the Literature.pdf', 2304654, 36, 12896, 88071, '2024-12-03 04:50:25', '', 'Not Accepted', 0, 1);
INSERT INTO `archive_research` (`id`, `archive_id`, `student_id`, `department_id`, `course_id`, `project_title`, `dateOFSubmit`, `project_year`, `project_abstract`, `keywords`, `content`, `research_owner_email`, `project_members`, `project_picture`, `documents`, `file_size`, `page_count`, `word_count`, `character_count`, `submission_date`, `date_published`, `document_status`, `read_status`, `inbox_read`) VALUES
(79, '4134983947', '51', 12, 1, 'STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS ', '2024-12-03 18:39:19.024207', '2024', 'STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS STATUS OF THE IMPLEMENTATION OF THE E-LEARNING CLASSROOM   IN SELECTED HIGHER EDUCATION INSTITUTIONS ', 'plagiarized test', 'The\nprimary\naim\nof\nthis\npaper\nis\nto\nuse\nsimulations\nto\ntackle\nthe\nprob\nlem\nof\npricing\nQuanto\noptions\non\ntwo\nand\nthree\nunderlying\nassets\nunder\nstochastic\ncorrelation\nand\nvolatility\ndriven\nby\ndifferent\nstochastic\ndifferential\nequations\n(SDEs).\nThe\nfollowing\nmodels\nare\ntested\nand\ncompared:\nHes\nton,\nGARCH,\nGARCH-Jump,\n3/2\ndiffusion,\nand\nBates\nfor\nvolatility,\nand\nJacobi,\nWright-Fisher\ndiffusion,\nWeibull\ndiffusion,\nand\na\nmean-reverting\nSC\nfor\ncorrelation.\nThe\nstudy\nis\nfocused\nspecifically\non\nQuanto\noptions\non\ntwo\nor\nthree\nforeign\nequity\nmarket\nindices.\nThese\noptions\nact\nlike\na\nbasket\ncor\nrelation\noption\nwith\nthe\npayoff\ndepending\non\nmultiple\ncorrelated\nassets\nbut\nalso\non\nexchange\nrates\nbetween\nthe\ncurrencies\nof\nthe\nindices.\nWe\ntest\nthree\ndifferent\nmodels\nof\nexchange\nrate\ndynamics,\nwith\nboth\nrates\nbeing\neither\nGBM,\na\nmean\nreverting\nSDE\ninspired\nby\nthe\nOU\nprocess,\nor\nan\nexponential\nlevy\nprocess\nthat\nincorporates\njumps.\nApplications\nto\nwater-solvated\nsystems\ndemonstrate\nthat\nthis\napproach\nachieves\nunprecedented,\nvery\nrapid\nconvergence\nto\nchemical\naccuracy\nas\nthe\nsize\nof\nthe\nQM\nsubsystem\nincreases.\nWe\nvalidate\nthe\nmethod\nwith\nseveral\npilot\nstudies,\nincluding\nwater\nbulk,\nwater\nclusters\n(prism\nhexamer\nand\npentamers),\nsolvated\nglucose,\na\npalladium\naqua\nion,\nand\na\nwet\nmonolayer\nof\nMoS', 'raytos.r.bsinfotech@gmail.com', 'Xin Chen, Jessica A. Martinez B., Xuecheng Shao, Marc Riera, Francesco  Paesani, Oliviero Andreussi, and Michele Pavanello', '', '../pdf_files/674edfd6e1dea-TESTING 1.pdf', 30046, 1, 195, 1290, '2024-12-03 10:40:54', '2024-12-03', 'Accepted', 0, 1);

-- --------------------------------------------------------

--
-- Table structure for table `archive_research_views`
--

CREATE TABLE `archive_research_views` (
  `id` int(11) NOT NULL,
  `archive_research_id` varchar(13) NOT NULL,
  `student_id` int(11) NOT NULL,
  `date_of_views` date NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `archive_research_views`
--

INSERT INTO `archive_research_views` (`id`, `archive_research_id`, `student_id`, `date_of_views`) VALUES
(1, '7281507465', 1, '2024-11-27'),
(2, '3967794083', 1, '2024-11-28'),
(3, '3967794083', 1, '2024-11-28'),
(4, '2680556192', 26, '2024-11-28'),
(5, '7281507465', 26, '2024-11-28'),
(6, '8220120796', 32, '2024-11-29'),
(7, '7281507465', 32, '2024-11-29'),
(8, '7281507465', 33, '2024-11-29'),
(9, '6005762357', 33, '2024-11-29'),
(10, '6005762357', 33, '2024-11-29'),
(11, '6005762357', 33, '2024-11-29'),
(12, '7281507465', 34, '2024-11-29'),
(13, '1704859159', 34, '2024-11-29'),
(14, '2460559462', 34, '2024-11-29'),
(15, '2901515339', 34, '2024-11-29'),
(16, '2901515339', 1, '2024-11-29'),
(17, '7281507465', 35, '2024-11-29'),
(18, '4549105180', 35, '2024-11-29'),
(19, '2901515339', 35, '2024-11-29'),
(20, '7281507465', 36, '2024-11-29'),
(21, '4549105180', 1, '2024-11-30'),
(22, '4549105180', 1, '2024-11-30'),
(23, '7281507465', 1, '2024-11-30'),
(24, '7281507465', 1, '2024-11-30'),
(25, '7281507465', 1, '2024-11-30'),
(26, '7281507465', 1, '2024-11-30'),
(27, '7281507465', 1, '2024-11-30'),
(28, '7281507465', 1, '2024-11-30'),
(29, '7281507465', 1, '2024-11-30'),
(30, '7281507465', 1, '2024-11-30'),
(31, '7281507465', 1, '2024-11-30'),
(32, '7281507465', 1, '2024-11-30'),
(33, '7281507465', 1, '2024-11-30'),
(34, '7281507465', 1, '2024-11-30'),
(35, '7281507465', 1, '2024-11-30'),
(36, '7281507465', 1, '2024-11-30'),
(37, '7281507465', 1, '2024-11-30'),
(38, '7281507465', 1, '2024-11-30'),
(39, '7281507465', 1, '2024-11-30'),
(40, '7281507465', 1, '2024-11-30'),
(41, '7281507465', 1, '2024-11-30'),
(42, '7281507465', 1, '2024-11-30'),
(43, '7281507465', 1, '2024-11-30'),
(44, '7281507465', 1, '2024-11-30'),
(45, '7281507465', 1, '2024-11-30'),
(46, '7281507465', 1, '2024-11-30'),
(47, '7281507465', 1, '2024-11-30'),
(48, '7281507465', 1, '2024-11-30'),
(49, '7281507465', 1, '2024-11-30'),
(50, '7281507465', 1, '2024-11-30'),
(51, '7281507465', 1, '2024-11-30'),
(52, '7281507465', 1, '2024-11-30'),
(53, '7281507465', 1, '2024-11-30'),
(54, '4549105180', 1, '2024-11-30'),
(55, '4549105180', 1, '2024-11-30'),
(56, '4549105180', 1, '2024-11-30'),
(57, '4549105180', 1, '2024-11-30'),
(58, '4549105180', 1, '2024-11-30'),
(59, '4549105180', 1, '2024-11-30'),
(60, '4549105180', 1, '2024-11-30'),
(61, '4549105180', 1, '2024-11-30'),
(62, '4549105180', 1, '2024-11-30'),
(63, '7281507465', 1, '2024-11-30'),
(64, '9835465462', 1, '2024-11-30'),
(65, '9835465462', 1, '2024-11-30'),
(66, '9835465462', 1, '2024-11-30'),
(67, '9835465462', 1, '2024-11-30'),
(68, '9835465462', 1, '2024-11-30'),
(69, '9835465462', 1, '2024-11-30'),
(70, '9835465462', 1, '2024-11-30'),
(71, '9835465462', 1, '2024-11-30'),
(72, '9835465462', 1, '2024-11-30'),
(73, '9835465462', 1, '2024-11-30'),
(74, '3628018459', 1, '2024-12-01'),
(75, '2901515339', 1, '2024-12-01'),
(76, '2901515339', 1, '2024-12-01'),
(77, '2901515339', 1, '2024-12-01'),
(78, '9075194517', 1, '2024-12-01'),
(79, '9075194517', 1, '2024-12-01'),
(80, '2901515339', 1, '2024-12-01'),
(81, '5217627810', 1, '2024-12-01'),
(82, '9835465462', 1, '2024-12-01'),
(83, '7281507465', 37, '2024-12-01'),
(84, '7281507465', 37, '2024-12-01'),
(85, '2194359980', 37, '2024-12-01'),
(86, '7281507465', 37, '2024-12-01'),
(87, '1545767915', 1, '2024-12-02'),
(88, '7281507465', 38, '2024-12-02'),
(89, '7665704852', 38, '2024-12-02'),
(90, '7281507465', 38, '2024-12-02'),
(91, '7281507465', 39, '2024-12-02'),
(92, '7281507465', 41, '2024-12-02'),
(93, '8103123931', 1, '2024-12-02'),
(94, '8103123931', 47, '2024-12-02'),
(95, '8103123931', 48, '2024-12-02'),
(96, '8103123931', 49, '2024-12-02'),
(97, '7281507465', 50, '2024-12-02'),
(98, '7281507465', 51, '2024-12-03'),
(99, '8103123931', 52, '2024-12-03'),
(100, '1545767915', 51, '2024-12-03'),
(101, '2901515339', 51, '2024-12-03'),
(102, '5217627810', 51, '2024-12-03');

-- --------------------------------------------------------

--
-- Table structure for table `course`
--

CREATE TABLE `course` (
  `id` int(11) NOT NULL,
  `department_id` int(11) NOT NULL,
  `course_name` varchar(250) NOT NULL,
  `course_status` varchar(80) NOT NULL DEFAULT 'Active'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `course`
--

INSERT INTO `course` (`id`, `department_id`, `course_name`, `course_status`) VALUES
(1, 12, 'BS Information Technology', 'Active'),
(2, 12, 'BS Computer Science', 'Active'),
(3, 3, 'BSIT Major in Food Technology', 'Active'),
(4, 2, 'BS Architecture', 'Active'),
(5, 5, 'BSBA Major in Marketing Management', 'Active'),
(6, 5, 'BS Office Administration', 'Active'),
(7, 4, 'BS Computer Engineering', 'Active'),
(8, 4, 'BS Civil Engineering', 'Active'),
(9, 6, 'BS Secondary Education Major in TLE', 'Active'),
(10, 6, 'BTLE Major in Home Economics', 'Active'),
(11, 4, 'BS Electronics and Communication Engineering', 'Not Active'),
(12, 4, 'BS Electronics Engineering', 'Not Active'),
(13, 4, 'BS Electrical Engineering', 'Not Active'),
(14, 7, 'BS Hospitality Management', 'Active'),
(15, 1, 'BS Psychology', 'Active'),
(16, 1, 'BS Mathematics', 'Active'),
(17, 6, 'Bachelor in Special Needs Education', 'Active'),
(18, 11, 'BS Criminology', 'Not Active'),
(19, 5, 'BS Public Administration', 'Active'),
(20, 7, 'BS Hospitality Management Major in Hotel Management', 'Active'),
(21, 7, 'BS Hospitality Management Major in Culinary Arts', 'Active'),
(22, 7, 'BS Hospitality Management Major in Cruise Line Operations', 'Active'),
(23, 2, 'Bachelor of Fine Arts Major in Visual Communication', 'Active'),
(24, 6, 'BTLE Major in Industrial Arts', 'Active');

-- --------------------------------------------------------

--
-- Table structure for table `departments`
--

CREATE TABLE `departments` (
  `id` int(11) NOT NULL,
  `dept_code` varchar(50) NOT NULL,
  `name` varchar(150) NOT NULL,
  `description` varchar(1000) NOT NULL,
  `department_status` varchar(20) NOT NULL DEFAULT 'Active'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `departments`
--

INSERT INTO `departments` (`id`, `dept_code`, `name`, `description`, `department_status`) VALUES
(1, 'CAS', 'College of Arts and Science', '', 'Active'),
(2, 'CAFA', 'College of Architecture and Fine Arts', '', 'Not Active'),
(3, 'CIT', 'College of Industrial Technology', '', 'Not Active'),
(4, 'CEN', 'College of Engineering', '', 'Not Active'),
(5, 'CBPA', 'College of Business and Public Administration', '', 'Not Active'),
(6, 'COE', 'College of Education', '', 'Not Active'),
(7, 'CHM', 'College of Hospitality Management', '', 'Not Active'),
(11, 'CCJE', 'College of Criminology and Justice Education', '', 'Not Active'),
(12, 'CCS', 'College of Computer Studies', '', 'Active'),
(18, 'COEX', 'College of Example', '', 'Active');

-- --------------------------------------------------------

--
-- Table structure for table `plagiarism_results`
--

CREATE TABLE `plagiarism_results` (
  `id` int(11) NOT NULL,
  `archive_id` int(11) NOT NULL,
  `submitted_sentence` text NOT NULL,
  `existing_sentence` text NOT NULL,
  `similar_archive_id` int(11) NOT NULL,
  `similarity_percentage` float NOT NULL,
  `is_plagiarized` tinyint(1) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `plagiarism_results`
--

INSERT INTO `plagiarism_results` (`id`, `archive_id`, `submitted_sentence`, `existing_sentence`, `similar_archive_id`, `similarity_percentage`, `is_plagiarized`) VALUES
(7452, 62, 'the remainder of this paper is organized as follows', 'the remainder of our paper is as follows', 15, 76.3642, 1),
(9270, 73, 'the main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of information technology it knowledge from basic to a dvance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 'the main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of information technology it knowledge from basic to a dvance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 55, 100, 1),
(9271, 73, 'the main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of information technology it knowledge from basic to a dvance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 'on one hand t he main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of it knowledge from basic to advance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 55, 88.6531, 1),
(9272, 73, 'the content of this course is set up to meet the standard 4 in cdio', 'the content of this course is set up to meet the standard 4 in cdio', 55, 100, 1),
(9273, 73, 'we divide the introduction into two cou rses and teach the first year students in the first and second semesters', 'we divide the introduction into two cou rses and teach the first year students in the first and second semesters', 55, 100, 1),
(9274, 73, 'we divide the introduction into two cou rses and teach the first year students in the first and second semesters', 'we divide the content of iit into two courses and teach the first year students in the first and second semesters', 55, 75.2759, 1),
(9275, 73, 'the first course is the introduction of computer computing internet ethics and some technical skills of analysis design implementation and testing', 'the first course is the introduction of computer computing internet ethics and some technical skills of analysis design implementation and testing', 55, 100, 1),
(9276, 73, 'this is an overview of it from the outside rs', 'this is an overview of it from the outside rs', 55, 100, 1),
(9277, 73, 'this is an overview of it from the outside rs', 'this is an overview of it from outside viewpoint', 55, 72.4799, 1),
(9278, 73, 'the second is a hierarchy of it knowledge from basic to advance through education systems and research in our faculty', 'the second is a hierarchy of it knowledge from basic to advance through education systems and research in our faculty', 55, 100, 1),
(9279, 73, 'the second is a hierarchy of it knowledge from basic to advance through education systems and research in our faculty', 'the second is a hierarchy of it knowledge from basic to advance through systems of education and research in our f aculty', 55, 83.8186, 1),
(9280, 73, 'this is an overview of it from inside viewpoint', 'this is an overview of it from inside viewpoint', 55, 100, 1),
(9281, 73, 'this is an overview of it from inside viewpoint', 'this is an overview of it from outside viewpoint', 55, 75.0912, 1),
(9282, 73, 'this is an overview of it from inside viewpoint', 'this is an overview of it from inside viewpoint of our faculty', 55, 89.3801, 1),
(9283, 73, 'we also present some experiences about the project based approach fo r labs an d explain how we train person al skills and professional attitude for our students', 'we also present some experiences about the project based approach fo r labs an d explain how we train person al skills and professional attitude for our students', 55, 100, 1),
(9284, 73, 'many similar work s in engineering ha ve been published in the cdio conference', 'many similar work s in engineering ha ve been published in the cdio conference', 55, 100, 1),
(9285, 73, '2 presented a method that they have conceived designed and implement ed introduction to engineering course at telecom bcn upc barcelona using the cdio syllabus and standards', '2 presented a method that they have conceived designed and implement ed introduction to engineering course at telecom bcn upc barcelona using the cdio syllabus and standards', 55, 100, 1),
(9286, 73, 'the basic concepts and professional skills were given to the students through lessons and simple projects', 'the basic concepts and professional skills were given to the students through lessons and simple projects', 55, 100, 1),
(9287, 73, 'from that the students were able to recognize problems of which solutions we were going to teach in the following courses o f the curriculum', 'from that the students were able to recognize problems of which solutions we were going to teach in the following courses o f the curriculum', 55, 100, 1),
(9288, 73, '3 introduced the implementation of the cornerstone project', '3 introduced the implementation of the cornerstone project', 55, 100, 1),
(9289, 73, 'they transform ed the name of introduction to civil engineering into introduction to civil engineering design', 'they transform ed the name of introduction to civil engineering into introduction to civil engineering design', 55, 100, 1),
(9290, 73, 'the difference is that students are put into an environment where they could learn and use knowledge and professional skills to study design actively', 'the difference is that students are put into an environment where they could learn and use knowledge and professional skills to study design actively', 55, 100, 1),
(9291, 73, '4 introduced one approach of multi disciplinary project for the introduction course', '4 introduced one approach of multi disciplinary project for the introduction course', 55, 100, 1),
(9292, 73, 'in his class the students were divided into different disciplinary group s and join ed in project based learning', 'in his class the students were divided into different disciplinary group s and join ed in project based learning', 55, 100, 1),
(9293, 73, 'that project required student s to design and build a computer controlled tower crane at shantou university', 'that project required student s to design and build a computer controlled tower crane at shantou university', 55, 100, 1),
(9294, 73, 'this process help ed students to understand the different modules and the inputoutput of each module', 'this process help ed students to understand the different modules and the inputoutput of each module', 55, 100, 1),
(9295, 73, 'as a result the multi disciplinary p roject i s a good approach to introduction courses', 'as a result the multi disciplinary p roject i s a good approach to introduction courses', 55, 100, 1),
(9296, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university goran gustafsson et', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university goran gustafsson et', 55, 100, 1),
(9297, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university goran gustafsson et', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university project house prototype building a', 55, 70.0372, 1),
(9298, 73, '5 presented his work of engineering education program s the first year introductory course was discussed and shared to improve and increase student motivation', '5 presented his work of engineering education program s the first year introductory course was discussed and shared to improve and increase student motivation', 55, 100, 1),
(9299, 73, 'they have identified projects and teamwork as important parts of the firstyear courses', 'they have identified projects and teamwork as important parts of the firstyear courses', 55, 100, 1),
(9300, 73, 'with the cdio approach a new model for engineering education is developed to be able to implement this projects and professional skills', 'with the cdio approach a new model for engineering education is developed to be able to implement this projects and professional skills', 55, 100, 1),
(9301, 73, 'in many previous work s we rarely see the firstyear introductory course to information technology it', 'in many previous work s we rarely see the firstyear introductory course to information technology it', 55, 100, 1),
(9302, 73, 'in this paper w e present our experience in designing a course of introduction to information technology iit for the first year students', 'in this paper w e present our experience in designing a course of introduction to information technology iit for the first year students', 55, 100, 1),
(9303, 73, 'on one hand t he main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of it knowledge from basic to advance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 'the main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of information technology it knowledge from basic to a dvance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 55, 88.6531, 1),
(9304, 73, 'on one hand t he main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of it knowledge from basic to advance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 'on one hand t he main purpose of this course is to introduce the concepts of computing and computer and to present a hierarchy of it knowledge from basic to advance through the introduction of syllabus system research trends of our faculty it applications in society ethics and career potentials in it', 55, 100, 1),
(9305, 73, 'on the other hand the purpose of this course will introduce the relationship between the contents of 4 year learning in the university with it career after graduation to first year students', 'on the other hand the purpose of this course will introduce the relationship between the contents of 4 year learning in the university with it career after graduation to first year students', 55, 100, 1),
(9306, 73, 'the iit course also shows students the social requirements to it not only in vietnam but also worldwide', 'the iit course also shows students the social requirements to it not only in vietnam but also worldwide', 55, 100, 1),
(9307, 73, 'after studying this course the first year student will have another point of view about their role in the development of it', 'after studying this course the first year student will have another point of view about their role in the development of it', 55, 100, 1),
(9308, 73, 'from that starting point it will help student s to think and navigate their future career in it', 'from that starting point it will help student s to think and navigate their future career in it', 55, 100, 1),
(9309, 73, 'it also influences to students decision in course selections for undergraduate program at the current time or their intention to enter the graduate program in the future', 'it also influences to students decision in course selections for undergraduate program at the current time or their intention to enter the graduate program in the future', 55, 100, 1),
(9310, 73, 'this course wi ll also help the students to identify the importance of engineering skills and appropriate attitudes for the success in their future career path', 'this course wi ll also help the students to identify the importance of engineering skills and appropriate attitudes for the success in their future career path', 55, 100, 1),
(9311, 73, 'from the above mot ivation the design and implementation of this course have been considered seriously by our senior lecturers and professors in our faculty', 'from the above mot ivation the design and implementation of this course have been considered seriously by our senior lecturers and professors in our faculty', 55, 100, 1),
(9312, 73, 'we have already spent more than one year to prepare the learning outcome syllabus teaching learning documents and workspace for this course 6', 'we have already spent more than one year to prepare the learning outcome syllabus teaching learning documents and workspace for this course 6', 55, 100, 1),
(9313, 73, 'this paper will present our experiences in design building teaching and evaluation of this course to the first year students in 2012', 'this paper will present our experiences in design building teaching and evaluation of this course to the first year students in 2012', 55, 100, 1),
(9314, 73, 'the content of this paper is presented as follows section 2 presents the design and building of course goals and learning outcomes for iit course', 'the content of this paper is presented as follows section 2 presents the design and building of course goals and learning outcomes for iit course', 55, 100, 1),
(9315, 73, 'section 3 presents the appro ach of project based learning to embed cdio concepts in teaching and training for students', 'section 3 presents the appro ach of project based learning to embed cdio concepts in teaching and training for students', 55, 100, 1),
(9316, 73, 'section 4 presents the meeting and feedback between it companies and the first year students', 'section 4 presents the meeting and feedback between it companies and the first year students', 55, 100, 1),
(9317, 73, 'section 5 presents the assessments and some rubrics for this course', 'section 5 presents the assessments and some rubrics for this course', 55, 100, 1),
(9318, 73, 's ection 6 is our discussions about pros and cons in operating this course at our faculty', 's ection 6 is our discussions about pros and cons in operating this course at our faculty', 55, 100, 1),
(9319, 73, 'course goals and learning outcome s design and building the course goals and learning outcome s of one course in cdio system is not easy because the scope of course goal s must be suitable to the learning outcome s of the curriculum', 'course goals and learning outcome s design and building the course goals and learning outcome s of one course in cdio system is not easy because the scope of course goal s must be suitable to the learning outcome s of the curriculum', 55, 100, 1),
(9320, 73, '1 we can see that the learnin g outcome s are defined from the course goals while the course goals are defined by the learning outcome s of our curriculum', '1 we can see that the learnin g outcome s are defined from the course goals while the course goals are defined by the learning outcome s of our curriculum', 55, 100, 1),
(9321, 73, 'in practice the number of course goals is less than or equal to 8 and there are about 2 to 4 learning outcomes corresponding to eac h course goal', 'in practice the number of course goals is less than or equal to 8 and there are about 2 to 4 learning outcomes corresponding to eac h course goal', 55, 100, 1),
(9322, 73, 'we can see that t he content of course goals is presented more in details by the learning outcomes', 'we can see that t he content of course goals is presented more in details by the learning outcomes', 55, 100, 1),
(9323, 73, 'most important contents in the course goal s will be the objectives of the assessment corresponding to source of evidence in fig1', 'most important contents in the course goal s will be the objectives of the assessment corresponding to source of evidence in fig1', 55, 100, 1),
(9324, 73, 'it is notic ed that the course goals and the learning outcome will involve directly to the design of the course', 'it is notic ed that the course goals and the learning outcome will involve directly to the design of the course', 55, 100, 1),
(9325, 73, 'the solid lines in fig1 show the task order in workflow and the dash lines show the revision and comparison', 'the solid lines in fig1 show the task order in workflow and the dash lines show the revision and comparison', 55, 100, 1),
(9326, 73, 'the total score is the final score of student s after studying the course', 'the total score is the final score of student s after studying the course', 55, 100, 1),
(9327, 73, 'we divide the content of iit into two courses and teach the first year students in the first and second semesters', 'we divide the introduction into two cou rses and teach the first year students in the first and second semesters', 55, 75.2759, 1),
(9328, 73, 'we divide the content of iit into two courses and teach the first year students in the first and second semesters', 'we divide the content of iit into two courses and teach the first year students in the first and second semesters', 55, 100, 1),
(9329, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university figure 1 workflow to build a cdio syllabus the first course is the introduction of computer computing in ternet ethics and some technical skills of analysis design implementation and testing', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university figure 1 workflow to build a cdio syllabus the first course is the introduction of computer computing in ternet ethics and some technical skills of analysis design implementation and testing', 55, 100, 1),
(9330, 73, 'this is an overview of it from outside viewpoint', 'this is an overview of it from the outside rs', 55, 72.4799, 1),
(9331, 73, 'this is an overview of it from outside viewpoint', 'this is an overview of it from inside viewpoint', 55, 75.0912, 1),
(9332, 73, 'this is an overview of it from outside viewpoint', 'this is an overview of it from outside viewpoint', 55, 100, 1),
(9333, 73, 'the second is a hierarchy of it knowledge from basic to advance through systems of education and research in our f aculty', 'the second is a hierarchy of it knowledge from basic to advance through education systems and research in our faculty', 55, 83.8186, 1),
(9334, 73, 'the second is a hierarchy of it knowledge from basic to advance through systems of education and research in our f aculty', 'the second is a hierarchy of it knowledge from basic to advance through systems of education and research in our f aculty', 55, 100, 1),
(9335, 73, 'this is an overview of it from inside viewpoint of our faculty', 'this is an overview of it from inside viewpoint', 55, 89.3801, 1),
(9336, 73, 'this is an overview of it from inside viewpoint of our faculty', 'this is an overview of it from inside viewpoint of our faculty', 55, 100, 1),
(9337, 73, 'the course goal of introduction to information technology can be written into two stages as follows a the course goals of the first course explain general knowledge of it include basic knowledge about counting system operating system internet email and office applications', 'the course goal of introduction to information technology can be written into two stages as follows a the course goals of the first course explain general knowledge of it include basic knowledge about counting system operating system internet email and office applications', 55, 100, 1),
(9338, 73, 'describe the basic values related to professional ethics of those working in it sector', 'describe the basic values related to professional ethics of those working in it sector', 55, 100, 1),
(9339, 73, 'describe the work and job position in a company related to it which is one it student can undertake after graduation', 'describe the work and job position in a company related to it which is one it student can undertake after graduation', 55, 100, 1),
(9340, 73, 'recognize the importance of self study team work and communication skills', 'recognize the importance of self study team work and communication skills', 55, 100, 1),
(9341, 73, 'recognize the importance of self study team work and communication skills', 'recognize the importance of self study team work and problem solving', 55, 75.931, 1),
(9342, 73, 'recognize the professional attitude regulatory compliance and reliability', 'recognize the professional attitude regulatory compliance and reliability', 55, 100, 1),
(9343, 73, 'recognize the professional attitude regulatory compliance and reliability', 'recognize the professional attitude regulatory compliance and reliability', 55, 100, 1),
(9344, 73, 'the first course is taught in ten weeks with 15 hours in class 20 hours in lab an d 15 hours of self studying at home note that details of weekly c lasses will be provided by contacting the authors', 'the first course is taught in ten weeks with 15 hours in class 20 hours in lab an d 15 hours of self studying at home note that details of weekly c lasses will be provided by contacting the authors', 55, 100, 1),
(9345, 73, 'the first course is taught in ten weeks with 15 hours in class 20 hours in lab an d 15 hours of self studying at home note that details of weekly c lasses will be provided by contacting the authors', 'it also takes ten weeks with 15 hours in class 20 hours in lab and 15 hours of self studying at home', 55, 76.4804, 1),
(9346, 73, 'b the course goals of the second course describe relationship between the syllabus system researches and the it career development in the department of information technology university of science hoch iminh city vietnam', 'b the course goals of the second course describe relationship between the syllabus system researches and the it career development in the department of information technology university of science hoch iminh city vietnam', 55, 100, 1),
(9347, 73, 'describe basic concepts related to the fields of information systems software engineering computer networking telecommunications knowledge engineering and machine vision robotics', 'describe basic concepts related to the fields of information systems software engineering computer networking telecommunications knowledge engineering and machine vision robotics', 55, 100, 1),
(9348, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university figure 2 the course outline of introduction to information technology iit 1 2', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university figure 2 the course outline of introduction to information technology iit 1 2', 55, 100, 1),
(9349, 73, 'describe outline of jobs which directly and indirectly related to the above it fields', 'describe outline of jobs which directly and indirectly related to the above it fields', 55, 100, 1),
(9350, 73, 'recognize the importance of self study team work and problem solving', 'recognize the importance of self study team work and communication skills', 55, 75.931, 1),
(9351, 73, 'recognize the importance of self study team work and problem solving', 'recognize the importance of self study team work and problem solving', 55, 100, 1),
(9352, 73, 'recognize the professional attitude regulatory compliance and reliability', 'recognize the professional attitude regulatory compliance and reliability', 55, 100, 1),
(9353, 73, 'recognize the professional attitude regulatory compliance and reliability', 'recognize the professional attitude regulatory compliance and reliability', 55, 100, 1),
(9354, 73, 'the second course is similar to the first course', 'the second course is similar to the first course', 55, 100, 1),
(9355, 73, 'it also takes ten weeks with 15 hours in class 20 hours in lab and 15 hours of self studying at home', 'the first course is taught in ten weeks with 15 hours in class 20 hours in lab an d 15 hours of self studying at home note that details of weekly c lasses will be provided by contacting the authors', 55, 76.4804, 1),
(9356, 73, 'it also takes ten weeks with 15 hours in class 20 hours in lab and 15 hours of self studying at home', 'it also takes ten weeks with 15 hours in class 20 hours in lab and 15 hours of self studying at home', 55, 100, 1),
(9357, 73, 'based on the course goal of the 1st and 2nd courses the outline of two iit courses is presented in fig', 'based on the course goal of the 1st and 2nd courses the outline of two iit courses is presented in fig', 55, 100, 1),
(9358, 73, 'we can see that the content of the second course describes more in details about the system of research and education in our faculty', 'we can see that the content of the second course describes more in details about the system of research and education in our faculty', 55, 100, 1),
(9359, 73, 'it provides experiences and case study about the influence and importance of advanced courses in the syllabus system to career selection of students', 'it provides experiences and case study about the influence and importance of advanced courses in the syllabus system to career selection of students', 55, 100, 1),
(9360, 73, 'through the content of this course we also give students a general view of it applications and potential fields where it can be integrated successfully', 'through the content of this course we also give students a general view of it applications and potential fields where it can be integrated successfully', 55, 100, 1),
(9361, 73, 'beside s providing knowledge we apply the project based approach to embed skills and attitudes into the teachinglearning activities of two iit courses', 'beside s providing knowledge we apply the project based approach to embed skills and attitudes into the teachinglearning activities of two iit courses', 55, 100, 1),
(9362, 73, 'here the cdio concept s can be explained easily to our students by using a simple project first and then the requirements in the second project are upgraded to higher level in order to give students a chance of thinking recognizing and implementing their knowledge skills and att itudes', 'here the cdio concept s can be explained easily to our students by using a simple project first and then the requirements in the second project are upgraded to higher level in order to give students a chance of thinking recognizing and implementing their knowledge skills and att itudes', 55, 100, 1),
(9363, 73, 'meanwhile the project in the second course is designed to train the first year students all stages of c dio', 'meanwhile the project in the second course is designed to train the first year students all stages of c dio', 55, 100, 1),
(9364, 73, 'project based approach as mentioned above the project based approach is appli ed in both two iit courses in our it program', 'project based approach as mentioned above the project based approach is appli ed in both two iit courses in our it program', 55, 100, 1),
(9365, 73, 'when we design the project system our expectation is to present the four st ages of c dio to students as soo n as possible', 'when we design the project system our expectation is to present the four st ages of c dio to students as soo n as possible', 55, 100, 1),
(9366, 73, 'however most first year students cannot understand the concept of conceives when we give them a set of initial conditions to produce software', 'however most first year students cannot understand the concept of conceives when we give them a set of initial conditions to produce software', 55, 100, 1),
(9367, 73, 'the limitation of students to recognize and understand all stag es of cdio is describes as follows limitation of knowledge and time', 'the limitation of students to recognize and understand all stag es of cdio is describes as follows limitation of knowledge and time', 55, 100, 1),
(9368, 73, 'limitation of personal skills and professional skills', 'limitation of personal skills and professional skills', 55, 100, 1),
(9369, 73, 'as a result we propose one project where students will study d io instead of c dio', 'as a result we propose one project where students will study d io instead of c dio', 55, 100, 1),
(9370, 73, 'in the content of the first course we see that there is a relation between the concept s of analysisdesignimplementoperation and testing to the concept s of dio', 'in the content of the first course we see that there is a relation between the concept s of analysisdesignimplementoperation and testing to the concept s of dio', 55, 100, 1),
(9371, 73, 'in practice it t akes a short time around 2 classes for the first year students to understand d io concepts', 'in practice it t akes a short time around 2 classes for the first year students to understand d io concepts', 55, 100, 1),
(9372, 73, 'we divide the cla ss into many groups with 5 members for each', 'we divide the cla ss into many groups with 5 members for each', 55, 100, 1),
(9373, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university project house prototype building a', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university goran gustafsson et', 55, 70.0372, 1),
(9374, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university project house prototype building a', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university project house prototype building a', 55, 100, 1),
(9375, 73, 'build a prototype of house by using paper and bamboo stick such that a it can be waterproof', 'build a prototype of house by using paper and bamboo stick such that a it can be waterproof', 55, 100, 1),
(9376, 73, 'b shape of house must be stable when we put 330 gram on the roof for di agnostic load test', 'b shape of house must be stable when we put 330 gram on the roof for di agnostic load test', 55, 100, 1),
(9377, 73, 'c maximum size of house is 20 cm x 20 cm x 20 cm', 'c maximum size of house is 20 cm x 20 cm x 20 cm', 55, 100, 1),
(9378, 73, 'material 3 daily papers 250 bamboo sticks 02 cm x 5cm stick 3 glue bottles 50 ml bottle', 'material 3 daily papers 250 bamboo sticks 02 cm x 5cm stick 3 glue bottles 50 ml bottle', 55, 100, 1),
(9379, 73, 'report and documents of design solution work load time and position balance sheet salary price and explanation of testing result', 'report and documents of design solution work load time and position balance sheet salary price and explanation of testing result', 55, 100, 1),
(9380, 73, 'some of firstyear students wonder why we give them the above project', 'some of firstyear students wonder why we give them the above project', 55, 100, 1),
(9381, 73, 'the question is why it student s must study to build a house prototype instead of one software', 'the question is why it student s must study to build a house prototype instead of one software', 55, 100, 1),
(9382, 73, 'the answer comes from the output of the projects where using it app lications such as word processor excel and power point is one of the important requirements and the concepts of d io must be reflected in the report of students', 'the answer comes from the output of the projects where using it app lications such as word processor excel and power point is one of the important requirements and the concepts of d io must be reflected in the report of students', 55, 100, 1),
(9383, 73, 'teamwo rk can be evaluated by the quality of house prototype and sheet of workload', 'teamwo rk can be evaluated by the quality of house prototype and sheet of workload', 55, 100, 1),
(9384, 73, 'we can also check students communication skill through their slide s and presentation', 'we can also check students communication skill through their slide s and presentation', 55, 100, 1),
(9385, 73, 'in the second course the level of project is upgraded to present the concept of cdio', 'in the second course the level of project is upgraded to present the concept of cdio', 55, 100, 1),
(9386, 73, 'we group the contents of information system software engineering network and telecommunication into one pro ject', 'we group the contents of information system software engineering network and telecommunication into one pro ject', 55, 100, 1),
(9387, 73, 'meanwhile those o f computing science knowledge engineering computer vision and robotics are designed in one other c dio project', 'meanwhile those o f computing science knowledge engineering computer vision and robotics are designed in one other c dio project', 55, 100, 1),
(9388, 73, 'the lecturer and ta play a role of the end user s or customer s of their service', 'the lecturer and ta play a role of the end user s or customer s of their service', 55, 100, 1),
(9389, 73, 'the output of this project is evaluated by checking demo softwares reports and presentation s one other kind of the project is to build a system of data analysis for multimedia data such as video information retrieval or video audio processing by using free ware', 'the output of this project is evaluated by checking demo softwares reports and presentation s one other kind of the project is to build a system of data analysis for multimedia data such as video information retrieval or video audio processing by using free ware', 55, 100, 1),
(9390, 73, 'through the meeting student s our faculty staffs and company members can share viewpoints about the development of it in vietnam and in the world', 'through the meeting student s our faculty staffs and company members can share viewpoints about the development of it in vietnam and in the world', 55, 100, 1),
(9391, 73, 'after the meeting we can have some thoughts about important demand s from it companies in vietnam such as personal skills specifical ly team work and communication play an important role for the success of ones career path', 'after the meeting we can have some thoughts about important demand s from it companies in vietnam such as personal skills specifical ly team work and communication play an important role for the success of ones career path', 55, 100, 1),
(9392, 73, 'problem solving capa bility is the key of admission to company', 'problem solving capa bility is the key of admission to company', 55, 100, 1),
(9393, 73, 'for most companies r eliability and loyalty are the most precious characteristics', 'for most companies r eliability and loyalty are the most precious characteristics', 55, 100, 1),
(9394, 73, 'assessment and feedbacks assessment is the main difference between cdio approach and the conventional teaching methods', 'assessment and feedbacks assessment is the main difference between cdio approach and the conventional teaching methods', 55, 100, 1),
(9395, 73, 'we divide 70 of final exam and 30 of project in the first course', 'we divide 70 of final exam and 30 of project in the first course', 55, 100, 1),
(9396, 73, 'meanwhile the ratio of final exam and project in the second course is 60 and 40 respectively', 'meanwhile the ratio of final exam and project in the second course is 60 and 40 respectively', 55, 100, 1),
(9397, 73, 'the assessment of each project is checked monthly in three months', 'the assessment of each project is checked monthly in three months', 55, 100, 1),
(9398, 73, 'the detail of assessment has been shown to students at the beginning of the course', 'the detail of assessment has been shown to students at the beginning of the course', 55, 100, 1),
(9399, 73, 'during the course studen ts have been reminded about the assessment and we have also encouraged them to provide a good strategy of learning for each group s o that all members of the same group can receive a good result', 'during the course studen ts have been reminded about the assessment and we have also encouraged them to provide a good strategy of learning for each group s o that all members of the same group can receive a good result', 55, 100, 1),
(9400, 73, 'in practice the peer review gives objective evaluation', 'in practice the peer review gives objective evaluation', 55, 100, 1),
(9401, 73, 'it h elps students have a strong responsibility and a serious thinking about their contributions to the final results of their group', 'it h elps students have a strong responsibility and a serious thinking about their contributions to the final results of their group', 55, 100, 1),
(9402, 73, 'member performance inside group peer review member 15 5', 'member performance inside group peer review member 15 5', 55, 100, 1),
(9403, 73, 'group performance other group peer review group 15 a project evaluation order outputs 0 1 2 3 ratio 1', 'group performance other group peer review group 15 a project evaluation order outputs 0 1 2 3 ratio 1', 55, 100, 1),
(9404, 73, 'introduction motivation and survey none uncle ar clear but not enough enough and logical 15 2', 'introduction motivation and survey none uncle ar clear but not enough enough and logical 15 2', 55, 100, 1),
(9405, 73, 'description of basic concepts none unclear clear but not enough enough and logical 15 3', 'description of basic concepts none unclear clear but not enough enough and logical 15 3', 55, 100, 1),
(9406, 73, 'description of basic concepts none unclear clear but not enough enough and logical 15 3', 'formulation of problem none unclear clear but not enough enough and logical 15 4', 55, 74.3361, 1),
(9407, 73, 'description of basic concepts none unclear clear but not enough enough and logical 15 3', 'description of demo software none unclear clear but not enough enough and logical 10 6', 55, 73.4489, 1),
(9408, 73, 'formulation of problem none unclear clear but not enough enough and logical 15 4', 'description of basic concepts none unclear clear but not enough enough and logical 15 3', 55, 74.3361, 1),
(9409, 73, 'formulation of problem none unclear clear but not enough enough and logical 15 4', 'formulation of problem none unclear clear but not enough enough and logical 15 4', 55, 100, 1),
(9410, 73, 'experiment explanation none unclear clear but not enough enough and logical 15 proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university 5', 'experiment explanation none unclear clear but not enough enough and logical 15 proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university 5', 55, 100, 1),
(9411, 73, 'description of demo software none unclear clear but not enough enough and logical 10 6', 'description of basic concepts none unclear clear but not enough enough and logical 15 3', 55, 73.4489, 1),
(9412, 73, 'description of demo software none unclear clear but not enough enough and logical 10 6', 'description of demo software none unclear clear but not enough enough and logical 10 6', 55, 100, 1),
(9413, 73, 'creativity none unclear clear but not better clear and better 10 7', 'creativity none unclear clear but not better clear and better 10 7', 55, 100, 1),
(9414, 73, 'presentation none unclear clear clear and logical 10 8', 'presentation none unclear clear clear and logical 10 8', 55, 100, 1),
(9415, 73, 'documentation none not enough enough but not logical enough and logical 5 9', 'documentation none not enough enough but not logical enough and logical 5 9', 55, 100, 1),
(9416, 73, 'reference none not correct correct and not enough enough and correct 5 b report evaluation figure 5 some rubrics of project and report evaluation', 'reference none not correct correct and not enough enough and correct 5 b report evaluation figure 5 some rubrics of project and report evaluation', 55, 100, 1),
(9417, 73, 'after assessment we make s ome qa to receive the feedbacks from students', 'after assessment we make s ome qa to receive the feedbacks from students', 55, 100, 1),
(9418, 73, 'the result of feedback is presented as the following table table 1 feedback of students 1 2 3 4 5 nc homeworkproject is evaluated fairly and positively', 'the result of feedback is presented as the following table table 1 feedback of students 1 2 3 4 5 nc homeworkproject is evaluated fairly and positively', 55, 100, 1),
(9419, 73, '65 74 25 4 1 1 homeworkproject is evaluated on the fixed schedule exactly', '65 74 25 4 1 1 homeworkproject is evaluated on the fixed schedule exactly', 55, 100, 1),
(9420, 73, '44 86 31 6 0 3 syllabus content is presented in a suitable order', '44 86 31 6 0 3 syllabus content is presented in a suitable order', 55, 100, 1),
(9421, 73, '43 78 43 4 0 2 course slide and other resources are provided on time to be useful for teaching and learning', '43 78 43 4 0 2 course slide and other resources are provided on time to be useful for teaching and learning', 55, 100, 1),
(9422, 73, '50 80 34 4 1 1 a theory 1 2 3 4 5 nc homeworkproject is evaluated fairly and positively', '50 80 34 4 1 1 a theory 1 2 3 4 5 nc homeworkproject is evaluated fairly and positively', 55, 100, 1),
(9423, 73, '76 74 17 3 0 0 homeworkproject is evaluated on the fixed sch edule exactly', '76 74 17 3 0 0 homeworkproject is evaluated on the fixed sch edule exactly', 55, 100, 1),
(9424, 73, '49 79 37 4 0 1 labs documents are presented in a suitable order', '49 79 37 4 0 1 labs documents are presented in a suitable order', 55, 100, 1),
(9425, 73, '38 82 45 4 0 1 slide and other resources of lab experiments ar e provided on time to be useful for teaching and learning', '38 82 45 4 0 1 slide and other resources of lab experiments ar e provided on time to be useful for teaching and learning', 55, 100, 1),
(9426, 73, '52 79 33 4 0 2 b lab table 2 benchmark absolutely agree agree neutral object absolutely object no comments 1 2 3 4 5 nc table 1 presents the feedbacks of 170 students and table 2 gives the benchmark of score value', '52 79 33 4 0 2 b lab table 2 benchmark absolutely agree agree neutral object absolutely object no comments 1 2 3 4 5 nc table 1 presents the feedbacks of 170 students and table 2 gives the benchmark of score value', 55, 100, 1),
(9427, 73, 'we can see that most distribution of feedbacks stays on agree corresponding to the score value of 2', 'we can see that most distribution of feedbacks stays on agree corresponding to the score value of 2', 55, 100, 1),
(9428, 73, 'it means that the feedbacks of students are positive toward cdio approach', 'it means that the feedbacks of students are positive toward cdio approach', 55, 100, 1),
(9429, 73, 'however there are still some complain ts about overloa ded and stressful because the first year students have got a lot of project and homework deadl ines from the first semester of the undergraduate program in the university', 'however there are still some complain ts about overloa ded and stressful because the first year students have got a lot of project and homework deadl ines from the first semester of the undergraduate program in the university', 55, 100, 1),
(9430, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university discussions after one year implementing cdio to it program we found some interesti ng points and difficulties in cdio implementation', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university discussions after one year implementing cdio to it program we found some interesti ng points and difficulties in cdio implementation', 55, 100, 1),
(9431, 73, 'the approach of cdio helps us to clarify the quality of the syllabus easily', 'the approach of cdio helps us to clarify the quality of the syllabus easily', 55, 100, 1),
(9432, 73, 'by checking the learning outcome and course goal s we can see an overview to our whole program and find whether there is any inconsisten ce or overlap in the undergraduate program', 'by checking the learning outcome and course goal s we can see an overview to our whole program and find whether there is any inconsisten ce or overlap in the undergraduate program', 55, 100, 1),
(9433, 73, 'the introduction of it course provides the students motivation prospective view of their career and important concept s of it', 'the introduction of it course provides the students motivation prospective view of their career and important concept s of it', 55, 100, 1),
(9434, 73, 'besides the advantage s this course still has some difficult problems in tea ching and learning activities some s tudents feel stressful because of overloaded project s and homework', 'besides the advantage s this course still has some difficult problems in tea ching and learning activities some s tudents feel stressful because of overloaded project s and homework', 55, 100, 1),
(9435, 73, 'most courses designed in cdio approach have a requirement of project based learning', 'most courses designed in cdio approach have a requirement of project based learning', 55, 100, 1),
(9436, 73, 'consequently the number of projects that a student needs to work o n during one semester increas e considerably', 'consequently the number of projects that a student needs to work o n during one semester increas e considerably', 55, 100, 1),
(9437, 73, 'as a matter of fact the requirements of project become more difficult because it will check both knowledge and skills in the learning outcomes', 'as a matter of fact the requirements of project become more difficult because it will check both knowledge and skills in the learning outcomes', 55, 100, 1),
(9438, 73, 'it takes students a lot of time and effort to catch up projects deadlines and requirements', 'it takes students a lot of time and effort to catch up projects deadlines and requirements', 55, 100, 1),
(9439, 73, 'one solution of the above is to design one big project which can be applied for multiple courses', 'one solution of the above is to design one big project which can be applied for multiple courses', 55, 100, 1),
(9440, 73, 'however there is always a limitation about time and the coverage of learning outcomes in a project', 'however there is always a limitation about time and the coverage of learning outcomes in a project', 55, 100, 1),
(9441, 73, 'it is not easy to make decisi on whether we should select or not one learning outcome from a bunch of multiple courses', 'it is not easy to make decisi on whether we should select or not one learning outcome from a bunch of multiple courses', 55, 100, 1),
(9442, 73, 'the number of lecture rs and teaching assistants t as are not enough to cover a class of 450 students', 'the number of lecture rs and teaching assistants t as are not enough to cover a class of 450 students', 55, 100, 1),
(9443, 73, 'originally cdio program has been developed from engineering school where the number of students in each class is just a few dozen', 'originally cdio program has been developed from engineering school where the number of students in each class is just a few dozen', 55, 100, 1),
(9444, 73, 'now the number of first year students in our it faculty is around 450 a year', 'now the number of first year students in our it faculty is around 450 a year', 55, 100, 1),
(9445, 73, 'as a result w e need more space and more t as to organize teaching and learning activities in class', 'as a result w e need more space and more t as to organize teaching and learning activities in class', 55, 100, 1),
(9446, 73, 'one s olution is to divide into many small classes with a few dozen students', 'one s olution is to divide into many small classes with a few dozen students', 55, 100, 1),
(9447, 73, 'however this also brings some difficulties in scheduling and funding for extra hour payment', 'however this also brings some difficulties in scheduling and funding for extra hour payment', 55, 100, 1),
(9448, 73, 'lecturer s and t as are still familiar with the conventional teaching approach', 'lecturer s and t as are still familiar with the conventional teaching approach', 55, 100, 1),
(9449, 73, 'it will take time to change their thinking and teaching approach', 'it will take time to change their thinking and teaching approach', 55, 100, 1),
(9450, 73, 'we have already organized some training programs for lecturers to explain cdio program and enhance their professional skills', 'we have already organized some training programs for lecturers to explain cdio program and enhance their professional skills', 55, 100, 1),
(9451, 73, 'the cdio approach requires students lecturer s and t as spend more time in preparation', 'the cdio approach requires students lecturer s and t as spend more time in preparation', 55, 100, 1),
(9452, 73, 'hence w e need an efficient administration to support and encourage them in long run', 'hence w e need an efficient administration to support and encourage them in long run', 55, 100, 1),
(9453, 73, 'as mentioned above scheduling and workspace management play a very important role in our cdio p rogram', 'as mentioned above scheduling and workspace management play a very important role in our cdio p rogram', 55, 100, 1),
(9454, 73, 'if administration staff could be trained well they will help us to save much time in learning and teaching activities', 'if administration staff could be trained well they will help us to save much time in learning and teaching activities', 55, 100, 1),
(9455, 73, 'we need a sufficient funding to set up the workspace evaluate the learning outcomes and revise the program every year', 'we need a sufficient funding to set up the workspace evaluate the learning outcomes and revise the program every year', 55, 100, 1),
(9456, 73, 'cdio based program is usually applied for the first year students and we must wait until four years later when all the first year students graduate in order to receive the feedbacks from the sta keholders to decide the cdio program successful or not', 'cdio based program is usually applied for the first year students and we must wait until four years later when all the first year students graduate in order to receive the feedbacks from the sta keholders to decide the cdio program successful or not', 55, 100, 1);
INSERT INTO `plagiarism_results` (`id`, `archive_id`, `submitted_sentence`, `existing_sentence`, `similar_archive_id`, `similarity_percentage`, `is_plagiarized`) VALUES
(9457, 73, 'absolutely nobody wants to see it failed after four years', 'absolutely nobody wants to see it failed after four years', 55, 100, 1),
(9458, 73, 'therefore we must clarify what we should evaluate and revise periodically eg yearly in order to ensure that the cdio program is develop ed with high efficiency', 'therefore we must clarify what we should evaluate and revise periodically eg yearly in order to ensure that the cdio program is develop ed with high efficiency', 55, 100, 1),
(9459, 73, 'since we invest more time money and human resource to follow the cdio program we really need the posit ive evidence to persu ade our students faculty staff the university and the society for supporting us to keep it going on', 'since we invest more time money and human resource to follow the cdio program we really need the posit ive evidence to persu ade our students faculty staff the university and the society for supporting us to keep it going on', 55, 100, 1),
(9460, 73, 'conclusions proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university we present our experience of designing a course of introduction to information technology iit for the first year s tudents', 'conclusions proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university we present our experience of designing a course of introduction to information technology iit for the first year s tudents', 55, 100, 1),
(9461, 73, 'we design two courses for it introduction one is a general view from outsiders to it and the other is an introduction of research in it', 'we design two courses for it introduction one is a general view from outsiders to it and the other is an introduction of research in it', 55, 100, 1),
(9462, 73, 'we have experiences to teach those two courses for 450 students and receive both positive and negative feedba cks', 'we have experiences to teach those two courses for 450 students and receive both positive and negative feedba cks', 55, 100, 1),
(9463, 73, 'most of the students think that those two courses are useful to motivate them to it and give them a near vision of their career in the future', 'most of the students think that those two courses are useful to motivate them to it and give them a near vision of their career in the future', 55, 100, 1),
(9464, 73, 'students have been trained personal and professional skills', 'students have been trained personal and professional skills', 55, 100, 1),
(9465, 73, 'it makes them more confident than students of the conventional classes', 'it makes them more confident than students of the conventional classes', 55, 100, 1),
(9466, 73, 'although most students think that cdio based approach is interestin g it makes them a bit pressure with deadlines', 'although most students think that cdio based approach is interestin g it makes them a bit pressure with deadlines', 55, 100, 1),
(9467, 73, 'lecturer s and tas also find it difficult in handling a few hundred student class', 'lecturer s and tas also find it difficult in handling a few hundred student class', 55, 100, 1),
(9468, 73, 'last but not least the cdio base d program needs a sufficient and stable fund to support it in the long run', 'last but not least the cdio base d program needs a sufficient and stable fund to support it in the long run', 55, 100, 1),
(9469, 73, 'in fact once we decide to start cdio program we must k eep it going until the result of our program comes up ie feedback from stakeholders once student graduation', 'in fact once we decide to start cdio program we must k eep it going until the result of our program comes up ie feedback from stakeholders once student graduation', 55, 100, 1),
(9470, 73, 'referen ces 1 crawley e f the cdio syllabus a statement of goals for undergraduate engineering education mit cdio report 1 2001', 'referen ces 1 crawley e f the cdio syllabus a statement of goals for undergraduate engineering education mit cdio report 1 2001', 55, 100, 1),
(9471, 73, 'al conceiving and designing an introduction to engineering course within the new curricula at t elecom bcn upc barcelona proceedings of the 6th international cdio conference école polytechnique montréal june 15 18 2010', 'al conceiving and designing an introduction to engineering course within the new curricula at t elecom bcn upc barcelona proceedings of the 6th international cdio conference école polytechnique montréal june 15 18 2010', 55, 100, 1),
(9472, 73, '5 goran gustafsson etal firstyear introductory courses as a means to develop conceive design implement operate skills in engineering education programmes presented the sefi annual conferenc e firenze italy 08 11 september 2002', '5 goran gustafsson etal firstyear introductory courses as a means to develop conceive design implement operate skills in engineering education programmes presented the sefi annual conferenc e firenze italy 08 11 september 2002', 55, 100, 1),
(9473, 73, '6 edward crawley johan malmqvist soren ostlund doris brodeur rethinking engineering education the cdio approach springer 2007', '6 edward crawley johan malmqvist soren ostlund doris brodeur rethinking engineering education the cdio approach springer 2007', 55, 100, 1),
(9474, 73, 'biographical information son thai tran is lecturer at the faculty of information technology fit university of scie nce hochiminh city vietnam', 'biographical information son thai tran is lecturer at the faculty of information technology fit university of scie nce hochiminh city vietnam', 55, 100, 1),
(9475, 73, 'he is the deputy h ead of department of computer vision and robotics', 'he is the deputy h ead of department of computer vision and robotics', 55, 100, 1),
(9476, 73, 'he joined the cdio program as a designer of i ntroduction to information technology course in 2012', 'he joined the cdio program as a designer of i ntroduction to information technology course in 2012', 55, 100, 1),
(9477, 73, 'his research interests are in statistical data analysis c omputer vision and discrete optimization', 'his research interests are in statistical data analysis c omputer vision and discrete optimization', 55, 100, 1),
(9478, 73, 'le ngoc thanh is the deputy head of computer science department', 'le ngoc thanh is the deputy head of computer science department', 55, 100, 1),
(9479, 73, 'he is also a member of the cdio project that implemented in fit', 'he is also a member of the cdio project that implemented in fit', 55, 100, 1),
(9480, 73, 'with this promotion he is responsible for evaluating and applying cdio standard into introduction to information technology course', 'with this promotion he is responsible for evaluating and applying cdio standard into introduction to information technology course', 55, 100, 1),
(9481, 73, 'in addition he joins in the construction of other courses syllabus based on cdio approach to ensure the students achieve learning outcomes thoroughly', 'in addition he joins in the construction of other courses syllabus based on cdio approach to ensure the students achieve learning outcomes thoroughly', 55, 100, 1),
(9482, 73, 'tha nhs research interests are in data mining social network and graph t heory', 'tha nhs research interests are in data mining social network and graph t heory', 55, 100, 1),
(9483, 73, 'nguyen quoc binh is teaching assistant at the faculty of information technology fit university of science hochiminh city vietnam', 'nguyen quoc binh is teaching assistant at the faculty of information technology fit university of science hochiminh city vietnam', 55, 100, 1),
(9484, 73, 'he is at department of knowledge engineering', 'he is at department of knowledge engineering', 55, 100, 1),
(9485, 73, 'he is at department of knowledge engineering', 'he is at department of software engineering', 55, 80.0781, 1),
(9486, 73, 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university he joined the cdio program as a teaching ass istant of introduction to information technology course in 2012', 'proceedings of the 9th international cdio conference massachusetts institute of technology and harvard university he joined the cdio program as a teaching ass istant of introduction to information technology course in 2012', 55, 100, 1),
(9487, 73, 'his research interests are in cryptography privacy and statistical data analysis', 'his research interests are in cryptography privacy and statistical data analysis', 55, 100, 1),
(9488, 73, 'dang binh phuong is lecturer at the faculty of information technology fit university of science hochim inh city vietnam', 'dang binh phuong is lecturer at the faculty of information technology fit university of science hochim inh city vietnam', 55, 100, 1),
(9489, 73, 'he is at department of software engineering', 'he is at department of knowledge engineering', 55, 80.0781, 1),
(9490, 73, 'he is at department of software engineering', 'he is at department of software engineering', 55, 100, 1),
(9491, 73, 'he joined the cdio program as a lecturer of introduction to information technology course in 2012 and 2013', 'he joined the cdio program as a lecturer of introduction to information technology course in 2012 and 2013', 55, 100, 1),
(9492, 73, 'his research interests are in software engineering and mobile programming', 'his research interests are in software engineering and mobile programming', 55, 100, 1),
(9493, 73, 'le hoai bac is associate professor at the faculty of information technology fit university of science hochiminh city vietnam', 'le hoai bac is associate professor at the faculty of information technology fit university of science hochiminh city vietnam', 55, 100, 1),
(9494, 73, 'he is the vice dean of the facu lty of information technology head of computer science department', 'he is the vice dean of the facu lty of information technology head of computer science department', 55, 100, 1),
(9495, 73, 'he is monitoring and controlling t he progress of the cdio program at the fit', 'he is monitoring and controlling t he progress of the cdio program at the fit', 55, 100, 1),
(9496, 73, 'he is an active member in adopting cdio in fit', 'he is an active member in adopting cdio in fit', 55, 100, 1),
(9497, 73, 'le hoai bacs research interests are in data mining soft c ompu ting and artificial intelligence', 'le hoai bacs research interests are in data mining soft c ompu ting and artificial intelligence', 55, 100, 1),
(9498, 73, 'corresponding author son thai tran deputy head of depa rtment of computer vision robotics faculty of information technology university of science hcmc vietnam national university 227 nguyen van cu district 5th hochiminh city vietnam email ttsonfithcmuseduvn this work is licensed under a creative commons attribution noncommercial noderivs 30 unported license', 'corresponding author son thai tran deputy head of depa rtment of computer vision robotics faculty of information technology university of science hcmc vietnam national university 227 nguyen van cu district 5th hochiminh city vietnam email ttsonfithcmuseduvn this work is licensed under a creative commons attribution noncommercial noderivs 30 unported license', 55, 100, 1),
(9858, 75, 'information technology and productivity a review of the literature erik brynjolfsson and shinkyu yang mit sloan school of management cambridge massachusetts abstract in recent years the relationship between information technology it and pro ductivity has become a source of debate', 'information technology and productivity a review of the literature erik brynjolfsson and shinkyu yang mit sloan school of management cambridge massachusetts abstract in recent years the relationship between information technology it and pro ductivity has become a source of debate', 59, 100, 1),
(9859, 75, 'in the 1980s and early 1990s empirical research on it productivity generally did not identify significant productivity improvements', 'in the 1980s and early 1990s empirical research on it productivity generally did not identify significant productivity improvements', 59, 100, 1),
(9860, 75, 'more recently as new data are identified and more sophisticated methodologies are applied several researchers have found evidence that it is associated not only with improvement in productivity but also in intermediate measures consumer surplus and economic growth', 'more recently as new data are identified and more sophisticated methodologies are applied several researchers have found evidence that it is associated not only with improvement in productivity but also in intermediate measures consumer surplus and economic growth', 59, 100, 1),
(9861, 75, 'nonetheless new questions emerge as old puzzles fade', 'nonetheless new questions emerge as old puzzles fade', 59, 100, 1),
(9862, 75, 'this survey reviews the literature identifies remain ing questions and concludes with recommendations for applications of tradi tional methodologies to new data sources as well as alternative broader metrics of welfare to assess and enhance the benefits of it', 'this survey reviews the literature identifies remain ing questions and concludes with recommendations for applications of tradi tional methodologies to new data sources as well as alternative broader metrics of welfare to assess and enhance the benefits of it', 59, 100, 1),
(9863, 75, 'the productivity paradoxa clash of expectations and statistics 179 2', 'the productivity paradoxa clash of expectations and statistics 179 2', 59, 100, 1),
(9864, 75, 'research on economywide productivity and information worker productivity 187 3', 'research on economywide productivity and information worker productivity 187 3', 59, 100, 1),
(9865, 75, 'firmlevel studies of information technology productivity 196 41 service sector studies', 'firmlevel studies of information technology productivity 196 41 service sector studies', 59, 100, 1),
(9866, 75, '196 42 studies of manufacturing sector and crosssector studies', '196 42 studies of manufacturing sector and crosssector studies', 59, 100, 1),
(9867, 75, '196 42 studies of manufacturing sector and crosssector studies', '42 studies of manufacturing sector and crosssector studies there have been several firmlevel studies of it productivity in the manufacturing sector', 59, 77.2236, 1),
(9868, 75, 'contribution to consumer surplus and economic growth 201 6', 'contribution to consumer surplus and economic growth 201 6', 59, 100, 1),
(9869, 75, 'the productivity paradoxa clash of expectations and statistics during the past decade both academics and the business press have periodically revisited the socalled productivity paradox of computers 179 copyright 0 1996 by academic pre inc all rights of reproductinn in any form rewved advances in computers', 'the productivity paradoxa clash of expectations and statistics during the past decade both academics and the business press have periodically revisited the socalled productivity paradox of computers 179 copyright 0 1996 by academic pre inc all rights of reproductinn in any form rewved advances in computers', 59, 100, 1),
(9870, 75, 'vol 43 180 erik brynjolfsson and shinkyu yang while delivered computing power in the united states has increased by more than two orders of magnitude since the early 1970s fig', 'vol 43 180 erik brynjolfsson and shinkyu yang while delivered computing power in the united states has increased by more than two orders of magnitude since the early 1970s fig', 59, 100, 1),
(9871, 75, 'l productiv ity especially in the service sector seems to have stagnated fig', 'l productiv ity especially in the service sector seems to have stagnated fig', 59, 100, 1),
(9872, 75, 'despite the enormous promise of information technology it to effect the biggest technological revolution men have known snow 1966 disillusionment and frustration with the technology are evident in headlines like computer data overload limits productivity gains zachary 1991', 'despite the enormous promise of information technology it to effect the biggest technological revolution men have known snow 1966 disillusionment and frustration with the technology are evident in headlines like computer data overload limits productivity gains zachary 1991', 59, 100, 1),
(9873, 75, 'interest in the productivity paradox has engendered a significant amount of research', 'interest in the productivity paradox has engendered a significant amount of research', 59, 100, 1),
(9874, 75, 'although researchers analyzed statistics extensively during the 1980s they found little evidence that information technology significantly increased productivity', 'although researchers analyzed statistics extensively during the 1980s they found little evidence that information technology significantly increased productivity', 59, 100, 1),
(9875, 75, 'as robert solow quipped you can see the computer age everywhere but in the productivity statistics 80 70 20 10 0 1955 1960 1965 1970 1975 1980 1985 1990 1995 year fig', 'as robert solow quipped you can see the computer age everywhere but in the productivity statistics 80 70 20 10 0 1955 1960 1965 1970 1975 1980 1985 1990 1995 year fig', 59, 100, 1),
(9876, 75, 'investment in information technology is growing at a rapid pace', 'investment in information technology is growing at a rapid pace', 59, 100, 1),
(9877, 75, 'note constant dollars base year 1987 calculated by hedonic price method see dulberger tyxy', 'note constant dollars base year 1987 calculated by hedonic price method see dulberger tyxy', 59, 100, 1),
(9878, 75, 'based on data from bea national income and wealth division and adapted from jorgenson and stiroh 1995', 'based on data from bea national income and wealth division and adapted from jorgenson and stiroh 1995', 59, 100, 1),
(9879, 75, 'based on data from bea national income and wealth division and adapted from jorgenson and stiroh 1995', 'based on data from bea national income and wealth division', 59, 78.6903, 1),
(9880, 75, 'solow robert m wed better watch out new york times book review july 12 1987 p 36', 'solow robert m wed better watch out new york times book review july 12 1987 p 36', 59, 100, 1),
(9881, 75, 'productivity in the service sector has not kept pace with that in manufacturing', 'productivity in the service sector has not kept pace with that in manufacturing', 59, 100, 1),
(9882, 75, 'based on data from bureau of labor statistics productivity testing division', 'based on data from bureau of labor statistics productivity testing division', 59, 100, 1),
(9883, 75, 'now after some researchers found firmlevel evidence that it invest ments earned hefty returns the media pendulum has swung in the opposite direction', 'now after some researchers found firmlevel evidence that it invest ments earned hefty returns the media pendulum has swung in the opposite direction', 59, 100, 1),
(9884, 75, 'businessweeks proclamation of the productivity surge due to information technology2 and fortune magazines headline heralding the arrival of technology payoff represent the latest trend', 'businessweeks proclamation of the productivity surge due to information technology2 and fortune magazines headline heralding the arrival of technology payoff represent the latest trend', 59, 100, 1),
(9885, 75, 'a growing num ber of academic studies also report positive effects of information technol ogy on various measures of economic performance', 'a growing num ber of academic studies also report positive effects of information technol ogy on various measures of economic performance', 59, 100, 1),
(9886, 75, 'just as the business medias premature announcement of a productivity paradox was out of proportion to the more carefully worded academic research the current cover stories on productivity payoff are often over blown', 'just as the business medias premature announcement of a productivity paradox was out of proportion to the more carefully worded academic research the current cover stories on productivity payoff are often over blown', 59, 100, 1),
(9887, 75, 'a consensus on the relationship between it investment and eco nomic performance is still elusive', 'a consensus on the relationship between it investment and eco nomic performance is still elusive', 59, 100, 1),
(9888, 75, 'more than a decade ago one of the earliest surveys concluded that we still had much to learn about measuring the effects of computers on organizations attewell and rule 1984', 'more than a decade ago one of the earliest surveys concluded that we still had much to learn about measuring the effects of computers on organizations attewell and rule 1984', 59, 100, 1),
(9889, 75, 'a more recent survey also reports a sobering conclusion our understanding of how information technology affects productivity either at the level of the firm or for the economy as a whole is extremely limited wilson 1995', 'a more recent survey also reports a sobering conclusion our understanding of how information technology affects productivity either at the level of the firm or for the economy as a whole is extremely limited wilson 1995', 59, 100, 1),
(9890, 75, 'wildstrom stephen h the technology payoff businessweek june 14 1993 p 5668', 'wildstrom stephen h the technology payoff businessweek june 14 1993 p 5668', 59, 100, 1),
(9891, 75, 'mandel michael j the digital juggernaut businessweek the information revolution may 181994 bonus issue pp', 'mandel michael j the digital juggernaut businessweek the information revolution may 181994 bonus issue pp', 59, 100, 1),
(9892, 75, 'businessweek recently ran another cover story produc tivity to the rescue october 9 1995', 'businessweek recently ran another cover story produc tivity to the rescue october 9 1995', 59, 100, 1),
(9893, 75, 'magnet myron productivity payoff arrives fortune june 27 1994 pp', 'magnet myron productivity payoff arrives fortune june 27 1994 pp', 59, 100, 1),
(9894, 75, '182 erik brynjolfsson and shinkyu yang as more research is conducted we are gradually developing a clearer picture of the relationship between it and productivity', '182 erik brynjolfsson and shinkyu yang as more research is conducted we are gradually developing a clearer picture of the relationship between it and productivity', 59, 100, 1),
(9895, 75, 'however produc tivity measurement is not an exact science the tools are blunt and the conclusions are not definitive', 'however produc tivity measurement is not an exact science the tools are blunt and the conclusions are not definitive', 59, 100, 1),
(9896, 75, 'thus while one study shows a negative correlation between total factor productivity and high share of hightech capital formation during the 196886 period berndt and morrison 1995 another study suggests that computer capital contributes to growth more than ordinary capital jorgenson and stiroh 1995', 'thus while one study shows a negative correlation between total factor productivity and high share of hightech capital formation during the 196886 period berndt and morrison 1995 another study suggests that computer capital contributes to growth more than ordinary capital jorgenson and stiroh 1995', 59, 100, 1),
(9897, 75, 'more recently brynjolf son and hitt 1996 report positive effects of it based on firmlevel evi dence', 'more recently brynjolf son and hitt 1996 report positive effects of it based on firmlevel evi dence', 59, 100, 1),
(9898, 75, 'this article seeks to summarize what we know distinguish the central issues from peripheral ones and clarify the questions that future research should explore', 'this article seeks to summarize what we know distinguish the central issues from peripheral ones and clarify the questions that future research should explore', 59, 100, 1),
(9899, 75, 'results and implications of different studies should be interpreted in the context of specific research questions', 'results and implications of different studies should be interpreted in the context of specific research questions', 59, 100, 1),
(9900, 75, 'the question of aggregate economic performance differs from the question of firmlevel economic performance', 'the question of aggregate economic performance differs from the question of firmlevel economic performance', 59, 100, 1),
(9901, 75, 'data sources and performance measures may also depend on the level of aggregation', 'data sources and performance measures may also depend on the level of aggregation', 59, 100, 1),
(9902, 75, 'even within one level of aggregation results may depend on the measure of performance or research method', 'even within one level of aggregation results may depend on the measure of performance or research method', 59, 100, 1),
(9903, 75, 'it is hoped that the process of reviewing studies of the productivity mystery will serve as a useful springboard for examining alternative methodologies and the broader issues involved', 'it is hoped that the process of reviewing studies of the productivity mystery will serve as a useful springboard for examining alternative methodologies and the broader issues involved', 59, 100, 1),
(9904, 75, 'as a prelude to the literature survey it is useful to define some of the terms used and to highlight some of the basic trends in the economics of it', 'as a prelude to the literature survey it is useful to define some of the terms used and to highlight some of the basic trends in the economics of it', 59, 100, 1),
(9905, 75, 'definitions 0 information technology can be defined in various ways', 'definitions 0 information technology can be defined in various ways', 59, 100, 1),
(9906, 75, 'in terms of capital among the most common is the beas us bureau of eco nomic analysis category office computing and accounting machin ery ocam which consists primarily of computers', 'in terms of capital among the most common is the beas us bureau of eco nomic analysis category office computing and accounting machin ery ocam which consists primarily of computers', 59, 100, 1),
(9907, 75, 'some research ers look specifically at computer capital whereas others consider the beas broader category information processing equipment ipe ipe includes communications equipment scientific and engineering instruments photocopiers and related equipment', 'some research ers look specifically at computer capital whereas others consider the beas broader category information processing equipment ipe ipe includes communications equipment scientific and engineering instruments photocopiers and related equipment', 59, 100, 1),
(9908, 75, 'in addition soft ware and related services are sometimes included in the it capital', 'in addition soft ware and related services are sometimes included in the it capital', 59, 100, 1),
(9909, 75, 'recent studies often examine the productivity of information systems staff or of workers who use computers', 'recent studies often examine the productivity of information systems staff or of workers who use computers', 59, 100, 1),
(9910, 75, '0 labor productivity is calculated as the level of output divided by a given level of labor input', '0 labor productivity is calculated as the level of output divided by a given level of labor input', 59, 100, 1),
(9911, 75, 'multifactor productivity sometimes more ambitiously called total factor productivity is calculated as the level of output for a given level of several inputs typically labor capital and materials', 'multifactor productivity sometimes more ambitiously called total factor productivity is calculated as the level of output for a given level of several inputs typically labor capital and materials', 59, 100, 1),
(9912, 75, 'in principle multifactor productivity is a better measure information technology and productivity 183 of a firm or industrys efficiency because it adjusts for shifts among inputs such as substituting capital equipment for labor', 'in principle multifactor productivity is a better measure information technology and productivity 183 of a firm or industrys efficiency because it adjusts for shifts among inputs such as substituting capital equipment for labor', 59, 100, 1),
(9913, 75, 'however the data needed to calculate multifactor productivity are more complex', 'however the data needed to calculate multifactor productivity are more complex', 59, 100, 1),
(9914, 75, '0 in productivity calculations output is defined as the number of units produced times their unit value proxied by their real price', '0 in productivity calculations output is defined as the number of units produced times their unit value proxied by their real price', 59, 100, 1),
(9915, 75, 'determin ing the real price of a good or service requires the calculation of individual price deflators to eliminate the effects of inflation', 'determin ing the real price of a good or service requires the calculation of individual price deflators to eliminate the effects of inflation', 59, 100, 1),
(9916, 75, 'trends the price of computing has dropped by half every 23 years figs', 'trends the price of computing has dropped by half every 23 years figs', 59, 100, 1),
(9917, 75, '3a and b4 if progress in the rest of the economy had matched progress in the computer sector a cadillac would cost 498 while 10 minutes labor would buy a years worth of groceries 0 there have been increasing levels of business investment in informa tion technology equipment', '3a and b4 if progress in the rest of the economy had matched progress in the computer sector a cadillac would cost 498 while 10 minutes labor would buy a years worth of groceries 0 there have been increasing levels of business investment in informa tion technology equipment', 59, 100, 1),
(9918, 75, 'these investments now account for more than 10 of new investment in capital equipment by american firms fig', 'these investments now account for more than 10 of new investment in capital equipment by american firms fig', 59, 100, 1),
(9919, 75, '4 table ii6 information processing continues to be the principal task undertaken by americas workforce', '4 table ii6 information processing continues to be the principal task undertaken by americas workforce', 59, 100, 1),
(9920, 75, 'more than half the labor force is employed in informationhandling activities fig', 'more than half the labor force is employed in informationhandling activities fig', 59, 100, 1),
(9921, 75, '5 0 overall productivity growth appears to have slowed significantly since the early 1970s and measured productivity growth has fallen especially sharply in the service sectors which account for 80 of it investment fig', '5 0 overall productivity growth appears to have slowed significantly since the early 1970s and measured productivity growth has fallen especially sharply in the service sectors which account for 80 of it investment fig', 59, 100, 1),
(9922, 75, 'white collar productivity statistics have been essentially stagnant for 20 years fig', 'white collar productivity statistics have been essentially stagnant for 20 years fig', 59, 100, 1),
(9923, 75, 'this relationship has been dubbed moores law after john moore who first documented the trend in microprocessors', 'this relationship has been dubbed moores law after john moore who first documented the trend in microprocessors', 59, 100, 1),
(9924, 75, 'it is widely projected to continue at least into the next century', 'it is widely projected to continue at least into the next century', 59, 100, 1),
(9925, 75, 'in the last 35 years the qualityadjusted costs of computing have decreased over 6000fold relative to equipment prices outside the computer sector gordon 1987b', 'in the last 35 years the qualityadjusted costs of computing have decreased over 6000fold relative to equipment prices outside the computer sector gordon 1987b', 59, 100, 1),
(9926, 75, 'this comparison was inspired by the slightly exaggerated claim in forbes magazine 11980 that if the auto industry had done what the computer industry has done', 'this comparison was inspired by the slightly exaggerated claim in forbes magazine 11980 that if the auto industry had done what the computer industry has done', 59, 100, 1),
(9927, 75, 'a rollsroyce would cost 250 and get 2000ooo miles to the gallon the 498 cadillac is based on a price of 30890 for a 1991 sedan de ville divided by 6203 the relative deflator for computers', 'a rollsroyce would cost 250 and get 2000ooo miles to the gallon the 498 cadillac is based on a price of 30890 for a 1991 sedan de ville divided by 6203 the relative deflator for computers', 59, 100, 1),
(9928, 75, 'the grocery comparison is based on a wage of 10 an hour and 10000 worth of groceries each in 1991 dollars', 'the grocery comparison is based on a wage of 10 an hour and 10000 worth of groceries each in 1991 dollars', 59, 100, 1),
(9929, 75, 'some studies estimate that as much as 50 of recent equipment investment is in informa tion technology kriebel 1989', 'some studies estimate that as much as 50 of recent equipment investment is in informa tion technology kriebel 1989', 59, 100, 1),
(9930, 75, 'this higher figure seems to be partly due to a broader definition of it', 'this higher figure seems to be partly due to a broader definition of it', 59, 100, 1),
(9931, 75, 'a discrepancy also arises when recent investments are expressed in 1982 dollars when it was relatively more expensive', 'a discrepancy also arises when recent investments are expressed in 1982 dollars when it was relatively more expensive', 59, 100, 1),
(9932, 75, 'this has the effect of boosting its real share over time faster than its nominal share grows', 'this has the effect of boosting its real share over time faster than its nominal share grows', 59, 100, 1),
(9933, 75, 'the recent change by bea to a chainweighted index instead of a fixedweight index will largely alleviate this problem', 'the recent change by bea to a chainweighted index instead of a fixedweight index will largely alleviate this problem', 59, 100, 1),
(9934, 75, 'b 1oooo lw0 100 1 o 01 1955 1960 1965 1970 1975 1980 1985 1990 year 52year 42iyear growth growth year mcroprocessor a dram fig', 'b 1oooo lw0 100 1 o 01 1955 1960 1965 1970 1975 1980 1985 1990 year 52year 42iyear growth growth year mcroprocessor a dram fig', 59, 100, 1),
(9935, 75, 'a the cost of computing has declined substantially relative to other capital pur chases', 'a the cost of computing has declined substantially relative to other capital pur chases', 59, 100, 1),
(9936, 75, 'based on data from us department of com merce survey of current business', 'based on data from us department of com merce survey of current business', 59, 100, 1),
(9937, 75, 'b microchip performance has shown uninterrupted exponential growth', 'b microchip performance has shown uninterrupted exponential growth', 59, 100, 1),
(9938, 75, 'p6 p7 microprocessors and 256m lg 4g drams are estimated by intel and the semiconductor industry association', 'p6 p7 microprocessors and 256m lg 4g drams are estimated by intel and the semiconductor industry association', 59, 100, 1),
(9939, 75, 'based on data from grove 1990 and intel data', 'based on data from grove 1990 and intel data', 59, 100, 1),
(9940, 75, 'computers comprise about 10 of currentdollar investment in pde', 'computers comprise about 10 of currentdollar investment in pde', 59, 100, 1),
(9941, 75, 'based on data from bea national income and wealth division', 'based on data from bea national income and wealth division and adapted from jorgenson and stiroh 1995', 59, 78.6903, 1),
(9942, 75, 'based on data from bea national income and wealth division', 'based on data from bea national income and wealth division', 59, 100, 1),
(9943, 75, 'these trends suggest the two central questions of the productivity paradox 1 why would companies invest so heavily in information technology if it did not add to productivity', 'these trends suggest the two central questions of the productivity paradox 1 why would companies invest so heavily in information technology if it did not add to productivity', 59, 100, 1),
(9944, 75, '2 if information technology does contribute to productivity why is its contribution so difficult to measure', '2 if information technology does contribute to productivity why is its contribution so difficult to measure', 59, 100, 1),
(9945, 75, 'this article builds on a number of earlier literature surveys this review considers more than 150 articles but is not comprehensive', 'this article builds on a number of earlier literature surveys this review considers more than 150 articles but is not comprehensive', 59, 100, 1),
(9946, 75, 'rather we aim much of the material is adapted from a previous paper by brynjolfsson 1993', 'rather we aim much of the material is adapted from a previous paper by brynjolfsson 1993', 59, 100, 1),
(9947, 75, 'crowston and treacy 1986 surveyed 11 articles from 1975 to 1985 on the impact of it on enterprise level performance and conclude that attempts to measure the impact of it were surprisingly unsuccessful', 'crowston and treacy 1986 surveyed 11 articles from 1975 to 1985 on the impact of it on enterprise level performance and conclude that attempts to measure the impact of it were surprisingly unsuccessful', 59, 100, 1),
(9948, 75, 'they attribute this to poorly defined variables a result of inadequate reference disciplines and methodologies', 'they attribute this to poorly defined variables a result of inadequate reference disciplines and methodologies', 59, 100, 1),
(9949, 75, 'a review of research combining information systems and economics by bakos and kemerer 1992 includes particularly relevant work', 'a review of research combining information systems and economics by bakos and kemerer 1992 includes particularly relevant work', 59, 100, 1),
(9950, 75, 'in addition many papers that seek to assess it productivity directly begin with a literature survey the reviews by brooke 1992 barua ef al', 'in addition many papers that seek to assess it productivity directly begin with a literature survey the reviews by brooke 1992 barua ef al', 59, 100, 1),
(9951, 75, '1991 and berndt and morrison 1995 were particu larly useful', '1991 and berndt and morrison 1995 were particu larly useful', 59, 100, 1),
(9952, 75, 'most recently the first part of landauer 1995 details research on the productivity puzzle', 'most recently the first part of landauer 1995 details research on the productivity puzzle', 59, 100, 1),
(9953, 75, 'wilson 1995 also provides a useful survey of articles', 'wilson 1995 also provides a useful survey of articles', 59, 100, 1),
(9954, 75, 'q pi 8 100 3 go 80 50 white collar productivity infomation agricultum industry c bnb 0 1850 1800 in50 2000 year fic', 'q pi 8 100 3 go 80 50 white collar productivity infomation agricultum industry c bnb 0 1850 1800 in50 2000 year fic', 59, 100, 1),
(9955, 75, 'information processing is the largest category of employment', 'information processing is the largest category of employment', 59, 100, 1),
(9956, 75, 'the defining criterion for information workers is whether the primary activity is knowledge creation warehousing or dissemination', 'the defining criterion for information workers is whether the primary activity is knowledge creation warehousing or dissemination', 59, 100, 1),
(9957, 75, 'information technology and productivity 187 to clarify the principal issues surrounding it and productivity', 'information technology and productivity 187 to clarify the principal issues surrounding it and productivity', 59, 100, 1),
(9958, 75, 'we assimilate the results of a computerized literature surrounding it and productivity', 'we assimilate the results of a computerized literature surrounding it and productivity', 59, 100, 1),
(9959, 75, 'we assimilate the results of a computerized literature search of 30 leading journals in information systems and economics8 in addition many of the leading researchers in this area identified recent research that has not yet been published', 'we assimilate the results of a computerized literature search of 30 leading journals in information systems and economics8 in addition many of the leading researchers in this area identified recent research that has not yet been published', 59, 100, 1),
(9960, 75, 'the productivity of it can be measured using data on the whole economy on specified industries or on individual firms', 'the productivity of it can be measured using data on the whole economy on specified industries or on individual firms', 59, 100, 1),
(9961, 75, 'in the 1980s and early 1990s disappointment in information technology was chronicles in articles disclos ing broad negative correlations with economywide productivity', 'in the 1980s and early 1990s disappointment in information technology was chronicles in articles disclos ing broad negative correlations with economywide productivity', 59, 100, 1),
(9962, 75, 'several econometric estimates also indicated low it capital productivity in a variety of manufacturing and service industries', 'several econometric estimates also indicated low it capital productivity in a variety of manufacturing and service industries', 59, 100, 1),
(9963, 75, 'more recently researchers began to find positive relationships between it investment and various measures of economic performance at the level of individual firms', 'more recently researchers began to find positive relationships between it investment and various measures of economic performance at the level of individual firms', 59, 100, 1),
(9964, 75, 'the principal empirical research studies of it and productivity are listed in table i', 'the principal empirical research studies of it and productivity are listed in table i', 59, 100, 1),
(9965, 75, 'research on economywide productivity and information worker productivity economists have been unable to explain the slowdown in measured productivity growth that began in the early 1970s', 'research on economywide productivity and information worker productivity economists have been unable to explain the slowdown in measured productivity growth that began in the early 1970s', 59, 100, 1),
(9966, 75, 'labor productivity grew about 25 per year from 1953 to 1968 but dropped to about 07 per year from 1973 to 1979', 'labor productivity grew about 25 per year from 1953 to 1968 but dropped to about 07 per year from 1973 to 1979', 59, 100, 1),
(9967, 75, 'multifactor productivity growth declined from 175 a year to 032 baily 1986b', 'multifactor productivity growth declined from 175 a year to 032 baily 1986b', 59, 100, 1),
(9968, 75, 'even after accounting for factors such as the oil price shocks changes in the quality of the labor force and potential measurement errors most researchers still find an unexplained residual drop in productivity that roughly coincides with the rapid increase in the use of information technology', 'even after accounting for factors such as the oil price shocks changes in the quality of the labor force and potential measurement errors most researchers still find an unexplained residual drop in productivity that roughly coincides with the rapid increase in the use of information technology', 59, 100, 1),
(9969, 75, 'jorgenson and stirohs 1995 more recent growth accounting confirms this correlation', 'jorgenson and stirohs 1995 more recent growth accounting confirms this correlation', 59, 100, 1),
(9970, 75, 'articles were selected if they indicated an emphasis on computers information systems information technology decision support sys tems expert systems or high technology combined with an emphasis on productivity', 'articles were selected if they indicated an emphasis on computers information systems information technology decision support sys tems expert systems or high technology combined with an emphasis on productivity', 59, 100, 1),
(9971, 75, 'roach 1987 1989b brooke 1992 lau tokutsu 1992 oliner sichel 1994 jorgenson stiroh 1995 osterman 1986 dos santos er al', 'roach 1987 1989b brooke 1992 lau tokutsu 1992 oliner sichel 1994 jorgenson stiroh 1995 osterman 1986 dos santos er al', 59, 100, 1),
(9972, 75, '1993 krueger 1993 brynjolfsson hitt 1994 hitt brynjolfsson 1994 lichtenberg 1995 brynjolfsson hitt 1996 baily gordon 1988 morrison berndt 1991 berndt et al', '1993 krueger 1993 brynjolfsson hitt 1994 hitt brynjolfsson 1994 lichtenberg 1995 brynjolfsson hitt 1996 baily gordon 1988 morrison berndt 1991 berndt et al', 59, 100, 1),
(9973, 75, '1992 berndt morrison 1995 siegel griliches 1992 siegel 1994 brand duke 1982 baily 1986a roach 1987 1989a 1991 loveman 1994 weill 1992 dudley lasserre 1989 barua er al', '1992 berndt morrison 1995 siegel griliches 1992 siegel 1994 brand duke 1982 baily 1986a roach 1987 1989a 1991 loveman 1994 weill 1992 dudley lasserre 1989 barua er al', 59, 100, 1),
(9974, 75, '1991 brynjolfsson hitt 1993 1995 1996 cron sobol 1983 pulley braunstein 1984 bender 1986 bresnahan 1986 franke 1987 strassmann 1985 1990 harris katz 1991 parsons et al', '1991 brynjolfsson hitt 1993 1995 1996 cron sobol 1983 pulley braunstein 1984 bender 1986 bresnahan 1986 franke 1987 strassmann 1985 1990 harris katz 1991 parsons et al', 59, 100, 1),
(9975, 75, '1990 diewert smith 1994 information technology and productivity 189 197392 period', '1990 diewert smith 1994 information technology and productivity 189 197392 period', 59, 100, 1),
(9976, 75, 'at the same time ocam capital as a percentage of all producers durable equipment pde investment rose from about 05 in the 1960s to 12 in 1993', 'at the same time ocam capital as a percentage of all producers durable equipment pde investment rose from about 05 in the 1960s to 12 in 1993', 59, 100, 1),
(9977, 75, 'a broader category of it capital information processing equipment ipe now constitutes 342 of all pde investment table 11', 'a broader category of it capital information processing equipment ipe now constitutes 342 of all pde investment table 11', 59, 100, 1),
(9978, 75, 'although productivity growth especially in manufacturing has rebounded somewhat recently the overall negative correlation between productivity and the advent of computers underlies many arguments that information technology has not helped the united states productivity and that information technology investments have been counterproductive', 'although productivity growth especially in manufacturing has rebounded somewhat recently the overall negative correlation between productivity and the advent of computers underlies many arguments that information technology has not helped the united states productivity and that information technology investments have been counterproductive', 59, 100, 1),
(9979, 75, 'see for example baily 1986bl this argument was made more explicitly by stephen roach 19871988 who focused on the productivity of information workers', 'see for example baily 1986bl this argument was made more explicitly by stephen roach 19871988 who focused on the productivity of information workers', 59, 100, 1),
(9980, 75, 'in the past office work was not very capital intensive but recently the level of it capital per white collar information worker has approached that of production capital per blue collar production worker', 'in the past office work was not very capital intensive but recently the level of it capital per white collar information worker has approached that of production capital per blue collar production worker', 59, 100, 1),
(9981, 75, 'concurrently the ranks of information workers have ballooned and the ranks of production workers have shrunk', 'concurrently the ranks of information workers have ballooned and the ranks of production workers have shrunk', 59, 100, 1),
(9982, 75, 'roach shows that output per production worker grew by 169 between the 1970s and 1986 while output per information worker decreased by 66', 'roach shows that output per production worker grew by 169 between the 1970s and 1986 while output per information worker decreased by 66', 59, 100, 1),
(9983, 75, 'in 1992 it capital stock ocam was equal to about 10 of gdp with a base year of 1987', 'in 1992 it capital stock ocam was equal to about 10 of gdp with a base year of 1987', 59, 100, 1),
(9984, 75, 'if hypothetically its marginal product were 50 exceeding the return to most other capital investments then the level of gross domes tic product gdp would be directly increased about 5 10 x 50 because of the current stock of it', 'if hypothetically its marginal product were 50 exceeding the return to most other capital investments then the level of gross domes tic product gdp would be directly increased about 5 10 x 50 because of the current stock of it', 59, 100, 1),
(9985, 75, 'however information technology capital stock did not jump to its current level in 1 year rather the increase must be spread over about 30 years suggesting an average annual contribution to aggregate gdp growth of 015', 'however information technology capital stock did not jump to its current level in 1 year rather the increase must be spread over about 30 years suggesting an average annual contribution to aggregate gdp growth of 015', 59, 100, 1),
(9986, 75, 'this contribution would be very difficult to isolate because so many other factors affected gdp especially in the relatively turbulent 1970s and 1980s', 'this contribution would be very difficult to isolate because so many other factors affected gdp especially in the relatively turbulent 1970s and 1980s', 59, 100, 1),
(9987, 75, '1 90 erik brynjolfsson and shinkyu yang table i1 selected investment components in 1970 and 1993 current', '1 90 erik brynjolfsson and shinkyu yang table i1 selected investment components in 1970 and 1993 current', 59, 100, 1),
(9988, 75, 'ery communication equipment and scientific and engineering equipment', 'ery communication equipment and scientific and engineering equipment', 59, 100, 1),
(9989, 75, 'capital were anywhere from 0 to 65 it would still not have affected aggregate gdp growth by more than about 02 per year', 'capital were anywhere from 0 to 65 it would still not have affected aggregate gdp growth by more than about 02 per year', 59, 100, 1);
INSERT INTO `plagiarism_results` (`id`, `archive_id`, `submitted_sentence`, `existing_sentence`, `similar_archive_id`, `similarity_percentage`, `is_plagiarized`) VALUES
(9990, 75, 'more compre hensive growth accounting exercises confirm this estimate see section 5', 'more compre hensive growth accounting exercises confirm this estimate see section 5', 59, 100, 1),
(9991, 75, 'thus very large changes in capital stock are needed to change total output measurably although computers may have had significant effects in specific activities such as transaction processing and on other characteris tics of the economy such as employment shares organizational structure and product variety', 'thus very large changes in capital stock are needed to change total output measurably although computers may have had significant effects in specific activities such as transaction processing and on other characteris tics of the economy such as employment shares organizational structure and product variety', 59, 100, 1),
(9992, 75, 'in contrast it costs about 100000 or so in salary and overhead to employ a white collar worker', 'in contrast it costs about 100000 or so in salary and overhead to employ a white collar worker', 59, 100, 1),
(9993, 75, 'for instance if a new delivery schedule optimizer allows a firm to substitute one clerk for two truckers the increase in the number of white collar workers is evidence of an increase in their relative productivity as well as the firms productivity', 'for instance if a new delivery schedule optimizer allows a firm to substitute one clerk for two truckers the increase in the number of white collar workers is evidence of an increase in their relative productivity as well as the firms productivity', 59, 100, 1),
(9994, 75, 'osterman 1986 suggests that such efficiency improvements can explain why firms often hire more clerical workers after they introduce computers and berndt et al', 'osterman 1986 suggests that such efficiency improvements can explain why firms often hire more clerical workers after they introduce computers and berndt et al', 59, 100, 1),
(9995, 75, '1992 confirm that information technology capital is on average a complement for white collar labor and is correlated with fewer blue collar workers', '1992 confirm that information technology capital is on average a complement for white collar labor and is correlated with fewer blue collar workers', 59, 100, 1),
(9996, 75, '1994 also find that the increased use of nonproduc tion workers is strongly correlated with investment in computers and rd unfortunately it is exceedlingly difficult to measure directly the productivity of office workers', '1994 also find that the increased use of nonproduc tion workers is strongly correlated with investment in computers and rd unfortunately it is exceedlingly difficult to measure directly the productivity of office workers', 59, 100, 1),
(9997, 75, 'independent of its implications for productivity growth in the white collar workforce cannot be attributed solely to information technology', 'independent of its implications for productivity growth in the white collar workforce cannot be attributed solely to information technology', 59, 100, 1),
(9998, 75, 'although almost half of workers now use computers in their jobs katz and kreuger 1994 the ranks of information workers began to surge even before the advent of computers porat 1977', 'although almost half of workers now use computers in their jobs katz and kreuger 1994 the ranks of information workers began to surge even before the advent of computers porat 1977', 59, 100, 1),
(9999, 75, 'in fact jonscher 1994 argues that the increased demand for information technology created econ omies of scale and learning in the computer industry thereby reducing the cost of computers', 'in fact jonscher 1994 argues that the increased demand for information technology created econ omies of scale and learning in the computer industry thereby reducing the cost of computers', 59, 100, 1),
(10000, 75, 'in line with this argument the unbalanced growth hypothesis may provide a sensible economic explanation economic growth may slow down be cause of intrinsically slow technical progress in the white colalr sector since it is less subject to automation', 'in line with this argument the unbalanced growth hypothesis may provide a sensible economic explanation economic growth may slow down be cause of intrinsically slow technical progress in the white colalr sector since it is less subject to automation', 59, 100, 1),
(10001, 75, 'then why is the white collar sectors share in the economy growing', 'then why is the white collar sectors share in the economy growing', 59, 100, 1),
(10002, 75, 'one possible answer is the higher income elasticity and lower price elasticity of demand for services of this sector', 'one possible answer is the higher income elasticity and lower price elasticity of demand for services of this sector', 59, 100, 1),
(10003, 75, 'as income an important study of computerusing workers by krueger 1993 indirectly supports this view', 'as income an important study of computerusing workers by krueger 1993 indirectly supports this view', 59, 100, 1),
(10004, 75, 'he found that computerusing workers earned wages 10 to 18 higher than nonusers', 'he found that computerusing workers earned wages 10 to 18 higher than nonusers', 59, 100, 1),
(10005, 75, 'in 1984 246 of workers were using computers at work', 'in 1984 246 of workers were using computers at work', 59, 100, 1),
(10006, 75, 'katz and krueger 1994 also report that this share of workers had risen to 47 by 1993', 'katz and krueger 1994 also report that this share of workers had risen to 47 by 1993', 59, 100, 1),
(10007, 75, 'assuming that workers are paid according to their productivity this implies that computers at work increase gdp level by 3 3 07 x 01 x 374', 'assuming that workers are paid according to their productivity this implies that computers at work increase gdp level by 3 3 07 x 01 x 374', 59, 100, 1),
(10008, 75, '01 is the excess marginal product and 07 is the labor share of gdp', '01 is the excess marginal product and 07 is the labor share of gdp', 59, 100, 1),
(10009, 75, 'although this numbcr is not sufficient to compensate for the annual 1 productivity slowdown after the early 1970s', 'although this numbcr is not sufficient to compensate for the annual 1 productivity slowdown after the early 1970s', 59, 100, 1),
(10010, 75, 'it indicates that information technology may boost office worker productivity', 'it indicates that information technology may boost office worker productivity', 59, 100, 1),
(10011, 75, 'for example baumol 1967 and baumol et al', 'for example baumol 1967 and baumol et al', 59, 100, 1),
(10012, 75, '192 erik brynjolfsson and shinkyu yang increases people demand more services of white collar sectors', '192 erik brynjolfsson and shinkyu yang increases people demand more services of white collar sectors', 59, 100, 1),
(10013, 75, 'thus even if information technology does not add to productivity companies in devel oped countries may be forced to invest in it', 'thus even if information technology does not add to productivity companies in devel oped countries may be forced to invest in it', 59, 100, 1),
(10014, 75, 'since it is difficult to measure white collar sector output the story becomes complicated', 'since it is difficult to measure white collar sector output the story becomes complicated', 59, 100, 1),
(10015, 75, 'companies in vest in computers to produce unmeasurables as argued in griliches 1994', 'companies in vest in computers to produce unmeasurables as argued in griliches 1994', 59, 100, 1),
(10016, 75, 'in short the increased it use may not be a source of the productivity slowdown but simply a response to the overall transformation of the econ omy', 'in short the increased it use may not be a source of the productivity slowdown but simply a response to the overall transformation of the econ omy', 59, 100, 1),
(10017, 75, 'furthermore the main benefits from using computers appear to be in areas such as improved quality variety timeliness and customization which are not wellmeasured in official productivity statistics brynjolf sson 1994', 'furthermore the main benefits from using computers appear to be in areas such as improved quality variety timeliness and customization which are not wellmeasured in official productivity statistics brynjolf sson 1994', 59, 100, 1),
(10018, 75, 'industrylevel studies of information technology productivity the preceding section has shown that contrasting the economywide productivity slowdown with increasing it investment is an obtuse ap proach because so many other factors may intervene', 'industrylevel studies of information technology productivity the preceding section has shown that contrasting the economywide productivity slowdown with increasing it investment is an obtuse ap proach because so many other factors may intervene', 59, 100, 1),
(10019, 75, 'going down to the firm level helps to control many problems that arise from aggregation but it is often difficult to find data representative for the whole economy', 'going down to the firm level helps to control many problems that arise from aggregation but it is often difficult to find data representative for the whole economy', 59, 100, 1),
(10020, 75, 'we start with studies on service sectors', 'we start with studies on service sectors', 59, 100, 1),
(10021, 75, 'it has been widely reported that most of the productivity slowdown is concentrated in the service sector schneider 1987 roach 1987 1991', 'it has been widely reported that most of the productivity slowdown is concentrated in the service sector schneider 1987 roach 1987 1991', 59, 100, 1),
(10022, 75, 'before about 1970 service and manufacturing productivity growth rates were comparable but since then the trends have diverged significantlyi3 meanwhile services have dramatically increased as a share of total employ ment and to a lesser extent as a share of total output', 'before about 1970 service and manufacturing productivity growth rates were comparable but since then the trends have diverged significantlyi3 meanwhile services have dramatically increased as a share of total employ ment and to a lesser extent as a share of total output', 59, 100, 1),
(10023, 75, 'because services use up to 80 of computer capital table iv the slow growth of productivity in the service sector has been taken as indirect evidence of poor information according to government statistics from 1953 to 1968 labor productivity growth in services averaged 256 versus 261 in manufacturing', 'because services use up to 80 of computer capital table iv the slow growth of productivity in the service sector has been taken as indirect evidence of poor information according to government statistics from 1953 to 1968 labor productivity growth in services averaged 256 versus 261 in manufacturing', 59, 100, 1),
(10024, 75, 'for 1973 to 1979 the figures are 068 versus 153 respectively baily 1986b', 'for 1973 to 1979 the figures are 068 versus 153 respectively baily 1986b', 59, 100, 1),
(10025, 75, 'however gordon and baily 1989 and griliches 19941995 suggest that measurement errors in us', 'however gordon and baily 1989 and griliches 19941995 suggest that measurement errors in us', 59, 100, 1),
(10026, 75, 'statistics systematically under state service productivity growth relative to manufacturing', 'statistics systematically under state service productivity growth relative to manufacturing', 59, 100, 1),
(10027, 75, 'more recently computers defi nitely have caused some divergence in the statistics on manufacturing and service productivity but for a very different reason', 'more recently computers defi nitely have caused some divergence in the statistics on manufacturing and service productivity but for a very different reason', 59, 100, 1),
(10028, 75, 'because of the enormous quality improvements attributed to the computers the nonelectrical machinery category containing the computerproducing industry has shown tremendous growth', 'because of the enormous quality improvements attributed to the computers the nonelectrical machinery category containing the computerproducing industry has shown tremendous growth', 59, 100, 1),
(10029, 75, 'partly as a result overall manufacturing productivity growth has rebounded from about is in the 1970s to 35 in the 1980s', 'partly as a result overall manufacturing productivity growth has rebounded from about is in the 1970s to 35 in the 1980s', 59, 100, 1),
(10030, 75, 'economy percentage of total in current dollars 1979 1989 1992 industry agriculture 01 01 01 mining 24 11 09 manufacturing 294 203 202 construction 01 03 02 nonservice total 320 218 214 communication 15 14 15 utilities 12 28 28 trade 199 163 200 finance 325 387 378 other services 116 170 139 services total 680 782 786 unmeasurable sectors 641 723 719 plus consumer and 677 776 770 unmeasurable sector output 63 69 70 source bea adapted from griliches 1995', 'economy percentage of total in current dollars 1979 1989 1992 industry agriculture 01 01 01 mining 24 11 09 manufacturing 294 203 202 construction 01 03 02 nonservice total 320 218 214 communication 15 14 15 utilities 12 28 28 trade 199 163 200 finance 325 387 378 other services 116 170 139 services total 680 782 786 unmeasurable sectors 641 723 719 plus consumer and 677 776 770 unmeasurable sector output 63 69 70 source bea adapted from griliches 1995', 59, 100, 1),
(10031, 75, 'unmeasurable sectors construction trade fi nance and other services in these sectors outputs are difficult to measure relative to measurable sectors', 'unmeasurable sectors construction trade fi nance and other services in these sectors outputs are difficult to measure relative to measurable sectors', 59, 100, 1),
(10032, 75, 'roachs research 1987 1989a 1989b 1991 on white collar productivity discussed earlier focused principally on its per formance in the service sector', 'roachs research 1987 1989a 1989b 1991 on white collar productivity discussed earlier focused principally on its per formance in the service sector', 59, 100, 1),
(10033, 75, 'he argued that it is an effective substitute for labor in most manufacturing industries but has been associated with bloating white collar employment in services especially finance', 'he argued that it is an effective substitute for labor in most manufacturing industries but has been associated with bloating white collar employment in services especially finance', 59, 100, 1),
(10034, 75, 'he attrib uted this to relatively keener competitive pressures in manufacturing and he foresees a period of belttightening and restructuring in services as they begin to face international competition', 'he attrib uted this to relatively keener competitive pressures in manufacturing and he foresees a period of belttightening and restructuring in services as they begin to face international competition', 59, 100, 1),
(10035, 75, 'however studies of manufacturing also found evidence that computers may not increase productivity', 'however studies of manufacturing also found evidence that computers may not increase productivity', 59, 100, 1),
(10036, 75, 'berndt and morrison analyzed a broader data set from the us bureau of economic analysis bea that encom passes the whole us manufacturing sector', 'berndt and morrison analyzed a broader data set from the us bureau of economic analysis bea that encom passes the whole us manufacturing sector', 59, 100, 1),
(10037, 75, 'in their first paper morrison and berndt 1991 they examined a series of parameterized models of production and found evidence that every dollar spent on it delivered on average only about 080 of value on the margin indicating a general overinvestment in it', 'in their first paper morrison and berndt 1991 they examined a series of parameterized models of production and found evidence that every dollar spent on it delivered on average only about 080 of value on the margin indicating a general overinvestment in it', 59, 100, 1),
(10038, 75, 'their later paper berndt and morrison 1995 exam information technology and productivity 195 ined broad correlations of it investment with labor productivity and multi factor productivity', 'their later paper berndt and morrison 1995 exam information technology and productivity 195 ined broad correlations of it investment with labor productivity and multi factor productivity', 59, 100, 1),
(10039, 75, 'this approach did not find a significant difference be tween the productivity of it capital and other types of capital for a majority of the 20 industry categories examined', 'this approach did not find a significant difference be tween the productivity of it capital and other types of capital for a majority of the 20 industry categories examined', 59, 100, 1),
(10040, 75, 'they did find that investment in it was correlated with increased demand for skilled labor', 'they did find that investment in it was correlated with increased demand for skilled labor', 59, 100, 1),
(10041, 75, 'siegel and griliches 1992 used industry and establishment data from a variety of sources to examine several possible biases in conventional productivity estimates', 'siegel and griliches 1992 used industry and establishment data from a variety of sources to examine several possible biases in conventional productivity estimates', 59, 100, 1),
(10042, 75, 'they found a positive simple correlation between an industrys level of investment in computers and its multifactor productivity growth in the 1980s', 'they found a positive simple correlation between an industrys level of investment in computers and its multifactor productivity growth in the 1980s', 59, 100, 1),
(10043, 75, 'they did not examine more structural approaches in part because of troubling concerns about the reliability of the data and government measurement techniques', 'they did not examine more structural approaches in part because of troubling concerns about the reliability of the data and government measurement techniques', 59, 100, 1),
(10044, 75, 'their findings contrast with those of berndt and morrison 1995', 'their findings contrast with those of berndt and morrison 1995', 59, 100, 1),
(10045, 75, 'however berndt and morrision 1995 also document positive correlations between it capital and some measures of economic performance in the specifications where crosssectional effects were emphasized', 'however berndt and morrision 1995 also document positive correlations between it capital and some measures of economic performance in the specifications where crosssectional effects were emphasized', 59, 100, 1),
(10046, 75, 'in addition berndt and morrisons level of aggregation twodigit sic code is broader than that of siegel and griliches four digit sic code', 'in addition berndt and morrisons level of aggregation twodigit sic code is broader than that of siegel and griliches four digit sic code', 59, 100, 1),
(10047, 75, 'many researchers working on industrylevel data express concerns about data problems which are often caused by aggregation', 'many researchers working on industrylevel data express concerns about data problems which are often caused by aggregation', 59, 100, 1),
(10048, 75, 'for example the bea data are mainly used for industrylevel analyses but it is subject to subtle biases due to the techniques used to aggregate and classify establish ments', 'for example the bea data are mainly used for industrylevel analyses but it is subject to subtle biases due to the techniques used to aggregate and classify establish ments', 59, 100, 1),
(10049, 75, 'one of siegel and griliches 1992 principal conclusions was that after auditing the industry numbers we found that a nonnegligible num ber of sectors were not consistently defined over time siegel 1994 attempts to tackle the data problems that arise from two possible sources of measurement error', 'one of siegel and griliches 1992 principal conclusions was that after auditing the industry numbers we found that a nonnegligible num ber of sectors were not consistently defined over time siegel 1994 attempts to tackle the data problems that arise from two possible sources of measurement error', 59, 100, 1),
(10050, 75, 'the first kind of error occurs when computer price and quantity are measured with error', 'the first kind of error occurs when computer price and quantity are measured with error', 59, 100, 1),
(10051, 75, 'the second source of error is more subtle firms invest in computers not only for cost reduction but also for quality imprvement because the quality improvement is not fully taken into account in traditional statistics the errors in output measurement are correlated with computer investment', 'the second source of error is more subtle firms invest in computers not only for cost reduction but also for quality imprvement because the quality improvement is not fully taken into account in traditional statistics the errors in output measurement are correlated with computer investment', 59, 100, 1),
(10052, 75, 'these two kinds of errors cause bias and inefficiency in estimation', 'these two kinds of errors cause bias and inefficiency in estimation', 59, 100, 1),
(10053, 75, 'after controlling these errors using a multipleindicators and multiplecauses model siegel found a significant positive relationship between multifactor productivity growth and computer investment', 'after controlling these errors using a multipleindicators and multiplecauses model siegel found a significant positive relationship between multifactor productivity growth and computer investment', 59, 100, 1),
(10054, 75, 'he also found that computer investment is positively correlated with both product quality and labor quality a result that is consistent with brynjolfsson 1994 berndt and morrison 1995 and berman et al', 'he also found that computer investment is positively correlated with both product quality and labor quality a result that is consistent with brynjolfsson 1994 berndt and morrison 1995 and berman et al', 59, 100, 1),
(10055, 75, 'l4 see also brynjolfsson 1994 196 erik brynjolfsson and shinkyu yang 4', 'l4 see also brynjolfsson 1994 196 erik brynjolfsson and shinkyu yang 4', 59, 100, 1),
(10056, 75, 'firmlevel studies of information technology productivity during the past 10 years many studies examined the relationship between firms it investment and their performance', 'firmlevel studies of information technology productivity during the past 10 years many studies examined the relationship between firms it investment and their performance', 59, 100, 1),
(10057, 75, 'interestingly studies that have used larger and more recent data sets have found evidence that it positively affects firm performance', 'interestingly studies that have used larger and more recent data sets have found evidence that it positively affects firm performance', 59, 100, 1),
(10058, 75, 'research results in manufacturing often show stronger effects than studies of services probably because of better mea surement', 'research results in manufacturing often show stronger effects than studies of services probably because of better mea surement', 59, 100, 1),
(10059, 75, '41 service sector studies strassmann 1985 reports disappointing evidence in several studies see table v for a list of service sector studies', '41 service sector studies strassmann 1985 reports disappointing evidence in several studies see table v for a list of service sector studies', 59, 100, 1),
(10060, 75, 'in particular he found that there was no correlation between it and return on investment in a sample of 38 service sector firms some top performers invest heavily in it others do not', 'in particular he found that there was no correlation between it and return on investment in a sample of 38 service sector firms some top performers invest heavily in it others do not', 59, 100, 1),
(10061, 75, 'in his later book 1990 strassmann concludes that there is no relation between spending for computers profits and productivity several studies have examined its impact on the performance of finan cial services firms', 'in his later book 1990 strassmann concludes that there is no relation between spending for computers profits and productivity several studies have examined its impact on the performance of finan cial services firms', 59, 100, 1),
(10062, 75, '1990 estimated a production function for banking services in canada', '1990 estimated a production function for banking services in canada', 59, 100, 1),
(10063, 75, 'they found that the impact of it on multifactor productivity was quite low between 1974 and 1987', 'they found that the impact of it on multifactor productivity was quite low between 1974 and 1987', 59, 100, 1),
(10064, 75, 'they specu lated that it has positioned the industry for greater growth in the future', 'they specu lated that it has positioned the industry for greater growth in the future', 59, 100, 1),
(10065, 75, 'similarly franke 1987 found that it was associated with a sharp drop in capital productivity and stagnation in labor productivity but remained optimistic about the future potential of it citing the long time lags associ ated with previous technological transformations such as the conversion to steam power', 'similarly franke 1987 found that it was associated with a sharp drop in capital productivity and stagnation in labor productivity but remained optimistic about the future potential of it citing the long time lags associ ated with previous technological transformations such as the conversion to steam power', 59, 100, 1),
(10066, 75, 'in contrast brand and duke 1982 used bureau of labor statistics bls data and techniques and found that moderate productivity growth had already occurred in banking', 'in contrast brand and duke 1982 used bureau of labor statistics bls data and techniques and found that moderate productivity growth had already occurred in banking', 59, 100, 1),
(10067, 75, 'harris and katz 1991 and bender 1986 examined data on the insur ance industry from the life office management association information processing database', 'harris and katz 1991 and bender 1986 examined data on the insur ance industry from the life office management association information processing database', 59, 100, 1),
(10068, 75, 'they found positive but sometimes weak relationships between it expense ratios and various performance ratios', 'they found positive but sometimes weak relationships between it expense ratios and various performance ratios', 59, 100, 1),
(10069, 75, 'aipar and kim 1991 studied 759 banks and found that a 10 increase in it capital is associated with a 19 decrease in total costs', 'aipar and kim 1991 studied 759 banks and found that a 10 increase in it capital is associated with a 19 decrease in total costs', 59, 100, 1),
(10070, 75, 'several case studies of its impact on performance have also been done', 'several case studies of its impact on performance have also been done', 59, 100, 1),
(10071, 75, 'weitzendorf and wigand 1991 developed a model of information use in two service firms and pulley and braunstein 1984 studied an information services firm and found an association between it investment and increased economies of scope', 'weitzendorf and wigand 1991 developed a model of information use in two service firms and pulley and braunstein 1984 studied an information services firm and found an association between it investment and increased economies of scope', 59, 100, 1),
(10072, 75, 'estimating a production function brynjolfsson and hitt 1993 found that for the service firms in their sample gross marginal product averaged table v studies of firms in the service sector study data source findings pulley braunstein 1984 clarke 1985 strassmann 1985 1990 bender 1986 franke 1987 harris katz 1991 noyelle 1990 parsons er al', 'estimating a production function brynjolfsson and hitt 1993 found that for the service firms in their sample gross marginal product averaged table v studies of firms in the service sector study data source findings pulley braunstein 1984 clarke 1985 strassmann 1985 1990 bender 1986 franke 1987 harris katz 1991 noyelle 1990 parsons er al', 59, 100, 1),
(10073, 75, 'their 1995 study reports that it contributes as much output in the service sector as in the manufacturing sector brynjolfs son and hitt 1995', 'their 1995 study reports that it contributes as much output in the service sector as in the manufacturing sector brynjolfs son and hitt 1995', 59, 100, 1),
(10074, 75, 'because they used firmlevel data this result suggests that the productivity slowdown in the service sector may be an artifact of the mismeasurement of output in aggregate data sets', 'because they used firmlevel data this result suggests that the productivity slowdown in the service sector may be an artifact of the mismeasurement of output in aggregate data sets', 59, 100, 1),
(10075, 75, 'indeed even when firms were classified into measurable and unmeasurable sectors as defined by griliches 1994 no noticeable difference in it productivity between the sectors was found using this firmlevel data', 'indeed even when firms were classified into measurable and unmeasurable sectors as defined by griliches 1994 no noticeable difference in it productivity between the sectors was found using this firmlevel data', 59, 100, 1),
(10076, 75, 'diewert and smith 1994 provide an interesting case study of a large canadian retail distribution firm', 'diewert and smith 1994 provide an interesting case study of a large canadian retail distribution firm', 59, 100, 1),
(10077, 75, 'they found that the firm experienced an astounding 94 quarterly multifactor productivity growth for six consecu tive quarters starting at the second quarter of 1988', 'they found that the firm experienced an astounding 94 quarterly multifactor productivity growth for six consecu tive quarters starting at the second quarter of 1988', 59, 100, 1),
(10078, 75, 'even when data are abundant classifications sometimes seem arbitrary', 'even when data are abundant classifications sometimes seem arbitrary', 59, 100, 1),
(10079, 75, 'for instance in accordance with one standard approach parsons et al', 'for instance in accordance with one standard approach parsons et al', 59, 100, 1),
(10080, 75, '1990 treat time deposits as inputs into the banking production function and demand deposits as outputs', '1990 treat time deposits as inputs into the banking production function and demand deposits as outputs', 59, 100, 1),
(10081, 75, 'the logic for such decisions is sometimes tenuous and subtle changes in deposit patterns or classification standards can have disproportionate impacts', 'the logic for such decisions is sometimes tenuous and subtle changes in deposit patterns or classification standards can have disproportionate impacts', 59, 100, 1),
(10082, 75, 'the importance of variables other than it is also particularly apparent in some of the service sector studies', 'the importance of variables other than it is also particularly apparent in some of the service sector studies', 59, 100, 1),
(10083, 75, 'in particular researchers and consul tants have increasingly emphasized the need to reengineer work when introducing major it investments as wilson 1995 suggests it would be interesting to know whether reengineering efforts are the main explana tion for brynjolfsson and hitts 1993 1995 findings that it is correlated with increased output', 'in particular researchers and consul tants have increasingly emphasized the need to reengineer work when introducing major it investments as wilson 1995 suggests it would be interesting to know whether reengineering efforts are the main explana tion for brynjolfsson and hitts 1993 1995 findings that it is correlated with increased output', 59, 100, 1),
(10084, 75, 'a recent survey found that in fact firms that had reengineered were significantly more productive than their competitors b rynjolfsson 1994', 'a recent survey found that in fact firms that had reengineered were significantly more productive than their competitors b rynjolfsson 1994', 59, 100, 1),
(10085, 75, '42 studies of manufacturing sector and crosssector studies there have been several firmlevel studies of it productivity in the manufacturing sector', '196 42 studies of manufacturing sector and crosssector studies', 59, 77.2236, 1),
(10086, 75, '42 studies of manufacturing sector and crosssector studies there have been several firmlevel studies of it productivity in the manufacturing sector', '42 studies of manufacturing sector and crosssector studies there have been several firmlevel studies of it productivity in the manufacturing sector', 59, 100, 1),
(10087, 75, 'some of the important results are summarized in is see for example', 'some of the important results are summarized in is see for example', 59, 100, 1),
(10088, 75, 'a study by loveman 1994 provided some of the first economet ric evidence of an it productivity shortfall when he examined data from 60 business units using the management productivity and information tech nology mpit subset of the profit impact of market strategy pims database', 'a study by loveman 1994 provided some of the first economet ric evidence of an it productivity shortfall when he examined data from 60 business units using the management productivity and information tech nology mpit subset of the profit impact of market strategy pims database', 59, 100, 1),
(10089, 75, 'as is common in productivity literature he used an ordinary least squares regression and assumed that production functions could be approximated by a cobbdouglas function', 'as is common in productivity literature he used an ordinary least squares regression and assumed that production functions could be approximated by a cobbdouglas function', 59, 100, 1),
(10090, 75, 'loveman estimated that the contribution of information technology capital to final output was approxi mately zero over the 5year period he studied in almost every subsample', 'loveman estimated that the contribution of information technology capital to final output was approxi mately zero over the 5year period he studied in almost every subsample', 59, 100, 1),
(10091, 75, 'his findings were fairly robust to a number of variations on his basic formu lation', 'his findings were fairly robust to a number of variations on his basic formu lation', 59, 100, 1),
(10092, 75, '1991 traced lovemans results back a step by looking at its effect on intermediate variables such as capacity utilization inventory turnover quality relative price and new product introduction', '1991 traced lovemans results back a step by looking at its effect on intermediate variables such as capacity utilization inventory turnover quality relative price and new product introduction', 59, 100, 1),
(10093, 75, 'using the same data set they found that it was positively related to three of these five intermediate measures but that the effect was generally too small to affect final output measurably', 'using the same data set they found that it was positively related to three of these five intermediate measures but that the effect was generally too small to affect final output measurably', 59, 100, 1),
(10094, 75, 'dudley and lasserre 1989 also found econometric support for the hypothesis that better communication and information reduce the need for inventories without explicitly relating this to bottomline performance measures', 'dudley and lasserre 1989 also found econometric support for the hypothesis that better communication and information reduce the need for inventories without explicitly relating this to bottomline performance measures', 59, 100, 1),
(10095, 75, 'using a different data set weill 1992 disaggregated it by use and found that significant productivity could table vi studies of manufacturing firms and crosssector firms study data source findings loveman 1994 dudley lasserre 1989 weill 1992 barua et al', 'using a different data set weill 1992 disaggregated it by use and found that significant productivity could table vi studies of manufacturing firms and crosssector firms study data source findings loveman 1994 dudley lasserre 1989 weill 1992 barua et al', 59, 100, 1),
(10096, 75, '1991 brynjolfsson hitt 1993 brynjolfsson hitt 1995 lichtenberg 1995 kwon stoneman 1995 pimsmpit us', '1991 brynjolfsson hitt 1993 brynjolfsson hitt 1995 lichtenberg 1995 kwon stoneman 1995 pimsmpit us', 59, 100, 1),
(10097, 75, 'in a series of studies utilizing large firmlevel surveys by international data group idg brynjolfsson and hitt report that it improves produc tivity', 'in a series of studies utilizing large firmlevel surveys by international data group idg brynjolfsson and hitt report that it improves produc tivity', 59, 100, 1),
(10098, 75, 'their 1993 study found that while the gross marginal product of noncomputer capital ranges from 414 to 686 that of computer capital averages 56 to 68', 'their 1993 study found that while the gross marginal product of noncomputer capital ranges from 414 to 686 that of computer capital averages 56 to 68', 59, 100, 1),
(10099, 75, 'the results of this and their later study hitt and brynjolfsson 1994 imply that the following three null hypotheses can be rejected h1 it capital has a zero gross marginal product', 'the results of this and their later study hitt and brynjolfsson 1994 imply that the following three null hypotheses can be rejected h1 it capital has a zero gross marginal product', 59, 100, 1),
(10100, 75, 'h2 it capital has zero net marginal benefit after all costs have been sub h3 it capitals marginal product is not different from that of other tracted', 'h2 it capital has zero net marginal benefit after all costs have been sub h3 it capitals marginal product is not different from that of other tracted', 59, 100, 1),
(10101, 75, 'their point estimates of gross marginal products indicate that at the margin computer capital generates 10 times more output than other capital of equal value', 'their point estimates of gross marginal products indicate that at the margin computer capital generates 10 times more output than other capital of equal value', 59, 100, 1),
(10102, 75, 'brynjolfsson and hitt 1995 show that up to half of the excess returns imputed to it could be attributed to firmspecific effects', 'brynjolfsson and hitt 1995 show that up to half of the excess returns imputed to it could be attributed to firmspecific effects', 59, 100, 1),
(10103, 75, 'if gross marginal product of information technology capital is really so large what friction or market failure prevents firms from investing in more computers until the marginal products of all capital goods become equali6 one reason is that computer capital has a higher user cost', 'if gross marginal product of information technology capital is really so large what friction or market failure prevents firms from investing in more computers until the marginal products of all capital goods become equali6 one reason is that computer capital has a higher user cost', 59, 100, 1),
(10104, 75, 'he also analyzes informationweek survey data and uncovers essentially the same results', 'he also analyzes informationweek survey data and uncovers essentially the same results', 59, 100, 1),
(10105, 75, 'his formal tests reject the above null hypotheses', 'his formal tests reject the above null hypotheses', 59, 100, 1),
(10106, 75, 'importantly lichtenberg extends his study to report the i see for example robert j gordons comment on oliner and sichel 1994', 'importantly lichtenberg extends his study to report the i see for example robert j gordons comment on oliner and sichel 1994', 59, 100, 1),
(10107, 75, 'take 60 per year as brynjolfsson and hitts 1993 estimate of gross marginal product of information technology capital', 'take 60 per year as brynjolfsson and hitts 1993 estimate of gross marginal product of information technology capital', 59, 100, 1),
(10108, 75, 'its marginal product is more than 50 higher than that of other types of capital', 'its marginal product is more than 50 higher than that of other types of capital', 59, 100, 1),
(10109, 75, 'about 20 366154 is explained by the user costs of capital differential', 'about 20 366154 is explained by the user costs of capital differential', 59, 100, 1),
(10110, 75, 'because the unexplained portion is large we may expect a considerable amount in adjustment costs when implementing it investmentannual 30 of computer capital stock', 'because the unexplained portion is large we may expect a considerable amount in adjustment costs when implementing it investmentannual 30 of computer capital stock', 59, 100, 1),
(10111, 75, 'the differential is largely due to the rapid decline in computer prices', 'the differential is largely due to the rapid decline in computer prices', 59, 100, 1),
(10112, 75, 'information technology and productivity 20 1 marginal rate of substitution between it and nonit workers', 'information technology and productivity 20 1 marginal rate of substitution between it and nonit workers', 59, 100, 1),
(10113, 75, 'at the sample mean one it worker can apparently be substituted for six nonit workers', 'at the sample mean one it worker can apparently be substituted for six nonit workers', 59, 100, 1),
(10114, 75, 'research in manufacturing generally finds higher returns to it invest ment than in the services probably because of better measurement', 'research in manufacturing generally finds higher returns to it invest ment than in the services probably because of better measurement', 59, 100, 1),
(10115, 75, 'yet the mpit data which both loveman 1994 and barua et al', 'yet the mpit data which both loveman 1994 and barua et al', 59, 100, 1),
(10116, 75, 'although the point estimates for its contribution were quite low the standard errors were very high so that the 95 confi dence interval often exceeded 2200 for lovemans estimates', 'although the point estimates for its contribution were quite low the standard errors were very high so that the 95 confi dence interval often exceeded 2200 for lovemans estimates', 59, 100, 1),
(10117, 75, 'these stud ies may also be unrepresentative since the period covered by the mpit data 197883 was unusually turbulent', 'these stud ies may also be unrepresentative since the period covered by the mpit data 197883 was unusually turbulent', 59, 100, 1),
(10118, 75, 'the idg data set which is among the largest data sets used in this research area substantially mitigates data problems although it contains data on large firms only and so may not be a representative random sample', 'the idg data set which is among the largest data sets used in this research area substantially mitigates data problems although it contains data on large firms only and so may not be a representative random sample', 59, 100, 1),
(10119, 75, 'indeed brynjolfsson and hitt 1993 attribute the statistical significance of their findings partly to the large size of the idg data set which enables them to more precisely estimate returns for all factors', 'indeed brynjolfsson and hitt 1993 attribute the statistical significance of their findings partly to the large size of the idg data set which enables them to more precisely estimate returns for all factors', 59, 100, 1),
(10120, 75, 'utilizing comprehen sive surveys of the uk engineering industry undertaken in 1981 1986 and 1993 kwon and stoneman 1995 also find that the use of computers and numerical control machines has increased output and productivity', 'utilizing comprehen sive surveys of the uk engineering industry undertaken in 1981 1986 and 1993 kwon and stoneman 1995 also find that the use of computers and numerical control machines has increased output and productivity', 59, 100, 1),
(10121, 75, 'contribution to consumer surplus and economic growth some researchers have identified sizable contributions of it to consumer surplus and to economic growth', 'contribution to consumer surplus and economic growth some researchers have identified sizable contributions of it to consumer surplus and to economic growth', 59, 100, 1),
(10122, 75, 'some important studies are summarized in table vii', 'some important studies are summarized in table vii', 59, 100, 1),
(10123, 75, 'growth accounting and consumer surplus analysis are tech niques to identify and measure pecuniary externalities which griliches 19921994 distinguishes from nonpecuniary externalities of spillovers pecuniary externalities arise when the price of some input declines', 'growth accounting and consumer surplus analysis are tech niques to identify and measure pecuniary externalities which griliches 19921994 distinguishes from nonpecuniary externalities of spillovers pecuniary externalities arise when the price of some input declines', 59, 100, 1),
(10124, 75, 'for example when computer prices are declining exogenously profitmaximiz ing firms substitute computer systems for other input factors such as labor or warehouse space', 'for example when computer prices are declining exogenously profitmaximiz ing firms substitute computer systems for other input factors such as labor or warehouse space', 59, 100, 1),
(10125, 75, 'lowered prices of computers and other inputs shift marginal cost curves downward', 'lowered prices of computers and other inputs shift marginal cost curves downward', 59, 100, 1),
(10126, 75, 'these marginal cost curves result in higher output and lower prices', 'these marginal cost curves result in higher output and lower prices', 59, 100, 1),
(10127, 75, 'the output increase is a measure of the pecuniary externality the benefits created by the computer sector are reflected in greater output of computerusing industries', 'the output increase is a measure of the pecuniary externality the benefits created by the computer sector are reflected in greater output of computerusing industries', 59, 100, 1),
(10128, 75, 'a second measure of the pecu niary externality is consumer surplus', 'a second measure of the pecu niary externality is consumer surplus', 59, 100, 1),
(10129, 75, 'as computer prices fall many firms and customers that could not afford computers become able to purchase them whereas the customers who were willing to pay higher prices enjoy a windfall of price reduction', 'as computer prices fall many firms and customers that could not afford computers become able to purchase them whereas the customers who were willing to pay higher prices enjoy a windfall of price reduction', 59, 100, 1),
(10130, 75, 'large firms 016038 per year varying by different assumptions jorgenson stiroh principally bea growth contribution of computers for the 197992 period is 038052 per year brynjolfsson 1995 bea 70 billion consumer surplus is generated annually in the late 1980s', 'large firms 016038 per year varying by different assumptions jorgenson stiroh principally bea growth contribution of computers for the 197992 period is 038052 per year brynjolfsson 1995 bea 70 billion consumer surplus is generated annually in the late 1980s', 59, 100, 1),
(10131, 75, 'pecuniary externalities directly increase labor productivity yet they do not necessarily increase multifactor productivity', 'pecuniary externalities directly increase labor productivity yet they do not necessarily increase multifactor productivity', 59, 100, 1),
(10132, 75, 'pecuniary externalities do not change the production function rather they change the input mix', 'pecuniary externalities do not change the production function rather they change the input mix', 59, 100, 1),
(10133, 75, 'in contrast nonpecuniary externalities or spillovers arise from technical change people may have found smarter ways of making goods and services using information technlogy', 'in contrast nonpecuniary externalities or spillovers arise from technical change people may have found smarter ways of making goods and services using information technlogy', 59, 100, 1),
(10134, 75, 'the production possibility frontier shifts out both labor productivity and multifactor productivity should go up', 'the production possibility frontier shifts out both labor productivity and multifactor productivity should go up', 59, 100, 1),
(10135, 75, 'bresnahan 1986 estimated the benefits to consumers of declining com puter prices', 'bresnahan 1986 estimated the benefits to consumers of declining com puter prices', 59, 100, 1),
(10136, 75, 'he calculates that the consumer surplus was five or more times that of computer expenditures in the late 1960s financial sector', 'he calculates that the consumer surplus was five or more times that of computer expenditures in the late 1960s financial sector', 59, 100, 1),
(10137, 75, 'adopting similar assumptions brynjolfs son 1995 estimates that in 1987 between 69 billion and 79 billion consumer surplus was generated by 25 billion in expenditures on informa tion technology capital', 'adopting similar assumptions brynjolfs son 1995 estimates that in 1987 between 69 billion and 79 billion consumer surplus was generated by 25 billion in expenditures on informa tion technology capital', 59, 100, 1),
(10138, 75, 'now we turn to several growth accounting results', 'now we turn to several growth accounting results', 59, 100, 1),
(10139, 75, 'jorgenson and stirohs 1995 comprehensive growth accounting found that from 1979 to 1985 computers and peripherals contributed to output growth by 052 per year and that from 1985 to 1992 the contribution was 038 per year see table bresnahan and trajtenberg 1995 argue that general purpose technologies like com puters engender waves of smaller and complementary innovations', 'jorgenson and stirohs 1995 comprehensive growth accounting found that from 1979 to 1985 computers and peripherals contributed to output growth by 052 per year and that from 1985 to 1992 the contribution was 038 per year see table bresnahan and trajtenberg 1995 argue that general purpose technologies like com puters engender waves of smaller and complementary innovations', 59, 100, 1);
INSERT INTO `plagiarism_results` (`id`, `archive_id`, `submitted_sentence`, `existing_sentence`, `similar_archive_id`, `similarity_percentage`, `is_plagiarized`) VALUES
(10140, 75, 'this creates the potential for positive externalities from it and thus the possibility that it investment is too low compared to the socially optimal level', 'this creates the potential for positive externalities from it and thus the possibility that it investment is too low compared to the socially optimal level', 59, 100, 1),
(10141, 75, 'the hedonic price index method is an attempt to incorporate quality changes when constructing price indices using the regression technique', 'the hedonic price index method is an attempt to incorporate quality changes when constructing price indices using the regression technique', 59, 100, 1),
(10142, 75, 'information technology and productivity 203 viii21 because they assume that computers maintain their full ability until retirement their estimation of computer capitals contribution be comes larger than that of oliner and sichel 1994', 'information technology and productivity 203 viii21 because they assume that computers maintain their full ability until retirement their estimation of computer capitals contribution be comes larger than that of oliner and sichel 1994', 59, 100, 1),
(10143, 75, 'oliner and sichell994 carefully examine how the various excess return hypotheses of computer capital affect growth', 'oliner and sichell994 carefully examine how the various excess return hypotheses of computer capital affect growth', 59, 100, 1),
(10144, 75, 'as a baseline they estimate that the contribution of computer capital to output growth is 016 per year for the 197092 period', 'as a baseline they estimate that the contribution of computer capital to output growth is 016 per year for the 197092 period', 59, 100, 1),
(10145, 75, 'using romers 1986 1987 assumption that physical capital provides a positive externality the contribution goes up to 032', 'using romers 1986 1987 assumption that physical capital provides a positive externality the contribution goes up to 032', 59, 100, 1),
(10146, 75, 'brynjolfsson and hitts 1993 higher estimate for the return on computer capital raises the contribution to 035', 'brynjolfsson and hitts 1993 higher estimate for the return on computer capital raises the contribution to 035', 59, 100, 1),
(10147, 75, 'they also try to incorpo rate alan kruegers 1993 result of return on workers computer use', 'they also try to incorpo rate alan kruegers 1993 result of return on workers computer use', 59, 100, 1),
(10148, 75, 'if the return is equal to the difference in the marginal product between computerusing workers and nonusing workers the contribution is 038', 'if the return is equal to the difference in the marginal product between computerusing workers and nonusing workers the contribution is 038', 59, 100, 1),
(10149, 75, 'oliver and sichel claim that an annual contribution of up to 038 is not large enough to offset the approximately 1 drop in output growth since the 1970 the following rough calculation may provide some intuition about the size of the contribution of computers to national output', 'oliver and sichel claim that an annual contribution of up to 038 is not large enough to offset the approximately 1 drop in output growth since the 1970 the following rough calculation may provide some intuition about the size of the contribution of computers to national output', 59, 100, 1),
(10150, 75, 'from jorgenson and stiroh 1995 we take the simple average contribution for the 197992 period or 045', 'from jorgenson and stiroh 1995 we take the simple average contribution for the 197992 period or 045', 59, 100, 1),
(10151, 75, 'we compare it with the 072 contribution of other capital', 'we compare it with the 072 contribution of other capital', 59, 100, 1),
(10152, 75, 'the share of computers in total capital stock was 16 in 1993 implying that 1 unit of computer capital contributes as much to the growth of output as 98 units of other forms of capital', 'the share of computers in total capital stock was 16 in 1993 implying that 1 unit of computer capital contributes as much to the growth of output as 98 units of other forms of capital', 59, 100, 1),
(10153, 75, 'in 1993 gdp grew by 173 billion23 computers contributed 29 billion other capital contributed 46 billion', 'in 1993 gdp grew by 173 billion23 computers contributed 29 billion other capital contributed 46 billion', 59, 100, 1),
(10154, 75, 'the unexplained residual mfp contribution is 40 billion', 'the unexplained residual mfp contribution is 40 billion', 59, 100, 1),
(10155, 75, '22 however an alternative view is that the glass is halffull jorgenson calls 038 a pretty hefty contribution personal letter feb 7 1995', '22 however an alternative view is that the glass is halffull jorgenson calls 038 a pretty hefty contribution personal letter feb 7 1995', 59, 100, 1),
(10156, 75, '23 survey of current business march 1994 table 11 nominal dollars', '23 survey of current business march 1994 table 11 nominal dollars', 59, 100, 1),
(10157, 75, '24 one of the standard growth accounting assumptions is that factors are paid according to their marginal product', '24 one of the standard growth accounting assumptions is that factors are paid according to their marginal product', 59, 100, 1),
(10158, 75, 'jorgenson and stiroh report 038 growth contribution for the period 198592', 'jorgenson and stiroh report 038 growth contribution for the period 198592', 59, 100, 1),
(10159, 75, 'the 038 is computers nominal income share times computer capitals growth rate', 'the 038 is computers nominal income share times computer capitals growth rate', 59, 100, 1),
(10160, 75, 'by their data we can also estimate computer capitals growth rate during the 198587 period 24', 'by their data we can also estimate computer capitals growth rate during the 198587 period 24', 59, 100, 1),
(10161, 75, 'now computers nominal income share is equal to computers capitals marginal product x computer capitaligdp', 'now computers nominal income share is equal to computers capitals marginal product x computer capitaligdp', 59, 100, 1),
(10162, 75, 'in 1987 computer capital stock amounted to 1 1324 billion and gdp was 45399 trillion thus the implicit marginal product of computers is estimated to 63 038 453991132424', 'in 1987 computer capital stock amounted to 1 1324 billion and gdp was 45399 trillion thus the implicit marginal product of computers is estimated to 63 038 453991132424', 59, 100, 1),
(10163, 75, 'information technology and productivity 205 an interesting growth accounting result', 'information technology and productivity 205 an interesting growth accounting result', 59, 100, 1),
(10164, 75, 'for their sample of firms it capital contributes about 1 per annum to output growtha larger growth contri bution than that of ordinary capital in absolute value', 'for their sample of firms it capital contributes about 1 per annum to output growtha larger growth contri bution than that of ordinary capital in absolute value', 59, 100, 1),
(10165, 75, 'lau and tokutsu 1992 calculate an even bigger contribution to growth attributing approxi mately half of the real output growth 15 growth per annum during the past three decades to computer capital', 'lau and tokutsu 1992 calculate an even bigger contribution to growth attributing approxi mately half of the real output growth 15 growth per annum during the past three decades to computer capital', 59, 100, 1),
(10166, 75, 'they also argue that the annual rate of inflation dropped by 12 per year because of the rapid decline in computer prices', 'they also argue that the annual rate of inflation dropped by 12 per year because of the rapid decline in computer prices', 59, 100, 1),
(10167, 75, 'in line with these studies roy radner suggests that productivity growth has slowed down for other reasons unrelated to the it story', 'in line with these studies roy radner suggests that productivity growth has slowed down for other reasons unrelated to the it story', 59, 100, 1),
(10168, 75, 'without it things would have been worse and output growth would have been lower griliches 1995', 'without it things would have been worse and output growth would have been lower griliches 1995', 59, 100, 1),
(10169, 75, 'in summary the weight of evidence from various studies indicates that information technology capital generates billions of dollars annually for the us economy both in terms of output growth and consumer surplus', 'in summary the weight of evidence from various studies indicates that information technology capital generates billions of dollars annually for the us economy both in terms of output growth and consumer surplus', 59, 100, 1),
(10170, 75, 'meanwhile the recent firmlevel analyses of brynjolfsson and hitt 1993 1995 and lichtenberg 1995 have begun to remedy the shortfall of evi dence regarding the productivity contribution of it', 'meanwhile the recent firmlevel analyses of brynjolfsson and hitt 1993 1995 and lichtenberg 1995 have begun to remedy the shortfall of evi dence regarding the productivity contribution of it', 59, 100, 1),
(10171, 75, 'sections 2 3 4 and 5 reviewed the principal empirical literature on the productivity of information technology', 'sections 2 3 4 and 5 reviewed the principal empirical literature on the productivity of information technology', 59, 100, 1),
(10172, 75, 'looking at the simple relationship between the productivity slowdown of the whole us economy and the rapid growth of computer capital is too general an approach', 'looking at the simple relationship between the productivity slowdown of the whole us economy and the rapid growth of computer capital is too general an approach', 59, 100, 1),
(10173, 75, 'poor data quality for it outputs and inputs has exacerbated this problem', 'poor data quality for it outputs and inputs has exacerbated this problem', 59, 100, 1),
(10174, 75, 'due to the application of improved methodologies and the identification of more reliable and larger data sets researchers have made some progress with industrylevel and firmlevel studies', 'due to the application of improved methodologies and the identification of more reliable and larger data sets researchers have made some progress with industrylevel and firmlevel studies', 59, 100, 1),
(10175, 75, 'recently some researchers have found positive effects of it', 'recently some researchers have found positive effects of it', 59, 100, 1),
(10176, 75, 'careful growth accounting exercises and estimation of production and cost functions for specific sectors or industries can provide sharper insights', 'careful growth accounting exercises and estimation of production and cost functions for specific sectors or industries can provide sharper insights', 59, 100, 1),
(10177, 75, 'consumer surplus analyses are useful exercises for identify ing alternative ways to triangulate it value', 'consumer surplus analyses are useful exercises for identify ing alternative ways to triangulate it value', 59, 100, 1),
(10178, 75, 'these studies suggest that without it the us economy would probably be in a worse situation than it is', 'these studies suggest that without it the us economy would probably be in a worse situation than it is', 59, 100, 1),
(10179, 75, 'this section proposes further research questions and methodologies', 'this section proposes further research questions and methodologies', 59, 100, 1),
(10180, 75, 'the first priority is to improve the data and the measurement techniques', 'the first priority is to improve the data and the measurement techniques', 59, 100, 1),
(10181, 75, 'government statistics especially in services and for information workers have not kept up with the growing importance and complexity of these sectors', 'government statistics especially in services and for information workers have not kept up with the growing importance and complexity of these sectors', 59, 100, 1),
(10182, 75, 'therefore researchers may have to perform their own corrections on the data turn to private sources of secondary data or gather data themselves', 'therefore researchers may have to perform their own corrections on the data turn to private sources of secondary data or gather data themselves', 59, 100, 1),
(10183, 75, 'researchers should make their data available to other research ers so that a cumulative tradition can be maintained', 'researchers should make their data available to other research ers so that a cumulative tradition can be maintained', 59, 100, 1),
(10184, 75, 'the studies of weill 206 erik brynjolfsson and shinkyu yang 1992 dos santos et al', 'the studies of weill 206 erik brynjolfsson and shinkyu yang 1992 dos santos et al', 59, 100, 1),
(10185, 75, '1993 and brynjolfsson and hitt 1993 1995 are examples of new data identification and development', '1993 and brynjolfsson and hitt 1993 1995 are examples of new data identification and development', 59, 100, 1),
(10186, 75, 'one effective way to identify possible gaps in the data is to compare them with the benefits that managers and customers expect from it such as quality timeliness customer service flexibility innovation customiza tion and variety', 'one effective way to identify possible gaps in the data is to compare them with the benefits that managers and customers expect from it such as quality timeliness customer service flexibility innovation customiza tion and variety', 59, 100, 1),
(10187, 75, 'in principle many of these benefits are quantifiable', 'in principle many of these benefits are quantifiable', 59, 100, 1),
(10188, 75, 'in fact some firms already attempt such an analysis in their capital budgeting and justification processes', 'in fact some firms already attempt such an analysis in their capital budgeting and justification processes', 59, 100, 1),
(10189, 75, 'in addition many companies have developed elaborate measurement programs for example as part of total quality management', 'in addition many companies have developed elaborate measurement programs for example as part of total quality management', 59, 100, 1),
(10190, 75, 'these programs augment or even supersede financial ac counting measures and can serve as a foundation for more refined metrics kaplan and norton 1992', 'these programs augment or even supersede financial ac counting measures and can serve as a foundation for more refined metrics kaplan and norton 1992', 59, 100, 1),
(10191, 75, 'many economists also have tried various methods to overcome the short fall of government statistics and to incorporate quality changes when esti mating price indices', 'many economists also have tried various methods to overcome the short fall of government statistics and to incorporate quality changes when esti mating price indices', 59, 100, 1),
(10192, 75, 'the long history of hedonic price index method is a good example but some economists argue that even the hedonic method does not capture all the benefits associated with product innovation and differentiation', 'the long history of hedonic price index method is a good example but some economists argue that even the hedonic method does not capture all the benefits associated with product innovation and differentiation', 59, 100, 1),
(10193, 75, 'unfortunately for many services even basic output measures must be created because government and accounting data records only inputs', 'unfortunately for many services even basic output measures must be created because government and accounting data records only inputs', 59, 100, 1),
(10194, 75, 'baily and gordon 1988 and noyelle 1990 among others have done much to improve measurement in areas such as banking and retailing while rela tively good statistics can be compiled from private sources in areas such as package delivery', 'baily and gordon 1988 and noyelle 1990 among others have done much to improve measurement in areas such as banking and retailing while rela tively good statistics can be compiled from private sources in areas such as package delivery', 59, 100, 1),
(10195, 75, 'unfortunately the individualized nature of many services defies aggregation', 'unfortunately the individualized nature of many services defies aggregation', 59, 100, 1),
(10196, 75, 'the output of a lawyer manager or doctor cannot be extrapolated from the number of meetings attended memoranda written or medications provided', 'the output of a lawyer manager or doctor cannot be extrapolated from the number of meetings attended memoranda written or medications provided', 59, 100, 1),
(10197, 75, 'the complexity of the diagnosticrelated group approach to valuing medical care is both a step in the right direction and a testament to these difficulties', 'the complexity of the diagnosticrelated group approach to valuing medical care is both a step in the right direction and a testament to these difficulties', 59, 100, 1),
(10198, 75, 'a researcher who seeks to measure for the period of 197382 trajtenbergs price deflator for the computed tomography scanner industry averages minus 55 in contrast the hedonic price index shows a 13 decline and government price statistics indicate a 9 increase', 'a researcher who seeks to measure for the period of 197382 trajtenbergs price deflator for the computed tomography scanner industry averages minus 55 in contrast the hedonic price index shows a 13 decline and government price statistics indicate a 9 increase', 59, 100, 1),
(10199, 75, 'empirical evidence for their argument is presented in griliches and cockburn 1994', 'empirical evidence for their argument is presented in griliches and cockburn 1994', 59, 100, 1),
(10200, 75, 'they show that the adjusted price index for the cephalexin drug during the 198791 period dropped by 30 to 53 the official figure records a 14 increase', 'they show that the adjusted price index for the cephalexin drug during the 198791 period dropped by 30 to 53 the official figure records a 14 increase', 59, 100, 1),
(10201, 75, 'information technology and productivity 207 rigorously the productivity of service industries generally must undertake this detailed work before jumping to conclusions based on inputbased statistics', 'information technology and productivity 207 rigorously the productivity of service industries generally must undertake this detailed work before jumping to conclusions based on inputbased statistics', 59, 100, 1),
(10202, 75, 'similarly disaggregating heterogeneous types of it by use as weill 1992 did in a manufacturing study can increase the resolution of standard statistical techniques', 'similarly disaggregating heterogeneous types of it by use as weill 1992 did in a manufacturing study can increase the resolution of standard statistical techniques', 59, 100, 1),
(10203, 75, 'because so many factors affect firm performance it is generally impossi ble to distinguish the impact of it using simple bivariate correlations it is essential to control for other factors such as other inputs and their prices the macroeconomic environment demand schedules for output and the nature of competition', 'because so many factors affect firm performance it is generally impossi ble to distinguish the impact of it using simple bivariate correlations it is essential to control for other factors such as other inputs and their prices the macroeconomic environment demand schedules for output and the nature of competition', 59, 100, 1),
(10204, 75, 'because many unobservable factors affect either the whole industry or one firm persistently examining a panel consisting of both time series and crosssectional data is the best approach where fea sible', 'because many unobservable factors affect either the whole industry or one firm persistently examining a panel consisting of both time series and crosssectional data is the best approach where fea sible', 59, 100, 1),
(10205, 75, 'importantly we must remember that our tools are still blunt', 'importantly we must remember that our tools are still blunt', 59, 100, 1),
(10206, 75, 'managers do not always recognize this and tend to rely too much on any one study of it and productivity', 'managers do not always recognize this and tend to rely too much on any one study of it and productivity', 59, 100, 1),
(10207, 75, 'while the studies usually state the limitations of the data and methods sometimes only the surprising conclusions are re ported by the media', 'while the studies usually state the limitations of the data and methods sometimes only the surprising conclusions are re ported by the media', 59, 100, 1),
(10208, 75, 'because significant investment decisions are based on these conclusion researchers must be doubly careful to communicate the limitations of their work', 'because significant investment decisions are based on these conclusion researchers must be doubly careful to communicate the limitations of their work', 59, 100, 1),
(10209, 75, 'researchers might also look to business for profitable research questions', 'researchers might also look to business for profitable research questions', 59, 100, 1),
(10210, 75, 'diewert and smiths 1994 study makes another interesting point with respect to variety', 'diewert and smiths 1994 study makes another interesting point with respect to variety', 59, 100, 1),
(10211, 75, 'they show that while it facilitates great efficiency in inventory management aggregate inventory level of the us', 'they show that while it facilitates great efficiency in inventory management aggregate inventory level of the us', 59, 100, 1),
(10212, 75, 'economy did not shrink during the past 40 years as reported by blinder and maccini 1991', 'economy did not shrink during the past 40 years as reported by blinder and maccini 1991', 59, 100, 1),
(10213, 75, 'diewert and smith argue that a wide spread prolifera tion of new products into the world economy results in no macrolevel inventory change even when great microlevel improvements have been made', 'diewert and smith argue that a wide spread prolifera tion of new products into the world economy results in no macrolevel inventory change even when great microlevel improvements have been made', 59, 100, 1),
(10214, 75, 'the stock prices of major it vendors appeared to change significantly in response to a wall street journal article on it productivity dos santos et al 1991', 'the stock prices of major it vendors appeared to change significantly in response to a wall street journal article on it productivity dos santos et al 1991', 59, 100, 1),
(10215, 75, 'cecil and hall 1988 davenport lyy3 hammer and champy 19y3 malone and rockart 1991 porter and miller 1985 and watts 1986', 'cecil and hall 1988 davenport lyy3 hammer and champy 19y3 malone and rockart 1991 porter and miller 1985 and watts 1986', 59, 100, 1),
(10216, 75, '208 erik brynjolfsson and shinkyu yang this literature highlights how difficult and perhaps inappropriate it would be to translate some of the benefits of information technology into quantifi able productivity measures of output', '208 erik brynjolfsson and shinkyu yang this literature highlights how difficult and perhaps inappropriate it would be to tr', 59, 71.4296, 1),
(11036, 79, 'the primary aim of this paper is to use simulations to tackle the prob lem of pricing quanto options on two and three underlying assets under stochastic correlation and volatility driven by different stochastic differential equations sdes', 'the primary aim of this paper is to use simulations to tackle the prob lem of pricing quanto options on two and three underlying assets under stochastic correlation and volatility driven by different stochastic differential equations sdes', 18, 100, 1),
(11037, 79, 'the following models are tested and compared hes ton garch garchjump 32 diffusion and bates for volatility and jacobi wrightfisher diffusion weibull diffusion and a meanreverting sc for correlation', 'the following models are tested and compared hes ton garch garchjump 32 diffusion and bates for volatility and jacobi wrightfisher diffusion weibull diffusion and a meanreverting sc for correlation', 18, 100, 1),
(11038, 79, 'the study is focused specifically on quanto options on two or three foreign equity market indices', 'the study is focused specifically on quanto options on two or three foreign equity market indices', 18, 100, 1),
(11039, 79, 'these options act like a basket cor relation option with the payoff depending on multiple correlated assets but also on exchange rates between the currencies of the indices', 'these options act like a basket cor relation option with the payoff depending on multiple correlated assets but also on exchange rates between the currencies of the indices', 18, 100, 1),
(11040, 79, 'we test three different models of exchange rate dynamics with both rates being either gbm a mean reverting sde inspired by the ou process or an exponential levy process that incorporates jumps', 'we test three different models of exchange rate dynamics with both rates being either gbm a mean reverting sde inspired by the ou process or an exponential levy process that incorporates jumps', 18, 100, 1),
(11041, 79, 'applications to watersolvated systems demonstrate that this approach achieves unprecedented very rapid convergence to chemical accuracy as the size of the qm subsystem increases', 'applications to watersolvated systems demonstrate that this approach achieves unprecedented very rapid convergence to chemical accuracy as the size of the qm subsystem increases', 31, 100, 1),
(11042, 79, 'applications to watersolvated systems demonstrate that this approach achieves unprecedented very rapid convergence to chemical accuracy as the size of the qm subsystem increases', 'applications to watersolvated systems demonstrate that this approach achieves unprecedented very rapid convergence to chemical accuracy as the size of the qm subsystem increases', 67, 100, 1),
(11043, 79, 'we validate the method with several pilot studies including water bulk water clusters prism hexamer and pentamers solvated glucose a palladium aqua ion and a wet monolayer of mos', 'we validate the method with several pilot studies including water bulk water clusters prism hexamer and pentamers solvated glucose a palladium aqua ion and a wet monolayer of mos 2', 31, 98.9981, 1),
(11044, 79, 'we validate the method with several pilot studies including water bulk water clusters prism hexamer and pentamers solvated glucose a palladium aqua ion and a wet monolayer of mos', 'we validate the method with several pilot studies including water bulk water clusters prism hexamer and pentamers solvated glucose a palladium aqua ion and a wet monolayer of mos 2', 67, 98.9981, 1);

-- --------------------------------------------------------

--
-- Table structure for table `plagiarism_summary`
--

CREATE TABLE `plagiarism_summary` (
  `id` int(11) NOT NULL,
  `archive_id` int(11) NOT NULL,
  `similar_archive_id` int(11) NOT NULL,
  `plagiarism_percentage` float NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `plagiarism_summary`
--

INSERT INTO `plagiarism_summary` (`id`, `archive_id`, `similar_archive_id`, `plagiarism_percentage`) VALUES
(314, 62, 15, 0.176361),
(337, 73, 55, 110.197),
(339, 75, 59, 100.798),
(349, 79, 18, 1.55763),
(350, 79, 31, 0.610424),
(351, 79, 67, 0.610424);

-- --------------------------------------------------------

--
-- Table structure for table `roles`
--

CREATE TABLE `roles` (
  `id` int(11) NOT NULL,
  `role_name` varchar(255) NOT NULL,
  `description` text DEFAULT NULL,
  `department_id` int(11) DEFAULT NULL,
  `permissions` text DEFAULT NULL,
  `role_status` varchar(12) NOT NULL DEFAULT 'Active',
  `created_at` timestamp NOT NULL DEFAULT current_timestamp(),
  `delete_flag` tinyint(1) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `roles`
--

INSERT INTO `roles` (`id`, `role_name`, `description`, `department_id`, `permissions`, `role_status`, `created_at`, `delete_flag`) VALUES
(1, 'SUPER ADMIN', 'SUPER ADMIN', 0, 'research_paper:0,research_view:0,research_add:0,research_edit:0,research_delete:0,research_publish:0,research_download:0,student_list:1,student_list_view:0,student_list_edit:0,student_list_delete:0,student_list_status:0,student_list_download:0,dashboard:1,dashboard_view:1,dashboard_download:1,department:1,department_view:1,department_add:1,department_edit:1,department_delete:1,department_status:1,department_download:1,course:1,course_view:1,course_add:1,course_edit:1,course_delete:1,course_status:1,course_download:1,role:1,role_view:1,role_add:1,role_edit:1,role_delete:1,role_download:1,user:1,user_view:1,user_add:1,user_edit:1,user_delete:1,user_status:1,user_download:1', 'Active', '2024-12-03 18:19:24', 0),
(2, 'CCS', 'Description', 12, 'research_paper:12,research_view:12,research_edit:12,research_delete:12,research_publish:12,research_unpublish:12,research_print:12,student_list:1,student_list_view:12,student_list_edit:12,student_list_delete:12', 'Active', '2024-12-03 16:55:08', 0),
(3, 'CAS', 'Description', 1, 'course:1,course_view:1,course_edit:1,course_delete:1', 'Active', '2024-12-03 15:31:22', 0),
(6, 'DEPARTMENT', 'DEPARTMENT ACCESS', 0, 'department:1,department_view:1,department_add:1,department_edit:1,department_delete:1,department_status:1,department_download:1', 'Active', '2024-12-04 07:51:34', 0);

-- --------------------------------------------------------

--
-- Table structure for table `students_data`
--

CREATE TABLE `students_data` (
  `id` int(11) NOT NULL,
  `department_id` int(11) NOT NULL,
  `course_id` int(11) NOT NULL,
  `student_id` varchar(20) NOT NULL,
  `first_name` varchar(70) NOT NULL,
  `middle_name` varchar(70) NOT NULL,
  `last_name` varchar(70) NOT NULL,
  `phone_number` varchar(15) NOT NULL,
  `student_email` varchar(200) NOT NULL,
  `student_password` varchar(200) NOT NULL,
  `profile_picture` varchar(200) DEFAULT NULL,
  `verification_code` int(8) NOT NULL,
  `verify_status` varchar(80) NOT NULL DEFAULT 'Not Verified',
  `school_verify` varchar(100) NOT NULL DEFAULT 'For Approval'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `students_data`
--

INSERT INTO `students_data` (`id`, `department_id`, `course_id`, `student_id`, `first_name`, `middle_name`, `last_name`, `phone_number`, `student_email`, `student_password`, `profile_picture`, `verification_code`, `verify_status`, `school_verify`) VALUES
(51, 12, 1, '214-01312M', 'Rolly', '', 'Raytos', '09123123123', 'raytos.r.bsinfotech@gmail.com', '52c22378cc6a55621dc67fd2022153fe', NULL, 230127, 'Verified', 'Approved'),
(52, 12, 1, '214-01313M', 'Roy', '', 'Raytos', '09123123123', 'raytos.bsinfotech@gmail.com', '52c22378cc6a55621dc67fd2022153fe', '../imageFiles/674e8dfa56862-aiahhhhh.jpg', 683207, 'Verified', 'Approved');

-- --------------------------------------------------------

--
-- Table structure for table `student_download_logs`
--

CREATE TABLE `student_download_logs` (
  `id` int(11) NOT NULL,
  `student_id` int(11) NOT NULL,
  `archive_id` varchar(13) NOT NULL,
  `download_date` datetime NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `student_download_logs`
--

INSERT INTO `student_download_logs` (`id`, `student_id`, `archive_id`, `download_date`) VALUES
(1, 1, '4549105180', '2024-11-30 15:03:21'),
(2, 1, '4549105180', '2024-11-30 15:10:25'),
(3, 37, '7281507465', '2024-12-01 21:51:58'),
(4, 50, '7281507465', '2024-12-02 23:36:44');

-- --------------------------------------------------------

--
-- Table structure for table `system_notification`
--

CREATE TABLE `system_notification` (
  `id` int(11) NOT NULL,
  `student_id` int(12) NOT NULL,
  `logs` varchar(200) NOT NULL,
  `logs_date` varchar(50) NOT NULL,
  `logs_time` varchar(50) NOT NULL,
  `status` varchar(100) NOT NULL DEFAULT 'Unread'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `system_notification`
--

INSERT INTO `system_notification` (`id`, `student_id`, `logs`, `logs_date`, `logs_time`, `status`) VALUES
(1, 1, 'You successfully updated your information.', 'November / 27 Wednesday / 2024', '5:13 PM', 'Read'),
(2, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '5:13 PM', 'Read'),
(3, 1, 'You successfully submitted your research paper.', 'November / 27 Wednesday / 2024', '5:21 PM', 'Read'),
(4, 1, 'You successfully logged out to your account.', 'November / 27 Wednesday / 2024', '5:25 PM', 'Read'),
(5, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '5:25 PM', 'Read'),
(6, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '5:27 PM', 'Read'),
(7, 1, 'You successfully submitted your research paper.', 'November / 27 Wednesday / 2024', '5:30 PM', 'Read'),
(8, 1, 'You successfully submitted your research paper.', 'November / 27 Wednesday / 2024', '5:33 PM', 'Read'),
(9, 1, 'You successfully logged out to your account.', 'November / 27 Wednesday / 2024', '5:33 PM', 'Read'),
(10, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '8:02 PM', 'Read'),
(11, 1, 'You successfully logged out to your account.', 'November / 27 Wednesday / 2024', '8:03 PM', 'Read'),
(12, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '9:39 PM', 'Read'),
(13, 1, 'You successfully logged out to your account.', 'November / 27 Wednesday / 2024', '9:42 PM', 'Read'),
(14, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '9:43 PM', 'Read'),
(15, 1, 'You successfully logged out to your account.', 'November / 27 Wednesday / 2024', '10:20 PM', 'Read'),
(16, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '10:21 PM', 'Read'),
(17, 1, 'You successfully logged out to your account.', 'November / 27 Wednesday / 2024', '10:28 PM', 'Read'),
(18, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '10:38 PM', 'Read'),
(19, 1, 'You successfully logged in to your account.', 'November / 27 Wednesday / 2024', '11:02 PM', 'Read'),
(20, 1, 'You successfully submitted your research paper.', 'November / 27 Wednesday / 2024', '11:09 PM', 'Read'),
(21, 1, 'You successfully logged in to your account.', 'November / 28 Thursday / 2024', '3:31 PM', 'Read'),
(22, 1, 'You successfully logged out to your account.', 'November / 28 Thursday / 2024', '4:14 PM', 'Read'),
(23, 1, 'You successfully logged in to your account.', 'November / 28 Thursday / 2024', '4:16 PM', 'Read'),
(24, 1, 'You successfully logged in to your account.', 'November / 28 Thursday / 2024', '4:50 PM', 'Read'),
(25, 26, 'You successfully logged in to your account.', 'November / 28 Thursday / 2024', '4:55 PM', 'Unread'),
(26, 26, 'You successfully submitted your research paper.', 'November / 28 Thursday / 2024', '4:56 PM', 'Unread'),
(27, 26, 'You successfully submitted your research paper.', 'November / 28 Thursday / 2024', '5:01 PM', 'Unread'),
(28, 1, 'You successfully logged in to your account.', 'November / 28 Thursday / 2024', '5:04 PM', 'Read'),
(29, 1, 'You successfully logged out to your account.', 'November / 28 Thursday / 2024', '5:05 PM', 'Read'),
(30, 1, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '5:00 PM', 'Read'),
(31, 1, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '5:03 PM', 'Read'),
(32, 32, 'You successfully submitted your research paper.', 'November / 29 Friday / 2024', '5:34 PM', 'Read'),
(33, 32, 'You successfully submitted your research paper.', 'November / 29 Friday / 2024', '5:38 PM', 'Unread'),
(34, 32, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '5:39 PM', 'Unread'),
(35, 32, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '5:48 PM', 'Unread'),
(36, 32, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '5:48 PM', 'Unread'),
(37, 32, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '5:48 PM', 'Unread'),
(38, 32, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '5:49 PM', 'Unread'),
(39, 1, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '8:48 PM', 'Read'),
(40, 1, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '8:48 PM', 'Read'),
(41, 34, 'You successfully submitted your research paper.', 'November / 29 Friday / 2024', '9:12 PM', 'Read'),
(42, 34, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '9:16 PM', 'Unread'),
(43, 1, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '9:16 PM', 'Read'),
(44, 1, 'You successfully submitted your research paper.', 'November / 29 Friday / 2024', '9:16 PM', 'Read'),
(45, 1, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '9:18 PM', 'Read'),
(46, 1, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '9:18 PM', 'Read'),
(47, 1, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '9:18 PM', 'Read'),
(48, 34, 'You successfully recover your account.', 'November / 29 Friday / 2024', '9:20 PM', 'Unread'),
(49, 34, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '9:21 PM', 'Unread'),
(50, 1, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '9:22 PM', 'Read'),
(51, 1, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '9:23 PM', 'Read'),
(52, 35, 'You successfully submitted your research paper.', 'November / 29 Friday / 2024', '9:41 PM', 'Read'),
(53, 35, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '9:43 PM', 'Unread'),
(54, 35, 'You successfully recover your account.', 'November / 29 Friday / 2024', '9:45 PM', 'Unread'),
(55, 35, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '9:45 PM', 'Unread'),
(56, 36, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '10:07 PM', 'Read'),
(57, 36, 'You successfully logged in to your account.', 'November / 29 Friday / 2024', '10:08 PM', 'Read'),
(58, 36, 'You successfully logged out to your account.', 'November / 29 Friday / 2024', '10:10 PM', 'Unread'),
(59, 1, 'You successfully logged in to your account.', 'November / 30 Saturday / 2024', '2:40 PM', 'Read'),
(60, 1, 'You successfully logged out to your account.', 'November / 30 Saturday / 2024', '2:48 PM', 'Read'),
(61, 1, 'You successfully logged in to your account.', 'November / 30 Saturday / 2024', '2:48 PM', 'Read'),
(62, 1, 'You downloaded a PDF file.', 'November / 30 Saturday / 2024', '3:10 PM', 'Read'),
(63, 1, 'You successfully logged out to your account.', 'November / 30 Saturday / 2024', '3:34 PM', 'Read'),
(64, 1, 'You logged in.', 'November / 30 Saturday / 2024', '6:14 PM', 'Read'),
(65, 1, 'You logged out.', 'November / 30 Saturday / 2024', '6:25 PM', 'Read'),
(66, 1, 'You logged in.', 'November / 30 Saturday / 2024', '8:54 PM', 'Read'),
(67, 1, 'You logged out.', 'November / 30 Saturday / 2024', '8:55 PM', 'Read'),
(68, 1, 'You logged in.', 'November / 30 Saturday / 2024', '8:58 PM', 'Read'),
(69, 1, 'You logged out.', 'November / 30 Saturday / 2024', '9:11 PM', 'Read'),
(70, 1, 'You logged in.', 'November / 30 Saturday / 2024', '9:26 PM', 'Read'),
(71, 1, 'You logged in.', 'December / 01 Sunday / 2024', '12:12 AM', 'Read'),
(72, 1, 'You logged out.', 'December / 01 Sunday / 2024', '12:18 AM', 'Read'),
(73, 1, 'You logged in.', 'December / 01 Sunday / 2024', '12:43 AM', 'Read'),
(74, 1, 'You logged in.', 'December / 01 Sunday / 2024', '1:24 PM', 'Read'),
(75, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '1:33 PM', 'Read'),
(76, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '1:34 PM', 'Read'),
(77, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '1:35 PM', 'Read'),
(78, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '1:39 PM', 'Read'),
(79, 1, 'You logged in.', 'December / 01 Sunday / 2024', '1:43 PM', 'Read'),
(80, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '1:51 PM', 'Read'),
(81, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '1:59 PM', 'Read'),
(82, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '2:05 PM', 'Read'),
(83, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '2:07 PM', 'Read'),
(84, 1, 'You logged in.', 'December / 01 Sunday / 2024', '2:32 PM', 'Read'),
(85, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '2:33 PM', 'Read'),
(86, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '2:35 PM', 'Read'),
(87, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '2:36 PM', 'Read'),
(88, 1, 'You logged out.', 'December / 01 Sunday / 2024', '2:38 PM', 'Read'),
(89, 1, 'You logged in.', 'December / 01 Sunday / 2024', '8:09 PM', 'Read'),
(90, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '8:10 PM', 'Read'),
(91, 1, 'You logged out.', 'December / 01 Sunday / 2024', '8:10 PM', 'Read'),
(92, 1, 'You logged in.', 'December / 01 Sunday / 2024', '8:49 PM', 'Read'),
(93, 1, 'You logged in.', 'December / 01 Sunday / 2024', '8:53 PM', 'Read'),
(94, 1, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '8:53 PM', 'Read'),
(95, 1, 'You logged out.', 'December / 01 Sunday / 2024', '8:53 PM', 'Read'),
(96, 1, 'You logged in.', 'December / 01 Sunday / 2024', '8:58 PM', 'Read'),
(97, 1, 'You logged in.', 'December / 01 Sunday / 2024', '8:59 PM', 'Read'),
(98, 1, 'You logged out.', 'December / 01 Sunday / 2024', '9:07 PM', 'Read'),
(99, 37, 'You downloaded a PDF file.', 'December / 01 Sunday / 2024', '9:51 PM', 'Read'),
(100, 37, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '9:55 PM', 'Read'),
(101, 37, 'You successfully submitted your research paper.', 'December / 01 Sunday / 2024', '10:06 PM', 'Read'),
(102, 37, 'You logged out.', 'December / 01 Sunday / 2024', '10:16 PM', 'Read'),
(103, 37, 'You successfully recover your account.', 'December / 01 Sunday / 2024', '10:20 PM', 'Read'),
(104, 37, 'You logged out.', 'December / 01 Sunday / 2024', '10:21 PM', 'Unread'),
(105, 1, 'You logged in.', 'December / 02 Monday / 2024', '12:24 PM', 'Read'),
(106, 1, 'You logged out.', 'December / 02 Monday / 2024', '12:24 PM', 'Read'),
(107, 1, 'You logged in.', 'December / 02 Monday / 2024', '12:25 PM', 'Read'),
(108, 1, 'You logged out.', 'December / 02 Monday / 2024', '12:25 PM', 'Read'),
(109, 1, 'You logged in.', 'December / 02 Monday / 2024', '12:25 PM', 'Read'),
(110, 1, 'You logged out.', 'December / 02 Monday / 2024', '12:25 PM', 'Read'),
(111, 1, 'You logged in.', 'December / 02 Monday / 2024', '12:26 PM', 'Read'),
(112, 1, 'You logged out.', 'December / 02 Monday / 2024', '12:28 PM', 'Read'),
(113, 1, 'You successfully recover your account.', 'December / 02 Monday / 2024', '1:14 PM', 'Read'),
(114, 1, 'You logged out.', 'December / 02 Monday / 2024', '1:15 PM', 'Read'),
(115, 1, 'You successfully recover your account.', 'December / 02 Monday / 2024', '1:16 PM', 'Read'),
(116, 1, 'You logged out.', 'December / 02 Monday / 2024', '1:18 PM', 'Read'),
(117, 1, 'You successfully recover your account.', 'December / 02 Monday / 2024', '1:18 PM', 'Read'),
(118, 1, 'You logged out.', 'December / 02 Monday / 2024', '1:24 PM', 'Read'),
(119, 1, 'You successfully recover your account.', 'December / 02 Monday / 2024', '1:26 PM', 'Read'),
(120, 1, 'You logged out.', 'December / 02 Monday / 2024', '1:28 PM', 'Read'),
(121, 1, 'You successfully recover your account.', 'December / 02 Monday / 2024', '1:44 PM', 'Read'),
(122, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '1:55 PM', 'Read'),
(123, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:02 PM', 'Read'),
(124, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:07 PM', 'Read'),
(125, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:09 PM', 'Read'),
(126, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:11 PM', 'Read'),
(127, 1, 'You logged out.', 'December / 02 Monday / 2024', '2:11 PM', 'Read'),
(128, 1, 'You logged in.', 'December / 02 Monday / 2024', '2:21 PM', 'Read'),
(129, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:22 PM', 'Read'),
(130, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:24 PM', 'Read'),
(131, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:25 PM', 'Read'),
(132, 1, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '2:27 PM', 'Read'),
(133, 1, 'You logged out.', 'December / 02 Monday / 2024', '2:46 PM', 'Read'),
(134, 38, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '4:26 PM', 'Unread'),
(135, 38, 'You successfully updated your password.', 'December / 02 Monday / 2024', '4:28 PM', 'Unread'),
(136, 38, 'You logged out.', 'December / 02 Monday / 2024', '4:29 PM', 'Unread'),
(137, 38, 'You successfully recover your account.', 'December / 02 Monday / 2024', '4:30 PM', 'Unread'),
(138, 38, 'You logged out.', 'December / 02 Monday / 2024', '4:30 PM', 'Unread'),
(139, 39, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '4:54 PM', 'Unread'),
(140, 39, 'You successfully updated your password.', 'December / 02 Monday / 2024', '4:56 PM', 'Unread'),
(141, 39, 'You logged out.', 'December / 02 Monday / 2024', '4:56 PM', 'Unread'),
(142, 39, 'You successfully recover your account.', 'December / 02 Monday / 2024', '4:57 PM', 'Unread'),
(143, 39, 'You logged out.', 'December / 02 Monday / 2024', '4:58 PM', 'Unread'),
(144, 40, 'You logged out.', 'December / 02 Monday / 2024', '5:00 PM', 'Unread'),
(145, 41, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '5:03 PM', 'Read'),
(146, 41, 'You successfully updated your password.', 'December / 02 Monday / 2024', '5:04 PM', 'Read'),
(147, 41, 'You logged out.', 'December / 02 Monday / 2024', '5:05 PM', 'Read'),
(148, 41, 'You successfully recover your account.', 'December / 02 Monday / 2024', '5:06 PM', 'Read'),
(149, 41, 'You logged out.', 'December / 02 Monday / 2024', '5:06 PM', 'Unread'),
(150, 46, 'You logged out.', 'December / 02 Monday / 2024', '9:42 PM', 'Unread'),
(151, 1, 'You logged in.', 'December / 02 Monday / 2024', '9:56 PM', 'Read'),
(152, 1, 'You logged out.', 'December / 02 Monday / 2024', '9:56 PM', 'Read'),
(153, 1, 'You logged in.', 'December / 02 Monday / 2024', '9:56 PM', 'Read'),
(154, 1, 'You logged out.', 'December / 02 Monday / 2024', '9:58 PM', 'Read'),
(155, 1, 'You logged in.', 'December / 02 Monday / 2024', '9:58 PM', 'Read'),
(156, 1, 'You logged out.', 'December / 02 Monday / 2024', '9:58 PM', 'Read'),
(157, 1, 'You logged in.', 'December / 02 Monday / 2024', '9:58 PM', 'Read'),
(158, 1, 'You logged out.', 'December / 02 Monday / 2024', '9:58 PM', 'Read'),
(159, 1, 'You logged in.', 'December / 02 Monday / 2024', '9:59 PM', 'Read'),
(160, 1, 'You logged in.', 'December / 02 Monday / 2024', '9:59 PM', 'Read'),
(161, 1, 'You logged in.', 'December / 02 Monday / 2024', '9:59 PM', 'Read'),
(162, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:00 PM', 'Read'),
(163, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:00 PM', 'Read'),
(164, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:01 PM', 'Read'),
(165, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:01 PM', 'Read'),
(166, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:01 PM', 'Read'),
(167, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:01 PM', 'Read'),
(168, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:01 PM', 'Read'),
(169, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:01 PM', 'Read'),
(170, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:02 PM', 'Read'),
(171, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:04 PM', 'Read'),
(172, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:10 PM', 'Read'),
(173, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:11 PM', 'Read'),
(174, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:31 PM', 'Read'),
(175, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:32 PM', 'Read'),
(176, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:37 PM', 'Read'),
(177, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:38 PM', 'Unread'),
(178, 1, 'You logged in.', 'December / 02 Monday / 2024', '10:45 PM', 'Unread'),
(179, 1, 'You logged out.', 'December / 02 Monday / 2024', '10:46 PM', 'Unread'),
(180, 47, 'You successfully registered an account.', 'December / 02 Monday / 2024', '11:08 PM', 'Unread'),
(181, 47, 'You logged out.', 'December / 02 Monday / 2024', '11:09 PM', 'Unread'),
(182, 48, 'You successfully registered an account.', 'December / 02 Monday / 2024', '11:11 PM', 'Read'),
(183, 48, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '11:13 PM', 'Read'),
(184, 48, 'Profile picture updated successfully.', 'December / 02 Monday / 2024', '11:14 PM', 'Read'),
(185, 48, 'You successfully updated your password.', 'December / 02 Monday / 2024', '11:14 PM', 'Read'),
(186, 48, 'You logged out.', 'December / 02 Monday / 2024', '11:15 PM', 'Read'),
(187, 48, 'You successfully recover your account.', 'December / 02 Monday / 2024', '11:15 PM', 'Read'),
(188, 48, 'You logged out.', 'December / 02 Monday / 2024', '11:16 PM', 'Unread'),
(189, 49, 'You successfully registered an account.', 'December / 02 Monday / 2024', '11:21 PM', 'Read'),
(190, 49, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '11:23 PM', 'Read'),
(191, 49, 'Profile picture updated successfully.', 'December / 02 Monday / 2024', '11:24 PM', 'Read'),
(192, 49, 'You successfully updated your password.', 'December / 02 Monday / 2024', '11:24 PM', 'Read'),
(193, 49, 'You logged out.', 'December / 02 Monday / 2024', '11:24 PM', 'Read'),
(194, 49, 'You successfully recover your account.', 'December / 02 Monday / 2024', '11:25 PM', 'Read'),
(195, 49, 'You logged out.', 'December / 02 Monday / 2024', '11:25 PM', 'Unread'),
(196, 50, 'You successfully registered an account.', 'December / 02 Monday / 2024', '11:36 PM', 'Read'),
(197, 50, 'You downloaded a PDF file.', 'December / 02 Monday / 2024', '11:36 PM', 'Read'),
(198, 50, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '11:38 PM', 'Read'),
(199, 50, 'You successfully submitted your research paper.', 'December / 02 Monday / 2024', '11:39 PM', 'Read'),
(200, 50, 'Profile picture updated successfully.', 'December / 02 Monday / 2024', '11:40 PM', 'Read'),
(201, 50, 'You successfully updated your password.', 'December / 02 Monday / 2024', '11:42 PM', 'Read'),
(202, 50, 'You logged out.', 'December / 02 Monday / 2024', '11:42 PM', 'Read'),
(203, 50, 'You successfully recover your account.', 'December / 02 Monday / 2024', '11:43 PM', 'Read'),
(204, 50, 'You logged out.', 'December / 02 Monday / 2024', '11:44 PM', 'Unread'),
(205, 1, 'You successfully updated your information.', 'December / 03 Tuesday / 2024', '12:52 AM', 'Unread'),
(206, 1, 'You logged in.', 'December / 03 Tuesday / 2024', '10:01 AM', 'Unread'),
(207, 51, 'You successfully registered an account.', 'December / 03 Tuesday / 2024', '12:40 PM', 'Read'),
(208, 51, 'You logged out.', 'December / 03 Tuesday / 2024', '12:43 PM', 'Read'),
(209, 52, 'You successfully registered an account.', 'December / 03 Tuesday / 2024', '12:47 PM', 'Read'),
(210, 52, 'You successfully submitted your research paper.', 'December / 03 Tuesday / 2024', '12:48 PM', 'Read'),
(211, 52, 'Profile picture updated successfully.', 'December / 03 Tuesday / 2024', '12:50 PM', 'Read'),
(212, 52, 'You successfully updated your password.', 'December / 03 Tuesday / 2024', '12:50 PM', 'Read'),
(213, 52, 'You logged out.', 'December / 03 Tuesday / 2024', '12:50 PM', 'Read'),
(214, 52, 'You successfully recover your account.', 'December / 03 Tuesday / 2024', '12:51 PM', 'Read'),
(215, 52, 'You logged out.', 'December / 03 Tuesday / 2024', '12:51 PM', 'Read'),
(216, 52, 'You logged in.', 'December / 03 Tuesday / 2024', '1:04 PM', 'Read'),
(217, 52, 'You successfully submitted your research paper.', 'December / 03 Tuesday / 2024', '1:04 PM', 'Read'),
(218, 52, 'You logged out.', 'December / 03 Tuesday / 2024', '1:04 PM', 'Unread'),
(219, 51, 'You logged in.', 'December / 03 Tuesday / 2024', '6:32 PM', 'Read'),
(220, 51, 'You successfully submitted your research paper.', 'December / 03 Tuesday / 2024', '6:39 PM', 'Read'),
(221, 51, 'You logged in.', 'December / 04 Wednesday / 2024', '3:38 PM', 'Read');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `admin_account`
--
ALTER TABLE `admin_account`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `admin_download_logs`
--
ALTER TABLE `admin_download_logs`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `admin_systemnotification`
--
ALTER TABLE `admin_systemnotification`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `archive_research`
--
ALTER TABLE `archive_research`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `archive_research_views`
--
ALTER TABLE `archive_research_views`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `course`
--
ALTER TABLE `course`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `departments`
--
ALTER TABLE `departments`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `plagiarism_results`
--
ALTER TABLE `plagiarism_results`
  ADD PRIMARY KEY (`id`),
  ADD KEY `archive_id` (`archive_id`),
  ADD KEY `similar_archive_id` (`similar_archive_id`);

--
-- Indexes for table `plagiarism_summary`
--
ALTER TABLE `plagiarism_summary`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `roles`
--
ALTER TABLE `roles`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `students_data`
--
ALTER TABLE `students_data`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `student_download_logs`
--
ALTER TABLE `student_download_logs`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `system_notification`
--
ALTER TABLE `system_notification`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `admin_account`
--
ALTER TABLE `admin_account`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=13;

--
-- AUTO_INCREMENT for table `admin_download_logs`
--
ALTER TABLE `admin_download_logs`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=12;

--
-- AUTO_INCREMENT for table `admin_systemnotification`
--
ALTER TABLE `admin_systemnotification`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=475;

--
-- AUTO_INCREMENT for table `archive_research`
--
ALTER TABLE `archive_research`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=80;

--
-- AUTO_INCREMENT for table `archive_research_views`
--
ALTER TABLE `archive_research_views`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=103;

--
-- AUTO_INCREMENT for table `course`
--
ALTER TABLE `course`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=33;

--
-- AUTO_INCREMENT for table `departments`
--
ALTER TABLE `departments`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=19;

--
-- AUTO_INCREMENT for table `plagiarism_results`
--
ALTER TABLE `plagiarism_results`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=11045;

--
-- AUTO_INCREMENT for table `plagiarism_summary`
--
ALTER TABLE `plagiarism_summary`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=352;

--
-- AUTO_INCREMENT for table `roles`
--
ALTER TABLE `roles`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=7;

--
-- AUTO_INCREMENT for table `students_data`
--
ALTER TABLE `students_data`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=53;

--
-- AUTO_INCREMENT for table `student_download_logs`
--
ALTER TABLE `student_download_logs`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=5;

--
-- AUTO_INCREMENT for table `system_notification`
--
ALTER TABLE `system_notification`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=222;

--
-- Constraints for dumped tables
--

--
-- Constraints for table `plagiarism_results`
--
ALTER TABLE `plagiarism_results`
  ADD CONSTRAINT `plagiarism_results_ibfk_1` FOREIGN KEY (`archive_id`) REFERENCES `archive_research` (`id`),
  ADD CONSTRAINT `plagiarism_results_ibfk_2` FOREIGN KEY (`similar_archive_id`) REFERENCES `archive_research` (`id`);
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
